//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-21373419
// Cuda compilation tools, release 8.0, V8.0.55
// Based on LLVM 3.4svn
//

.version 5.0
.target sm_30
.address_size 64

	// .globl	convolute_double

.visible .entry convolute_double(
	.param .u64 convolute_double_param_0,
	.param .u64 convolute_double_param_1,
	.param .u32 convolute_double_param_2,
	.param .u32 convolute_double_param_3,
	.param .u32 convolute_double_param_4,
	.param .u32 convolute_double_param_5,
	.param .u32 convolute_double_param_6,
	.param .u32 convolute_double_param_7,
	.param .u32 convolute_double_param_8,
	.param .u32 convolute_double_param_9,
	.param .u32 convolute_double_param_10,
	.param .u32 convolute_double_param_11,
	.param .u32 convolute_double_param_12,
	.param .u32 convolute_double_param_13
)
{
	.reg .pred 	%p<18>;
	.reg .b32 	%r<61>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd2, [convolute_double_param_0];
	ld.param.u64 	%rd3, [convolute_double_param_1];
	ld.param.u32 	%r12, [convolute_double_param_2];
	ld.param.u32 	%r13, [convolute_double_param_3];
	ld.param.u32 	%r14, [convolute_double_param_4];
	ld.param.u32 	%r15, [convolute_double_param_5];
	ld.param.u32 	%r16, [convolute_double_param_6];
	ld.param.u32 	%r23, [convolute_double_param_7];
	ld.param.u32 	%r17, [convolute_double_param_8];
	ld.param.u32 	%r18, [convolute_double_param_9];
	ld.param.u32 	%r19, [convolute_double_param_10];
	ld.param.u32 	%r20, [convolute_double_param_11];
	ld.param.u32 	%r21, [convolute_double_param_12];
	ld.param.u32 	%r22, [convolute_double_param_13];
	mov.u32 	%r24, %ntid.x;
	mov.u32 	%r25, %ctaid.x;
	mov.u32 	%r26, %tid.x;
	mad.lo.s32 	%r27, %r24, %r25, %r26;
	mov.u32 	%r28, %ntid.y;
	mov.u32 	%r29, %ctaid.y;
	mov.u32 	%r30, %tid.y;
	mad.lo.s32 	%r1, %r28, %r29, %r30;
	mov.u32 	%r31, %ntid.z;
	mov.u32 	%r32, %ctaid.z;
	mov.u32 	%r33, %tid.z;
	mad.lo.s32 	%r2, %r31, %r32, %r33;
	mul.lo.s32 	%r34, %r23, %r14;
	setp.lt.s32	%p2, %r27, %r34;
	setp.lt.s32	%p3, %r1, %r15;
	and.pred  	%p4, %p2, %p3;
	setp.lt.s32	%p5, %r2, %r16;
	and.pred  	%p6, %p4, %p5;
	setp.gt.s32	%p7, %r17, 0;
	and.pred  	%p8, %p6, %p7;
	@!%p8 bra 	BB0_8;
	bra.uni 	BB0_1;

BB0_1:
	cvta.to.global.u64 	%rd1, %rd3;
	mul.lo.s32 	%r3, %r1, %r20;
	add.s32 	%r4, %r22, %r13;
	mov.u32 	%r59, 0;
	cvta.to.global.u64 	%rd4, %rd2;

BB0_2:
	setp.lt.s32	%p9, %r18, 1;
	@%p9 bra 	BB0_7;

	rem.s32 	%r41, %r27, %r14;
	div.s32 	%r42, %r27, %r14;
	mad.lo.s32 	%r43, %r41, %r19, %r59;
	add.s32 	%r44, %r21, %r12;
	setp.lt.s32	%p10, %r43, %r44;
	setp.ge.s32	%p11, %r43, %r21;
	and.pred  	%p1, %p10, %p11;
	sub.s32 	%r45, %r43, %r21;
	mad.lo.s32 	%r46, %r42, %r12, %r45;
	mul.lo.s32 	%r6, %r46, %r13;
	mad.lo.s32 	%r47, %r42, %r14, %r41;
	mad.lo.s32 	%r52, %r47, %r15, %r1;
	mad.lo.s32 	%r53, %r52, %r16, %r2;
	mad.lo.s32 	%r54, %r53, %r17, %r59;
	mul.lo.s32 	%r7, %r54, %r18;
	mov.u32 	%r60, 0;

BB0_4:
	add.s32 	%r9, %r60, %r3;
	setp.ge.s32	%p12, %r9, %r22;
	and.pred  	%p13, %p1, %p12;
	setp.lt.s32	%p14, %r9, %r4;
	and.pred  	%p15, %p13, %p14;
	@!%p15 bra 	BB0_6;
	bra.uni 	BB0_5;

BB0_5:
	sub.s32 	%r55, %r9, %r22;
	add.s32 	%r56, %r55, %r6;
	mad.lo.s32 	%r57, %r56, %r16, %r2;
	mul.wide.s32 	%rd5, %r57, 8;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	add.s32 	%r58, %r7, %r60;
	mul.wide.s32 	%rd7, %r58, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd1;

BB0_6:
	add.s32 	%r60, %r60, 1;
	setp.lt.s32	%p16, %r60, %r18;
	@%p16 bra 	BB0_4;

BB0_7:
	add.s32 	%r59, %r59, 1;
	setp.lt.s32	%p17, %r59, %r17;
	@%p17 bra 	BB0_2;

BB0_8:
	ret;
}

	// .globl	convolute_bp_double
.visible .entry convolute_bp_double(
	.param .u64 convolute_bp_double_param_0,
	.param .u64 convolute_bp_double_param_1,
	.param .u32 convolute_bp_double_param_2,
	.param .u32 convolute_bp_double_param_3,
	.param .u32 convolute_bp_double_param_4,
	.param .u32 convolute_bp_double_param_5,
	.param .u32 convolute_bp_double_param_6,
	.param .u32 convolute_bp_double_param_7,
	.param .u32 convolute_bp_double_param_8,
	.param .u32 convolute_bp_double_param_9,
	.param .u32 convolute_bp_double_param_10,
	.param .u32 convolute_bp_double_param_11,
	.param .u32 convolute_bp_double_param_12,
	.param .u32 convolute_bp_double_param_13
)
{
	.reg .pred 	%p<18>;
	.reg .b32 	%r<60>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd3, [convolute_bp_double_param_0];
	ld.param.u64 	%rd4, [convolute_bp_double_param_1];
	ld.param.u32 	%r11, [convolute_bp_double_param_2];
	ld.param.u32 	%r12, [convolute_bp_double_param_3];
	ld.param.u32 	%r13, [convolute_bp_double_param_4];
	ld.param.u32 	%r14, [convolute_bp_double_param_5];
	ld.param.u32 	%r15, [convolute_bp_double_param_6];
	ld.param.u32 	%r22, [convolute_bp_double_param_7];
	ld.param.u32 	%r16, [convolute_bp_double_param_8];
	ld.param.u32 	%r17, [convolute_bp_double_param_9];
	ld.param.u32 	%r18, [convolute_bp_double_param_10];
	ld.param.u32 	%r19, [convolute_bp_double_param_11];
	ld.param.u32 	%r20, [convolute_bp_double_param_12];
	ld.param.u32 	%r21, [convolute_bp_double_param_13];
	mov.u32 	%r23, %ntid.x;
	mov.u32 	%r24, %ctaid.x;
	mov.u32 	%r25, %tid.x;
	mad.lo.s32 	%r26, %r23, %r24, %r25;
	mov.u32 	%r27, %ntid.y;
	mov.u32 	%r28, %ctaid.y;
	mov.u32 	%r29, %tid.y;
	mad.lo.s32 	%r1, %r27, %r28, %r29;
	mov.u32 	%r30, %ntid.z;
	mov.u32 	%r31, %ctaid.z;
	mov.u32 	%r32, %tid.z;
	mad.lo.s32 	%r2, %r30, %r31, %r32;
	mul.lo.s32 	%r33, %r22, %r13;
	setp.lt.s32	%p2, %r26, %r33;
	setp.lt.s32	%p3, %r1, %r14;
	and.pred  	%p4, %p2, %p3;
	setp.lt.s32	%p5, %r2, %r15;
	and.pred  	%p6, %p4, %p5;
	setp.gt.s32	%p7, %r16, 0;
	and.pred  	%p8, %p6, %p7;
	@!%p8 bra 	BB1_8;
	bra.uni 	BB1_1;

BB1_1:
	cvta.to.global.u64 	%rd1, %rd4;
	mul.lo.s32 	%r3, %r1, %r19;
	add.s32 	%r4, %r21, %r12;
	mov.u32 	%r58, 0;
	cvta.to.global.u64 	%rd5, %rd3;

BB1_2:
	setp.lt.s32	%p9, %r17, 1;
	@%p9 bra 	BB1_7;

	rem.s32 	%r40, %r26, %r13;
	div.s32 	%r41, %r26, %r13;
	mad.lo.s32 	%r42, %r40, %r18, %r58;
	add.s32 	%r43, %r20, %r11;
	setp.lt.s32	%p10, %r42, %r43;
	setp.ge.s32	%p11, %r42, %r20;
	and.pred  	%p1, %p10, %p11;
	sub.s32 	%r44, %r42, %r20;
	mad.lo.s32 	%r45, %r41, %r13, %r40;
	mad.lo.s32 	%r50, %r45, %r14, %r1;
	mad.lo.s32 	%r51, %r41, %r11, %r44;
	mul.lo.s32 	%r6, %r51, %r12;
	mad.lo.s32 	%r52, %r50, %r15, %r2;
	mul.wide.s32 	%rd6, %r52, 8;
	add.s64 	%rd2, %rd5, %rd6;
	mov.u32 	%r59, 0;

BB1_4:
	add.s32 	%r8, %r59, %r3;
	setp.ge.s32	%p12, %r8, %r21;
	and.pred  	%p13, %p1, %p12;
	setp.lt.s32	%p14, %r8, %r4;
	and.pred  	%p15, %p13, %p14;
	@!%p15 bra 	BB1_6;
	bra.uni 	BB1_5;

BB1_5:
	sub.s32 	%r53, %r8, %r21;
	add.s32 	%r54, %r53, %r6;
	ld.global.f64 	%fd1, [%rd2];
	mad.lo.s32 	%r55, %r54, %r15, %r2;
	mad.lo.s32 	%r56, %r55, %r16, %r58;
	mad.lo.s32 	%r57, %r56, %r17, %r59;
	mul.wide.s32 	%rd7, %r57, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd1;

BB1_6:
	add.s32 	%r59, %r59, 1;
	setp.lt.s32	%p16, %r59, %r17;
	@%p16 bra 	BB1_4;

BB1_7:
	add.s32 	%r58, %r58, 1;
	setp.lt.s32	%p17, %r58, %r16;
	@%p17 bra 	BB1_2;

BB1_8:
	ret;
}

	// .globl	reshape_batch_double
.visible .entry reshape_batch_double(
	.param .u64 reshape_batch_double_param_0,
	.param .u64 reshape_batch_double_param_1,
	.param .u32 reshape_batch_double_param_2,
	.param .u32 reshape_batch_double_param_3,
	.param .u32 reshape_batch_double_param_4,
	.param .u32 reshape_batch_double_param_5
)
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<20>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [reshape_batch_double_param_0];
	ld.param.u64 	%rd2, [reshape_batch_double_param_1];
	ld.param.u32 	%r6, [reshape_batch_double_param_2];
	ld.param.u32 	%r7, [reshape_batch_double_param_3];
	ld.param.u32 	%r4, [reshape_batch_double_param_4];
	ld.param.u32 	%r5, [reshape_batch_double_param_5];
	mov.u32 	%r8, %tid.x;
	mov.u32 	%r9, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mad.lo.s32 	%r1, %r9, %r10, %r8;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r2, %r11, %r12, %r13;
	mul.lo.s32 	%r3, %r7, %r6;
	mul.lo.s32 	%r14, %r3, %r4;
	setp.lt.s32	%p1, %r1, %r14;
	setp.lt.s32	%p2, %r2, %r5;
	and.pred  	%p3, %p1, %p2;
	@!%p3 bra 	BB2_2;
	bra.uni 	BB2_1;

BB2_1:
	cvta.to.global.u64 	%rd3, %rd1;
	rem.s32 	%r15, %r1, %r3;
	mad.lo.s32 	%r16, %r2, %r3, %r15;
	div.s32 	%r17, %r1, %r3;
	mad.lo.s32 	%r18, %r16, %r4, %r17;
	mul.wide.s32 	%rd4, %r18, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	mad.lo.s32 	%r19, %r1, %r5, %r2;
	cvta.to.global.u64 	%rd6, %rd2;
	mul.wide.s32 	%rd7, %r19, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd1;

BB2_2:
	ret;
}

	// .globl	reshape_batch_bp_double
.visible .entry reshape_batch_bp_double(
	.param .u64 reshape_batch_bp_double_param_0,
	.param .u64 reshape_batch_bp_double_param_1,
	.param .u32 reshape_batch_bp_double_param_2,
	.param .u32 reshape_batch_bp_double_param_3,
	.param .u32 reshape_batch_bp_double_param_4,
	.param .u32 reshape_batch_bp_double_param_5
)
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<20>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [reshape_batch_bp_double_param_0];
	ld.param.u64 	%rd2, [reshape_batch_bp_double_param_1];
	ld.param.u32 	%r6, [reshape_batch_bp_double_param_2];
	ld.param.u32 	%r7, [reshape_batch_bp_double_param_3];
	ld.param.u32 	%r4, [reshape_batch_bp_double_param_4];
	ld.param.u32 	%r5, [reshape_batch_bp_double_param_5];
	mov.u32 	%r8, %tid.x;
	mov.u32 	%r9, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mad.lo.s32 	%r1, %r9, %r10, %r8;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r2, %r11, %r12, %r13;
	mul.lo.s32 	%r3, %r7, %r6;
	mul.lo.s32 	%r14, %r3, %r4;
	setp.lt.s32	%p1, %r1, %r14;
	setp.lt.s32	%p2, %r2, %r5;
	and.pred  	%p3, %p1, %p2;
	@!%p3 bra 	BB3_2;
	bra.uni 	BB3_1;

BB3_1:
	cvta.to.global.u64 	%rd3, %rd1;
	mad.lo.s32 	%r15, %r1, %r5, %r2;
	mul.wide.s32 	%rd4, %r15, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	rem.s32 	%r16, %r1, %r3;
	mad.lo.s32 	%r17, %r2, %r3, %r16;
	div.s32 	%r18, %r1, %r3;
	mad.lo.s32 	%r19, %r17, %r4, %r18;
	cvta.to.global.u64 	%rd6, %rd2;
	mul.wide.s32 	%rd7, %r19, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd1;

BB3_2:
	ret;
}


