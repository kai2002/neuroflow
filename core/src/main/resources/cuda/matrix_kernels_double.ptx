//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-21373419
// Cuda compilation tools, release 8.0, V8.0.55
// Based on LLVM 3.4svn
//

.version 5.0
.target sm_30
.address_size 64

	// .globl	map_relu_a_double
.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd
(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
;
.func  (.param .b64 func_retval0) __internal_accurate_pow
(
	.param .b64 __internal_accurate_pow_param_0,
	.param .b64 __internal_accurate_pow_param_1
)
;
.func  (.param .b64 func_retval0) __internal_lgamma_pos
(
	.param .b64 __internal_lgamma_pos_param_0
)
;
// map2_transpose_add_double$__cuda_local_var_16371_1747_non_const_tile has been demoted
// map2_transpose_sub_double$__cuda_local_var_16372_1747_non_const_tile has been demoted
// map2_transpose_mul_double$__cuda_local_var_16373_1747_non_const_tile has been demoted
// map2_transpose_div_double$__cuda_local_var_16374_1747_non_const_tile has been demoted
// map2_transpose_mod_double$__cuda_local_var_16375_1747_non_const_tile has been demoted
// map2_transpose_pow_double$__cuda_local_var_16376_1747_non_const_tile has been demoted
// map2_transpose_max_double$__cuda_local_var_16377_1747_non_const_tile has been demoted
// map2_transpose_min_double$__cuda_local_var_16378_1747_non_const_tile has been demoted
// map2_transpose_set_double$__cuda_local_var_16379_1747_non_const_tile has been demoted
.const .align 8 .b8 __cudart_i2opi_d[144] = {8, 93, 141, 31, 177, 95, 251, 107, 234, 146, 82, 138, 247, 57, 7, 61, 123, 241, 229, 235, 199, 186, 39, 117, 45, 234, 95, 158, 102, 63, 70, 79, 183, 9, 203, 39, 207, 126, 54, 109, 31, 109, 10, 90, 139, 17, 47, 239, 15, 152, 5, 222, 255, 151, 248, 31, 59, 40, 249, 189, 139, 95, 132, 156, 244, 57, 83, 131, 57, 214, 145, 57, 65, 126, 95, 180, 38, 112, 156, 233, 132, 68, 187, 46, 245, 53, 130, 232, 62, 167, 41, 177, 28, 235, 29, 254, 28, 146, 209, 9, 234, 46, 73, 6, 224, 210, 77, 66, 58, 110, 36, 183, 97, 197, 187, 222, 171, 99, 81, 254, 65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};
.const .align 8 .b8 __cudart_sin_cos_coeffs[128] = {186, 94, 120, 249, 101, 219, 229, 61, 70, 210, 176, 44, 241, 229, 90, 190, 146, 227, 172, 105, 227, 29, 199, 62, 161, 98, 219, 25, 160, 1, 42, 191, 24, 8, 17, 17, 17, 17, 129, 63, 84, 85, 85, 85, 85, 85, 197, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 129, 253, 32, 131, 255, 168, 189, 40, 133, 239, 193, 167, 238, 33, 62, 217, 230, 6, 142, 79, 126, 146, 190, 233, 188, 221, 25, 160, 1, 250, 62, 71, 93, 193, 22, 108, 193, 86, 191, 81, 85, 85, 85, 85, 85, 165, 63, 0, 0, 0, 0, 0, 0, 224, 191, 0, 0, 0, 0, 0, 0, 240, 63};

.visible .entry map_relu_a_double(
	.param .u32 map_relu_a_double_param_0,
	.param .u32 map_relu_a_double_param_1,
	.param .u64 map_relu_a_double_param_2,
	.param .u32 map_relu_a_double_param_3,
	.param .u64 map_relu_a_double_param_4,
	.param .u32 map_relu_a_double_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map_relu_a_double_param_0];
	ld.param.u32 	%r13, [map_relu_a_double_param_1];
	ld.param.u64 	%rd3, [map_relu_a_double_param_2];
	ld.param.u32 	%r14, [map_relu_a_double_param_3];
	ld.param.u64 	%rd4, [map_relu_a_double_param_4];
	ld.param.u32 	%r15, [map_relu_a_double_param_5];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB0_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB0_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB0_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB0_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	setp.gt.f64	%p3, %fd1, 0d0000000000000000;
	selp.f64	%fd2, %fd1, 0d0000000000000000, %p3;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd2;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p4, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p4 bra 	BB0_4;

BB0_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p5, %r25, %r13;
	@%p5 bra 	BB0_2;

BB0_6:
	ret;
}

	// .globl	map_relu_d_double
.visible .entry map_relu_d_double(
	.param .u32 map_relu_d_double_param_0,
	.param .u32 map_relu_d_double_param_1,
	.param .u64 map_relu_d_double_param_2,
	.param .u32 map_relu_d_double_param_3,
	.param .u64 map_relu_d_double_param_4,
	.param .u32 map_relu_d_double_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map_relu_d_double_param_0];
	ld.param.u32 	%r13, [map_relu_d_double_param_1];
	ld.param.u64 	%rd3, [map_relu_d_double_param_2];
	ld.param.u32 	%r14, [map_relu_d_double_param_3];
	ld.param.u64 	%rd4, [map_relu_d_double_param_4];
	ld.param.u32 	%r15, [map_relu_d_double_param_5];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB1_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB1_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB1_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB1_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	setp.gt.f64	%p3, %fd1, 0d0000000000000000;
	selp.f64	%fd2, 0d3FF0000000000000, 0d0000000000000000, %p3;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd2;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p4, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p4 bra 	BB1_4;

BB1_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p5, %r25, %r13;
	@%p5 bra 	BB1_2;

BB1_6:
	ret;
}

	// .globl	map_linear_a_double
.visible .entry map_linear_a_double(
	.param .u32 map_linear_a_double_param_0,
	.param .u32 map_linear_a_double_param_1,
	.param .u64 map_linear_a_double_param_2,
	.param .u32 map_linear_a_double_param_3,
	.param .u64 map_linear_a_double_param_4,
	.param .u32 map_linear_a_double_param_5
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map_linear_a_double_param_0];
	ld.param.u32 	%r13, [map_linear_a_double_param_1];
	ld.param.u64 	%rd3, [map_linear_a_double_param_2];
	ld.param.u32 	%r14, [map_linear_a_double_param_3];
	ld.param.u64 	%rd4, [map_linear_a_double_param_4];
	ld.param.u32 	%r15, [map_linear_a_double_param_5];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB2_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB2_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB2_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB2_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd1;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB2_4;

BB2_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB2_2;

BB2_6:
	ret;
}

	// .globl	map_linear_d_double
.visible .entry map_linear_d_double(
	.param .u32 map_linear_d_double_param_0,
	.param .u32 map_linear_d_double_param_1,
	.param .u64 map_linear_d_double_param_2,
	.param .u32 map_linear_d_double_param_3,
	.param .u64 map_linear_d_double_param_4,
	.param .u32 map_linear_d_double_param_5
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<24>;
	.reg .b64 	%rd<6>;


	ld.param.u32 	%r11, [map_linear_d_double_param_0];
	ld.param.u32 	%r12, [map_linear_d_double_param_1];
	ld.param.u64 	%rd2, [map_linear_d_double_param_2];
	ld.param.u32 	%r13, [map_linear_d_double_param_3];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r14, %ctaid.x;
	mov.u32 	%r15, %tid.x;
	mad.lo.s32 	%r22, %r1, %r14, %r15;
	setp.ge.s32	%p1, %r22, %r12;
	@%p1 bra 	BB3_6;

	cvta.to.global.u64 	%rd1, %rd2;
	mov.u32 	%r16, %tid.y;
	mov.u32 	%r17, %ntid.y;
	mov.u32 	%r18, %ctaid.y;
	mad.lo.s32 	%r3, %r17, %r18, %r16;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r4, %r19, %r1;
	mov.u32 	%r20, %nctaid.y;
	mul.lo.s32 	%r5, %r20, %r17;

BB3_2:
	setp.ge.s32	%p2, %r3, %r11;
	@%p2 bra 	BB3_5;

	mul.lo.s32 	%r7, %r22, %r13;
	mov.u32 	%r23, %r3;

BB3_4:
	mov.u32 	%r8, %r23;
	add.s32 	%r21, %r8, %r7;
	mul.wide.s32 	%rd3, %r21, 8;
	add.s64 	%rd4, %rd1, %rd3;
	mov.u64 	%rd5, 4607182418800017408;
	st.global.u64 	[%rd4], %rd5;
	add.s32 	%r9, %r5, %r8;
	setp.lt.s32	%p3, %r9, %r11;
	mov.u32 	%r23, %r9;
	@%p3 bra 	BB3_4;

BB3_5:
	add.s32 	%r22, %r4, %r22;
	setp.lt.s32	%p4, %r22, %r12;
	@%p4 bra 	BB3_2;

BB3_6:
	ret;
}

	// .globl	map_tanh_a_double
.visible .entry map_tanh_a_double(
	.param .u32 map_tanh_a_double_param_0,
	.param .u32 map_tanh_a_double_param_1,
	.param .u64 map_tanh_a_double_param_2,
	.param .u32 map_tanh_a_double_param_3,
	.param .u64 map_tanh_a_double_param_4,
	.param .u32 map_tanh_a_double_param_5
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<38>;
	.reg .f64 	%fd<74>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map_tanh_a_double_param_0];
	ld.param.u32 	%r13, [map_tanh_a_double_param_1];
	ld.param.u64 	%rd2, [map_tanh_a_double_param_2];
	ld.param.u32 	%r14, [map_tanh_a_double_param_3];
	ld.param.u64 	%rd3, [map_tanh_a_double_param_4];
	ld.param.u32 	%r15, [map_tanh_a_double_param_5];
	mov.u32 	%r16, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r36, %r16, %r17, %r18;
	setp.ge.s32	%p1, %r36, %r13;
	@%p1 bra 	BB4_9;

	cvta.to.global.u64 	%rd1, %rd3;
	mov.u32 	%r19, %tid.y;
	mov.u32 	%r20, %ntid.y;
	mov.u32 	%r21, %ctaid.y;
	mad.lo.s32 	%r2, %r20, %r21, %r19;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r3, %r22, %r20;
	cvta.to.global.u64 	%rd6, %rd2;

BB4_2:
	setp.ge.s32	%p2, %r2, %r12;
	@%p2 bra 	BB4_8;

	mul.lo.s32 	%r5, %r36, %r15;
	mul.lo.s32 	%r6, %r36, %r14;
	mov.u32 	%r37, %r2;

BB4_4:
	mov.u32 	%r7, %r37;
	add.s32 	%r23, %r7, %r5;
	mul.wide.s32 	%rd4, %r23, 8;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd1;
	}
	and.b32  	%r9, %r8, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r24, %temp}, %fd1;
	}
	mov.b64 	%fd2, {%r24, %r9};
	setp.ltu.f64	%p3, %fd2, 0d3FE1C7A398201CD6;
	@%p3 bra 	BB4_6;
	bra.uni 	BB4_5;

BB4_6:
	mul.f64 	%fd51, %fd1, %fd1;
	mov.f64 	%fd52, 0dBF2B9093D89F0E23;
	mov.f64 	%fd53, 0d3F0ABFFC9B5786C4;
	fma.rn.f64 	%fd54, %fd53, %fd51, %fd52;
	mov.f64 	%fd55, 0d3F42FA2744C30B61;
	fma.rn.f64 	%fd56, %fd54, %fd51, %fd55;
	mov.f64 	%fd57, 0dBF57CF3B9C1E491D;
	fma.rn.f64 	%fd58, %fd56, %fd51, %fd57;
	mov.f64 	%fd59, 0d3F6D6C61D450119A;
	fma.rn.f64 	%fd60, %fd58, %fd51, %fd59;
	mov.f64 	%fd61, 0dBF8226DDD44294F5;
	fma.rn.f64 	%fd62, %fd60, %fd51, %fd61;
	mov.f64 	%fd63, 0d3F9664F45C2B04A6;
	fma.rn.f64 	%fd64, %fd62, %fd51, %fd63;
	mov.f64 	%fd65, 0dBFABA1BA1AD70754;
	fma.rn.f64 	%fd66, %fd64, %fd51, %fd65;
	mov.f64 	%fd67, 0d3FC111111110295E;
	fma.rn.f64 	%fd68, %fd66, %fd51, %fd67;
	mov.f64 	%fd69, 0dBFD555555555549F;
	fma.rn.f64 	%fd70, %fd68, %fd51, %fd69;
	mul.f64 	%fd71, %fd51, %fd70;
	fma.rn.f64 	%fd73, %fd71, %fd1, %fd1;
	bra.uni 	BB4_7;

BB4_5:
	add.f64 	%fd8, %fd2, %fd2;
	mov.f64 	%fd9, 0d4338000000000000;
	mov.f64 	%fd10, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd11, %fd8, %fd10, %fd9;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r25, %temp}, %fd11;
	}
	mov.f64 	%fd12, 0dC338000000000000;
	add.rn.f64 	%fd13, %fd11, %fd12;
	mov.f64 	%fd14, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd15, %fd13, %fd14, %fd8;
	mov.f64 	%fd16, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd17, %fd13, %fd16, %fd15;
	mov.f64 	%fd18, 0d3E5AF86D8EBD13CD;
	mov.f64 	%fd19, 0d3E21F4076ACD15B6;
	fma.rn.f64 	%fd20, %fd19, %fd17, %fd18;
	mov.f64 	%fd21, 0d3E927E5092BA033D;
	fma.rn.f64 	%fd22, %fd20, %fd17, %fd21;
	mov.f64 	%fd23, 0d3EC71DDE6C5F9DA1;
	fma.rn.f64 	%fd24, %fd22, %fd17, %fd23;
	mov.f64 	%fd25, 0d3EFA01A018D034E6;
	fma.rn.f64 	%fd26, %fd24, %fd17, %fd25;
	mov.f64 	%fd27, 0d3F2A01A01B3B6940;
	fma.rn.f64 	%fd28, %fd26, %fd17, %fd27;
	mov.f64 	%fd29, 0d3F56C16C16C1B5DD;
	fma.rn.f64 	%fd30, %fd28, %fd17, %fd29;
	mov.f64 	%fd31, 0d3F8111111110F74D;
	fma.rn.f64 	%fd32, %fd30, %fd17, %fd31;
	mov.f64 	%fd33, 0d3FA555555555554D;
	fma.rn.f64 	%fd34, %fd32, %fd17, %fd33;
	mov.f64 	%fd35, 0d3FC5555555555557;
	fma.rn.f64 	%fd36, %fd34, %fd17, %fd35;
	mov.f64 	%fd37, 0d3FE0000000000000;
	fma.rn.f64 	%fd38, %fd36, %fd17, %fd37;
	mul.f64 	%fd39, %fd17, %fd38;
	fma.rn.f64 	%fd40, %fd39, %fd17, %fd17;
	shl.b32 	%r26, %r25, 20;
	add.s32 	%r27, %r26, 1072693248;
	mov.u32 	%r28, 0;
	mov.b64 	%fd41, {%r28, %r27};
	fma.rn.f64 	%fd42, %fd40, %fd41, %fd41;
	add.f64 	%fd7, %fd42, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd6,%fd7;
	// inline asm
	neg.f64 	%fd43, %fd7;
	mov.f64 	%fd44, 0d3FF0000000000000;
	fma.rn.f64 	%fd45, %fd43, %fd6, %fd44;
	fma.rn.f64 	%fd46, %fd45, %fd45, %fd45;
	fma.rn.f64 	%fd47, %fd46, %fd6, %fd6;
	neg.f64 	%fd48, %fd47;
	mov.f64 	%fd49, 0d4000000000000000;
	fma.rn.f64 	%fd50, %fd49, %fd48, %fd44;
	setp.gt.u32	%p4, %r9, 1077936127;
	selp.f64	%fd73, 0d3FF0000000000000, %fd50, %p4;

BB4_7:
	and.b32  	%r29, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r30}, %fd73;
	}
	or.b32  	%r31, %r30, %r29;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r32, %temp}, %fd73;
	}
	mov.b64 	%fd72, {%r32, %r31};
	add.s32 	%r33, %r7, %r6;
	mul.wide.s32 	%rd7, %r33, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd72;
	add.s32 	%r10, %r3, %r7;
	setp.lt.s32	%p5, %r10, %r12;
	mov.u32 	%r37, %r10;
	@%p5 bra 	BB4_4;

BB4_8:
	mov.u32 	%r34, %nctaid.x;
	mad.lo.s32 	%r36, %r34, %r16, %r36;
	setp.lt.s32	%p6, %r36, %r13;
	@%p6 bra 	BB4_2;

BB4_9:
	ret;
}

	// .globl	map_tanh_d_double
.visible .entry map_tanh_d_double(
	.param .u32 map_tanh_d_double_param_0,
	.param .u32 map_tanh_d_double_param_1,
	.param .u64 map_tanh_d_double_param_2,
	.param .u32 map_tanh_d_double_param_3,
	.param .u64 map_tanh_d_double_param_4,
	.param .u32 map_tanh_d_double_param_5
)
{
	.reg .pred 	%p<25>;
	.reg .b32 	%r<77>;
	.reg .f64 	%fd<100>;
	.reg .b64 	%rd<13>;


	ld.param.u32 	%r12, [map_tanh_d_double_param_0];
	ld.param.u32 	%r13, [map_tanh_d_double_param_1];
	ld.param.u64 	%rd1, [map_tanh_d_double_param_2];
	ld.param.u64 	%rd2, [map_tanh_d_double_param_4];
	mov.u32 	%r16, %tid.x;
	mov.u32 	%r17, %ntid.x;
	mov.u32 	%r18, %ctaid.x;
	mad.lo.s32 	%r75, %r17, %r18, %r16;
	setp.ge.s32	%p2, %r75, %r13;
	@%p2 bra 	BB5_23;

	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd10, %rd1;

BB5_2:
	mov.u32 	%r19, %ctaid.y;
	mov.u32 	%r20, %ntid.y;
	mov.u32 	%r21, %tid.y;
	mad.lo.s32 	%r76, %r20, %r19, %r21;
	setp.ge.s32	%p3, %r76, %r12;
	@%p3 bra 	BB5_22;

	mov.f64 	%fd18, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd18;
	}

BB5_4:
	ld.param.u32 	%r71, [map_tanh_d_double_param_5];
	mad.lo.s32 	%r28, %r75, %r71, %r76;
	mul.wide.s32 	%rd4, %r28, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd1;
	}
	and.b32  	%r8, %r7, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r29, %temp}, %fd1;
	}
	mov.b64 	%fd2, {%r29, %r8};
	setp.ltu.f64	%p4, %fd2, 0d3FE1C7A398201CD6;
	@%p4 bra 	BB5_6;
	bra.uni 	BB5_5;

BB5_6:
	mul.f64 	%fd64, %fd1, %fd1;
	mov.f64 	%fd65, 0dBF2B9093D89F0E23;
	mov.f64 	%fd66, 0d3F0ABFFC9B5786C4;
	fma.rn.f64 	%fd67, %fd66, %fd64, %fd65;
	mov.f64 	%fd68, 0d3F42FA2744C30B61;
	fma.rn.f64 	%fd69, %fd67, %fd64, %fd68;
	mov.f64 	%fd70, 0dBF57CF3B9C1E491D;
	fma.rn.f64 	%fd71, %fd69, %fd64, %fd70;
	mov.f64 	%fd72, 0d3F6D6C61D450119A;
	fma.rn.f64 	%fd73, %fd71, %fd64, %fd72;
	mov.f64 	%fd74, 0dBF8226DDD44294F5;
	fma.rn.f64 	%fd75, %fd73, %fd64, %fd74;
	mov.f64 	%fd76, 0d3F9664F45C2B04A6;
	fma.rn.f64 	%fd77, %fd75, %fd64, %fd76;
	mov.f64 	%fd78, 0dBFABA1BA1AD70754;
	fma.rn.f64 	%fd79, %fd77, %fd64, %fd78;
	mov.f64 	%fd80, 0d3FC111111110295E;
	fma.rn.f64 	%fd81, %fd79, %fd64, %fd80;
	mov.f64 	%fd82, 0dBFD555555555549F;
	fma.rn.f64 	%fd83, %fd81, %fd64, %fd82;
	mul.f64 	%fd84, %fd64, %fd83;
	fma.rn.f64 	%fd92, %fd84, %fd1, %fd1;
	bra.uni 	BB5_7;

BB5_5:
	add.f64 	%fd21, %fd2, %fd2;
	mov.f64 	%fd22, 0d4338000000000000;
	mov.f64 	%fd23, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd24, %fd21, %fd23, %fd22;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r30, %temp}, %fd24;
	}
	mov.f64 	%fd25, 0dC338000000000000;
	add.rn.f64 	%fd26, %fd24, %fd25;
	mov.f64 	%fd27, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd28, %fd26, %fd27, %fd21;
	mov.f64 	%fd29, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd30, %fd26, %fd29, %fd28;
	mov.f64 	%fd31, 0d3E5AF86D8EBD13CD;
	mov.f64 	%fd32, 0d3E21F4076ACD15B6;
	fma.rn.f64 	%fd33, %fd32, %fd30, %fd31;
	mov.f64 	%fd34, 0d3E927E5092BA033D;
	fma.rn.f64 	%fd35, %fd33, %fd30, %fd34;
	mov.f64 	%fd36, 0d3EC71DDE6C5F9DA1;
	fma.rn.f64 	%fd37, %fd35, %fd30, %fd36;
	mov.f64 	%fd38, 0d3EFA01A018D034E6;
	fma.rn.f64 	%fd39, %fd37, %fd30, %fd38;
	mov.f64 	%fd40, 0d3F2A01A01B3B6940;
	fma.rn.f64 	%fd41, %fd39, %fd30, %fd40;
	mov.f64 	%fd42, 0d3F56C16C16C1B5DD;
	fma.rn.f64 	%fd43, %fd41, %fd30, %fd42;
	mov.f64 	%fd44, 0d3F8111111110F74D;
	fma.rn.f64 	%fd45, %fd43, %fd30, %fd44;
	mov.f64 	%fd46, 0d3FA555555555554D;
	fma.rn.f64 	%fd47, %fd45, %fd30, %fd46;
	mov.f64 	%fd48, 0d3FC5555555555557;
	fma.rn.f64 	%fd49, %fd47, %fd30, %fd48;
	mov.f64 	%fd50, 0d3FE0000000000000;
	fma.rn.f64 	%fd51, %fd49, %fd30, %fd50;
	mul.f64 	%fd52, %fd30, %fd51;
	fma.rn.f64 	%fd53, %fd52, %fd30, %fd30;
	shl.b32 	%r31, %r30, 20;
	add.s32 	%r32, %r31, 1072693248;
	mov.u32 	%r33, 0;
	mov.b64 	%fd54, {%r33, %r32};
	fma.rn.f64 	%fd55, %fd53, %fd54, %fd54;
	add.f64 	%fd20, %fd55, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd19,%fd20;
	// inline asm
	neg.f64 	%fd56, %fd20;
	mov.f64 	%fd57, 0d3FF0000000000000;
	fma.rn.f64 	%fd58, %fd56, %fd19, %fd57;
	fma.rn.f64 	%fd59, %fd58, %fd58, %fd58;
	fma.rn.f64 	%fd60, %fd59, %fd19, %fd19;
	neg.f64 	%fd61, %fd60;
	fma.rn.f64 	%fd63, %fd18, %fd61, %fd57;
	setp.gt.u32	%p5, %r8, 1077936127;
	selp.f64	%fd92, 0d3FF0000000000000, %fd63, %p5;

BB5_7:
	bfe.u32 	%r34, %r3, 20, 11;
	add.s32 	%r35, %r34, -1012;
	mov.u64 	%rd6, 4611686018427387904;
	shl.b64 	%rd7, %rd6, %r35;
	setp.eq.s64	%p6, %rd7, -9223372036854775808;
	and.b32  	%r36, %r7, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r37}, %fd92;
	}
	or.b32  	%r38, %r37, %r36;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r39, %temp}, %fd92;
	}
	mov.b64 	%fd6, {%r39, %r38};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd6;
	}
	abs.f64 	%fd7, %fd6;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd7;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd99, [retval0+0];
	
	//{
	}// Callseq End 0
	setp.lt.s32	%p7, %r9, 0;
	and.pred  	%p1, %p7, %p6;
	@!%p1 bra 	BB5_9;
	bra.uni 	BB5_8;

BB5_8:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r40}, %fd99;
	}
	xor.b32  	%r41, %r40, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r42, %temp}, %fd99;
	}
	mov.b64 	%fd99, {%r42, %r41};

BB5_9:
	mov.f64 	%fd98, %fd99;
	setp.eq.f64	%p8, %fd6, 0d0000000000000000;
	@%p8 bra 	BB5_12;
	bra.uni 	BB5_10;

BB5_12:
	setp.lt.s32	%p11, %r3, 0;
	bfe.u32 	%r43, %r3, 20, 11;
	add.s32 	%r44, %r43, -1012;
	shl.b64 	%rd9, %rd6, %r44;
	setp.eq.s64	%p12, %rd9, -9223372036854775808;
	selp.b32	%r45, %r9, 0, %p12;
	or.b32  	%r46, %r45, 2146435072;
	selp.b32	%r47, %r46, %r45, %p11;
	mov.u32 	%r48, 0;
	mov.b64 	%fd98, {%r48, %r47};
	bra.uni 	BB5_13;

BB5_10:
	setp.gt.s32	%p9, %r9, -1;
	@%p9 bra 	BB5_13;

	cvt.rzi.f64.f64	%fd87, %fd18;
	setp.neu.f64	%p10, %fd87, 0d4000000000000000;
	selp.f64	%fd98, 0dFFF8000000000000, %fd98, %p10;

BB5_13:
	mov.f64 	%fd13, %fd98;
	add.f64 	%fd14, %fd6, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r49}, %fd14;
	}
	and.b32  	%r50, %r49, 2146435072;
	setp.ne.s32	%p13, %r50, 2146435072;
	mov.f64 	%fd97, %fd13;
	@%p13 bra 	BB5_21;

	setp.gtu.f64	%p14, %fd7, 0d7FF0000000000000;
	mov.f64 	%fd97, %fd14;
	@%p14 bra 	BB5_21;

	and.b32  	%r51, %r3, 2147483647;
	setp.ne.s32	%p15, %r51, 2146435072;
	@%p15 bra 	BB5_17;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r52, %temp}, %fd18;
	}
	setp.eq.s32	%p16, %r52, 0;
	@%p16 bra 	BB5_20;
	bra.uni 	BB5_17;

BB5_20:
	setp.lt.s32	%p19, %r3, 0;
	setp.gt.f64	%p20, %fd7, 0d3FF0000000000000;
	selp.b32	%r58, 2146435072, 0, %p20;
	xor.b32  	%r59, %r58, 2146435072;
	selp.b32	%r60, %r59, %r58, %p19;
	setp.eq.f64	%p21, %fd6, 0dBFF0000000000000;
	selp.b32	%r61, 1072693248, %r60, %p21;
	mov.u32 	%r62, 0;
	mov.b64 	%fd97, {%r62, %r61};
	bra.uni 	BB5_21;

BB5_17:
	and.b32  	%r53, %r9, 2147483647;
	setp.ne.s32	%p17, %r53, 2146435072;
	mov.f64 	%fd95, %fd13;
	mov.f64 	%fd97, %fd95;
	@%p17 bra 	BB5_21;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r54, %temp}, %fd6;
	}
	setp.ne.s32	%p18, %r54, 0;
	mov.f64 	%fd97, %fd13;
	@%p18 bra 	BB5_21;

	shr.s32 	%r74, %r3, 31;
	and.b32  	%r73, %r74, -2146435072;
	add.s32 	%r72, %r73, 2146435072;
	or.b32  	%r55, %r72, -2147483648;
	selp.b32	%r56, %r55, %r72, %p1;
	mov.u32 	%r57, 0;
	mov.b64 	%fd97, {%r57, %r56};

BB5_21:
	mov.u32 	%r69, %ntid.y;
	ld.param.u32 	%r68, [map_tanh_d_double_param_3];
	mov.f64 	%fd89, 0d3FF0000000000000;
	sub.f64 	%fd90, %fd89, %fd97;
	setp.eq.f64	%p22, %fd6, 0d3FF0000000000000;
	selp.f64	%fd91, 0d0000000000000000, %fd90, %p22;
	mad.lo.s32 	%r63, %r75, %r68, %r76;
	mul.wide.s32 	%rd11, %r63, 8;
	add.s64 	%rd12, %rd10, %rd11;
	st.global.f64 	[%rd12], %fd91;
	mov.u32 	%r65, %nctaid.y;
	mad.lo.s32 	%r76, %r65, %r69, %r76;
	setp.lt.s32	%p23, %r76, %r12;
	@%p23 bra 	BB5_4;

BB5_22:
	mov.u32 	%r70, %ntid.x;
	mov.u32 	%r66, %nctaid.x;
	mad.lo.s32 	%r75, %r66, %r70, %r75;
	setp.lt.s32	%p24, %r75, %r13;
	@%p24 bra 	BB5_2;

BB5_23:
	ret;
}

	// .globl	map_sigmoid_a_double
.visible .entry map_sigmoid_a_double(
	.param .u32 map_sigmoid_a_double_param_0,
	.param .u32 map_sigmoid_a_double_param_1,
	.param .u64 map_sigmoid_a_double_param_2,
	.param .u32 map_sigmoid_a_double_param_3,
	.param .u64 map_sigmoid_a_double_param_4,
	.param .u32 map_sigmoid_a_double_param_5
)
{
	.reg .pred 	%p<8>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<47>;
	.reg .f64 	%fd<45>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r13, [map_sigmoid_a_double_param_0];
	ld.param.u32 	%r14, [map_sigmoid_a_double_param_1];
	ld.param.u64 	%rd1, [map_sigmoid_a_double_param_2];
	ld.param.u32 	%r15, [map_sigmoid_a_double_param_3];
	ld.param.u64 	%rd2, [map_sigmoid_a_double_param_4];
	ld.param.u32 	%r16, [map_sigmoid_a_double_param_5];
	mov.u32 	%r17, %tid.x;
	mov.u32 	%r18, %ntid.x;
	mov.u32 	%r19, %ctaid.x;
	mad.lo.s32 	%r45, %r18, %r19, %r17;
	setp.ge.s32	%p1, %r45, %r14;
	@%p1 bra 	BB6_9;

	mov.u32 	%r20, %ntid.y;
	mov.u32 	%r21, %nctaid.y;
	mul.lo.s32 	%r2, %r21, %r20;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd6, %rd1;

BB6_2:
	mov.u32 	%r22, %ctaid.y;
	mov.u32 	%r24, %tid.y;
	mad.lo.s32 	%r46, %r20, %r22, %r24;
	setp.ge.s32	%p2, %r46, %r13;
	@%p2 bra 	BB6_8;

	mul.lo.s32 	%r4, %r45, %r16;
	mul.lo.s32 	%r5, %r45, %r15;

BB6_4:
	add.s32 	%r29, %r46, %r4;
	mul.wide.s32 	%rd4, %r29, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	neg.f64 	%fd6, %fd1;
	mov.f64 	%fd7, 0d4338000000000000;
	mov.f64 	%fd8, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd9, %fd6, %fd8, %fd7;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r8, %temp}, %fd9;
	}
	mov.f64 	%fd10, 0dC338000000000000;
	add.rn.f64 	%fd11, %fd9, %fd10;
	mov.f64 	%fd12, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd13, %fd11, %fd12, %fd6;
	mov.f64 	%fd14, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd15, %fd11, %fd14, %fd13;
	mov.f64 	%fd16, 0d3E928AF3FCA213EA;
	mov.f64 	%fd17, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd18, %fd17, %fd15, %fd16;
	mov.f64 	%fd19, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd20, %fd18, %fd15, %fd19;
	mov.f64 	%fd21, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd22, %fd20, %fd15, %fd21;
	mov.f64 	%fd23, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd24, %fd22, %fd15, %fd23;
	mov.f64 	%fd25, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd26, %fd24, %fd15, %fd25;
	mov.f64 	%fd27, 0d3F81111111122322;
	fma.rn.f64 	%fd28, %fd26, %fd15, %fd27;
	mov.f64 	%fd29, 0d3FA55555555502A1;
	fma.rn.f64 	%fd30, %fd28, %fd15, %fd29;
	mov.f64 	%fd31, 0d3FC5555555555511;
	fma.rn.f64 	%fd32, %fd30, %fd15, %fd31;
	mov.f64 	%fd33, 0d3FE000000000000B;
	fma.rn.f64 	%fd34, %fd32, %fd15, %fd33;
	mov.f64 	%fd35, 0d3FF0000000000000;
	fma.rn.f64 	%fd36, %fd34, %fd15, %fd35;
	fma.rn.f64 	%fd37, %fd36, %fd15, %fd35;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r9, %temp}, %fd37;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd37;
	}
	shl.b32 	%r30, %r8, 20;
	add.s32 	%r31, %r10, %r30;
	mov.b64 	%fd44, {%r9, %r31};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd6;
	}
	mov.b32 	 %f2, %r32;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p3, %f1, 0f4086232B;
	@%p3 bra 	BB6_7;

	setp.gt.f64	%p4, %fd1, 0d8000000000000000;
	mov.f64 	%fd38, 0d7FF0000000000000;
	sub.f64 	%fd39, %fd38, %fd1;
	selp.f64	%fd44, 0d0000000000000000, %fd39, %p4;
	setp.geu.f32	%p5, %f1, 0f40874800;
	@%p5 bra 	BB6_7;

	shr.u32 	%r33, %r8, 31;
	add.s32 	%r34, %r8, %r33;
	shr.s32 	%r35, %r34, 1;
	shl.b32 	%r36, %r35, 20;
	add.s32 	%r37, %r36, %r10;
	mov.b64 	%fd40, {%r9, %r37};
	sub.s32 	%r38, %r8, %r35;
	shl.b32 	%r39, %r38, 20;
	add.s32 	%r40, %r39, 1072693248;
	mov.u32 	%r41, 0;
	mov.b64 	%fd41, {%r41, %r40};
	mul.f64 	%fd44, %fd40, %fd41;

BB6_7:
	add.f64 	%fd42, %fd44, 0d3FF0000000000000;
	rcp.rn.f64 	%fd43, %fd42;
	add.s32 	%r42, %r46, %r5;
	mul.wide.s32 	%rd7, %r42, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd43;
	add.s32 	%r46, %r2, %r46;
	setp.lt.s32	%p6, %r46, %r13;
	@%p6 bra 	BB6_4;

BB6_8:
	mov.u32 	%r43, %nctaid.x;
	mad.lo.s32 	%r45, %r43, %r18, %r45;
	setp.lt.s32	%p7, %r45, %r14;
	@%p7 bra 	BB6_2;

BB6_9:
	ret;
}

	// .globl	map_sigmoid_d_double
.visible .entry map_sigmoid_d_double(
	.param .u32 map_sigmoid_d_double_param_0,
	.param .u32 map_sigmoid_d_double_param_1,
	.param .u64 map_sigmoid_d_double_param_2,
	.param .u32 map_sigmoid_d_double_param_3,
	.param .u64 map_sigmoid_d_double_param_4,
	.param .u32 map_sigmoid_d_double_param_5
)
{
	.reg .pred 	%p<26>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<74>;
	.reg .f64 	%fd<67>;
	.reg .b64 	%rd<13>;


	ld.param.u32 	%r12, [map_sigmoid_d_double_param_0];
	ld.param.u32 	%r13, [map_sigmoid_d_double_param_1];
	ld.param.u64 	%rd1, [map_sigmoid_d_double_param_2];
	ld.param.u32 	%r14, [map_sigmoid_d_double_param_3];
	ld.param.u64 	%rd2, [map_sigmoid_d_double_param_4];
	ld.param.u32 	%r15, [map_sigmoid_d_double_param_5];
	mov.u32 	%r16, %tid.x;
	mov.u32 	%r17, %ntid.x;
	mov.u32 	%r18, %ctaid.x;
	mad.lo.s32 	%r72, %r17, %r18, %r16;
	setp.ge.s32	%p2, %r72, %r13;
	@%p2 bra 	BB7_23;

	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd10, %rd1;

BB7_2:
	mov.u32 	%r19, %ctaid.y;
	mov.u32 	%r20, %ntid.y;
	mov.u32 	%r21, %tid.y;
	mad.lo.s32 	%r73, %r20, %r19, %r21;
	setp.ge.s32	%p3, %r73, %r12;
	@%p3 bra 	BB7_22;

	mov.f64 	%fd18, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd18;
	}

BB7_4:
	mad.lo.s32 	%r26, %r72, %r15, %r73;
	mul.wide.s32 	%rd4, %r26, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	mov.f64 	%fd19, 0d4338000000000000;
	mov.f64 	%fd20, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd21, %fd1, %fd20, %fd19;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r6, %temp}, %fd21;
	}
	mov.f64 	%fd22, 0dC338000000000000;
	add.rn.f64 	%fd23, %fd21, %fd22;
	mov.f64 	%fd24, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd25, %fd23, %fd24, %fd1;
	mov.f64 	%fd26, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd27, %fd23, %fd26, %fd25;
	mov.f64 	%fd28, 0d3E928AF3FCA213EA;
	mov.f64 	%fd29, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd30, %fd29, %fd27, %fd28;
	mov.f64 	%fd31, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd32, %fd30, %fd27, %fd31;
	mov.f64 	%fd33, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd34, %fd32, %fd27, %fd33;
	mov.f64 	%fd35, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd36, %fd34, %fd27, %fd35;
	mov.f64 	%fd37, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd38, %fd36, %fd27, %fd37;
	mov.f64 	%fd39, 0d3F81111111122322;
	fma.rn.f64 	%fd40, %fd38, %fd27, %fd39;
	mov.f64 	%fd41, 0d3FA55555555502A1;
	fma.rn.f64 	%fd42, %fd40, %fd27, %fd41;
	mov.f64 	%fd43, 0d3FC5555555555511;
	fma.rn.f64 	%fd44, %fd42, %fd27, %fd43;
	mov.f64 	%fd45, 0d3FE000000000000B;
	fma.rn.f64 	%fd46, %fd44, %fd27, %fd45;
	mov.f64 	%fd47, 0d3FF0000000000000;
	fma.rn.f64 	%fd48, %fd46, %fd27, %fd47;
	fma.rn.f64 	%fd49, %fd48, %fd27, %fd47;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r7, %temp}, %fd49;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd49;
	}
	shl.b32 	%r27, %r6, 20;
	add.s32 	%r28, %r8, %r27;
	mov.b64 	%fd59, {%r7, %r28};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd1;
	}
	mov.b32 	 %f2, %r29;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p4, %f1, 0f4086232B;
	@%p4 bra 	BB7_7;

	setp.lt.f64	%p5, %fd1, 0d0000000000000000;
	add.f64 	%fd50, %fd1, 0d7FF0000000000000;
	selp.f64	%fd59, 0d0000000000000000, %fd50, %p5;
	setp.geu.f32	%p6, %f1, 0f40874800;
	@%p6 bra 	BB7_7;

	shr.u32 	%r30, %r6, 31;
	add.s32 	%r31, %r6, %r30;
	shr.s32 	%r32, %r31, 1;
	shl.b32 	%r33, %r32, 20;
	add.s32 	%r34, %r33, %r8;
	mov.b64 	%fd51, {%r7, %r34};
	sub.s32 	%r35, %r6, %r32;
	shl.b32 	%r36, %r35, 20;
	add.s32 	%r37, %r36, 1072693248;
	mov.u32 	%r38, 0;
	mov.b64 	%fd52, {%r38, %r37};
	mul.f64 	%fd59, %fd51, %fd52;

BB7_7:
	bfe.u32 	%r39, %r3, 20, 11;
	add.s32 	%r40, %r39, -1012;
	mov.u64 	%rd6, 4611686018427387904;
	shl.b64 	%rd7, %rd6, %r40;
	setp.eq.s64	%p7, %rd7, -9223372036854775808;
	add.f64 	%fd6, %fd59, 0d3FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd6;
	}
	abs.f64 	%fd7, %fd6;
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd7;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd66, [retval0+0];
	
	//{
	}// Callseq End 1
	setp.lt.s32	%p8, %r9, 0;
	and.pred  	%p1, %p8, %p7;
	@!%p1 bra 	BB7_9;
	bra.uni 	BB7_8;

BB7_8:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r41}, %fd66;
	}
	xor.b32  	%r42, %r41, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r43, %temp}, %fd66;
	}
	mov.b64 	%fd66, {%r43, %r42};

BB7_9:
	mov.f64 	%fd65, %fd66;
	setp.eq.f64	%p9, %fd6, 0d0000000000000000;
	@%p9 bra 	BB7_12;
	bra.uni 	BB7_10;

BB7_12:
	setp.lt.s32	%p12, %r3, 0;
	bfe.u32 	%r44, %r3, 20, 11;
	add.s32 	%r45, %r44, -1012;
	shl.b64 	%rd9, %rd6, %r45;
	setp.eq.s64	%p13, %rd9, -9223372036854775808;
	selp.b32	%r46, %r9, 0, %p13;
	or.b32  	%r47, %r46, 2146435072;
	selp.b32	%r48, %r47, %r46, %p12;
	mov.u32 	%r49, 0;
	mov.b64 	%fd65, {%r49, %r48};
	bra.uni 	BB7_13;

BB7_10:
	setp.gt.s32	%p10, %r9, -1;
	@%p10 bra 	BB7_13;

	cvt.rzi.f64.f64	%fd55, %fd18;
	setp.neu.f64	%p11, %fd55, 0d4000000000000000;
	selp.f64	%fd65, 0dFFF8000000000000, %fd65, %p11;

BB7_13:
	mov.f64 	%fd13, %fd65;
	add.f64 	%fd14, %fd6, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd14;
	}
	and.b32  	%r51, %r50, 2146435072;
	setp.ne.s32	%p14, %r51, 2146435072;
	mov.f64 	%fd64, %fd13;
	@%p14 bra 	BB7_21;

	setp.gtu.f64	%p15, %fd7, 0d7FF0000000000000;
	mov.f64 	%fd64, %fd14;
	@%p15 bra 	BB7_21;

	and.b32  	%r52, %r3, 2147483647;
	setp.ne.s32	%p16, %r52, 2146435072;
	@%p16 bra 	BB7_17;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r53, %temp}, %fd18;
	}
	setp.eq.s32	%p17, %r53, 0;
	@%p17 bra 	BB7_20;
	bra.uni 	BB7_17;

BB7_20:
	setp.lt.s32	%p20, %r3, 0;
	setp.gt.f64	%p21, %fd7, 0d3FF0000000000000;
	selp.b32	%r62, 2146435072, 0, %p21;
	xor.b32  	%r63, %r62, 2146435072;
	selp.b32	%r64, %r63, %r62, %p20;
	setp.eq.f64	%p22, %fd6, 0dBFF0000000000000;
	selp.b32	%r65, 1072693248, %r64, %p22;
	mov.u32 	%r66, 0;
	mov.b64 	%fd64, {%r66, %r65};
	bra.uni 	BB7_21;

BB7_17:
	and.b32  	%r54, %r9, 2147483647;
	setp.ne.s32	%p18, %r54, 2146435072;
	mov.f64 	%fd62, %fd13;
	mov.f64 	%fd64, %fd62;
	@%p18 bra 	BB7_21;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r55, %temp}, %fd6;
	}
	setp.ne.s32	%p19, %r55, 0;
	mov.f64 	%fd64, %fd13;
	@%p19 bra 	BB7_21;

	shr.s32 	%r56, %r3, 31;
	and.b32  	%r57, %r56, -2146435072;
	add.s32 	%r58, %r57, 2146435072;
	or.b32  	%r59, %r58, -2147483648;
	selp.b32	%r60, %r59, %r58, %p1;
	mov.u32 	%r61, 0;
	mov.b64 	%fd64, {%r61, %r60};

BB7_21:
	setp.eq.f64	%p23, %fd6, 0d3FF0000000000000;
	selp.f64	%fd57, 0d3FF0000000000000, %fd64, %p23;
	div.rn.f64 	%fd58, %fd59, %fd57;
	mad.lo.s32 	%r67, %r72, %r14, %r73;
	mul.wide.s32 	%rd11, %r67, 8;
	add.s64 	%rd12, %rd10, %rd11;
	st.global.f64 	[%rd12], %fd58;
	mov.u32 	%r69, %nctaid.y;
	mad.lo.s32 	%r73, %r69, %r20, %r73;
	setp.lt.s32	%p24, %r73, %r12;
	@%p24 bra 	BB7_4;

BB7_22:
	mov.u32 	%r70, %nctaid.x;
	mad.lo.s32 	%r72, %r70, %r17, %r72;
	setp.lt.s32	%p25, %r72, %r13;
	@%p25 bra 	BB7_2;

BB7_23:
	ret;
}

	// .globl	map_negate_double
.visible .entry map_negate_double(
	.param .u32 map_negate_double_param_0,
	.param .u32 map_negate_double_param_1,
	.param .u64 map_negate_double_param_2,
	.param .u32 map_negate_double_param_3,
	.param .u64 map_negate_double_param_4,
	.param .u32 map_negate_double_param_5
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map_negate_double_param_0];
	ld.param.u32 	%r13, [map_negate_double_param_1];
	ld.param.u64 	%rd3, [map_negate_double_param_2];
	ld.param.u32 	%r14, [map_negate_double_param_3];
	ld.param.u64 	%rd4, [map_negate_double_param_4];
	ld.param.u32 	%r15, [map_negate_double_param_5];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB8_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB8_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB8_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB8_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	neg.f64 	%fd2, %fd1;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd2;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB8_4;

BB8_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB8_2;

BB8_6:
	ret;
}

	// .globl	map_acos_double
.visible .entry map_acos_double(
	.param .u32 map_acos_double_param_0,
	.param .u32 map_acos_double_param_1,
	.param .u64 map_acos_double_param_2,
	.param .u32 map_acos_double_param_3,
	.param .u64 map_acos_double_param_4,
	.param .u32 map_acos_double_param_5
)
{
	.reg .pred 	%p<10>;
	.reg .b32 	%r<41>;
	.reg .f64 	%fd<95>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r10, [map_acos_double_param_0];
	ld.param.u32 	%r11, [map_acos_double_param_1];
	ld.param.u64 	%rd1, [map_acos_double_param_2];
	ld.param.u32 	%r12, [map_acos_double_param_3];
	ld.param.u64 	%rd2, [map_acos_double_param_4];
	ld.param.u32 	%r13, [map_acos_double_param_5];
	mov.u32 	%r14, %tid.x;
	mov.u32 	%r15, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mad.lo.s32 	%r39, %r15, %r16, %r14;
	setp.ge.s32	%p1, %r39, %r11;
	@%p1 bra 	BB9_17;

	mov.u32 	%r17, %ntid.y;
	mov.u32 	%r18, %nctaid.y;
	mul.lo.s32 	%r2, %r18, %r17;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd6, %rd1;

BB9_2:
	mov.u32 	%r19, %ctaid.y;
	mov.u32 	%r21, %tid.y;
	mad.lo.s32 	%r40, %r17, %r19, %r21;
	setp.ge.s32	%p2, %r40, %r10;
	@%p2 bra 	BB9_16;

BB9_3:
	mad.lo.s32 	%r26, %r39, %r13, %r40;
	mul.wide.s32 	%rd4, %r26, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd16, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd16;
	}
	abs.f64 	%fd1, %fd16;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd1;
	}
	setp.lt.s32	%p3, %r27, 1071801958;
	@%p3 bra 	BB9_11;
	bra.uni 	BB9_4;

BB9_11:
	mul.f64 	%fd62, %fd1, %fd1;
	mov.f64 	%fd63, 0dBFB3823B180754AF;
	mov.f64 	%fd64, 0d3FB0066BDC1895E9;
	fma.rn.f64 	%fd65, %fd64, %fd62, %fd63;
	mov.f64 	%fd66, 0d3FB11E52CC2F79AE;
	fma.rn.f64 	%fd67, %fd65, %fd62, %fd66;
	mov.f64 	%fd68, 0dBF924EAF3526861B;
	fma.rn.f64 	%fd69, %fd67, %fd62, %fd68;
	mov.f64 	%fd70, 0d3F91DF02A31E6CB7;
	fma.rn.f64 	%fd71, %fd69, %fd62, %fd70;
	mov.f64 	%fd72, 0d3F847D18B0EEC6CC;
	fma.rn.f64 	%fd73, %fd71, %fd62, %fd72;
	mov.f64 	%fd74, 0d3F8D0AF961BA53B0;
	fma.rn.f64 	%fd75, %fd73, %fd62, %fd74;
	mov.f64 	%fd76, 0d3F91BF7734CF1C48;
	fma.rn.f64 	%fd77, %fd75, %fd62, %fd76;
	mov.f64 	%fd78, 0d3F96E91483144EF7;
	fma.rn.f64 	%fd79, %fd77, %fd62, %fd78;
	mov.f64 	%fd80, 0d3F9F1C6E0A4F9F81;
	fma.rn.f64 	%fd81, %fd79, %fd62, %fd80;
	mov.f64 	%fd82, 0d3FA6DB6DC27FA92B;
	fma.rn.f64 	%fd83, %fd81, %fd62, %fd82;
	mov.f64 	%fd84, 0d3FB333333320F91B;
	fma.rn.f64 	%fd85, %fd83, %fd62, %fd84;
	mov.f64 	%fd86, 0d3FC5555555555F4D;
	fma.rn.f64 	%fd87, %fd85, %fd62, %fd86;
	mul.f64 	%fd88, %fd62, %fd87;
	fma.rn.f64 	%fd10, %fd88, %fd1, %fd1;
	setp.lt.s32	%p7, %r6, 0;
	@%p7 bra 	BB9_13;
	bra.uni 	BB9_12;

BB9_13:
	mov.f64 	%fd91, 0d3C91A62633145C07;
	add.rn.f64 	%fd93, %fd10, %fd91;
	bra.uni 	BB9_14;

BB9_4:
	mov.f64 	%fd19, 0d3FF0000000000000;
	sub.f64 	%fd2, %fd19, %fd1;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r28, %temp}, %fd2;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd2;
	}
	add.s32 	%r29, %r7, -1048576;
	mov.b64 	%fd18, {%r28, %r29};
	// inline asm
	rsqrt.approx.ftz.f64 %fd17, %fd18;
	// inline asm
	{
	.reg .b32 %temp; 
	mov.b64 	{%r30, %temp}, %fd17;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd17;
	}
	add.s32 	%r32, %r31, -1048576;
	mov.b64 	%fd20, {%r30, %r32};
	mul.f64 	%fd21, %fd18, %fd17;
	neg.f64 	%fd22, %fd21;
	fma.rn.f64 	%fd23, %fd21, %fd22, %fd18;
	fma.rn.f64 	%fd24, %fd23, %fd20, %fd21;
	neg.f64 	%fd25, %fd24;
	fma.rn.f64 	%fd26, %fd17, %fd25, %fd19;
	fma.rn.f64 	%fd27, %fd26, %fd20, %fd20;
	fma.rn.f64 	%fd28, %fd24, %fd25, %fd18;
	fma.rn.f64 	%fd3, %fd28, %fd27, %fd24;
	setp.lt.s32	%p4, %r7, 1;
	@%p4 bra 	BB9_6;
	bra.uni 	BB9_5;

BB9_6:
	mov.f64 	%fd56, 0d0000000000000000;
	mul.rn.f64 	%fd94, %fd1, %fd56;
	bra.uni 	BB9_7;

BB9_12:
	mov.f64 	%fd89, 0dBC91A62633145C07;
	add.rn.f64 	%fd90, %fd10, %fd89;
	neg.f64 	%fd93, %fd90;

BB9_14:
	mov.f64 	%fd92, 0d3FF921FB54442D18;
	add.rn.f64 	%fd94, %fd92, %fd93;
	bra.uni 	BB9_15;

BB9_5:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r33, %temp}, %fd3;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd3;
	}
	add.s32 	%r35, %r34, 1048576;
	mov.b64 	%fd29, {%r33, %r35};
	mov.f64 	%fd30, 0dBEBAC2FE66FAAC4B;
	mov.f64 	%fd31, 0d3EC715B371155F70;
	fma.rn.f64 	%fd32, %fd31, %fd2, %fd30;
	mov.f64 	%fd33, 0d3ED9A9B88EFCD9B8;
	fma.rn.f64 	%fd34, %fd32, %fd2, %fd33;
	mov.f64 	%fd35, 0d3EDD0F40A8A0C4C3;
	fma.rn.f64 	%fd36, %fd34, %fd2, %fd35;
	mov.f64 	%fd37, 0d3EF46D4CFA9E0E1F;
	fma.rn.f64 	%fd38, %fd36, %fd2, %fd37;
	mov.f64 	%fd39, 0d3F079C168D1E2422;
	fma.rn.f64 	%fd40, %fd38, %fd2, %fd39;
	mov.f64 	%fd41, 0d3F1C9A88C3BCA540;
	fma.rn.f64 	%fd42, %fd40, %fd2, %fd41;
	mov.f64 	%fd43, 0d3F31C4E64BD476DF;
	fma.rn.f64 	%fd44, %fd42, %fd2, %fd43;
	mov.f64 	%fd45, 0d3F46E8BA60009C8F;
	fma.rn.f64 	%fd46, %fd44, %fd2, %fd45;
	mov.f64 	%fd47, 0d3F5F1C71C62B05A2;
	fma.rn.f64 	%fd48, %fd46, %fd2, %fd47;
	mov.f64 	%fd49, 0d3F76DB6DB6DC9F2C;
	fma.rn.f64 	%fd50, %fd48, %fd2, %fd49;
	mov.f64 	%fd51, 0d3F9333333333329C;
	fma.rn.f64 	%fd52, %fd50, %fd2, %fd51;
	mov.f64 	%fd53, 0d3FB5555555555555;
	fma.rn.f64 	%fd54, %fd52, %fd2, %fd53;
	mul.f64 	%fd55, %fd2, %fd54;
	fma.rn.f64 	%fd94, %fd55, %fd29, %fd29;

BB9_7:
	setp.gt.s32	%p5, %r7, -1;
	@%p5 bra 	BB9_9;

	mov.f64 	%fd57, 0d7FF0000000000000;
	mul.rn.f64 	%fd94, %fd94, %fd57;

BB9_9:
	setp.gt.s32	%p6, %r6, -1;
	@%p6 bra 	BB9_15;

	mov.f64 	%fd58, 0dBCA1A62633145C07;
	add.rn.f64 	%fd59, %fd94, %fd58;
	neg.f64 	%fd60, %fd59;
	mov.f64 	%fd61, 0d400921FB54442D18;
	add.rn.f64 	%fd94, %fd61, %fd60;

BB9_15:
	mad.lo.s32 	%r36, %r39, %r12, %r40;
	mul.wide.s32 	%rd7, %r36, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd94;
	add.s32 	%r40, %r2, %r40;
	setp.lt.s32	%p8, %r40, %r10;
	@%p8 bra 	BB9_3;

BB9_16:
	mov.u32 	%r37, %nctaid.x;
	mad.lo.s32 	%r39, %r37, %r15, %r39;
	setp.lt.s32	%p9, %r39, %r11;
	@%p9 bra 	BB9_2;

BB9_17:
	ret;
}

	// .globl	map_acosh_double
.visible .entry map_acosh_double(
	.param .u32 map_acosh_double_param_0,
	.param .u32 map_acosh_double_param_1,
	.param .u64 map_acosh_double_param_2,
	.param .u32 map_acosh_double_param_3,
	.param .u64 map_acosh_double_param_4,
	.param .u32 map_acosh_double_param_5
)
{
	.reg .pred 	%p<18>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<90>;
	.reg .f64 	%fd<160>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r30, [map_acosh_double_param_0];
	ld.param.u32 	%r31, [map_acosh_double_param_1];
	ld.param.u64 	%rd1, [map_acosh_double_param_2];
	ld.param.u32 	%r32, [map_acosh_double_param_3];
	ld.param.u64 	%rd2, [map_acosh_double_param_4];
	ld.param.u32 	%r33, [map_acosh_double_param_5];
	mov.u32 	%r34, %tid.x;
	mov.u32 	%r35, %ntid.x;
	mov.u32 	%r36, %ctaid.x;
	mad.lo.s32 	%r80, %r35, %r36, %r34;
	setp.ge.s32	%p1, %r80, %r31;
	@%p1 bra 	BB10_25;

	mov.u32 	%r37, %ntid.y;
	mov.u32 	%r38, %nctaid.y;
	mul.lo.s32 	%r2, %r38, %r37;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd6, %rd1;

BB10_2:
	mov.u32 	%r39, %ctaid.y;
	mov.u32 	%r41, %tid.y;
	mad.lo.s32 	%r81, %r37, %r39, %r41;
	setp.ge.s32	%p2, %r81, %r30;
	@%p2 bra 	BB10_24;

	mul.lo.s32 	%r4, %r80, %r33;
	mul.lo.s32 	%r5, %r80, %r32;

BB10_4:
	add.s32 	%r46, %r81, %r4;
	mul.wide.s32 	%rd4, %r46, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	add.f64 	%fd156, %fd1, 0dBFF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r86}, %fd156;
	}
	setp.gt.u32	%p3, %r86, 1127219199;
	@%p3 bra 	BB10_15;
	bra.uni 	BB10_5;

BB10_15:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r87, %temp}, %fd156;
	}
	mov.u32 	%r88, -1023;
	setp.gt.s32	%p12, %r86, 1048575;
	@%p12 bra 	BB10_17;

	mul.f64 	%fd156, %fd156, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r86}, %fd156;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r87, %temp}, %fd156;
	}
	mov.u32 	%r88, -1077;

BB10_17:
	add.s32 	%r66, %r86, -1;
	setp.lt.u32	%p13, %r66, 2146435071;
	@%p13 bra 	BB10_19;
	bra.uni 	BB10_18;

BB10_19:
	shr.u32 	%r68, %r86, 20;
	add.s32 	%r89, %r88, %r68;
	and.b32  	%r69, %r86, -2146435073;
	or.b32  	%r70, %r69, 1072693248;
	mov.b64 	%fd157, {%r87, %r70};
	setp.lt.s32	%p15, %r70, 1073127583;
	@%p15 bra 	BB10_21;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r71, %temp}, %fd157;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r72}, %fd157;
	}
	add.s32 	%r73, %r72, -1048576;
	mov.b64 	%fd157, {%r71, %r73};
	add.s32 	%r89, %r89, 1;

BB10_21:
	add.f64 	%fd110, %fd157, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd109,%fd110;
	// inline asm
	neg.f64 	%fd111, %fd110;
	mov.f64 	%fd112, 0d3FF0000000000000;
	fma.rn.f64 	%fd113, %fd111, %fd109, %fd112;
	fma.rn.f64 	%fd114, %fd113, %fd113, %fd113;
	fma.rn.f64 	%fd115, %fd114, %fd109, %fd109;
	add.f64 	%fd116, %fd157, 0dBFF0000000000000;
	mul.f64 	%fd117, %fd116, %fd115;
	fma.rn.f64 	%fd118, %fd116, %fd115, %fd117;
	mul.f64 	%fd119, %fd118, %fd118;
	mov.f64 	%fd120, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd121, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd122, %fd121, %fd119, %fd120;
	mov.f64 	%fd123, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd124, %fd122, %fd119, %fd123;
	mov.f64 	%fd125, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd126, %fd124, %fd119, %fd125;
	mov.f64 	%fd127, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd128, %fd126, %fd119, %fd127;
	mov.f64 	%fd129, 0d3F624924923BE72D;
	fma.rn.f64 	%fd130, %fd128, %fd119, %fd129;
	mov.f64 	%fd131, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd132, %fd130, %fd119, %fd131;
	mov.f64 	%fd133, 0d3FB5555555555554;
	fma.rn.f64 	%fd134, %fd132, %fd119, %fd133;
	sub.f64 	%fd135, %fd116, %fd118;
	add.f64 	%fd136, %fd135, %fd135;
	neg.f64 	%fd137, %fd118;
	fma.rn.f64 	%fd138, %fd137, %fd116, %fd136;
	mul.f64 	%fd139, %fd115, %fd138;
	mul.f64 	%fd140, %fd119, %fd134;
	fma.rn.f64 	%fd141, %fd140, %fd118, %fd139;
	xor.b32  	%r74, %r89, -2147483648;
	mov.u32 	%r75, 1127219200;
	mov.b64 	%fd142, {%r74, %r75};
	mov.u32 	%r76, -2147483648;
	mov.b64 	%fd143, {%r76, %r75};
	sub.f64 	%fd144, %fd142, %fd143;
	mov.f64 	%fd145, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd146, %fd144, %fd145, %fd118;
	neg.f64 	%fd147, %fd144;
	fma.rn.f64 	%fd148, %fd147, %fd145, %fd146;
	sub.f64 	%fd149, %fd148, %fd118;
	sub.f64 	%fd150, %fd141, %fd149;
	mov.f64 	%fd151, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd152, %fd144, %fd151, %fd150;
	add.f64 	%fd158, %fd146, %fd152;
	bra.uni 	BB10_22;

BB10_5:
	fma.rn.f64 	%fd26, %fd1, %fd156, %fd156;
	// inline asm
	rsqrt.approx.ftz.f64 %fd25, %fd26;
	// inline asm
	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd25;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r48}, %fd25;
	}
	add.s32 	%r49, %r48, -1048576;
	mov.b64 	%fd27, {%r47, %r49};
	mul.f64 	%fd28, %fd26, %fd25;
	neg.f64 	%fd29, %fd28;
	fma.rn.f64 	%fd30, %fd28, %fd29, %fd26;
	fma.rn.f64 	%fd31, %fd30, %fd27, %fd28;
	neg.f64 	%fd32, %fd31;
	mov.f64 	%fd33, 0d3FF0000000000000;
	fma.rn.f64 	%fd34, %fd25, %fd32, %fd33;
	fma.rn.f64 	%fd35, %fd34, %fd27, %fd27;
	fma.rn.f64 	%fd36, %fd31, %fd32, %fd26;
	fma.rn.f64 	%fd37, %fd36, %fd35, %fd31;
	add.f64 	%fd3, %fd156, %fd37;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd3;
	}
	setp.lt.u32	%p4, %r50, 1071994197;
	setp.lt.s32	%p5, %r50, -1076258407;
	or.pred  	%p6, %p4, %p5;
	@%p6 bra 	BB10_13;
	bra.uni 	BB10_6;

BB10_13:
	add.f64 	%fd84, %fd3, 0d4000000000000000;
	div.rn.f64 	%fd85, %fd3, %fd84;
	mul.f64 	%fd86, %fd3, %fd85;
	neg.f64 	%fd87, %fd86;
	sub.f64 	%fd88, %fd3, %fd86;
	mul.f64 	%fd89, %fd88, %fd88;
	mov.f64 	%fd90, 0d3ED087FFCEB2DC44;
	mov.f64 	%fd91, 0d3EB372FB2FBE14B5;
	fma.rn.f64 	%fd92, %fd91, %fd89, %fd90;
	mov.f64 	%fd93, 0d3EF3B9FF890F468C;
	fma.rn.f64 	%fd94, %fd92, %fd89, %fd93;
	mov.f64 	%fd95, 0d3F17457EFD51BAF8;
	fma.rn.f64 	%fd96, %fd94, %fd89, %fd95;
	mov.f64 	%fd97, 0d3F3C71C8DE3CE825;
	fma.rn.f64 	%fd98, %fd96, %fd89, %fd97;
	mov.f64 	%fd99, 0d3F6249248FA4661F;
	fma.rn.f64 	%fd100, %fd98, %fd89, %fd99;
	mov.f64 	%fd101, 0d3F899999999D70C4;
	fma.rn.f64 	%fd102, %fd100, %fd89, %fd101;
	mov.f64 	%fd103, 0d3FB5555555555462;
	fma.rn.f64 	%fd104, %fd102, %fd89, %fd103;
	mul.f64 	%fd105, %fd89, %fd104;
	fma.rn.f64 	%fd106, %fd105, %fd88, %fd87;
	add.f64 	%fd155, %fd3, %fd106;
	bra.uni 	BB10_14;

BB10_18:
	mov.f64 	%fd107, 0d7FF0000000000000;
	fma.rn.f64 	%fd108, %fd156, %fd107, %fd107;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r67}, %fd156;
	}
	mov.b32 	 %f2, %r67;
	setp.eq.f32	%p14, %f2, 0f00000000;
	selp.f64	%fd158, 0dFFF0000000000000, %fd108, %p14;

BB10_22:
	add.f64 	%fd159, %fd158, 0d3FE62E42FEFA39EF;
	bra.uni 	BB10_23;

BB10_6:
	add.f64 	%fd153, %fd3, 0d3FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r82}, %fd153;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r83, %temp}, %fd153;
	}
	mov.u32 	%r84, -1023;
	setp.gt.s32	%p7, %r82, 1048575;
	@%p7 bra 	BB10_8;

	mul.f64 	%fd153, %fd153, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r82}, %fd153;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r83, %temp}, %fd153;
	}
	mov.u32 	%r84, -1077;

BB10_8:
	add.s32 	%r53, %r82, -1;
	setp.lt.u32	%p8, %r53, 2146435071;
	@%p8 bra 	BB10_10;
	bra.uni 	BB10_9;

BB10_10:
	shr.u32 	%r55, %r82, 20;
	add.s32 	%r85, %r84, %r55;
	and.b32  	%r56, %r82, -2146435073;
	or.b32  	%r57, %r56, 1072693248;
	mov.b64 	%fd154, {%r83, %r57};
	setp.lt.s32	%p10, %r57, 1073127583;
	@%p10 bra 	BB10_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r58, %temp}, %fd154;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r59}, %fd154;
	}
	add.s32 	%r60, %r59, -1048576;
	mov.b64 	%fd154, {%r58, %r60};
	add.s32 	%r85, %r85, 1;

BB10_12:
	add.f64 	%fd41, %fd154, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd40,%fd41;
	// inline asm
	neg.f64 	%fd42, %fd41;
	fma.rn.f64 	%fd44, %fd42, %fd40, %fd33;
	fma.rn.f64 	%fd45, %fd44, %fd44, %fd44;
	fma.rn.f64 	%fd46, %fd45, %fd40, %fd40;
	add.f64 	%fd47, %fd154, 0dBFF0000000000000;
	mul.f64 	%fd48, %fd47, %fd46;
	fma.rn.f64 	%fd49, %fd47, %fd46, %fd48;
	mul.f64 	%fd50, %fd49, %fd49;
	mov.f64 	%fd51, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd52, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd53, %fd52, %fd50, %fd51;
	mov.f64 	%fd54, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd55, %fd53, %fd50, %fd54;
	mov.f64 	%fd56, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd57, %fd55, %fd50, %fd56;
	mov.f64 	%fd58, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd59, %fd57, %fd50, %fd58;
	mov.f64 	%fd60, 0d3F624924923BE72D;
	fma.rn.f64 	%fd61, %fd59, %fd50, %fd60;
	mov.f64 	%fd62, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd63, %fd61, %fd50, %fd62;
	mov.f64 	%fd64, 0d3FB5555555555554;
	fma.rn.f64 	%fd65, %fd63, %fd50, %fd64;
	sub.f64 	%fd66, %fd47, %fd49;
	add.f64 	%fd67, %fd66, %fd66;
	neg.f64 	%fd68, %fd49;
	fma.rn.f64 	%fd69, %fd68, %fd47, %fd67;
	mul.f64 	%fd70, %fd46, %fd69;
	mul.f64 	%fd71, %fd50, %fd65;
	fma.rn.f64 	%fd72, %fd71, %fd49, %fd70;
	xor.b32  	%r61, %r85, -2147483648;
	mov.u32 	%r62, 1127219200;
	mov.b64 	%fd73, {%r61, %r62};
	mov.u32 	%r63, -2147483648;
	mov.b64 	%fd74, {%r63, %r62};
	sub.f64 	%fd75, %fd73, %fd74;
	mov.f64 	%fd76, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd77, %fd75, %fd76, %fd49;
	neg.f64 	%fd78, %fd75;
	fma.rn.f64 	%fd79, %fd78, %fd76, %fd77;
	sub.f64 	%fd80, %fd79, %fd49;
	sub.f64 	%fd81, %fd72, %fd80;
	mov.f64 	%fd82, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd83, %fd75, %fd82, %fd81;
	add.f64 	%fd155, %fd77, %fd83;
	bra.uni 	BB10_14;

BB10_9:
	mov.f64 	%fd38, 0d7FF0000000000000;
	fma.rn.f64 	%fd39, %fd153, %fd38, %fd38;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r54}, %fd153;
	}
	mov.b32 	 %f1, %r54;
	setp.eq.f32	%p9, %f1, 0f00000000;
	selp.f64	%fd155, 0dFFF0000000000000, %fd39, %p9;

BB10_14:
	setp.eq.s32	%p11, %r86, 0;
	selp.f64	%fd159, %fd156, %fd155, %p11;

BB10_23:
	add.s32 	%r77, %r81, %r5;
	mul.wide.s32 	%rd7, %r77, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd159;
	add.s32 	%r81, %r2, %r81;
	setp.lt.s32	%p16, %r81, %r30;
	@%p16 bra 	BB10_4;

BB10_24:
	mov.u32 	%r78, %nctaid.x;
	mad.lo.s32 	%r80, %r78, %r35, %r80;
	setp.lt.s32	%p17, %r80, %r31;
	@%p17 bra 	BB10_2;

BB10_25:
	ret;
}

	// .globl	map_asin_double
.visible .entry map_asin_double(
	.param .u32 map_asin_double_param_0,
	.param .u32 map_asin_double_param_1,
	.param .u64 map_asin_double_param_2,
	.param .u32 map_asin_double_param_3,
	.param .u64 map_asin_double_param_4,
	.param .u32 map_asin_double_param_5
)
{
	.reg .pred 	%p<8>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<36>;
	.reg .f64 	%fd<83>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r11, [map_asin_double_param_0];
	ld.param.u32 	%r12, [map_asin_double_param_1];
	ld.param.u64 	%rd3, [map_asin_double_param_2];
	ld.param.u32 	%r13, [map_asin_double_param_3];
	ld.param.u64 	%rd4, [map_asin_double_param_4];
	ld.param.u32 	%r14, [map_asin_double_param_5];
	mov.u32 	%r15, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r34, %r15, %r16, %r17;
	setp.ge.s32	%p1, %r34, %r12;
	@%p1 bra 	BB11_9;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r2, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.y;
	mul.lo.s32 	%r3, %r21, %r19;

BB11_2:
	setp.ge.s32	%p2, %r2, %r11;
	@%p2 bra 	BB11_8;

	mul.lo.s32 	%r5, %r34, %r14;
	mul.lo.s32 	%r6, %r34, %r13;
	mov.u32 	%r35, %r2;

BB11_4:
	mov.u32 	%r7, %r35;
	add.s32 	%r22, %r7, %r5;
	mul.wide.s32 	%rd5, %r22, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd1;
	}
	mov.b32 	 %f1, %r8;
	abs.f32 	%f2, %f1;
	setp.lt.f32	%p3, %f2, 0f3FE26666;
	@%p3 bra 	BB11_6;
	bra.uni 	BB11_5;

BB11_6:
	mul.f64 	%fd55, %fd1, %fd1;
	mov.f64 	%fd56, 0dBFB3823B180754AF;
	mov.f64 	%fd57, 0d3FB0066BDC1895E9;
	fma.rn.f64 	%fd58, %fd57, %fd55, %fd56;
	mov.f64 	%fd59, 0d3FB11E52CC2F79AE;
	fma.rn.f64 	%fd60, %fd58, %fd55, %fd59;
	mov.f64 	%fd61, 0dBF924EAF3526861B;
	fma.rn.f64 	%fd62, %fd60, %fd55, %fd61;
	mov.f64 	%fd63, 0d3F91DF02A31E6CB7;
	fma.rn.f64 	%fd64, %fd62, %fd55, %fd63;
	mov.f64 	%fd65, 0d3F847D18B0EEC6CC;
	fma.rn.f64 	%fd66, %fd64, %fd55, %fd65;
	mov.f64 	%fd67, 0d3F8D0AF961BA53B0;
	fma.rn.f64 	%fd68, %fd66, %fd55, %fd67;
	mov.f64 	%fd69, 0d3F91BF7734CF1C48;
	fma.rn.f64 	%fd70, %fd68, %fd55, %fd69;
	mov.f64 	%fd71, 0d3F96E91483144EF7;
	fma.rn.f64 	%fd72, %fd70, %fd55, %fd71;
	mov.f64 	%fd73, 0d3F9F1C6E0A4F9F81;
	fma.rn.f64 	%fd74, %fd72, %fd55, %fd73;
	mov.f64 	%fd75, 0d3FA6DB6DC27FA92B;
	fma.rn.f64 	%fd76, %fd74, %fd55, %fd75;
	mov.f64 	%fd77, 0d3FB333333320F91B;
	fma.rn.f64 	%fd78, %fd76, %fd55, %fd77;
	mov.f64 	%fd79, 0d3FC5555555555F4D;
	fma.rn.f64 	%fd80, %fd78, %fd55, %fd79;
	mul.f64 	%fd81, %fd55, %fd80;
	fma.rn.f64 	%fd82, %fd81, %fd1, %fd1;
	bra.uni 	BB11_7;

BB11_5:
	abs.f64 	%fd7, %fd1;
	mov.f64 	%fd8, 0d3FE0000000000000;
	mov.f64 	%fd9, 0dBFE0000000000000;
	fma.rn.f64 	%fd6, %fd9, %fd7, %fd8;
	// inline asm
	rsqrt.approx.ftz.f64 %fd5, %fd6;
	// inline asm
	{
	.reg .b32 %temp; 
	mov.b64 	{%r23, %temp}, %fd5;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r24}, %fd5;
	}
	add.s32 	%r25, %r24, -1048576;
	mov.b64 	%fd10, {%r23, %r25};
	mul.f64 	%fd11, %fd6, %fd5;
	neg.f64 	%fd12, %fd11;
	fma.rn.f64 	%fd13, %fd11, %fd12, %fd6;
	fma.rn.f64 	%fd14, %fd13, %fd10, %fd11;
	neg.f64 	%fd15, %fd14;
	mov.f64 	%fd16, 0d3FF0000000000000;
	fma.rn.f64 	%fd17, %fd5, %fd15, %fd16;
	fma.rn.f64 	%fd18, %fd17, %fd10, %fd10;
	fma.rn.f64 	%fd19, %fd14, %fd15, %fd6;
	fma.rn.f64 	%fd20, %fd19, %fd18, %fd14;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r26}, %fd6;
	}
	setp.lt.s32	%p4, %r26, 0;
	selp.f64	%fd21, 0dFFF8000000000000, %fd20, %p4;
	setp.equ.f64	%p5, %fd6, 0d0000000000000000;
	selp.f64	%fd22, %fd6, %fd21, %p5;
	mov.f64 	%fd23, 0dBFB3823B180754AF;
	mov.f64 	%fd24, 0d3FB0066BDC1895E9;
	fma.rn.f64 	%fd25, %fd24, %fd6, %fd23;
	mov.f64 	%fd26, 0d3FB11E52CC2F79AE;
	fma.rn.f64 	%fd27, %fd25, %fd6, %fd26;
	mov.f64 	%fd28, 0dBF924EAF3526861B;
	fma.rn.f64 	%fd29, %fd27, %fd6, %fd28;
	mov.f64 	%fd30, 0d3F91DF02A31E6CB7;
	fma.rn.f64 	%fd31, %fd29, %fd6, %fd30;
	mov.f64 	%fd32, 0d3F847D18B0EEC6CC;
	fma.rn.f64 	%fd33, %fd31, %fd6, %fd32;
	mov.f64 	%fd34, 0d3F8D0AF961BA53B0;
	fma.rn.f64 	%fd35, %fd33, %fd6, %fd34;
	mov.f64 	%fd36, 0d3F91BF7734CF1C48;
	fma.rn.f64 	%fd37, %fd35, %fd6, %fd36;
	mov.f64 	%fd38, 0d3F96E91483144EF7;
	fma.rn.f64 	%fd39, %fd37, %fd6, %fd38;
	mov.f64 	%fd40, 0d3F9F1C6E0A4F9F81;
	fma.rn.f64 	%fd41, %fd39, %fd6, %fd40;
	mov.f64 	%fd42, 0d3FA6DB6DC27FA92B;
	fma.rn.f64 	%fd43, %fd41, %fd6, %fd42;
	mov.f64 	%fd44, 0d3FB333333320F91B;
	fma.rn.f64 	%fd45, %fd43, %fd6, %fd44;
	mov.f64 	%fd46, 0d3FC5555555555F4D;
	fma.rn.f64 	%fd47, %fd45, %fd6, %fd46;
	mul.f64 	%fd48, %fd6, %fd47;
	mul.f64 	%fd49, %fd22, 0dC000000000000000;
	mov.f64 	%fd50, 0d3C91A62633145C07;
	fma.rn.f64 	%fd51, %fd49, %fd48, %fd50;
	add.f64 	%fd52, %fd49, 0d3FE921FB54442D18;
	add.f64 	%fd53, %fd52, %fd51;
	add.f64 	%fd54, %fd53, 0d3FE921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r27, %temp}, %fd54;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd54;
	}
	and.b32  	%r29, %r8, -2147483648;
	or.b32  	%r30, %r28, %r29;
	mov.b64 	%fd82, {%r27, %r30};

BB11_7:
	add.s32 	%r31, %r7, %r6;
	mul.wide.s32 	%rd7, %r31, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd82;
	add.s32 	%r9, %r3, %r7;
	setp.lt.s32	%p6, %r9, %r11;
	mov.u32 	%r35, %r9;
	@%p6 bra 	BB11_4;

BB11_8:
	mov.u32 	%r32, %nctaid.x;
	mad.lo.s32 	%r34, %r32, %r15, %r34;
	setp.lt.s32	%p7, %r34, %r12;
	@%p7 bra 	BB11_2;

BB11_9:
	ret;
}

	// .globl	map_asinh_double
.visible .entry map_asinh_double(
	.param .u32 map_asinh_double_param_0,
	.param .u32 map_asinh_double_param_1,
	.param .u64 map_asinh_double_param_2,
	.param .u32 map_asinh_double_param_3,
	.param .u64 map_asinh_double_param_4,
	.param .u32 map_asinh_double_param_5
)
{
	.reg .pred 	%p<17>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<92>;
	.reg .f64 	%fd<161>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r31, [map_asinh_double_param_0];
	ld.param.u32 	%r32, [map_asinh_double_param_1];
	ld.param.u64 	%rd1, [map_asinh_double_param_2];
	ld.param.u32 	%r33, [map_asinh_double_param_3];
	ld.param.u64 	%rd2, [map_asinh_double_param_4];
	ld.param.u32 	%r34, [map_asinh_double_param_5];
	mov.u32 	%r35, %tid.x;
	mov.u32 	%r36, %ntid.x;
	mov.u32 	%r37, %ctaid.x;
	mad.lo.s32 	%r82, %r36, %r37, %r35;
	setp.ge.s32	%p1, %r82, %r32;
	@%p1 bra 	BB12_24;

	mov.u32 	%r38, %tid.y;
	mov.u32 	%r39, %ntid.y;
	mov.u32 	%r40, %ctaid.y;
	mad.lo.s32 	%r2, %r39, %r40, %r38;
	mov.u32 	%r41, %nctaid.y;
	mul.lo.s32 	%r3, %r41, %r39;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd6, %rd1;

BB12_2:
	setp.ge.s32	%p2, %r2, %r31;
	@%p2 bra 	BB12_23;

	mul.lo.s32 	%r5, %r82, %r34;
	mul.lo.s32 	%r6, %r82, %r33;
	mov.u32 	%r83, %r2;

BB12_4:
	mov.u32 	%r7, %r83;
	add.s32 	%r42, %r7, %r5;
	mul.wide.s32 	%rd4, %r42, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd1;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r43, %temp}, %fd1;
	}
	and.b32  	%r44, %r8, 2147483647;
	mov.b64 	%fd157, {%r43, %r44};
	setp.gt.u32	%p3, %r44, 1138753535;
	@%p3 bra 	BB12_14;
	bra.uni 	BB12_5;

BB12_14:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r88}, %fd157;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r89, %temp}, %fd157;
	}
	mov.u32 	%r90, -1023;
	setp.gt.s32	%p11, %r88, 1048575;
	@%p11 bra 	BB12_16;

	mul.f64 	%fd157, %fd157, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r88}, %fd157;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r89, %temp}, %fd157;
	}
	mov.u32 	%r90, -1077;

BB12_16:
	add.s32 	%r64, %r88, -1;
	setp.lt.u32	%p12, %r64, 2146435071;
	@%p12 bra 	BB12_18;
	bra.uni 	BB12_17;

BB12_18:
	shr.u32 	%r66, %r88, 20;
	add.s32 	%r91, %r90, %r66;
	and.b32  	%r67, %r88, -2146435073;
	or.b32  	%r68, %r67, 1072693248;
	mov.b64 	%fd158, {%r89, %r68};
	setp.lt.s32	%p14, %r68, 1073127583;
	@%p14 bra 	BB12_20;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r69, %temp}, %fd158;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd158;
	}
	add.s32 	%r71, %r70, -1048576;
	mov.b64 	%fd158, {%r69, %r71};
	add.s32 	%r91, %r91, 1;

BB12_20:
	add.f64 	%fd111, %fd158, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd110,%fd111;
	// inline asm
	neg.f64 	%fd112, %fd111;
	mov.f64 	%fd113, 0d3FF0000000000000;
	fma.rn.f64 	%fd114, %fd112, %fd110, %fd113;
	fma.rn.f64 	%fd115, %fd114, %fd114, %fd114;
	fma.rn.f64 	%fd116, %fd115, %fd110, %fd110;
	add.f64 	%fd117, %fd158, 0dBFF0000000000000;
	mul.f64 	%fd118, %fd117, %fd116;
	fma.rn.f64 	%fd119, %fd117, %fd116, %fd118;
	mul.f64 	%fd120, %fd119, %fd119;
	mov.f64 	%fd121, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd122, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd123, %fd122, %fd120, %fd121;
	mov.f64 	%fd124, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd125, %fd123, %fd120, %fd124;
	mov.f64 	%fd126, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd127, %fd125, %fd120, %fd126;
	mov.f64 	%fd128, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd129, %fd127, %fd120, %fd128;
	mov.f64 	%fd130, 0d3F624924923BE72D;
	fma.rn.f64 	%fd131, %fd129, %fd120, %fd130;
	mov.f64 	%fd132, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd133, %fd131, %fd120, %fd132;
	mov.f64 	%fd134, 0d3FB5555555555554;
	fma.rn.f64 	%fd135, %fd133, %fd120, %fd134;
	sub.f64 	%fd136, %fd117, %fd119;
	add.f64 	%fd137, %fd136, %fd136;
	neg.f64 	%fd138, %fd119;
	fma.rn.f64 	%fd139, %fd138, %fd117, %fd137;
	mul.f64 	%fd140, %fd116, %fd139;
	mul.f64 	%fd141, %fd120, %fd135;
	fma.rn.f64 	%fd142, %fd141, %fd119, %fd140;
	xor.b32  	%r72, %r91, -2147483648;
	mov.u32 	%r73, 1127219200;
	mov.b64 	%fd143, {%r72, %r73};
	mov.u32 	%r74, -2147483648;
	mov.b64 	%fd144, {%r74, %r73};
	sub.f64 	%fd145, %fd143, %fd144;
	mov.f64 	%fd146, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd147, %fd145, %fd146, %fd119;
	neg.f64 	%fd148, %fd145;
	fma.rn.f64 	%fd149, %fd148, %fd146, %fd147;
	sub.f64 	%fd150, %fd149, %fd119;
	sub.f64 	%fd151, %fd142, %fd150;
	mov.f64 	%fd152, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd153, %fd145, %fd152, %fd151;
	add.f64 	%fd159, %fd147, %fd153;
	bra.uni 	BB12_21;

BB12_5:
	mul.rn.f64 	%fd25, %fd1, %fd1;
	mov.f64 	%fd26, 0d3FF0000000000000;
	fma.rn.f64 	%fd24, %fd1, %fd1, %fd26;
	// inline asm
	rsqrt.approx.ftz.f64 %fd23, %fd24;
	// inline asm
	{
	.reg .b32 %temp; 
	mov.b64 	{%r45, %temp}, %fd23;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r46}, %fd23;
	}
	add.s32 	%r47, %r46, -1048576;
	mov.b64 	%fd27, {%r45, %r47};
	mul.f64 	%fd28, %fd24, %fd23;
	neg.f64 	%fd29, %fd28;
	fma.rn.f64 	%fd30, %fd28, %fd29, %fd24;
	fma.rn.f64 	%fd31, %fd30, %fd27, %fd28;
	neg.f64 	%fd32, %fd31;
	fma.rn.f64 	%fd33, %fd23, %fd32, %fd26;
	fma.rn.f64 	%fd34, %fd33, %fd27, %fd27;
	fma.rn.f64 	%fd35, %fd31, %fd32, %fd24;
	fma.rn.f64 	%fd36, %fd35, %fd34, %fd31;
	add.f64 	%fd37, %fd36, 0d3FF0000000000000;
	div.rn.f64 	%fd38, %fd25, %fd37;
	add.f64 	%fd3, %fd157, %fd38;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r48}, %fd3;
	}
	setp.lt.u32	%p4, %r48, 1071994197;
	setp.lt.s32	%p5, %r48, -1076258407;
	or.pred  	%p6, %p4, %p5;
	@%p6 bra 	BB12_13;
	bra.uni 	BB12_6;

BB12_13:
	add.f64 	%fd85, %fd3, 0d4000000000000000;
	div.rn.f64 	%fd86, %fd3, %fd85;
	mul.f64 	%fd87, %fd3, %fd86;
	neg.f64 	%fd88, %fd87;
	sub.f64 	%fd89, %fd3, %fd87;
	mul.f64 	%fd90, %fd89, %fd89;
	mov.f64 	%fd91, 0d3ED087FFCEB2DC44;
	mov.f64 	%fd92, 0d3EB372FB2FBE14B5;
	fma.rn.f64 	%fd93, %fd92, %fd90, %fd91;
	mov.f64 	%fd94, 0d3EF3B9FF890F468C;
	fma.rn.f64 	%fd95, %fd93, %fd90, %fd94;
	mov.f64 	%fd96, 0d3F17457EFD51BAF8;
	fma.rn.f64 	%fd97, %fd95, %fd90, %fd96;
	mov.f64 	%fd98, 0d3F3C71C8DE3CE825;
	fma.rn.f64 	%fd99, %fd97, %fd90, %fd98;
	mov.f64 	%fd100, 0d3F6249248FA4661F;
	fma.rn.f64 	%fd101, %fd99, %fd90, %fd100;
	mov.f64 	%fd102, 0d3F899999999D70C4;
	fma.rn.f64 	%fd103, %fd101, %fd90, %fd102;
	mov.f64 	%fd104, 0d3FB5555555555462;
	fma.rn.f64 	%fd105, %fd103, %fd90, %fd104;
	mul.f64 	%fd106, %fd90, %fd105;
	fma.rn.f64 	%fd107, %fd106, %fd89, %fd88;
	add.f64 	%fd160, %fd3, %fd107;
	bra.uni 	BB12_22;

BB12_17:
	mov.f64 	%fd108, 0d7FF0000000000000;
	fma.rn.f64 	%fd109, %fd157, %fd108, %fd108;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r65}, %fd157;
	}
	mov.b32 	 %f2, %r65;
	setp.eq.f32	%p13, %f2, 0f00000000;
	selp.f64	%fd159, 0dFFF0000000000000, %fd109, %p13;

BB12_21:
	add.f64 	%fd160, %fd159, 0d3FE62E42FEFA39EF;
	bra.uni 	BB12_22;

BB12_6:
	add.f64 	%fd155, %fd3, 0d3FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r84}, %fd155;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r85, %temp}, %fd155;
	}
	mov.u32 	%r86, -1023;
	setp.gt.s32	%p7, %r84, 1048575;
	@%p7 bra 	BB12_8;

	mul.f64 	%fd155, %fd155, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r84}, %fd155;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r85, %temp}, %fd155;
	}
	mov.u32 	%r86, -1077;

BB12_8:
	add.s32 	%r51, %r84, -1;
	setp.lt.u32	%p8, %r51, 2146435071;
	@%p8 bra 	BB12_10;
	bra.uni 	BB12_9;

BB12_10:
	shr.u32 	%r53, %r84, 20;
	add.s32 	%r87, %r86, %r53;
	and.b32  	%r54, %r84, -2146435073;
	or.b32  	%r55, %r54, 1072693248;
	mov.b64 	%fd156, {%r85, %r55};
	setp.lt.s32	%p10, %r55, 1073127583;
	@%p10 bra 	BB12_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r56, %temp}, %fd156;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r57}, %fd156;
	}
	add.s32 	%r58, %r57, -1048576;
	mov.b64 	%fd156, {%r56, %r58};
	add.s32 	%r87, %r87, 1;

BB12_12:
	add.f64 	%fd42, %fd156, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd41,%fd42;
	// inline asm
	neg.f64 	%fd43, %fd42;
	fma.rn.f64 	%fd45, %fd43, %fd41, %fd26;
	fma.rn.f64 	%fd46, %fd45, %fd45, %fd45;
	fma.rn.f64 	%fd47, %fd46, %fd41, %fd41;
	add.f64 	%fd48, %fd156, 0dBFF0000000000000;
	mul.f64 	%fd49, %fd48, %fd47;
	fma.rn.f64 	%fd50, %fd48, %fd47, %fd49;
	mul.f64 	%fd51, %fd50, %fd50;
	mov.f64 	%fd52, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd53, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd54, %fd53, %fd51, %fd52;
	mov.f64 	%fd55, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd56, %fd54, %fd51, %fd55;
	mov.f64 	%fd57, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd58, %fd56, %fd51, %fd57;
	mov.f64 	%fd59, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd60, %fd58, %fd51, %fd59;
	mov.f64 	%fd61, 0d3F624924923BE72D;
	fma.rn.f64 	%fd62, %fd60, %fd51, %fd61;
	mov.f64 	%fd63, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd64, %fd62, %fd51, %fd63;
	mov.f64 	%fd65, 0d3FB5555555555554;
	fma.rn.f64 	%fd66, %fd64, %fd51, %fd65;
	sub.f64 	%fd67, %fd48, %fd50;
	add.f64 	%fd68, %fd67, %fd67;
	neg.f64 	%fd69, %fd50;
	fma.rn.f64 	%fd70, %fd69, %fd48, %fd68;
	mul.f64 	%fd71, %fd47, %fd70;
	mul.f64 	%fd72, %fd51, %fd66;
	fma.rn.f64 	%fd73, %fd72, %fd50, %fd71;
	xor.b32  	%r59, %r87, -2147483648;
	mov.u32 	%r60, 1127219200;
	mov.b64 	%fd74, {%r59, %r60};
	mov.u32 	%r61, -2147483648;
	mov.b64 	%fd75, {%r61, %r60};
	sub.f64 	%fd76, %fd74, %fd75;
	mov.f64 	%fd77, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd78, %fd76, %fd77, %fd50;
	neg.f64 	%fd79, %fd76;
	fma.rn.f64 	%fd80, %fd79, %fd77, %fd78;
	sub.f64 	%fd81, %fd80, %fd50;
	sub.f64 	%fd82, %fd73, %fd81;
	mov.f64 	%fd83, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd84, %fd76, %fd83, %fd82;
	add.f64 	%fd160, %fd78, %fd84;
	bra.uni 	BB12_22;

BB12_9:
	mov.f64 	%fd39, 0d7FF0000000000000;
	fma.rn.f64 	%fd40, %fd155, %fd39, %fd39;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r52}, %fd155;
	}
	mov.b32 	 %f1, %r52;
	setp.eq.f32	%p9, %f1, 0f00000000;
	selp.f64	%fd160, 0dFFF0000000000000, %fd40, %p9;

BB12_22:
	and.b32  	%r75, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r76}, %fd160;
	}
	or.b32  	%r77, %r76, %r75;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r78, %temp}, %fd160;
	}
	mov.b64 	%fd154, {%r78, %r77};
	add.s32 	%r79, %r7, %r6;
	mul.wide.s32 	%rd7, %r79, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd154;
	add.s32 	%r29, %r3, %r7;
	setp.lt.s32	%p15, %r29, %r31;
	mov.u32 	%r83, %r29;
	@%p15 bra 	BB12_4;

BB12_23:
	mov.u32 	%r80, %nctaid.x;
	mad.lo.s32 	%r82, %r80, %r36, %r82;
	setp.lt.s32	%p16, %r82, %r32;
	@%p16 bra 	BB12_2;

BB12_24:
	ret;
}

	// .globl	map_atan_double
.visible .entry map_atan_double(
	.param .u32 map_atan_double_param_0,
	.param .u32 map_atan_double_param_1,
	.param .u64 map_atan_double_param_2,
	.param .u32 map_atan_double_param_3,
	.param .u64 map_atan_double_param_4,
	.param .u32 map_atan_double_param_5
)
{
	.reg .pred 	%p<8>;
	.reg .b32 	%r<32>;
	.reg .f64 	%fd<57>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r10, [map_atan_double_param_0];
	ld.param.u32 	%r11, [map_atan_double_param_1];
	ld.param.u64 	%rd3, [map_atan_double_param_2];
	ld.param.u32 	%r12, [map_atan_double_param_3];
	ld.param.u64 	%rd4, [map_atan_double_param_4];
	ld.param.u32 	%r13, [map_atan_double_param_5];
	mov.u32 	%r14, %ntid.x;
	mov.u32 	%r15, %ctaid.x;
	mov.u32 	%r16, %tid.x;
	mad.lo.s32 	%r30, %r14, %r15, %r16;
	setp.ge.s32	%p1, %r30, %r11;
	@%p1 bra 	BB13_8;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r17, %tid.y;
	mov.u32 	%r18, %ntid.y;
	mov.u32 	%r19, %ctaid.y;
	mad.lo.s32 	%r2, %r18, %r19, %r17;
	mov.u32 	%r20, %nctaid.y;
	mul.lo.s32 	%r3, %r20, %r18;

BB13_2:
	setp.ge.s32	%p2, %r2, %r10;
	@%p2 bra 	BB13_7;

	mul.lo.s32 	%r5, %r30, %r13;
	mul.lo.s32 	%r6, %r30, %r12;
	mov.u32 	%r31, %r2;

BB13_4:
	mov.u32 	%r7, %r31;
	add.s32 	%r21, %r7, %r5;
	mul.wide.s32 	%rd5, %r21, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	abs.f64 	%fd2, %fd1;
	setp.leu.f64	%p3, %fd2, 0d3FF0000000000000;
	mov.f64 	%fd56, %fd2;
	@%p3 bra 	BB13_6;

	// inline asm
	rcp.approx.ftz.f64 %fd5,%fd2;
	// inline asm
	neg.f64 	%fd7, %fd2;
	mov.f64 	%fd8, 0d3FF0000000000000;
	fma.rn.f64 	%fd9, %fd7, %fd5, %fd8;
	fma.rn.f64 	%fd10, %fd9, %fd9, %fd9;
	fma.rn.f64 	%fd11, %fd10, %fd5, %fd5;
	setp.eq.f64	%p4, %fd2, 0d7FF0000000000000;
	selp.f64	%fd3, 0d0000000000000000, %fd11, %p4;
	mov.f64 	%fd56, %fd3;

BB13_6:
	mov.f64 	%fd4, %fd56;
	mul.f64 	%fd12, %fd4, %fd4;
	mov.f64 	%fd13, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd14, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd15, %fd14, %fd12, %fd13;
	mov.f64 	%fd16, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd17, %fd15, %fd12, %fd16;
	mov.f64 	%fd18, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd19, %fd17, %fd12, %fd18;
	mov.f64 	%fd20, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd21, %fd19, %fd12, %fd20;
	mov.f64 	%fd22, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd23, %fd21, %fd12, %fd22;
	mov.f64 	%fd24, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd25, %fd23, %fd12, %fd24;
	mov.f64 	%fd26, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd27, %fd25, %fd12, %fd26;
	mov.f64 	%fd28, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd29, %fd27, %fd12, %fd28;
	mov.f64 	%fd30, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd31, %fd29, %fd12, %fd30;
	mov.f64 	%fd32, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd33, %fd31, %fd12, %fd32;
	mov.f64 	%fd34, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd35, %fd33, %fd12, %fd34;
	mov.f64 	%fd36, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd37, %fd35, %fd12, %fd36;
	mov.f64 	%fd38, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd39, %fd37, %fd12, %fd38;
	mov.f64 	%fd40, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd41, %fd39, %fd12, %fd40;
	mov.f64 	%fd42, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd43, %fd41, %fd12, %fd42;
	mov.f64 	%fd44, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd45, %fd43, %fd12, %fd44;
	mov.f64 	%fd46, 0d3FC99999999840D2;
	fma.rn.f64 	%fd47, %fd45, %fd12, %fd46;
	mov.f64 	%fd48, 0dBFD555555555544C;
	fma.rn.f64 	%fd49, %fd47, %fd12, %fd48;
	mul.f64 	%fd50, %fd12, %fd49;
	fma.rn.f64 	%fd51, %fd50, %fd4, %fd4;
	mov.f64 	%fd52, 0d3FF921FB54442D18;
	sub.f64 	%fd53, %fd52, %fd51;
	setp.gt.f64	%p5, %fd2, 0d3FF0000000000000;
	selp.f64	%fd54, %fd53, %fd51, %p5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd54;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd54;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r24}, %fd1;
	}
	and.b32  	%r25, %r24, -2147483648;
	or.b32  	%r26, %r23, %r25;
	mov.b64 	%fd55, {%r22, %r26};
	add.s32 	%r27, %r7, %r6;
	mul.wide.s32 	%rd7, %r27, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd55;
	add.s32 	%r8, %r3, %r7;
	setp.lt.s32	%p6, %r8, %r10;
	mov.u32 	%r31, %r8;
	@%p6 bra 	BB13_4;

BB13_7:
	mov.u32 	%r28, %nctaid.x;
	mad.lo.s32 	%r30, %r28, %r14, %r30;
	setp.lt.s32	%p7, %r30, %r11;
	@%p7 bra 	BB13_2;

BB13_8:
	ret;
}

	// .globl	map_atanh_double
.visible .entry map_atanh_double(
	.param .u32 map_atanh_double_param_0,
	.param .u32 map_atanh_double_param_1,
	.param .u64 map_atanh_double_param_2,
	.param .u32 map_atanh_double_param_3,
	.param .u64 map_atanh_double_param_4,
	.param .u32 map_atanh_double_param_5
)
{
	.reg .pred 	%p<12>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<60>;
	.reg .f64 	%fd<91>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r20, [map_atanh_double_param_0];
	ld.param.u32 	%r21, [map_atanh_double_param_1];
	ld.param.u64 	%rd1, [map_atanh_double_param_2];
	ld.param.u32 	%r22, [map_atanh_double_param_3];
	ld.param.u64 	%rd2, [map_atanh_double_param_4];
	ld.param.u32 	%r23, [map_atanh_double_param_5];
	mov.u32 	%r24, %tid.x;
	mov.u32 	%r25, %ntid.x;
	mov.u32 	%r26, %ctaid.x;
	mad.lo.s32 	%r54, %r25, %r26, %r24;
	setp.ge.s32	%p1, %r54, %r21;
	@%p1 bra 	BB14_15;

	mov.u32 	%r27, %tid.y;
	mov.u32 	%r28, %ntid.y;
	mov.u32 	%r29, %ctaid.y;
	mad.lo.s32 	%r2, %r28, %r29, %r27;
	mov.u32 	%r30, %nctaid.y;
	mul.lo.s32 	%r3, %r30, %r28;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd6, %rd1;

BB14_2:
	setp.ge.s32	%p2, %r2, %r20;
	@%p2 bra 	BB14_14;

	mul.lo.s32 	%r5, %r54, %r23;
	mul.lo.s32 	%r6, %r54, %r22;
	mov.u32 	%r55, %r2;

BB14_4:
	mov.u32 	%r7, %r55;
	add.s32 	%r31, %r7, %r5;
	mul.wide.s32 	%rd4, %r31, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	abs.f64 	%fd13, %fd1;
	add.f64 	%fd14, %fd13, %fd13;
	mov.f64 	%fd15, 0d3FF0000000000000;
	sub.f64 	%fd16, %fd15, %fd13;
	div.rn.f64 	%fd2, %fd14, %fd16;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd2;
	}
	setp.lt.u32	%p3, %r32, 1071994197;
	setp.lt.s32	%p4, %r32, -1076258407;
	or.pred  	%p5, %p3, %p4;
	@%p5 bra 	BB14_12;
	bra.uni 	BB14_5;

BB14_12:
	add.f64 	%fd63, %fd2, 0d4000000000000000;
	div.rn.f64 	%fd64, %fd2, %fd63;
	mul.f64 	%fd65, %fd2, %fd64;
	neg.f64 	%fd66, %fd65;
	sub.f64 	%fd67, %fd2, %fd65;
	mul.f64 	%fd68, %fd67, %fd67;
	mov.f64 	%fd69, 0d3ED087FFCEB2DC44;
	mov.f64 	%fd70, 0d3EB372FB2FBE14B5;
	fma.rn.f64 	%fd71, %fd70, %fd68, %fd69;
	mov.f64 	%fd72, 0d3EF3B9FF890F468C;
	fma.rn.f64 	%fd73, %fd71, %fd68, %fd72;
	mov.f64 	%fd74, 0d3F17457EFD51BAF8;
	fma.rn.f64 	%fd75, %fd73, %fd68, %fd74;
	mov.f64 	%fd76, 0d3F3C71C8DE3CE825;
	fma.rn.f64 	%fd77, %fd75, %fd68, %fd76;
	mov.f64 	%fd78, 0d3F6249248FA4661F;
	fma.rn.f64 	%fd79, %fd77, %fd68, %fd78;
	mov.f64 	%fd80, 0d3F899999999D70C4;
	fma.rn.f64 	%fd81, %fd79, %fd68, %fd80;
	mov.f64 	%fd82, 0d3FB5555555555462;
	fma.rn.f64 	%fd83, %fd81, %fd68, %fd82;
	mul.f64 	%fd84, %fd68, %fd83;
	fma.rn.f64 	%fd85, %fd84, %fd67, %fd66;
	add.f64 	%fd90, %fd2, %fd85;
	bra.uni 	BB14_13;

BB14_5:
	add.f64 	%fd88, %fd2, 0d3FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r56}, %fd88;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r57, %temp}, %fd88;
	}
	mov.u32 	%r58, -1023;
	setp.gt.s32	%p6, %r56, 1048575;
	@%p6 bra 	BB14_7;

	mul.f64 	%fd88, %fd88, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r56}, %fd88;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r57, %temp}, %fd88;
	}
	mov.u32 	%r58, -1077;

BB14_7:
	add.s32 	%r35, %r56, -1;
	setp.lt.u32	%p7, %r35, 2146435071;
	@%p7 bra 	BB14_9;
	bra.uni 	BB14_8;

BB14_9:
	shr.u32 	%r37, %r56, 20;
	add.s32 	%r59, %r58, %r37;
	and.b32  	%r38, %r56, -2146435073;
	or.b32  	%r39, %r38, 1072693248;
	mov.b64 	%fd89, {%r57, %r39};
	setp.lt.s32	%p9, %r39, 1073127583;
	@%p9 bra 	BB14_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r40, %temp}, %fd89;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r41}, %fd89;
	}
	add.s32 	%r42, %r41, -1048576;
	mov.b64 	%fd89, {%r40, %r42};
	add.s32 	%r59, %r59, 1;

BB14_11:
	add.f64 	%fd20, %fd89, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd19,%fd20;
	// inline asm
	neg.f64 	%fd21, %fd20;
	fma.rn.f64 	%fd23, %fd21, %fd19, %fd15;
	fma.rn.f64 	%fd24, %fd23, %fd23, %fd23;
	fma.rn.f64 	%fd25, %fd24, %fd19, %fd19;
	add.f64 	%fd26, %fd89, 0dBFF0000000000000;
	mul.f64 	%fd27, %fd26, %fd25;
	fma.rn.f64 	%fd28, %fd26, %fd25, %fd27;
	mul.f64 	%fd29, %fd28, %fd28;
	mov.f64 	%fd30, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd31, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd32, %fd31, %fd29, %fd30;
	mov.f64 	%fd33, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd34, %fd32, %fd29, %fd33;
	mov.f64 	%fd35, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd36, %fd34, %fd29, %fd35;
	mov.f64 	%fd37, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd38, %fd36, %fd29, %fd37;
	mov.f64 	%fd39, 0d3F624924923BE72D;
	fma.rn.f64 	%fd40, %fd38, %fd29, %fd39;
	mov.f64 	%fd41, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd42, %fd40, %fd29, %fd41;
	mov.f64 	%fd43, 0d3FB5555555555554;
	fma.rn.f64 	%fd44, %fd42, %fd29, %fd43;
	sub.f64 	%fd45, %fd26, %fd28;
	add.f64 	%fd46, %fd45, %fd45;
	neg.f64 	%fd47, %fd28;
	fma.rn.f64 	%fd48, %fd47, %fd26, %fd46;
	mul.f64 	%fd49, %fd25, %fd48;
	mul.f64 	%fd50, %fd29, %fd44;
	fma.rn.f64 	%fd51, %fd50, %fd28, %fd49;
	xor.b32  	%r43, %r59, -2147483648;
	mov.u32 	%r44, 1127219200;
	mov.b64 	%fd52, {%r43, %r44};
	mov.u32 	%r45, -2147483648;
	mov.b64 	%fd53, {%r45, %r44};
	sub.f64 	%fd54, %fd52, %fd53;
	mov.f64 	%fd55, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd56, %fd54, %fd55, %fd28;
	neg.f64 	%fd57, %fd54;
	fma.rn.f64 	%fd58, %fd57, %fd55, %fd56;
	sub.f64 	%fd59, %fd58, %fd28;
	sub.f64 	%fd60, %fd51, %fd59;
	mov.f64 	%fd61, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd62, %fd54, %fd61, %fd60;
	add.f64 	%fd90, %fd56, %fd62;
	bra.uni 	BB14_13;

BB14_8:
	mov.f64 	%fd17, 0d7FF0000000000000;
	fma.rn.f64 	%fd18, %fd88, %fd17, %fd17;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd88;
	}
	mov.b32 	 %f1, %r36;
	setp.eq.f32	%p8, %f1, 0f00000000;
	selp.f64	%fd90, 0dFFF0000000000000, %fd18, %p8;

BB14_13:
	mul.f64 	%fd86, %fd90, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd86;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd86;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r48}, %fd1;
	}
	and.b32  	%r49, %r48, -2147483648;
	or.b32  	%r50, %r47, %r49;
	mov.b64 	%fd87, {%r46, %r50};
	add.s32 	%r51, %r7, %r6;
	mul.wide.s32 	%rd7, %r51, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd87;
	add.s32 	%r18, %r3, %r7;
	setp.lt.s32	%p10, %r18, %r20;
	mov.u32 	%r55, %r18;
	@%p10 bra 	BB14_4;

BB14_14:
	mov.u32 	%r52, %nctaid.x;
	mad.lo.s32 	%r54, %r52, %r25, %r54;
	setp.lt.s32	%p11, %r54, %r21;
	@%p11 bra 	BB14_2;

BB14_15:
	ret;
}

	// .globl	map_cbrt_double
.visible .entry map_cbrt_double(
	.param .u32 map_cbrt_double_param_0,
	.param .u32 map_cbrt_double_param_1,
	.param .u64 map_cbrt_double_param_2,
	.param .u32 map_cbrt_double_param_3,
	.param .u64 map_cbrt_double_param_4,
	.param .u32 map_cbrt_double_param_5
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<59>;
	.reg .f64 	%fd<24>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r21, [map_cbrt_double_param_0];
	ld.param.u32 	%r22, [map_cbrt_double_param_1];
	ld.param.u64 	%rd2, [map_cbrt_double_param_2];
	ld.param.u32 	%r23, [map_cbrt_double_param_3];
	ld.param.u64 	%rd3, [map_cbrt_double_param_4];
	ld.param.u32 	%r24, [map_cbrt_double_param_5];
	mov.u32 	%r25, %ntid.x;
	mov.u32 	%r26, %ctaid.x;
	mov.u32 	%r27, %tid.x;
	mad.lo.s32 	%r53, %r25, %r26, %r27;
	setp.ge.s32	%p1, %r53, %r22;
	@%p1 bra 	BB15_11;

	cvta.to.global.u64 	%rd1, %rd3;
	mov.u32 	%r28, %tid.y;
	mov.u32 	%r29, %ntid.y;
	mov.u32 	%r30, %ctaid.y;
	mad.lo.s32 	%r2, %r29, %r30, %r28;
	mov.u32 	%r31, %nctaid.y;
	mul.lo.s32 	%r3, %r31, %r29;
	cvta.to.global.u64 	%rd6, %rd2;

BB15_2:
	setp.ge.s32	%p2, %r2, %r21;
	@%p2 bra 	BB15_10;

	mul.lo.s32 	%r5, %r53, %r24;
	mul.lo.s32 	%r6, %r53, %r23;
	mov.u32 	%r54, %r2;

BB15_4:
	mov.u32 	%r7, %r54;
	add.s32 	%r32, %r7, %r5;
	mul.wide.s32 	%rd4, %r32, 8;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%r55, %temp}, %fd1;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd1;
	}
	and.b32  	%r56, %r9, 2147483647;
	setp.neu.f64	%p3, %fd1, 0d0000000000000000;
	setp.lt.u32	%p4, %r56, 2146435072;
	and.pred  	%p5, %p3, %p4;
	@%p5 bra 	BB15_6;
	bra.uni 	BB15_5;

BB15_6:
	shr.u32 	%r57, %r56, 20;
	mov.u32 	%r58, 0;
	setp.ne.s32	%p6, %r57, 0;
	@%p6 bra 	BB15_8;

	mov.b64 	%fd5, {%r55, %r56};
	mul.f64 	%fd6, %fd5, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r55, %temp}, %fd6;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r56}, %fd6;
	}
	shr.u32 	%r57, %r56, 20;
	mov.u32 	%r58, 18;

BB15_8:
	add.s32 	%r35, %r57, -1022;
	cvt.rn.f32.s32	%f5, %r35;
	mul.f32 	%f6, %f5, 0f3EAAAAAB;
	cvt.rni.s32.f32	%r36, %f6;
	mad.lo.s32 	%r37, %r36, -3145728, %r56;
	mov.b64 	%fd9, {%r55, %r37};
	cvt.rn.f32.f64	%f2, %fd9;
	// inline asm
	lg2.approx.ftz.f32 %f1,%f2;
	// inline asm
	mul.f32 	%f4, %f1, 0f3EAAAAAB;
	// inline asm
	ex2.approx.ftz.f32 %f3,%f4;
	// inline asm
	cvt.f64.f32	%fd10, %f3;
	mul.f64 	%fd11, %fd10, %fd10;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd11;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r39}, %fd11;
	}
	add.s32 	%r40, %r39, 1048576;
	mov.b64 	%fd12, {%r38, %r40};
	fma.rn.f64 	%fd8, %fd12, %fd10, %fd9;
	// inline asm
	rcp.approx.ftz.f64 %fd7,%fd8;
	// inline asm
	neg.f64 	%fd13, %fd8;
	mov.f64 	%fd14, 0d3FF0000000000000;
	fma.rn.f64 	%fd15, %fd13, %fd7, %fd14;
	fma.rn.f64 	%fd16, %fd15, %fd15, %fd15;
	fma.rn.f64 	%fd17, %fd16, %fd7, %fd7;
	neg.f64 	%fd18, %fd10;
	fma.rn.f64 	%fd19, %fd11, %fd18, %fd9;
	mul.f64 	%fd20, %fd17, %fd19;
	fma.rn.f64 	%fd21, %fd10, %fd20, %fd10;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r41, %temp}, %fd21;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r42}, %fd21;
	}
	sub.s32 	%r43, %r36, %r58;
	shl.b32 	%r44, %r43, 20;
	add.s32 	%r45, %r42, %r44;
	mov.b64 	%fd22, {%r41, %r45};
	{
	.reg .b32 %temp; 
	mov.b64 	{%r46, %temp}, %fd22;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd22;
	}
	and.b32  	%r48, %r9, -2147483648;
	or.b32  	%r49, %r47, %r48;
	mov.b64 	%fd23, {%r46, %r49};
	bra.uni 	BB15_9;

BB15_5:
	add.f64 	%fd23, %fd1, %fd1;

BB15_9:
	add.s32 	%r50, %r7, %r6;
	mul.wide.s32 	%rd7, %r50, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd23;
	add.s32 	%r19, %r3, %r7;
	setp.lt.s32	%p7, %r19, %r21;
	mov.u32 	%r54, %r19;
	@%p7 bra 	BB15_4;

BB15_10:
	mov.u32 	%r51, %nctaid.x;
	mad.lo.s32 	%r53, %r51, %r25, %r53;
	setp.lt.s32	%p8, %r53, %r22;
	@%p8 bra 	BB15_2;

BB15_11:
	ret;
}

	// .globl	map_ceil_double
.visible .entry map_ceil_double(
	.param .u32 map_ceil_double_param_0,
	.param .u32 map_ceil_double_param_1,
	.param .u64 map_ceil_double_param_2,
	.param .u32 map_ceil_double_param_3,
	.param .u64 map_ceil_double_param_4,
	.param .u32 map_ceil_double_param_5
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map_ceil_double_param_0];
	ld.param.u32 	%r13, [map_ceil_double_param_1];
	ld.param.u64 	%rd3, [map_ceil_double_param_2];
	ld.param.u32 	%r14, [map_ceil_double_param_3];
	ld.param.u64 	%rd4, [map_ceil_double_param_4];
	ld.param.u32 	%r15, [map_ceil_double_param_5];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB16_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB16_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB16_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB16_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	cvt.rpi.f64.f64	%fd2, %fd1;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd2;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB16_4;

BB16_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB16_2;

BB16_6:
	ret;
}

	// .globl	map_cos_double
.visible .entry map_cos_double(
	.param .u32 map_cos_double_param_0,
	.param .u32 map_cos_double_param_1,
	.param .u64 map_cos_double_param_2,
	.param .u32 map_cos_double_param_3,
	.param .u64 map_cos_double_param_4,
	.param .u32 map_cos_double_param_5
)
{
	.local .align 4 .b8 	__local_depot17[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .b32 	%r<45>;
	.reg .f64 	%fd<41>;
	.reg .b64 	%rd<17>;


	mov.u64 	%rd16, __local_depot17;
	cvta.local.u64 	%SP, %rd16;
	ld.param.u32 	%r14, [map_cos_double_param_0];
	ld.param.u32 	%r15, [map_cos_double_param_1];
	ld.param.u64 	%rd1, [map_cos_double_param_2];
	ld.param.u32 	%r16, [map_cos_double_param_3];
	ld.param.u64 	%rd2, [map_cos_double_param_4];
	ld.param.u32 	%r17, [map_cos_double_param_5];
	mov.u32 	%r18, %ntid.x;
	mov.u32 	%r19, %ctaid.x;
	mov.u32 	%r20, %tid.x;
	mad.lo.s32 	%r42, %r18, %r19, %r20;
	setp.ge.s32	%p1, %r42, %r15;
	@%p1 bra 	BB17_15;

	mov.u32 	%r21, %ntid.y;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r2, %r22, %r21;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd13, %rd1;

BB17_2:
	mov.u32 	%r23, %ctaid.y;
	mov.u32 	%r25, %tid.y;
	mad.lo.s32 	%r43, %r21, %r23, %r25;
	setp.ge.s32	%p2, %r43, %r14;
	@%p2 bra 	BB17_14;

	mul.lo.s32 	%r4, %r42, %r17;
	mul.lo.s32 	%r5, %r42, %r16;

BB17_4:
	add.s32 	%r30, %r43, %r4;
	mul.wide.s32 	%rd4, %r30, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd38, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd38;
	}
	and.b32  	%r32, %r31, 2147483647;
	setp.ne.s32	%p3, %r32, 2146435072;
	@%p3 bra 	BB17_7;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r33, %temp}, %fd38;
	}
	setp.ne.s32	%p4, %r33, 0;
	@%p4 bra 	BB17_7;

	mov.f64 	%fd14, 0d0000000000000000;
	mul.rn.f64 	%fd38, %fd38, %fd14;

BB17_7:
	mul.f64 	%fd15, %fd38, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r44, %fd15;
	add.u64 	%rd6, %SP, 0;
	cvta.to.local.u64 	%rd7, %rd6;
	st.local.u32 	[%rd7], %r44;
	cvt.rn.f64.s32	%fd16, %r44;
	neg.f64 	%fd17, %fd16;
	mov.f64 	%fd18, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd19, %fd17, %fd18, %fd38;
	mov.f64 	%fd20, 0d3C91A62633145C00;
	fma.rn.f64 	%fd21, %fd17, %fd20, %fd19;
	mov.f64 	%fd22, 0d397B839A252049C0;
	fma.rn.f64 	%fd39, %fd17, %fd22, %fd21;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd38;
	}
	and.b32  	%r35, %r34, 2145386496;
	setp.lt.u32	%p5, %r35, 1105199104;
	@%p5 bra 	BB17_9;

	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd38;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd6;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd39, [retval0+0];
	
	//{
	}// Callseq End 2
	ld.local.u32 	%r44, [%rd7];

BB17_9:
	add.s32 	%r11, %r44, 1;
	and.b32  	%r36, %r11, 1;
	shl.b32 	%r37, %r36, 3;
	setp.eq.s32	%p6, %r36, 0;
	selp.f64	%fd23, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p6;
	mul.wide.u32 	%rd10, %r37, 8;
	mov.u64 	%rd11, __cudart_sin_cos_coeffs;
	add.s64 	%rd12, %rd10, %rd11;
	ld.const.f64 	%fd24, [%rd12+8];
	mul.rn.f64 	%fd7, %fd39, %fd39;
	fma.rn.f64 	%fd25, %fd23, %fd7, %fd24;
	ld.const.f64 	%fd26, [%rd12+16];
	fma.rn.f64 	%fd27, %fd25, %fd7, %fd26;
	ld.const.f64 	%fd28, [%rd12+24];
	fma.rn.f64 	%fd29, %fd27, %fd7, %fd28;
	ld.const.f64 	%fd30, [%rd12+32];
	fma.rn.f64 	%fd31, %fd29, %fd7, %fd30;
	ld.const.f64 	%fd32, [%rd12+40];
	fma.rn.f64 	%fd33, %fd31, %fd7, %fd32;
	ld.const.f64 	%fd34, [%rd12+48];
	fma.rn.f64 	%fd8, %fd33, %fd7, %fd34;
	fma.rn.f64 	%fd40, %fd8, %fd39, %fd39;
	@%p6 bra 	BB17_11;

	mov.f64 	%fd35, 0d3FF0000000000000;
	fma.rn.f64 	%fd40, %fd8, %fd7, %fd35;

BB17_11:
	and.b32  	%r38, %r11, 2;
	setp.eq.s32	%p7, %r38, 0;
	@%p7 bra 	BB17_13;

	mov.f64 	%fd36, 0d0000000000000000;
	mov.f64 	%fd37, 0dBFF0000000000000;
	fma.rn.f64 	%fd40, %fd40, %fd37, %fd36;

BB17_13:
	add.s32 	%r39, %r43, %r5;
	mul.wide.s32 	%rd14, %r39, 8;
	add.s64 	%rd15, %rd13, %rd14;
	st.global.f64 	[%rd15], %fd40;
	add.s32 	%r43, %r2, %r43;
	setp.lt.s32	%p8, %r43, %r14;
	@%p8 bra 	BB17_4;

BB17_14:
	mov.u32 	%r40, %nctaid.x;
	mad.lo.s32 	%r42, %r40, %r18, %r42;
	setp.lt.s32	%p9, %r42, %r15;
	@%p9 bra 	BB17_2;

BB17_15:
	ret;
}

	// .globl	map_cosh_double
.visible .entry map_cosh_double(
	.param .u32 map_cosh_double_param_0,
	.param .u32 map_cosh_double_param_1,
	.param .u64 map_cosh_double_param_2,
	.param .u32 map_cosh_double_param_3,
	.param .u64 map_cosh_double_param_4,
	.param .u32 map_cosh_double_param_5
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<39>;
	.reg .f64 	%fd<46>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map_cosh_double_param_0];
	ld.param.u32 	%r13, [map_cosh_double_param_1];
	ld.param.u64 	%rd3, [map_cosh_double_param_2];
	ld.param.u64 	%rd4, [map_cosh_double_param_4];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r37, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r37, %r13;
	@%p1 bra 	BB18_9;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB18_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB18_8;

	ld.param.u32 	%r36, [map_cosh_double_param_3];
	ld.param.u32 	%r35, [map_cosh_double_param_5];
	mul.lo.s32 	%r7, %r37, %r35;
	mul.lo.s32 	%r8, %r37, %r36;
	mov.u32 	%r38, %r3;

BB18_4:
	mov.u32 	%r9, %r38;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r24}, %fd1;
	}
	and.b32  	%r25, %r24, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r26, %temp}, %fd1;
	}
	mov.b64 	%fd2, {%r26, %r25};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd2;
	}
	setp.lt.u32	%p3, %r27, 1082536911;
	@%p3 bra 	BB18_6;
	bra.uni 	BB18_5;

BB18_6:
	mov.f64 	%fd8, 0d4338000000000000;
	mov.f64 	%fd9, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd10, %fd2, %fd9, %fd8;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r28, %temp}, %fd10;
	}
	mov.f64 	%fd11, 0dC338000000000000;
	add.rn.f64 	%fd12, %fd10, %fd11;
	mov.f64 	%fd13, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd14, %fd12, %fd13, %fd2;
	mov.f64 	%fd15, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd16, %fd12, %fd15, %fd14;
	mov.f64 	%fd17, 0d3E928AF3FCA213EA;
	mov.f64 	%fd18, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd19, %fd18, %fd16, %fd17;
	mov.f64 	%fd20, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd21, %fd19, %fd16, %fd20;
	mov.f64 	%fd22, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd23, %fd21, %fd16, %fd22;
	mov.f64 	%fd24, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd25, %fd23, %fd16, %fd24;
	mov.f64 	%fd26, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd27, %fd25, %fd16, %fd26;
	mov.f64 	%fd28, 0d3F81111111122322;
	fma.rn.f64 	%fd29, %fd27, %fd16, %fd28;
	mov.f64 	%fd30, 0d3FA55555555502A1;
	fma.rn.f64 	%fd31, %fd29, %fd16, %fd30;
	mov.f64 	%fd32, 0d3FC5555555555511;
	fma.rn.f64 	%fd33, %fd31, %fd16, %fd32;
	mov.f64 	%fd34, 0d3FE000000000000B;
	fma.rn.f64 	%fd35, %fd33, %fd16, %fd34;
	mov.f64 	%fd36, 0d3FF0000000000000;
	fma.rn.f64 	%fd37, %fd35, %fd16, %fd36;
	fma.rn.f64 	%fd38, %fd37, %fd16, %fd36;
	shl.b32 	%r29, %r28, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r30, %temp}, %fd38;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd38;
	}
	add.s32 	%r32, %r29, %r31;
	add.s32 	%r33, %r32, -2097152;
	mov.b64 	%fd7, {%r30, %r33};
	// inline asm
	rcp.approx.ftz.f64 %fd6,%fd7;
	// inline asm
	neg.f64 	%fd39, %fd7;
	fma.rn.f64 	%fd40, %fd39, %fd6, %fd36;
	fma.rn.f64 	%fd41, %fd40, %fd40, %fd40;
	fma.rn.f64 	%fd42, %fd41, %fd6, %fd6;
	mov.f64 	%fd43, 0d3FB0000000000000;
	fma.rn.f64 	%fd45, %fd42, %fd43, %fd7;
	bra.uni 	BB18_7;

BB18_5:
	setp.gtu.f64	%p4, %fd1, 0d7FF0000000000000;
	selp.f64	%fd45, %fd1, 0d7FF0000000000000, %p4;

BB18_7:
	add.s32 	%r34, %r9, %r8;
	mul.wide.s32 	%rd7, %r34, 8;
	add.s64 	%rd8, %rd1, %rd7;
	add.f64 	%fd44, %fd45, %fd45;
	st.global.f64 	[%rd8], %fd44;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p5, %r10, %r12;
	mov.u32 	%r38, %r10;
	@%p5 bra 	BB18_4;

BB18_8:
	add.s32 	%r37, %r4, %r37;
	setp.lt.s32	%p6, %r37, %r13;
	@%p6 bra 	BB18_2;

BB18_9:
	ret;
}

	// .globl	map_cospi_double
.visible .entry map_cospi_double(
	.param .u32 map_cospi_double_param_0,
	.param .u32 map_cospi_double_param_1,
	.param .u64 map_cospi_double_param_2,
	.param .u32 map_cospi_double_param_3,
	.param .u64 map_cospi_double_param_4,
	.param .u32 map_cospi_double_param_5
)
{
	.reg .pred 	%p<8>;
	.reg .b32 	%r<37>;
	.reg .f64 	%fd<37>;
	.reg .b64 	%rd<13>;


	ld.param.u32 	%r11, [map_cospi_double_param_0];
	ld.param.u32 	%r12, [map_cospi_double_param_1];
	ld.param.u64 	%rd1, [map_cospi_double_param_2];
	ld.param.u32 	%r13, [map_cospi_double_param_3];
	ld.param.u64 	%rd2, [map_cospi_double_param_4];
	ld.param.u32 	%r14, [map_cospi_double_param_5];
	mov.u32 	%r15, %tid.x;
	mov.u32 	%r16, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mad.lo.s32 	%r35, %r16, %r17, %r15;
	setp.ge.s32	%p1, %r35, %r12;
	@%p1 bra 	BB19_12;

	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r2, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.y;
	mul.lo.s32 	%r3, %r21, %r19;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd10, %rd1;

BB19_2:
	setp.ge.s32	%p2, %r2, %r11;
	@%p2 bra 	BB19_11;

	mul.lo.s32 	%r5, %r35, %r14;
	mul.lo.s32 	%r6, %r35, %r13;
	mov.u32 	%r36, %r2;

BB19_4:
	mov.u32 	%r7, %r36;
	add.s32 	%r22, %r7, %r5;
	mul.wide.s32 	%rd4, %r22, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd35, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd35;
	}
	add.s32 	%r24, %r23, %r23;
	setp.lt.u32	%p3, %r24, -2038431743;
	@%p3 bra 	BB19_6;

	mov.f64 	%fd11, 0d0000000000000000;
	mul.rn.f64 	%fd35, %fd35, %fd11;

BB19_6:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r25}, %fd35;
	}
	add.s32 	%r26, %r25, 1048576;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r27, %temp}, %fd35;
	}
	mov.b64 	%fd12, {%r27, %r26};
	cvt.rni.f64.f64	%fd13, %fd12;
	cvt.rzi.s64.f64	%rd6, %fd13;
	cvt.u32.u64	%r28, %rd6;
	neg.f64 	%fd14, %fd13;
	mov.f64 	%fd15, 0d3FE0000000000000;
	fma.rn.f64 	%fd16, %fd14, %fd15, %fd35;
	mul.f64 	%fd17, %fd16, 0d3CA1A62633145C07;
	mov.f64 	%fd18, 0d400921FB54442D18;
	fma.rn.f64 	%fd19, %fd16, %fd18, %fd17;
	add.s32 	%r8, %r28, 1;
	and.b32  	%r29, %r8, 1;
	shl.b32 	%r30, %r29, 3;
	mul.rn.f64 	%fd4, %fd19, %fd19;
	setp.eq.s32	%p4, %r29, 0;
	selp.f64	%fd20, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p4;
	mul.wide.u32 	%rd7, %r30, 8;
	mov.u64 	%rd8, __cudart_sin_cos_coeffs;
	add.s64 	%rd9, %rd7, %rd8;
	ld.const.f64 	%fd21, [%rd9+8];
	fma.rn.f64 	%fd22, %fd20, %fd4, %fd21;
	ld.const.f64 	%fd23, [%rd9+16];
	fma.rn.f64 	%fd24, %fd22, %fd4, %fd23;
	ld.const.f64 	%fd25, [%rd9+24];
	fma.rn.f64 	%fd26, %fd24, %fd4, %fd25;
	ld.const.f64 	%fd27, [%rd9+32];
	fma.rn.f64 	%fd28, %fd26, %fd4, %fd27;
	ld.const.f64 	%fd29, [%rd9+40];
	fma.rn.f64 	%fd30, %fd28, %fd4, %fd29;
	ld.const.f64 	%fd31, [%rd9+48];
	fma.rn.f64 	%fd5, %fd30, %fd4, %fd31;
	fma.rn.f64 	%fd36, %fd5, %fd19, %fd19;
	@%p4 bra 	BB19_8;

	mov.f64 	%fd32, 0d3FF0000000000000;
	fma.rn.f64 	%fd36, %fd5, %fd4, %fd32;

BB19_8:
	and.b32  	%r31, %r8, 2;
	setp.eq.s32	%p5, %r31, 0;
	@%p5 bra 	BB19_10;

	mov.f64 	%fd33, 0d0000000000000000;
	mov.f64 	%fd34, 0dBFF0000000000000;
	fma.rn.f64 	%fd36, %fd36, %fd34, %fd33;

BB19_10:
	add.s32 	%r32, %r7, %r6;
	mul.wide.s32 	%rd11, %r32, 8;
	add.s64 	%rd12, %rd10, %rd11;
	st.global.f64 	[%rd12], %fd36;
	add.s32 	%r9, %r3, %r7;
	setp.lt.s32	%p6, %r9, %r11;
	mov.u32 	%r36, %r9;
	@%p6 bra 	BB19_4;

BB19_11:
	mov.u32 	%r33, %nctaid.x;
	mad.lo.s32 	%r35, %r33, %r16, %r35;
	setp.lt.s32	%p7, %r35, %r12;
	@%p7 bra 	BB19_2;

BB19_12:
	ret;
}

	// .globl	map_erfc_double
.visible .entry map_erfc_double(
	.param .u32 map_erfc_double_param_0,
	.param .u32 map_erfc_double_param_1,
	.param .u64 map_erfc_double_param_2,
	.param .u32 map_erfc_double_param_3,
	.param .u64 map_erfc_double_param_4,
	.param .u32 map_erfc_double_param_5
)
{
	.reg .pred 	%p<12>;
	.reg .b32 	%r<49>;
	.reg .f64 	%fd<123>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r13, [map_erfc_double_param_0];
	ld.param.u32 	%r14, [map_erfc_double_param_1];
	ld.param.u64 	%rd1, [map_erfc_double_param_2];
	ld.param.u64 	%rd2, [map_erfc_double_param_4];
	mov.u32 	%r17, %tid.x;
	mov.u32 	%r18, %ntid.x;
	mov.u32 	%r19, %ctaid.x;
	mad.lo.s32 	%r47, %r18, %r19, %r17;
	setp.ge.s32	%p1, %r47, %r14;
	@%p1 bra 	BB20_9;

	mov.u32 	%r20, %tid.y;
	mov.u32 	%r21, %ntid.y;
	mov.u32 	%r22, %ctaid.y;
	mad.lo.s32 	%r2, %r21, %r22, %r20;
	mov.u32 	%r23, %nctaid.y;
	mul.lo.s32 	%r3, %r23, %r21;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd6, %rd1;

BB20_2:
	setp.ge.s32	%p2, %r2, %r13;
	@%p2 bra 	BB20_8;

	ld.param.u32 	%r44, [map_erfc_double_param_5];
	mov.u32 	%r48, %r2;

BB20_4:
	mov.u32 	%r7, %r48;
	mul.lo.s32 	%r46, %r47, %r44;
	add.s32 	%r24, %r7, %r46;
	mul.wide.s32 	%rd4, %r24, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd1;
	}
	and.b32  	%r9, %r8, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd1;
	}
	setp.lt.u32	%p3, %r9, 2146435072;
	@%p3 bra 	BB20_6;
	bra.uni 	BB20_5;

BB20_6:
	setp.lt.s32	%p8, %r8, 0;
	mov.b64 	%fd11, {%r10, %r9};
	add.f64 	%fd12, %fd11, 0dC010000000000000;
	add.f64 	%fd8, %fd11, 0d4010000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd7,%fd8;
	// inline asm
	neg.f64 	%fd13, %fd8;
	mov.f64 	%fd14, 0d3FF0000000000000;
	fma.rn.f64 	%fd15, %fd13, %fd7, %fd14;
	fma.rn.f64 	%fd16, %fd15, %fd15, %fd15;
	fma.rn.f64 	%fd17, %fd16, %fd7, %fd7;
	mul.f64 	%fd18, %fd12, %fd17;
	add.rn.f64 	%fd19, %fd18, %fd14;
	mov.f64 	%fd20, 0dC010000000000000;
	fma.rn.f64 	%fd21, %fd20, %fd19, %fd11;
	neg.f64 	%fd22, %fd18;
	fma.rn.f64 	%fd23, %fd22, %fd11, %fd21;
	fma.rn.f64 	%fd24, %fd17, %fd23, %fd18;
	mov.f64 	%fd25, 0dBE44E1C6FD03D328;
	mov.f64 	%fd26, 0dBDF8774AD4E0BFD7;
	fma.rn.f64 	%fd27, %fd26, %fd24, %fd25;
	mov.f64 	%fd28, 0dBE4330149F7A56B6;
	fma.rn.f64 	%fd29, %fd27, %fd24, %fd28;
	mov.f64 	%fd30, 0d3E7BEDDED8376273;
	fma.rn.f64 	%fd31, %fd29, %fd24, %fd30;
	mov.f64 	%fd32, 0d3E6F9254C3ABF22B;
	fma.rn.f64 	%fd33, %fd31, %fd24, %fd32;
	mov.f64 	%fd34, 0dBEAB9068C2148CF0;
	fma.rn.f64 	%fd35, %fd33, %fd24, %fd34;
	mov.f64 	%fd36, 0d3E94C6454DB34009;
	fma.rn.f64 	%fd37, %fd35, %fd24, %fd36;
	mov.f64 	%fd38, 0d3ED7F1C378F2311D;
	fma.rn.f64 	%fd39, %fd37, %fd24, %fd38;
	mov.f64 	%fd40, 0dBEE78E051C6D5C58;
	fma.rn.f64 	%fd41, %fd39, %fd24, %fd40;
	mov.f64 	%fd42, 0dBEF995B4EAD14A90;
	fma.rn.f64 	%fd43, %fd41, %fd24, %fd42;
	mov.f64 	%fd44, 0d3F23BE27CF0A29B2;
	fma.rn.f64 	%fd45, %fd43, %fd24, %fd44;
	mov.f64 	%fd46, 0dBF2A1DEF3E81672E;
	fma.rn.f64 	%fd47, %fd45, %fd24, %fd46;
	mov.f64 	%fd48, 0dBF48D4ABE68C1713;
	fma.rn.f64 	%fd49, %fd47, %fd24, %fd48;
	mov.f64 	%fd50, 0d3F749C67210DD6B4;
	fma.rn.f64 	%fd51, %fd49, %fd24, %fd50;
	mov.f64 	%fd52, 0dBF9096238568E357;
	fma.rn.f64 	%fd53, %fd51, %fd24, %fd52;
	mov.f64 	%fd54, 0d3FA3079EDF8C2DC9;
	fma.rn.f64 	%fd55, %fd53, %fd24, %fd54;
	mov.f64 	%fd56, 0dBFB0FB06DFF601FC;
	fma.rn.f64 	%fd57, %fd55, %fd24, %fd56;
	mov.f64 	%fd58, 0d3FB7FEE004DFBCDC;
	fma.rn.f64 	%fd59, %fd57, %fd24, %fd58;
	mov.f64 	%fd60, 0dBFB9DDB23C3DB8C6;
	fma.rn.f64 	%fd61, %fd59, %fd24, %fd60;
	mov.f64 	%fd62, 0d3FB16ECEFCFA5FDA;
	fma.rn.f64 	%fd63, %fd61, %fd24, %fd62;
	mov.f64 	%fd64, 0d3F8F7F5DF66FB6D6;
	fma.rn.f64 	%fd65, %fd63, %fd24, %fd64;
	mov.f64 	%fd66, 0dBFC1DF1AD154A29D;
	fma.rn.f64 	%fd67, %fd65, %fd24, %fd66;
	mov.f64 	%fd68, 0d3FF3BA5916E9FD7F;
	fma.rn.f64 	%fd69, %fd67, %fd24, %fd68;
	mov.f64 	%fd70, 0d4000000000000000;
	fma.rn.f64 	%fd10, %fd70, %fd11, %fd14;
	// inline asm
	rcp.approx.ftz.f64 %fd9,%fd10;
	// inline asm
	neg.f64 	%fd71, %fd10;
	fma.rn.f64 	%fd72, %fd71, %fd9, %fd14;
	fma.rn.f64 	%fd73, %fd72, %fd72, %fd72;
	fma.rn.f64 	%fd74, %fd73, %fd9, %fd9;
	mul.f64 	%fd75, %fd69, %fd74;
	mul.f64 	%fd76, %fd75, 0dC000000000000000;
	fma.rn.f64 	%fd77, %fd11, %fd76, %fd69;
	neg.f64 	%fd78, %fd75;
	add.rn.f64 	%fd79, %fd77, %fd78;
	fma.rn.f64 	%fd80, %fd79, %fd74, %fd75;
	mul.f64 	%fd81, %fd11, %fd11;
	neg.f64 	%fd82, %fd81;
	mov.f64 	%fd83, 0d4338000000000000;
	mov.f64 	%fd84, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd85, %fd82, %fd84, %fd83;
	mov.f64 	%fd86, 0dC338000000000000;
	add.rn.f64 	%fd87, %fd85, %fd86;
	mov.f64 	%fd88, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd89, %fd87, %fd88, %fd82;
	mov.f64 	%fd90, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd91, %fd87, %fd90, %fd89;
	mov.f64 	%fd92, 0d3E928AF3FCA213EA;
	mov.f64 	%fd93, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd94, %fd93, %fd91, %fd92;
	mov.f64 	%fd95, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd96, %fd94, %fd91, %fd95;
	mov.f64 	%fd97, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd98, %fd96, %fd91, %fd97;
	mov.f64 	%fd99, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd100, %fd98, %fd91, %fd99;
	mov.f64 	%fd101, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd102, %fd100, %fd91, %fd101;
	mov.f64 	%fd103, 0d3F81111111122322;
	fma.rn.f64 	%fd104, %fd102, %fd91, %fd103;
	mov.f64 	%fd105, 0d3FA55555555502A1;
	fma.rn.f64 	%fd106, %fd104, %fd91, %fd105;
	mov.f64 	%fd107, 0d3FC5555555555511;
	fma.rn.f64 	%fd108, %fd106, %fd91, %fd107;
	mov.f64 	%fd109, 0d3FE000000000000B;
	fma.rn.f64 	%fd110, %fd108, %fd91, %fd109;
	fma.rn.f64 	%fd111, %fd110, %fd91, %fd14;
	fma.rn.f64 	%fd112, %fd111, %fd91, %fd14;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r25, %temp}, %fd85;
	}
	shr.u32 	%r26, %r25, 31;
	add.s32 	%r27, %r25, %r26;
	shr.s32 	%r28, %r27, 1;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r29, %temp}, %fd112;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r30}, %fd112;
	}
	shl.b32 	%r31, %r28, 20;
	add.s32 	%r32, %r30, %r31;
	mov.b64 	%fd113, {%r29, %r32};
	sub.s32 	%r33, %r25, %r28;
	shl.b32 	%r34, %r33, 20;
	add.s32 	%r35, %r34, 1072693248;
	mov.u32 	%r36, 0;
	mov.b64 	%fd114, {%r36, %r35};
	mul.f64 	%fd115, %fd113, %fd114;
	neg.f64 	%fd116, %fd11;
	fma.rn.f64 	%fd117, %fd116, %fd11, %fd81;
	fma.rn.f64 	%fd118, %fd115, %fd117, %fd115;
	mul.f64 	%fd119, %fd80, %fd118;
	setp.gt.u32	%p9, %r9, 1077624832;
	selp.f64	%fd120, 0d0000000000000000, %fd119, %p9;
	sub.f64 	%fd121, %fd70, %fd120;
	selp.f64	%fd122, %fd121, %fd120, %p8;
	bra.uni 	BB20_7;

BB20_5:
	setp.lt.s32	%p4, %r8, 0;
	setp.eq.s32	%p5, %r10, 0;
	setp.eq.s32	%p6, %r9, 2146435072;
	and.pred  	%p7, %p6, %p5;
	selp.f64	%fd5, 0d4000000000000000, 0d0000000000000000, %p4;
	add.f64 	%fd6, %fd1, %fd1;
	selp.f64	%fd122, %fd5, %fd6, %p7;

BB20_7:
	ld.param.u32 	%r41, [map_erfc_double_param_3];
	mul.lo.s32 	%r40, %r47, %r41;
	add.s32 	%r37, %r7, %r40;
	mul.wide.s32 	%rd7, %r37, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd122;
	add.s32 	%r11, %r3, %r7;
	setp.lt.s32	%p10, %r11, %r13;
	mov.u32 	%r48, %r11;
	@%p10 bra 	BB20_4;

BB20_8:
	ld.param.u32 	%r43, [map_erfc_double_param_1];
	mov.u32 	%r42, %ntid.x;
	mov.u32 	%r38, %nctaid.x;
	mad.lo.s32 	%r47, %r38, %r42, %r47;
	setp.lt.s32	%p11, %r47, %r43;
	@%p11 bra 	BB20_2;

BB20_9:
	ret;
}

	// .globl	map_erfcinv_double
.visible .entry map_erfcinv_double(
	.param .u32 map_erfcinv_double_param_0,
	.param .u32 map_erfcinv_double_param_1,
	.param .u64 map_erfcinv_double_param_2,
	.param .u32 map_erfcinv_double_param_3,
	.param .u64 map_erfcinv_double_param_4,
	.param .u32 map_erfcinv_double_param_5
)
{
	.reg .pred 	%p<15>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<78>;
	.reg .f64 	%fd<268>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r21, [map_erfcinv_double_param_0];
	ld.param.u32 	%r22, [map_erfcinv_double_param_1];
	ld.param.u64 	%rd1, [map_erfcinv_double_param_2];
	ld.param.u64 	%rd2, [map_erfcinv_double_param_4];
	mov.u32 	%r25, %tid.x;
	mov.u32 	%r26, %ntid.x;
	mov.u32 	%r27, %ctaid.x;
	mad.lo.s32 	%r72, %r26, %r27, %r25;
	setp.ge.s32	%p1, %r72, %r22;
	@%p1 bra 	BB21_19;

	mov.u32 	%r28, %tid.y;
	mov.u32 	%r29, %ntid.y;
	mov.u32 	%r30, %ctaid.y;
	mad.lo.s32 	%r2, %r29, %r30, %r28;
	mov.u32 	%r31, %nctaid.y;
	mul.lo.s32 	%r3, %r31, %r29;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd6, %rd1;

BB21_2:
	setp.ge.s32	%p2, %r2, %r21;
	@%p2 bra 	BB21_18;

	ld.param.u32 	%r69, [map_erfcinv_double_param_5];
	mov.u32 	%r73, %r2;

BB21_4:
	mov.u32 	%r7, %r73;
	mul.lo.s32 	%r71, %r72, %r69;
	add.s32 	%r32, %r7, %r71;
	mul.wide.s32 	%rd4, %r32, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	neg.f64 	%fd2, %fd1;
	mov.f64 	%fd19, 0d4000000000000000;
	add.rn.f64 	%fd3, %fd19, %fd2;
	setp.le.f64	%p3, %fd1, 0d3FFFFC0B65AA4E0E;
	setp.ge.f64	%p4, %fd1, 0d3F4FA4D2AD8F904D;
	and.pred  	%p5, %p4, %p3;
	@%p5 bra 	BB21_16;
	bra.uni 	BB21_5;

BB21_16:
	mul.rn.f64 	%fd174, %fd3, %fd1;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r53}, %fd174;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r54, %temp}, %fd174;
	}
	shr.u32 	%r55, %r53, 20;
	and.b32  	%r56, %r55, 2046;
	add.s32 	%r57, %r56, 2147482626;
	mov.u32 	%r58, 1127219200;
	mov.b64 	%fd175, {%r57, %r58};
	mov.u32 	%r59, -2147483648;
	mov.b64 	%fd176, {%r59, %r58};
	sub.f64 	%fd177, %fd175, %fd176;
	and.b32  	%r60, %r53, -2145386497;
	add.s32 	%r61, %r60, 1071644672;
	mov.b64 	%fd178, {%r54, %r61};
	add.f64 	%fd179, %fd178, 0dBFF0000000000000;
	add.f64 	%fd173, %fd178, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd172,%fd173;
	// inline asm
	neg.f64 	%fd180, %fd173;
	mov.f64 	%fd181, 0d3FF0000000000000;
	fma.rn.f64 	%fd182, %fd180, %fd172, %fd181;
	fma.rn.f64 	%fd183, %fd182, %fd182, %fd182;
	fma.rn.f64 	%fd184, %fd183, %fd172, %fd172;
	mul.f64 	%fd185, %fd179, %fd184;
	mov.f64 	%fd186, 0dC000000000000000;
	fma.rn.f64 	%fd187, %fd186, %fd185, %fd179;
	neg.f64 	%fd188, %fd185;
	fma.rn.f64 	%fd189, %fd188, %fd179, %fd187;
	fma.rn.f64 	%fd190, %fd189, %fd184, %fd185;
	mul.f64 	%fd191, %fd190, %fd190;
	mov.f64 	%fd192, 0d3FA55CF59CDC5D89;
	mov.f64 	%fd193, 0d3FB5C5C218C775C9;
	fma.rn.f64 	%fd194, %fd193, %fd191, %fd192;
	mov.f64 	%fd195, 0d3FAEFD18CF6EBB9C;
	fma.rn.f64 	%fd196, %fd194, %fd191, %fd195;
	mov.f64 	%fd197, 0d3FB10682EDCB8D1B;
	fma.rn.f64 	%fd198, %fd196, %fd191, %fd197;
	mov.f64 	%fd199, 0d3FB3B1DD3AC7FC96;
	fma.rn.f64 	%fd200, %fd198, %fd191, %fd199;
	mov.f64 	%fd201, 0d3FB745CB459B54A6;
	fma.rn.f64 	%fd202, %fd200, %fd191, %fd201;
	mov.f64 	%fd203, 0d3FBC71C741A0669F;
	fma.rn.f64 	%fd204, %fd202, %fd191, %fd203;
	mov.f64 	%fd205, 0d3FC249249209112E;
	fma.rn.f64 	%fd206, %fd204, %fd191, %fd205;
	mov.f64 	%fd207, 0d3FC99999999A06C1;
	fma.rn.f64 	%fd208, %fd206, %fd191, %fd207;
	mov.f64 	%fd209, 0d3FD5555555555535;
	fma.rn.f64 	%fd210, %fd208, %fd191, %fd209;
	mul.f64 	%fd211, %fd191, %fd210;
	fma.rn.f64 	%fd212, %fd211, %fd190, %fd190;
	add.f64 	%fd213, %fd212, %fd212;
	mov.f64 	%fd214, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd215, %fd177, %fd214, %fd213;
	mov.f64 	%fd216, 0dC009000000000000;
	sub.f64 	%fd217, %fd216, %fd215;
	mov.f64 	%fd218, 0dBC08DDF93324D327;
	mov.f64 	%fd219, 0dBBB135D2E746E627;
	fma.rn.f64 	%fd220, %fd219, %fd217, %fd218;
	mov.f64 	%fd221, 0d3C37B83EEF0B7C9F;
	fma.rn.f64 	%fd222, %fd220, %fd217, %fd221;
	mov.f64 	%fd223, 0d3C69BA72CD589B91;
	fma.rn.f64 	%fd224, %fd222, %fd217, %fd223;
	mov.f64 	%fd225, 0dBCA33689090A6B96;
	fma.rn.f64 	%fd226, %fd224, %fd217, %fd225;
	mov.f64 	%fd227, 0d3C782E11898132E0;
	fma.rn.f64 	%fd228, %fd226, %fd217, %fd227;
	mov.f64 	%fd229, 0d3CFDE4ACFD9E26BA;
	fma.rn.f64 	%fd230, %fd228, %fd217, %fd229;
	mov.f64 	%fd231, 0dBD26D33EED66C487;
	fma.rn.f64 	%fd232, %fd230, %fd217, %fd231;
	mov.f64 	%fd233, 0dBD36F2167040D8E2;
	fma.rn.f64 	%fd234, %fd232, %fd217, %fd233;
	mov.f64 	%fd235, 0d3D872A22C2D77E20;
	fma.rn.f64 	%fd236, %fd234, %fd217, %fd235;
	mov.f64 	%fd237, 0dBDAC8859C4E5C0AF;
	fma.rn.f64 	%fd238, %fd236, %fd217, %fd237;
	mov.f64 	%fd239, 0dBDCDC583D118A561;
	fma.rn.f64 	%fd240, %fd238, %fd217, %fd239;
	mov.f64 	%fd241, 0d3E120F47CCF46B3C;
	fma.rn.f64 	%fd242, %fd240, %fd217, %fd241;
	mov.f64 	%fd243, 0dBE31A9E38DC84D60;
	fma.rn.f64 	%fd244, %fd242, %fd217, %fd243;
	mov.f64 	%fd245, 0dBE5F36CD6D3D46A9;
	fma.rn.f64 	%fd246, %fd244, %fd217, %fd245;
	mov.f64 	%fd247, 0d3E9C6B4F5D03B787;
	fma.rn.f64 	%fd248, %fd246, %fd217, %fd247;
	mov.f64 	%fd249, 0dBEB6E8A5434AE8A2;
	fma.rn.f64 	%fd250, %fd248, %fd217, %fd249;
	mov.f64 	%fd251, 0dBEED1D1F7B8736F6;
	fma.rn.f64 	%fd252, %fd250, %fd217, %fd251;
	mov.f64 	%fd253, 0d3F2879C2A212F024;
	fma.rn.f64 	%fd254, %fd252, %fd217, %fd253;
	mov.f64 	%fd255, 0dBF4845769484FCA8;
	fma.rn.f64 	%fd256, %fd254, %fd217, %fd255;
	mov.f64 	%fd257, 0dBF78B6C33114F909;
	fma.rn.f64 	%fd258, %fd256, %fd217, %fd257;
	mov.f64 	%fd259, 0d3FCEBD80D9B13E28;
	fma.rn.f64 	%fd260, %fd258, %fd217, %fd259;
	mov.f64 	%fd261, 0d3FFA755E7C99AE86;
	fma.rn.f64 	%fd262, %fd260, %fd217, %fd261;
	fma.rn.f64 	%fd267, %fd262, %fd2, %fd262;
	bra.uni 	BB21_17;

BB21_5:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd1;
	}
	setp.gt.s32	%p6, %r8, 1072693247;
	selp.f64	%fd263, %fd3, %fd1, %p6;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r74}, %fd263;
	}
	mov.b32 	 %f1, %r74;
	setp.ltu.f32	%p7, %f1, 0f2B2BFF2F;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r75, %temp}, %fd263;
	}
	@%p7 bra 	BB21_7;
	bra.uni 	BB21_6;

BB21_7:
	mov.u32 	%r76, -1023;
	setp.gt.s32	%p8, %r74, 1048575;
	@%p8 bra 	BB21_9;

	mul.f64 	%fd263, %fd263, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r74}, %fd263;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r75, %temp}, %fd263;
	}
	mov.u32 	%r76, -1077;

BB21_9:
	add.s32 	%r42, %r74, -1;
	setp.lt.u32	%p9, %r42, 2146435071;
	@%p9 bra 	BB21_11;
	bra.uni 	BB21_10;

BB21_11:
	shr.u32 	%r44, %r74, 20;
	add.s32 	%r77, %r76, %r44;
	and.b32  	%r45, %r74, -2146435073;
	or.b32  	%r46, %r45, 1072693248;
	mov.b64 	%fd264, {%r75, %r46};
	setp.lt.s32	%p11, %r46, 1073127583;
	@%p11 bra 	BB21_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd264;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r48}, %fd264;
	}
	add.s32 	%r49, %r48, -1048576;
	mov.b64 	%fd264, {%r47, %r49};
	add.s32 	%r77, %r77, 1;

BB21_13:
	add.f64 	%fd107, %fd264, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd106,%fd107;
	// inline asm
	neg.f64 	%fd108, %fd107;
	mov.f64 	%fd109, 0d3FF0000000000000;
	fma.rn.f64 	%fd110, %fd108, %fd106, %fd109;
	fma.rn.f64 	%fd111, %fd110, %fd110, %fd110;
	fma.rn.f64 	%fd112, %fd111, %fd106, %fd106;
	add.f64 	%fd113, %fd264, 0dBFF0000000000000;
	mul.f64 	%fd114, %fd113, %fd112;
	fma.rn.f64 	%fd115, %fd113, %fd112, %fd114;
	mul.f64 	%fd116, %fd115, %fd115;
	mov.f64 	%fd117, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd118, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd119, %fd118, %fd116, %fd117;
	mov.f64 	%fd120, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd121, %fd119, %fd116, %fd120;
	mov.f64 	%fd122, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd123, %fd121, %fd116, %fd122;
	mov.f64 	%fd124, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd125, %fd123, %fd116, %fd124;
	mov.f64 	%fd126, 0d3F624924923BE72D;
	fma.rn.f64 	%fd127, %fd125, %fd116, %fd126;
	mov.f64 	%fd128, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd129, %fd127, %fd116, %fd128;
	mov.f64 	%fd130, 0d3FB5555555555554;
	fma.rn.f64 	%fd131, %fd129, %fd116, %fd130;
	sub.f64 	%fd132, %fd113, %fd115;
	add.f64 	%fd133, %fd132, %fd132;
	neg.f64 	%fd134, %fd115;
	fma.rn.f64 	%fd135, %fd134, %fd113, %fd133;
	mul.f64 	%fd136, %fd112, %fd135;
	mul.f64 	%fd137, %fd116, %fd131;
	fma.rn.f64 	%fd138, %fd137, %fd115, %fd136;
	xor.b32  	%r50, %r77, -2147483648;
	mov.u32 	%r51, 1127219200;
	mov.b64 	%fd139, {%r50, %r51};
	mov.u32 	%r52, -2147483648;
	mov.b64 	%fd140, {%r52, %r51};
	sub.f64 	%fd141, %fd139, %fd140;
	mov.f64 	%fd142, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd143, %fd141, %fd142, %fd115;
	neg.f64 	%fd144, %fd141;
	fma.rn.f64 	%fd145, %fd144, %fd142, %fd143;
	sub.f64 	%fd146, %fd145, %fd115;
	sub.f64 	%fd147, %fd138, %fd146;
	mov.f64 	%fd148, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd149, %fd141, %fd148, %fd147;
	add.f64 	%fd265, %fd143, %fd149;
	bra.uni 	BB21_14;

BB21_6:
	shr.u32 	%r33, %r74, 20;
	and.b32  	%r34, %r33, 2046;
	add.s32 	%r35, %r34, 2147482626;
	mov.u32 	%r36, 1127219200;
	mov.b64 	%fd24, {%r35, %r36};
	mov.u32 	%r37, -2147483648;
	mov.b64 	%fd25, {%r37, %r36};
	sub.f64 	%fd26, %fd24, %fd25;
	and.b32  	%r38, %r74, -2145386497;
	add.s32 	%r39, %r38, 1071644672;
	mov.b64 	%fd27, {%r75, %r39};
	add.f64 	%fd28, %fd27, 0dBFF0000000000000;
	add.f64 	%fd21, %fd27, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd20,%fd21;
	// inline asm
	neg.f64 	%fd29, %fd21;
	mov.f64 	%fd30, 0d3FF0000000000000;
	fma.rn.f64 	%fd31, %fd29, %fd20, %fd30;
	fma.rn.f64 	%fd32, %fd31, %fd31, %fd31;
	fma.rn.f64 	%fd33, %fd32, %fd20, %fd20;
	mul.f64 	%fd34, %fd28, %fd33;
	mov.f64 	%fd35, 0dC000000000000000;
	fma.rn.f64 	%fd36, %fd35, %fd34, %fd28;
	neg.f64 	%fd37, %fd34;
	fma.rn.f64 	%fd38, %fd37, %fd28, %fd36;
	fma.rn.f64 	%fd39, %fd38, %fd33, %fd34;
	mul.f64 	%fd40, %fd39, %fd39;
	mov.f64 	%fd41, 0d3FA55CF59CDC5D89;
	mov.f64 	%fd42, 0d3FB5C5C218C775C9;
	fma.rn.f64 	%fd43, %fd42, %fd40, %fd41;
	mov.f64 	%fd44, 0d3FAEFD18CF6EBB9C;
	fma.rn.f64 	%fd45, %fd43, %fd40, %fd44;
	mov.f64 	%fd46, 0d3FB10682EDCB8D1B;
	fma.rn.f64 	%fd47, %fd45, %fd40, %fd46;
	mov.f64 	%fd48, 0d3FB3B1DD3AC7FC96;
	fma.rn.f64 	%fd49, %fd47, %fd40, %fd48;
	mov.f64 	%fd50, 0d3FB745CB459B54A6;
	fma.rn.f64 	%fd51, %fd49, %fd40, %fd50;
	mov.f64 	%fd52, 0d3FBC71C741A0669F;
	fma.rn.f64 	%fd53, %fd51, %fd40, %fd52;
	mov.f64 	%fd54, 0d3FC249249209112E;
	fma.rn.f64 	%fd55, %fd53, %fd40, %fd54;
	mov.f64 	%fd56, 0d3FC99999999A06C1;
	fma.rn.f64 	%fd57, %fd55, %fd40, %fd56;
	mov.f64 	%fd58, 0d3FD5555555555535;
	fma.rn.f64 	%fd59, %fd57, %fd40, %fd58;
	mul.f64 	%fd60, %fd40, %fd59;
	fma.rn.f64 	%fd61, %fd60, %fd39, %fd39;
	add.f64 	%fd62, %fd61, %fd61;
	mov.f64 	%fd63, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd64, %fd26, %fd63, %fd62;
	neg.f64 	%fd23, %fd64;
	// inline asm
	rsqrt.approx.ftz.f64 %fd22, %fd23;
	// inline asm
	mul.rn.f64 	%fd65, %fd22, %fd22;
	neg.f64 	%fd66, %fd65;
	fma.rn.f64 	%fd67, %fd23, %fd66, %fd30;
	mov.f64 	%fd68, 0d3FE0000000000000;
	mov.f64 	%fd69, 0d3FD8000000000000;
	fma.rn.f64 	%fd70, %fd69, %fd67, %fd68;
	mul.rn.f64 	%fd71, %fd67, %fd22;
	fma.rn.f64 	%fd72, %fd70, %fd71, %fd22;
	mov.f64 	%fd73, 0d4000A0E7333839AA;
	mov.f64 	%fd74, 0d3FEBE9222591AFAB;
	fma.rn.f64 	%fd75, %fd74, %fd72, %fd73;
	mov.f64 	%fd76, 0d4008768CF7E57D5C;
	fma.rn.f64 	%fd77, %fd75, %fd72, %fd76;
	mov.f64 	%fd78, 0d400B77E7E28DA583;
	fma.rn.f64 	%fd79, %fd77, %fd72, %fd78;
	mov.f64 	%fd80, 0d3FF34F26A4F99CF9;
	fma.rn.f64 	%fd81, %fd79, %fd72, %fd80;
	mov.f64 	%fd82, 0d3FC1F674ADB019ED;
	fma.rn.f64 	%fd83, %fd81, %fd72, %fd82;
	mov.f64 	%fd84, 0d3F75DDAE9506431D;
	fma.rn.f64 	%fd85, %fd83, %fd72, %fd84;
	mov.f64 	%fd86, 0d3F0ADA49AA32489C;
	fma.rn.f64 	%fd87, %fd85, %fd72, %fd86;
	add.f64 	%fd88, %fd72, 0d4001E90FF51C2197;
	mov.f64 	%fd89, 0d40111EA3A7CF3820;
	fma.rn.f64 	%fd90, %fd88, %fd72, %fd89;
	mov.f64 	%fd91, 0d4011A0E4A4749594;
	fma.rn.f64 	%fd92, %fd90, %fd72, %fd91;
	mov.f64 	%fd93, 0d400D4E977D38C14D;
	fma.rn.f64 	%fd94, %fd92, %fd72, %fd93;
	mov.f64 	%fd95, 0d3FF37FD567EC0D5F;
	fma.rn.f64 	%fd96, %fd94, %fd72, %fd95;
	mov.f64 	%fd97, 0d3FC1FB9D7F676033;
	fma.rn.f64 	%fd98, %fd96, %fd72, %fd97;
	mov.f64 	%fd99, 0d3F75DDCDF98946E4;
	fma.rn.f64 	%fd100, %fd98, %fd72, %fd99;
	mov.f64 	%fd101, 0d3F0ADA42D79D8DBB;
	fma.rn.f64 	%fd102, %fd100, %fd72, %fd101;
	mul.f64 	%fd103, %fd72, %fd102;
	div.rn.f64 	%fd266, %fd87, %fd103;
	bra.uni 	BB21_15;

BB21_10:
	mov.f64 	%fd104, 0d7FF0000000000000;
	fma.rn.f64 	%fd105, %fd263, %fd104, %fd104;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd263;
	}
	mov.b32 	 %f2, %r43;
	setp.eq.f32	%p10, %f2, 0f00000000;
	selp.f64	%fd265, 0dFFF0000000000000, %fd105, %p10;

BB21_14:
	neg.f64 	%fd150, %fd265;
	rsqrt.approx.f64 	%fd151, %fd150;
	mov.f64 	%fd152, 0d3FFA2013964E259C;
	mov.f64 	%fd153, 0d3FE8E2101C71B0BF;
	fma.rn.f64 	%fd154, %fd153, %fd151, %fd152;
	mov.f64 	%fd155, 0d3FDABFE90921BE68;
	fma.rn.f64 	%fd156, %fd154, %fd151, %fd155;
	mov.f64 	%fd157, 0d3F97E41314DE00D4;
	fma.rn.f64 	%fd158, %fd156, %fd151, %fd157;
	mov.f64 	%fd159, 0d3F311BD487102E94;
	fma.rn.f64 	%fd160, %fd158, %fd151, %fd159;
	add.f64 	%fd161, %fd151, 0d3FF59895C30BAA54;
	mov.f64 	%fd162, 0d3FFAE8E5956A143F;
	fma.rn.f64 	%fd163, %fd161, %fd151, %fd162;
	mov.f64 	%fd164, 0d3FDACCE85FF7383D;
	fma.rn.f64 	%fd165, %fd163, %fd151, %fd164;
	mov.f64 	%fd166, 0d3F97E43B6CAC34FE;
	fma.rn.f64 	%fd167, %fd165, %fd151, %fd166;
	mov.f64 	%fd168, 0d3F311BD08289EB12;
	fma.rn.f64 	%fd169, %fd167, %fd151, %fd168;
	mul.f64 	%fd170, %fd151, %fd169;
	div.rn.f64 	%fd266, %fd160, %fd170;

BB21_15:
	neg.f64 	%fd171, %fd266;
	selp.f64	%fd267, %fd171, %fd266, %p6;

BB21_17:
	ld.param.u32 	%r66, [map_erfcinv_double_param_3];
	mul.lo.s32 	%r65, %r72, %r66;
	add.s32 	%r62, %r7, %r65;
	mul.wide.s32 	%rd7, %r62, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd267;
	add.s32 	%r19, %r3, %r7;
	setp.lt.s32	%p13, %r19, %r21;
	mov.u32 	%r73, %r19;
	@%p13 bra 	BB21_4;

BB21_18:
	ld.param.u32 	%r68, [map_erfcinv_double_param_1];
	mov.u32 	%r67, %ntid.x;
	mov.u32 	%r63, %nctaid.x;
	mad.lo.s32 	%r72, %r63, %r67, %r72;
	setp.lt.s32	%p14, %r72, %r68;
	@%p14 bra 	BB21_2;

BB21_19:
	ret;
}

	// .globl	map_erfcx_double
.visible .entry map_erfcx_double(
	.param .u32 map_erfcx_double_param_0,
	.param .u32 map_erfcx_double_param_1,
	.param .u64 map_erfcx_double_param_2,
	.param .u32 map_erfcx_double_param_3,
	.param .u64 map_erfcx_double_param_4,
	.param .u32 map_erfcx_double_param_5
)
{
	.reg .pred 	%p<11>;
	.reg .f32 	%f<5>;
	.reg .b32 	%r<55>;
	.reg .f64 	%fd<140>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map_erfcx_double_param_0];
	ld.param.u32 	%r13, [map_erfcx_double_param_1];
	ld.param.u64 	%rd1, [map_erfcx_double_param_2];
	ld.param.u64 	%rd2, [map_erfcx_double_param_4];
	mov.u32 	%r16, %tid.x;
	mov.u32 	%r17, %ntid.x;
	mov.u32 	%r18, %ctaid.x;
	mad.lo.s32 	%r53, %r17, %r18, %r16;
	setp.ge.s32	%p1, %r53, %r13;
	@%p1 bra 	BB22_13;

	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %nctaid.y;
	mul.lo.s32 	%r2, %r20, %r19;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd6, %rd1;

BB22_2:
	mov.u32 	%r50, %ntid.y;
	mov.u32 	%r21, %ctaid.y;
	mov.u32 	%r23, %tid.y;
	mad.lo.s32 	%r54, %r50, %r21, %r23;
	setp.ge.s32	%p2, %r54, %r12;
	@%p2 bra 	BB22_12;

BB22_3:
	ld.param.u32 	%r51, [map_erfcx_double_param_5];
	mad.lo.s32 	%r28, %r53, %r51, %r54;
	mul.wide.s32 	%rd4, %r28, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd1;
	}
	mov.b32 	 %f2, %r6;
	abs.f32 	%f3, %f2;
	setp.lt.f32	%p3, %f3, 0f40400000;
	@%p3 bra 	BB22_5;
	bra.uni 	BB22_4;

BB22_5:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r52}, %fd1;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r29, %temp}, %fd1;
	}
	and.b32  	%r30, %r52, 2147483647;
	mov.b64 	%fd31, {%r29, %r30};
	add.f64 	%fd32, %fd31, 0dC010000000000000;
	add.f64 	%fd28, %fd31, 0d4010000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd27,%fd28;
	// inline asm
	neg.f64 	%fd33, %fd28;
	mov.f64 	%fd34, 0d3FF0000000000000;
	fma.rn.f64 	%fd35, %fd33, %fd27, %fd34;
	fma.rn.f64 	%fd36, %fd35, %fd35, %fd35;
	fma.rn.f64 	%fd37, %fd36, %fd27, %fd27;
	mul.f64 	%fd38, %fd32, %fd37;
	add.rn.f64 	%fd39, %fd38, %fd34;
	mov.f64 	%fd40, 0dC010000000000000;
	fma.rn.f64 	%fd41, %fd40, %fd39, %fd31;
	neg.f64 	%fd42, %fd38;
	fma.rn.f64 	%fd43, %fd42, %fd31, %fd41;
	fma.rn.f64 	%fd44, %fd37, %fd43, %fd38;
	mov.f64 	%fd45, 0dBE44E1C6FD03D328;
	mov.f64 	%fd46, 0dBDF8774AD4E0BFD7;
	fma.rn.f64 	%fd47, %fd46, %fd44, %fd45;
	mov.f64 	%fd48, 0dBE4330149F7A56B6;
	fma.rn.f64 	%fd49, %fd47, %fd44, %fd48;
	mov.f64 	%fd50, 0d3E7BEDDED8376273;
	fma.rn.f64 	%fd51, %fd49, %fd44, %fd50;
	mov.f64 	%fd52, 0d3E6F9254C3ABF22B;
	fma.rn.f64 	%fd53, %fd51, %fd44, %fd52;
	mov.f64 	%fd54, 0dBEAB9068C2148CF0;
	fma.rn.f64 	%fd55, %fd53, %fd44, %fd54;
	mov.f64 	%fd56, 0d3E94C6454DB34009;
	fma.rn.f64 	%fd57, %fd55, %fd44, %fd56;
	mov.f64 	%fd58, 0d3ED7F1C378F2311D;
	fma.rn.f64 	%fd59, %fd57, %fd44, %fd58;
	mov.f64 	%fd60, 0dBEE78E051C6D5C58;
	fma.rn.f64 	%fd61, %fd59, %fd44, %fd60;
	mov.f64 	%fd62, 0dBEF995B4EAD14A90;
	fma.rn.f64 	%fd63, %fd61, %fd44, %fd62;
	mov.f64 	%fd64, 0d3F23BE27CF0A29B2;
	fma.rn.f64 	%fd65, %fd63, %fd44, %fd64;
	mov.f64 	%fd66, 0dBF2A1DEF3E81672E;
	fma.rn.f64 	%fd67, %fd65, %fd44, %fd66;
	mov.f64 	%fd68, 0dBF48D4ABE68C1713;
	fma.rn.f64 	%fd69, %fd67, %fd44, %fd68;
	mov.f64 	%fd70, 0d3F749C67210DD6B4;
	fma.rn.f64 	%fd71, %fd69, %fd44, %fd70;
	mov.f64 	%fd72, 0dBF9096238568E357;
	fma.rn.f64 	%fd73, %fd71, %fd44, %fd72;
	mov.f64 	%fd74, 0d3FA3079EDF8C2DC9;
	fma.rn.f64 	%fd75, %fd73, %fd44, %fd74;
	mov.f64 	%fd76, 0dBFB0FB06DFF601FC;
	fma.rn.f64 	%fd77, %fd75, %fd44, %fd76;
	mov.f64 	%fd78, 0d3FB7FEE004DFBCDC;
	fma.rn.f64 	%fd79, %fd77, %fd44, %fd78;
	mov.f64 	%fd80, 0dBFB9DDB23C3DB8C6;
	fma.rn.f64 	%fd81, %fd79, %fd44, %fd80;
	mov.f64 	%fd82, 0d3FB16ECEFCFA5FDA;
	fma.rn.f64 	%fd83, %fd81, %fd44, %fd82;
	mov.f64 	%fd84, 0d3F8F7F5DF66FB6D6;
	fma.rn.f64 	%fd85, %fd83, %fd44, %fd84;
	mov.f64 	%fd86, 0dBFC1DF1AD154A29D;
	fma.rn.f64 	%fd87, %fd85, %fd44, %fd86;
	mov.f64 	%fd88, 0d3FF3BA5916E9FD7F;
	fma.rn.f64 	%fd89, %fd87, %fd44, %fd88;
	mov.f64 	%fd90, 0d4000000000000000;
	fma.rn.f64 	%fd30, %fd90, %fd31, %fd34;
	// inline asm
	rcp.approx.ftz.f64 %fd29,%fd30;
	// inline asm
	neg.f64 	%fd91, %fd30;
	fma.rn.f64 	%fd92, %fd91, %fd29, %fd34;
	fma.rn.f64 	%fd93, %fd92, %fd92, %fd92;
	fma.rn.f64 	%fd94, %fd93, %fd29, %fd29;
	mul.f64 	%fd95, %fd89, %fd94;
	mul.f64 	%fd96, %fd95, 0dC000000000000000;
	fma.rn.f64 	%fd97, %fd31, %fd96, %fd89;
	neg.f64 	%fd98, %fd95;
	add.rn.f64 	%fd99, %fd97, %fd98;
	fma.rn.f64 	%fd139, %fd99, %fd94, %fd95;
	bra.uni 	BB22_6;

BB22_4:
	rcp.rn.f64 	%fd13, %fd1;
	mul.f64 	%fd14, %fd13, %fd13;
	mov.f64 	%fd15, 0d401A400000000000;
	mov.f64 	%fd16, 0dC03D880000000000;
	fma.rn.f64 	%fd17, %fd16, %fd14, %fd15;
	mov.f64 	%fd18, 0dBFFE000000000000;
	fma.rn.f64 	%fd19, %fd17, %fd14, %fd18;
	mov.f64 	%fd20, 0d3FE8000000000000;
	fma.rn.f64 	%fd21, %fd19, %fd14, %fd20;
	mov.f64 	%fd22, 0dBFE0000000000000;
	fma.rn.f64 	%fd23, %fd21, %fd14, %fd22;
	mov.f64 	%fd24, 0d3FF0000000000000;
	fma.rn.f64 	%fd25, %fd23, %fd14, %fd24;
	mul.f64 	%fd26, %fd13, 0d3FE20DD750429B6D;
	mul.f64 	%fd139, %fd26, %fd25;

BB22_6:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r46}, %fd1;
	}
	setp.gt.s32	%p4, %r46, -1;
	@%p4 bra 	BB22_11;

	mul.f64 	%fd5, %fd1, %fd1;
	neg.f64 	%fd100, %fd5;
	fma.rn.f64 	%fd6, %fd1, %fd1, %fd100;
	mov.f64 	%fd101, 0d4338000000000000;
	mov.f64 	%fd102, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd103, %fd5, %fd102, %fd101;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r7, %temp}, %fd103;
	}
	mov.f64 	%fd104, 0dC338000000000000;
	add.rn.f64 	%fd105, %fd103, %fd104;
	mov.f64 	%fd106, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd107, %fd105, %fd106, %fd5;
	mov.f64 	%fd108, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd109, %fd105, %fd108, %fd107;
	mov.f64 	%fd110, 0d3E928AF3FCA213EA;
	mov.f64 	%fd111, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd112, %fd111, %fd109, %fd110;
	mov.f64 	%fd113, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd114, %fd112, %fd109, %fd113;
	mov.f64 	%fd115, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd116, %fd114, %fd109, %fd115;
	mov.f64 	%fd117, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd118, %fd116, %fd109, %fd117;
	mov.f64 	%fd119, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd120, %fd118, %fd109, %fd119;
	mov.f64 	%fd121, 0d3F81111111122322;
	fma.rn.f64 	%fd122, %fd120, %fd109, %fd121;
	mov.f64 	%fd123, 0d3FA55555555502A1;
	fma.rn.f64 	%fd124, %fd122, %fd109, %fd123;
	mov.f64 	%fd125, 0d3FC5555555555511;
	fma.rn.f64 	%fd126, %fd124, %fd109, %fd125;
	mov.f64 	%fd127, 0d3FE000000000000B;
	fma.rn.f64 	%fd128, %fd126, %fd109, %fd127;
	mov.f64 	%fd129, 0d3FF0000000000000;
	fma.rn.f64 	%fd130, %fd128, %fd109, %fd129;
	fma.rn.f64 	%fd131, %fd130, %fd109, %fd129;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r8, %temp}, %fd131;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd131;
	}
	shl.b32 	%r31, %r7, 20;
	add.s32 	%r32, %r9, %r31;
	mov.b64 	%fd138, {%r8, %r32};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd5;
	}
	mov.b32 	 %f4, %r33;
	abs.f32 	%f1, %f4;
	setp.lt.f32	%p5, %f1, 0f4086232B;
	@%p5 bra 	BB22_10;

	setp.lt.f64	%p6, %fd5, 0d0000000000000000;
	add.f64 	%fd132, %fd5, 0d7FF0000000000000;
	selp.f64	%fd138, 0d0000000000000000, %fd132, %p6;
	setp.geu.f32	%p7, %f1, 0f40874800;
	@%p7 bra 	BB22_10;

	shr.u32 	%r34, %r7, 31;
	add.s32 	%r35, %r7, %r34;
	shr.s32 	%r36, %r35, 1;
	shl.b32 	%r37, %r36, 20;
	add.s32 	%r38, %r37, %r9;
	mov.b64 	%fd133, {%r8, %r38};
	sub.s32 	%r39, %r7, %r36;
	shl.b32 	%r40, %r39, 20;
	add.s32 	%r41, %r40, 1072693248;
	mov.u32 	%r42, 0;
	mov.b64 	%fd134, {%r42, %r41};
	mul.f64 	%fd138, %fd133, %fd134;

BB22_10:
	add.f64 	%fd135, %fd138, %fd138;
	fma.rn.f64 	%fd136, %fd135, %fd6, %fd135;
	sub.f64 	%fd137, %fd136, %fd139;
	setp.eq.f64	%p8, %fd135, 0d7FF0000000000000;
	selp.f64	%fd139, %fd135, %fd137, %p8;

BB22_11:
	ld.param.u32 	%r47, [map_erfcx_double_param_3];
	mad.lo.s32 	%r43, %r53, %r47, %r54;
	mul.wide.s32 	%rd7, %r43, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd139;
	add.s32 	%r54, %r2, %r54;
	setp.lt.s32	%p9, %r54, %r12;
	@%p9 bra 	BB22_3;

BB22_12:
	ld.param.u32 	%r49, [map_erfcx_double_param_1];
	mov.u32 	%r48, %ntid.x;
	mov.u32 	%r44, %nctaid.x;
	mad.lo.s32 	%r53, %r44, %r48, %r53;
	setp.lt.s32	%p10, %r53, %r49;
	@%p10 bra 	BB22_2;

BB22_13:
	ret;
}

	// .globl	map_erf_double
.visible .entry map_erf_double(
	.param .u32 map_erf_double_param_0,
	.param .u32 map_erf_double_param_1,
	.param .u64 map_erf_double_param_2,
	.param .u32 map_erf_double_param_3,
	.param .u64 map_erf_double_param_4,
	.param .u32 map_erf_double_param_5
)
{
	.reg .pred 	%p<11>;
	.reg .b32 	%r<50>;
	.reg .f64 	%fd<111>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r13, [map_erf_double_param_0];
	ld.param.u32 	%r14, [map_erf_double_param_1];
	ld.param.u64 	%rd1, [map_erf_double_param_2];
	ld.param.u64 	%rd2, [map_erf_double_param_4];
	mov.u32 	%r17, %tid.x;
	mov.u32 	%r18, %ntid.x;
	mov.u32 	%r19, %ctaid.x;
	mad.lo.s32 	%r48, %r18, %r19, %r17;
	setp.ge.s32	%p1, %r48, %r14;
	@%p1 bra 	BB23_13;

	mov.u32 	%r20, %tid.y;
	mov.u32 	%r21, %ntid.y;
	mov.u32 	%r22, %ctaid.y;
	mad.lo.s32 	%r2, %r21, %r22, %r20;
	mov.u32 	%r23, %nctaid.y;
	mul.lo.s32 	%r3, %r23, %r21;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd6, %rd1;

BB23_2:
	setp.ge.s32	%p2, %r2, %r13;
	@%p2 bra 	BB23_12;

	ld.param.u32 	%r45, [map_erf_double_param_5];
	mov.u32 	%r49, %r2;

BB23_4:
	mov.u32 	%r7, %r49;
	mul.lo.s32 	%r47, %r48, %r45;
	add.s32 	%r24, %r7, %r47;
	mul.wide.s32 	%rd4, %r24, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd1;
	}
	and.b32  	%r9, %r8, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r10, %temp}, %fd1;
	}
	setp.lt.u32	%p3, %r9, 1072693248;
	@%p3 bra 	BB23_10;
	bra.uni 	BB23_5;

BB23_10:
	mul.f64 	%fd86, %fd1, %fd1;
	mov.f64 	%fd87, 0d3E4D5F4BB7A316F6;
	mov.f64 	%fd88, 0dBE0A83AA3B08FBC2;
	fma.rn.f64 	%fd89, %fd88, %fd86, %fd87;
	mov.f64 	%fd90, 0dBE85BDCE301B3CDF;
	fma.rn.f64 	%fd91, %fd89, %fd86, %fd90;
	mov.f64 	%fd92, 0d3EBB978FADB81BC9;
	fma.rn.f64 	%fd93, %fd91, %fd86, %fd92;
	mov.f64 	%fd94, 0dBEEF4C99D6AE5FB8;
	fma.rn.f64 	%fd95, %fd93, %fd86, %fd94;
	mov.f64 	%fd96, 0d3F1F9A2AF549012E;
	fma.rn.f64 	%fd97, %fd95, %fd86, %fd96;
	mov.f64 	%fd98, 0dBF4C02DAFC636A47;
	fma.rn.f64 	%fd99, %fd97, %fd86, %fd98;
	mov.f64 	%fd100, 0d3F7565BCCF619AC0;
	fma.rn.f64 	%fd101, %fd99, %fd86, %fd100;
	mov.f64 	%fd102, 0dBF9B82CE311E321A;
	fma.rn.f64 	%fd103, %fd101, %fd86, %fd102;
	mov.f64 	%fd104, 0d3FBCE2F21A04075C;
	fma.rn.f64 	%fd105, %fd103, %fd86, %fd104;
	mov.f64 	%fd106, 0dBFD812746B0379B4;
	fma.rn.f64 	%fd107, %fd105, %fd86, %fd106;
	mov.f64 	%fd108, 0d3FF20DD750429B6D;
	fma.rn.f64 	%fd109, %fd107, %fd86, %fd108;
	mul.f64 	%fd110, %fd1, %fd109;
	bra.uni 	BB23_11;

BB23_5:
	setp.lt.u32	%p4, %r9, 2146435072;
	@%p4 bra 	BB23_9;
	bra.uni 	BB23_6;

BB23_9:
	mov.b64 	%fd8, {%r10, %r9};
	mov.f64 	%fd9, 0dBCF1384CE38C616A;
	mov.f64 	%fd10, 0d3C8B9C2B870030E8;
	fma.rn.f64 	%fd11, %fd10, %fd8, %fd9;
	mov.f64 	%fd12, 0d3D4458AE9746C2FD;
	fma.rn.f64 	%fd13, %fd11, %fd8, %fd12;
	mov.f64 	%fd14, 0dBD8E4A44D4F1AB56;
	fma.rn.f64 	%fd15, %fd13, %fd8, %fd14;
	mov.f64 	%fd16, 0d3DCFDF15265C58EE;
	fma.rn.f64 	%fd17, %fd15, %fd8, %fd16;
	mov.f64 	%fd18, 0dBE0933832F358D51;
	fma.rn.f64 	%fd19, %fd17, %fd8, %fd18;
	mov.f64 	%fd20, 0d3E3F136D3F719446;
	fma.rn.f64 	%fd21, %fd19, %fd8, %fd20;
	mov.f64 	%fd22, 0dBE6E94C2FE151B3B;
	fma.rn.f64 	%fd23, %fd21, %fd8, %fd22;
	mov.f64 	%fd24, 0d3E985A70310EE0A8;
	fma.rn.f64 	%fd25, %fd23, %fd8, %fd24;
	mov.f64 	%fd26, 0dBEBF944DA1520B74;
	fma.rn.f64 	%fd27, %fd25, %fd8, %fd26;
	mov.f64 	%fd28, 0d3EE09F503825C543;
	fma.rn.f64 	%fd29, %fd27, %fd8, %fd28;
	mov.f64 	%fd30, 0dBEFBEEFE9F949E59;
	fma.rn.f64 	%fd31, %fd29, %fd8, %fd30;
	mov.f64 	%fd32, 0d3F11D785C6E28857;
	fma.rn.f64 	%fd33, %fd31, %fd8, %fd32;
	mov.f64 	%fd34, 0dBF1D866B223048C7;
	fma.rn.f64 	%fd35, %fd33, %fd8, %fd34;
	mov.f64 	%fd36, 0d3EF258F0847E8908;
	fma.rn.f64 	%fd37, %fd35, %fd8, %fd36;
	mov.f64 	%fd38, 0d3F429CFC58DBB776;
	fma.rn.f64 	%fd39, %fd37, %fd8, %fd38;
	mov.f64 	%fd40, 0dBF5BE16D3F71F3C5;
	fma.rn.f64 	%fd41, %fd39, %fd8, %fd40;
	mov.f64 	%fd42, 0d3F2E8BDA60326B1A;
	fma.rn.f64 	%fd43, %fd41, %fd8, %fd42;
	mov.f64 	%fd44, 0d3F938FB20B0988A6;
	fma.rn.f64 	%fd45, %fd43, %fd8, %fd44;
	mov.f64 	%fd46, 0dBFBA4E3A80F64E33;
	fma.rn.f64 	%fd47, %fd45, %fd8, %fd46;
	mov.f64 	%fd48, 0dBFE45F3E88093928;
	fma.rn.f64 	%fd49, %fd47, %fd8, %fd48;
	mov.f64 	%fd50, 0dBFF20DD599CAEEA0;
	fma.rn.f64 	%fd51, %fd49, %fd8, %fd50;
	mov.f64 	%fd52, 0dBE883BE1E31CE133;
	fma.rn.f64 	%fd53, %fd51, %fd8, %fd52;
	mov.f64 	%fd54, 0d4338000000000000;
	mov.f64 	%fd55, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd56, %fd53, %fd55, %fd54;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r29, %temp}, %fd56;
	}
	mov.f64 	%fd57, 0dC338000000000000;
	add.rn.f64 	%fd58, %fd56, %fd57;
	mov.f64 	%fd59, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd60, %fd58, %fd59, %fd53;
	mov.f64 	%fd61, 0d3E928AF3FCA213EA;
	mov.f64 	%fd62, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd63, %fd62, %fd60, %fd61;
	mov.f64 	%fd64, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd65, %fd63, %fd60, %fd64;
	mov.f64 	%fd66, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd67, %fd65, %fd60, %fd66;
	mov.f64 	%fd68, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd69, %fd67, %fd60, %fd68;
	mov.f64 	%fd70, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd71, %fd69, %fd60, %fd70;
	mov.f64 	%fd72, 0d3F81111111122322;
	fma.rn.f64 	%fd73, %fd71, %fd60, %fd72;
	mov.f64 	%fd74, 0d3FA55555555502A1;
	fma.rn.f64 	%fd75, %fd73, %fd60, %fd74;
	mov.f64 	%fd76, 0d3FC5555555555511;
	fma.rn.f64 	%fd77, %fd75, %fd60, %fd76;
	mov.f64 	%fd78, 0d3FE000000000000B;
	fma.rn.f64 	%fd79, %fd77, %fd60, %fd78;
	mov.f64 	%fd80, 0d3FF0000000000000;
	fma.rn.f64 	%fd81, %fd79, %fd60, %fd80;
	fma.rn.f64 	%fd82, %fd81, %fd60, %fd80;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r30}, %fd82;
	}
	shl.b32 	%r31, %r29, 20;
	add.s32 	%r32, %r30, %r31;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r33, %temp}, %fd82;
	}
	mov.b64 	%fd83, {%r33, %r32};
	sub.f64 	%fd84, %fd80, %fd83;
	setp.gt.u32	%p8, %r9, 1075294207;
	selp.f64	%fd85, 0d3FF0000000000000, %fd84, %p8;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r34, %temp}, %fd85;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd85;
	}
	and.b32  	%r36, %r8, -2147483648;
	or.b32  	%r37, %r35, %r36;
	mov.b64 	%fd110, {%r34, %r37};
	bra.uni 	BB23_11;

BB23_6:
	setp.eq.s32	%p5, %r9, 2146435072;
	setp.eq.s32	%p6, %r10, 0;
	and.pred  	%p7, %p5, %p6;
	@%p7 bra 	BB23_8;
	bra.uni 	BB23_7;

BB23_8:
	mov.f64 	%fd7, 0d3FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r25, %temp}, %fd7;
	}
	and.b32  	%r26, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd7;
	}
	or.b32  	%r28, %r27, %r26;
	mov.b64 	%fd110, {%r25, %r28};
	bra.uni 	BB23_11;

BB23_7:
	add.f64 	%fd110, %fd1, %fd1;

BB23_11:
	ld.param.u32 	%r42, [map_erf_double_param_3];
	mul.lo.s32 	%r41, %r48, %r42;
	add.s32 	%r38, %r7, %r41;
	mul.wide.s32 	%rd7, %r38, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd110;
	add.s32 	%r11, %r3, %r7;
	setp.lt.s32	%p9, %r11, %r13;
	mov.u32 	%r49, %r11;
	@%p9 bra 	BB23_4;

BB23_12:
	ld.param.u32 	%r44, [map_erf_double_param_1];
	mov.u32 	%r43, %ntid.x;
	mov.u32 	%r39, %nctaid.x;
	mad.lo.s32 	%r48, %r39, %r43, %r48;
	setp.lt.s32	%p10, %r48, %r44;
	@%p10 bra 	BB23_2;

BB23_13:
	ret;
}

	// .globl	map_erfinv_double
.visible .entry map_erfinv_double(
	.param .u32 map_erfinv_double_param_0,
	.param .u32 map_erfinv_double_param_1,
	.param .u64 map_erfinv_double_param_2,
	.param .u32 map_erfinv_double_param_3,
	.param .u64 map_erfinv_double_param_4,
	.param .u32 map_erfinv_double_param_5
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<46>;
	.reg .f64 	%fd<173>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r10, [map_erfinv_double_param_0];
	ld.param.u32 	%r11, [map_erfinv_double_param_1];
	ld.param.u64 	%rd3, [map_erfinv_double_param_2];
	ld.param.u64 	%rd4, [map_erfinv_double_param_4];
	mov.u32 	%r14, %ntid.x;
	mov.u32 	%r15, %ctaid.x;
	mov.u32 	%r16, %tid.x;
	mad.lo.s32 	%r44, %r14, %r15, %r16;
	setp.ge.s32	%p1, %r44, %r11;
	@%p1 bra 	BB24_14;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r17, %tid.y;
	mov.u32 	%r18, %ntid.y;
	mov.u32 	%r19, %ctaid.y;
	mad.lo.s32 	%r2, %r18, %r19, %r17;
	mov.u32 	%r20, %nctaid.y;
	mul.lo.s32 	%r3, %r20, %r18;

BB24_2:
	setp.ge.s32	%p2, %r2, %r10;
	@%p2 bra 	BB24_13;

	ld.param.u32 	%r41, [map_erfinv_double_param_5];
	mov.u32 	%r45, %r2;

BB24_4:
	mov.u32 	%r7, %r45;
	mul.lo.s32 	%r43, %r44, %r41;
	add.s32 	%r21, %r7, %r43;
	mul.wide.s32 	%rd5, %r21, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r22}, %fd1;
	}
	mov.b32 	 %f1, %r22;
	abs.f32 	%f2, %f1;
	setp.lt.f32	%p3, %f2, 0f3FF00000;
	@%p3 bra 	BB24_7;
	bra.uni 	BB24_5;

BB24_7:
	neg.f64 	%fd12, %fd1;
	mov.f64 	%fd13, 0d3FF0000000000000;
	fma.rn.f64 	%fd14, %fd1, %fd12, %fd13;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd14;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r24, %temp}, %fd14;
	}
	shr.u32 	%r25, %r23, 20;
	and.b32  	%r26, %r25, 2046;
	add.s32 	%r27, %r26, 2147482626;
	mov.u32 	%r28, 1127219200;
	mov.b64 	%fd15, {%r27, %r28};
	mov.u32 	%r29, -2147483648;
	mov.b64 	%fd16, {%r29, %r28};
	sub.f64 	%fd17, %fd15, %fd16;
	and.b32  	%r30, %r23, -2145386497;
	add.s32 	%r31, %r30, 1071644672;
	mov.b64 	%fd18, {%r24, %r31};
	add.f64 	%fd19, %fd18, 0dBFF0000000000000;
	add.f64 	%fd11, %fd18, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd10,%fd11;
	// inline asm
	neg.f64 	%fd20, %fd11;
	fma.rn.f64 	%fd21, %fd20, %fd10, %fd13;
	fma.rn.f64 	%fd22, %fd21, %fd21, %fd21;
	fma.rn.f64 	%fd23, %fd22, %fd10, %fd10;
	mul.f64 	%fd24, %fd19, %fd23;
	mov.f64 	%fd25, 0dC000000000000000;
	fma.rn.f64 	%fd26, %fd25, %fd24, %fd19;
	neg.f64 	%fd27, %fd24;
	fma.rn.f64 	%fd28, %fd27, %fd19, %fd26;
	fma.rn.f64 	%fd29, %fd28, %fd23, %fd24;
	mul.f64 	%fd30, %fd29, %fd29;
	mov.f64 	%fd31, 0d3FA55CF59CDC5D89;
	mov.f64 	%fd32, 0d3FB5C5C218C775C9;
	fma.rn.f64 	%fd33, %fd32, %fd30, %fd31;
	mov.f64 	%fd34, 0d3FAEFD18CF6EBB9C;
	fma.rn.f64 	%fd35, %fd33, %fd30, %fd34;
	mov.f64 	%fd36, 0d3FB10682EDCB8D1B;
	fma.rn.f64 	%fd37, %fd35, %fd30, %fd36;
	mov.f64 	%fd38, 0d3FB3B1DD3AC7FC96;
	fma.rn.f64 	%fd39, %fd37, %fd30, %fd38;
	mov.f64 	%fd40, 0d3FB745CB459B54A6;
	fma.rn.f64 	%fd41, %fd39, %fd30, %fd40;
	mov.f64 	%fd42, 0d3FBC71C741A0669F;
	fma.rn.f64 	%fd43, %fd41, %fd30, %fd42;
	mov.f64 	%fd44, 0d3FC249249209112E;
	fma.rn.f64 	%fd45, %fd43, %fd30, %fd44;
	mov.f64 	%fd46, 0d3FC99999999A06C1;
	fma.rn.f64 	%fd47, %fd45, %fd30, %fd46;
	mov.f64 	%fd48, 0d3FD5555555555535;
	fma.rn.f64 	%fd49, %fd47, %fd30, %fd48;
	mul.f64 	%fd50, %fd30, %fd49;
	fma.rn.f64 	%fd51, %fd50, %fd29, %fd29;
	add.f64 	%fd52, %fd51, %fd51;
	mov.f64 	%fd53, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd4, %fd17, %fd53, %fd52;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd4;
	}
	setp.lt.u32	%p6, %r32, -1072103424;
	@%p6 bra 	BB24_11;
	bra.uni 	BB24_8;

BB24_11:
	mov.f64 	%fd125, 0dC009000000000000;
	sub.f64 	%fd126, %fd125, %fd4;
	mov.f64 	%fd127, 0dBC08DDF93324D327;
	mov.f64 	%fd128, 0dBBB135D2E746E627;
	fma.rn.f64 	%fd129, %fd128, %fd126, %fd127;
	mov.f64 	%fd130, 0d3C37B83EEF0B7C9F;
	fma.rn.f64 	%fd131, %fd129, %fd126, %fd130;
	mov.f64 	%fd132, 0d3C69BA72CD589B91;
	fma.rn.f64 	%fd133, %fd131, %fd126, %fd132;
	mov.f64 	%fd134, 0dBCA33689090A6B96;
	fma.rn.f64 	%fd135, %fd133, %fd126, %fd134;
	mov.f64 	%fd136, 0d3C782E11898132E0;
	fma.rn.f64 	%fd137, %fd135, %fd126, %fd136;
	mov.f64 	%fd138, 0d3CFDE4ACFD9E26BA;
	fma.rn.f64 	%fd139, %fd137, %fd126, %fd138;
	mov.f64 	%fd140, 0dBD26D33EED66C487;
	fma.rn.f64 	%fd141, %fd139, %fd126, %fd140;
	mov.f64 	%fd142, 0dBD36F2167040D8E2;
	fma.rn.f64 	%fd143, %fd141, %fd126, %fd142;
	mov.f64 	%fd144, 0d3D872A22C2D77E20;
	fma.rn.f64 	%fd145, %fd143, %fd126, %fd144;
	mov.f64 	%fd146, 0dBDAC8859C4E5C0AF;
	fma.rn.f64 	%fd147, %fd145, %fd126, %fd146;
	mov.f64 	%fd148, 0dBDCDC583D118A561;
	fma.rn.f64 	%fd149, %fd147, %fd126, %fd148;
	mov.f64 	%fd150, 0d3E120F47CCF46B3C;
	fma.rn.f64 	%fd151, %fd149, %fd126, %fd150;
	mov.f64 	%fd152, 0dBE31A9E38DC84D60;
	fma.rn.f64 	%fd153, %fd151, %fd126, %fd152;
	mov.f64 	%fd154, 0dBE5F36CD6D3D46A9;
	fma.rn.f64 	%fd155, %fd153, %fd126, %fd154;
	mov.f64 	%fd156, 0d3E9C6B4F5D03B787;
	fma.rn.f64 	%fd157, %fd155, %fd126, %fd156;
	mov.f64 	%fd158, 0dBEB6E8A5434AE8A2;
	fma.rn.f64 	%fd159, %fd157, %fd126, %fd158;
	mov.f64 	%fd160, 0dBEED1D1F7B8736F6;
	fma.rn.f64 	%fd161, %fd159, %fd126, %fd160;
	mov.f64 	%fd162, 0d3F2879C2A212F024;
	fma.rn.f64 	%fd163, %fd161, %fd126, %fd162;
	mov.f64 	%fd164, 0dBF4845769484FCA8;
	fma.rn.f64 	%fd165, %fd163, %fd126, %fd164;
	mov.f64 	%fd166, 0dBF78B6C33114F909;
	fma.rn.f64 	%fd167, %fd165, %fd126, %fd166;
	mov.f64 	%fd168, 0d3FCEBD80D9B13E28;
	fma.rn.f64 	%fd169, %fd167, %fd126, %fd168;
	mov.f64 	%fd170, 0d3FFA755E7C99AE86;
	fma.rn.f64 	%fd8, %fd169, %fd126, %fd170;
	mov.f64 	%fd172, %fd8;
	bra.uni 	BB24_12;

BB24_5:
	abs.f64 	%fd2, %fd1;
	setp.gtu.f64	%p4, %fd2, 0d7FF0000000000000;
	mov.f64 	%fd172, %fd1;
	@%p4 bra 	BB24_12;

	setp.eq.f64	%p5, %fd2, 0d3FF0000000000000;
	selp.f64	%fd3, 0d7FF0000000000000, 0dFFF8000000000000, %p5;
	mov.f64 	%fd172, %fd3;
	bra.uni 	BB24_12;

BB24_8:
	neg.f64 	%fd54, %fd4;
	sqrt.rn.f64 	%fd5, %fd54;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd5;
	}
	setp.lt.s32	%p7, %r33, 1074790400;
	@%p7 bra 	BB24_10;
	bra.uni 	BB24_9;

BB24_10:
	add.f64 	%fd88, %fd5, 0dC00A000000000000;
	mov.f64 	%fd89, 0d3E785CBE52878635;
	mov.f64 	%fd90, 0d3E23040F87DBD932;
	fma.rn.f64 	%fd91, %fd90, %fd88, %fd89;
	mov.f64 	%fd92, 0dBE92777453DD3955;
	fma.rn.f64 	%fd93, %fd91, %fd88, %fd92;
	mov.f64 	%fd94, 0d3E5395ABCD554C6C;
	fma.rn.f64 	%fd95, %fd93, %fd88, %fd94;
	mov.f64 	%fd96, 0d3EB936388A3790AD;
	fma.rn.f64 	%fd97, %fd95, %fd88, %fd96;
	mov.f64 	%fd98, 0dBED0D5DB812B5083;
	fma.rn.f64 	%fd99, %fd97, %fd88, %fd98;
	mov.f64 	%fd100, 0d3EC8860CD5D652F6;
	fma.rn.f64 	%fd101, %fd99, %fd88, %fd100;
	mov.f64 	%fd102, 0d3EEA29A0CACDFB23;
	fma.rn.f64 	%fd103, %fd101, %fd88, %fd102;
	mov.f64 	%fd104, 0dBF08CEF1F80281F2;
	fma.rn.f64 	%fd105, %fd103, %fd88, %fd104;
	mov.f64 	%fd106, 0d3F11E684D0B9188A;
	fma.rn.f64 	%fd107, %fd105, %fd88, %fd106;
	mov.f64 	%fd108, 0d3EF932CD54C8A222;
	fma.rn.f64 	%fd109, %fd107, %fd88, %fd108;
	mov.f64 	%fd110, 0dBF37448A89EF8AA3;
	fma.rn.f64 	%fd111, %fd109, %fd88, %fd110;
	mov.f64 	%fd112, 0d3F4F3CC55AD40C25;
	fma.rn.f64 	%fd113, %fd111, %fd88, %fd112;
	mov.f64 	%fd114, 0dBF5BA924132F38B1;
	fma.rn.f64 	%fd115, %fd113, %fd88, %fd114;
	mov.f64 	%fd116, 0d3F6468EECA533CF8;
	fma.rn.f64 	%fd117, %fd115, %fd88, %fd116;
	mov.f64 	%fd118, 0dBF6EBADABB891BBD;
	fma.rn.f64 	%fd119, %fd117, %fd88, %fd118;
	mov.f64 	%fd120, 0d3F75FFCFE5B76AFC;
	fma.rn.f64 	%fd121, %fd119, %fd88, %fd120;
	mov.f64 	%fd122, 0d3FF0158A6D641D39;
	fma.rn.f64 	%fd123, %fd121, %fd88, %fd122;
	mov.f64 	%fd124, 0d4008ABCC380D5A48;
	fma.rn.f64 	%fd7, %fd123, %fd88, %fd124;
	mov.f64 	%fd172, %fd7;
	bra.uni 	BB24_12;

BB24_9:
	add.f64 	%fd55, %fd5, 0dC014000000000000;
	mov.f64 	%fd56, 0dBDF18FEEC0E38727;
	mov.f64 	%fd57, 0dBDBDCEC3A7785389;
	fma.rn.f64 	%fd58, %fd57, %fd55, %fd56;
	mov.f64 	%fd59, 0d3E19E6BF2DDA45E3;
	fma.rn.f64 	%fd60, %fd58, %fd55, %fd59;
	mov.f64 	%fd61, 0dBE30468FB24E2F5F;
	fma.rn.f64 	%fd62, %fd60, %fd55, %fd61;
	mov.f64 	%fd63, 0d3E405AC6A8FBA182;
	fma.rn.f64 	%fd64, %fd62, %fd55, %fd63;
	mov.f64 	%fd65, 0dBE50102E495FB9C0;
	fma.rn.f64 	%fd66, %fd64, %fd55, %fd65;
	mov.f64 	%fd67, 0d3E5F4C20E1334AF8;
	fma.rn.f64 	%fd68, %fd66, %fd55, %fd67;
	mov.f64 	%fd69, 0dBE722D220FDF9C3E;
	fma.rn.f64 	%fd70, %fd68, %fd55, %fd69;
	mov.f64 	%fd71, 0d3E8EBC8BB824CB54;
	fma.rn.f64 	%fd72, %fd70, %fd55, %fd71;
	mov.f64 	%fd73, 0dBEB0A8D40EA372CC;
	fma.rn.f64 	%fd74, %fd72, %fd55, %fd73;
	mov.f64 	%fd75, 0d3ED2FBD29D093D2B;
	fma.rn.f64 	%fd76, %fd74, %fd55, %fd75;
	mov.f64 	%fd77, 0dBEF4A3497E1E0FAC;
	fma.rn.f64 	%fd78, %fd76, %fd55, %fd77;
	mov.f64 	%fd79, 0d3F13EBF4EB00938F;
	fma.rn.f64 	%fd80, %fd78, %fd55, %fd79;
	mov.f64 	%fd81, 0dBF2C2F36A8FC5D53;
	fma.rn.f64 	%fd82, %fd80, %fd55, %fd81;
	mov.f64 	%fd83, 0dBF222EA5DF04047C;
	fma.rn.f64 	%fd84, %fd82, %fd55, %fd83;
	mov.f64 	%fd85, 0d3FF02A30D1FBA0DC;
	fma.rn.f64 	%fd86, %fd84, %fd55, %fd85;
	mov.f64 	%fd87, 0d4013664DDD1AD7FB;
	fma.rn.f64 	%fd6, %fd86, %fd55, %fd87;
	mov.f64 	%fd172, %fd6;

BB24_12:
	mov.f64 	%fd9, %fd172;
	ld.param.u32 	%r38, [map_erfinv_double_param_3];
	mul.lo.s32 	%r37, %r44, %r38;
	add.s32 	%r34, %r7, %r37;
	mul.wide.s32 	%rd7, %r34, 8;
	add.s64 	%rd8, %rd1, %rd7;
	mul.f64 	%fd171, %fd1, %fd9;
	st.global.f64 	[%rd8], %fd171;
	add.s32 	%r8, %r3, %r7;
	setp.lt.s32	%p8, %r8, %r10;
	mov.u32 	%r45, %r8;
	@%p8 bra 	BB24_4;

BB24_13:
	ld.param.u32 	%r40, [map_erfinv_double_param_1];
	mov.u32 	%r39, %ntid.x;
	mov.u32 	%r35, %nctaid.x;
	mad.lo.s32 	%r44, %r35, %r39, %r44;
	setp.lt.s32	%p9, %r44, %r40;
	@%p9 bra 	BB24_2;

BB24_14:
	ret;
}

	// .globl	map_exp10_double
.visible .entry map_exp10_double(
	.param .u32 map_exp10_double_param_0,
	.param .u32 map_exp10_double_param_1,
	.param .u64 map_exp10_double_param_2,
	.param .u32 map_exp10_double_param_3,
	.param .u64 map_exp10_double_param_4,
	.param .u32 map_exp10_double_param_5
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<46>;
	.reg .f64 	%fd<46>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r13, [map_exp10_double_param_0];
	ld.param.u32 	%r14, [map_exp10_double_param_1];
	ld.param.u64 	%rd1, [map_exp10_double_param_2];
	ld.param.u32 	%r15, [map_exp10_double_param_3];
	ld.param.u64 	%rd2, [map_exp10_double_param_4];
	ld.param.u32 	%r16, [map_exp10_double_param_5];
	mov.u32 	%r17, %tid.x;
	mov.u32 	%r18, %ntid.x;
	mov.u32 	%r19, %ctaid.x;
	mad.lo.s32 	%r44, %r18, %r19, %r17;
	setp.ge.s32	%p1, %r44, %r14;
	@%p1 bra 	BB25_9;

	mov.u32 	%r20, %ntid.y;
	mov.u32 	%r21, %nctaid.y;
	mul.lo.s32 	%r2, %r21, %r20;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd6, %rd1;

BB25_2:
	mov.u32 	%r22, %ctaid.y;
	mov.u32 	%r24, %tid.y;
	mad.lo.s32 	%r45, %r20, %r22, %r24;
	setp.ge.s32	%p2, %r45, %r13;
	@%p2 bra 	BB25_8;

	mul.lo.s32 	%r4, %r44, %r15;

BB25_4:
	mad.lo.s32 	%r29, %r44, %r16, %r45;
	mul.wide.s32 	%rd4, %r29, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	mov.f64 	%fd6, 0d4338000000000000;
	mov.f64 	%fd7, 0d400A934F0979A371;
	fma.rn.f64 	%fd8, %fd1, %fd7, %fd6;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r7, %temp}, %fd8;
	}
	mov.f64 	%fd9, 0dC338000000000000;
	add.rn.f64 	%fd10, %fd8, %fd9;
	mov.f64 	%fd11, 0dBFD34413509F79FF;
	fma.rn.f64 	%fd12, %fd10, %fd11, %fd1;
	mov.f64 	%fd13, 0d3C49DC1DA994FD21;
	fma.rn.f64 	%fd14, %fd10, %fd13, %fd12;
	mul.f64 	%fd15, %fd14, 0dBCAF48AD494EA3E9;
	mov.f64 	%fd16, 0d40026BB1BBB55516;
	fma.rn.f64 	%fd17, %fd14, %fd16, %fd15;
	mov.f64 	%fd18, 0d3E928AF3FCA213EA;
	mov.f64 	%fd19, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd20, %fd19, %fd17, %fd18;
	mov.f64 	%fd21, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd22, %fd20, %fd17, %fd21;
	mov.f64 	%fd23, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd24, %fd22, %fd17, %fd23;
	mov.f64 	%fd25, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd26, %fd24, %fd17, %fd25;
	mov.f64 	%fd27, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd28, %fd26, %fd17, %fd27;
	mov.f64 	%fd29, 0d3F81111111122322;
	fma.rn.f64 	%fd30, %fd28, %fd17, %fd29;
	mov.f64 	%fd31, 0d3FA55555555502A1;
	fma.rn.f64 	%fd32, %fd30, %fd17, %fd31;
	mov.f64 	%fd33, 0d3FC5555555555511;
	fma.rn.f64 	%fd34, %fd32, %fd17, %fd33;
	mov.f64 	%fd35, 0d3FE000000000000B;
	fma.rn.f64 	%fd36, %fd34, %fd17, %fd35;
	mov.f64 	%fd37, 0d3FF0000000000000;
	fma.rn.f64 	%fd38, %fd36, %fd17, %fd37;
	fma.rn.f64 	%fd39, %fd38, %fd17, %fd37;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r8, %temp}, %fd39;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd39;
	}
	shl.b32 	%r30, %r7, 20;
	add.s32 	%r31, %r9, %r30;
	mov.b64 	%fd45, {%r8, %r31};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd1;
	}
	mov.b32 	 %f2, %r10;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p3, %f1, 0f40733A71;
	@%p3 bra 	BB25_7;

	setp.lt.s32	%p4, %r10, 0;
	selp.f64	%fd40, 0d0000000000000000, 0d7FF0000000000000, %p4;
	abs.f64 	%fd41, %fd1;
	setp.gtu.f64	%p5, %fd41, 0d7FF0000000000000;
	add.f64 	%fd42, %fd1, %fd1;
	selp.f64	%fd45, %fd42, %fd40, %p5;
	setp.geu.f32	%p6, %f1, 0f407439B8;
	@%p6 bra 	BB25_7;

	shr.u32 	%r32, %r7, 31;
	add.s32 	%r33, %r7, %r32;
	shr.s32 	%r34, %r33, 1;
	shl.b32 	%r35, %r34, 20;
	add.s32 	%r36, %r35, %r9;
	mov.b64 	%fd43, {%r8, %r36};
	sub.s32 	%r37, %r7, %r34;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, 1072693248;
	mov.u32 	%r40, 0;
	mov.b64 	%fd44, {%r40, %r39};
	mul.f64 	%fd45, %fd43, %fd44;

BB25_7:
	add.s32 	%r41, %r45, %r4;
	mul.wide.s32 	%rd7, %r41, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd45;
	add.s32 	%r45, %r2, %r45;
	setp.lt.s32	%p7, %r45, %r13;
	@%p7 bra 	BB25_4;

BB25_8:
	mov.u32 	%r42, %nctaid.x;
	mad.lo.s32 	%r44, %r42, %r18, %r44;
	setp.lt.s32	%p8, %r44, %r14;
	@%p8 bra 	BB25_2;

BB25_9:
	ret;
}

	// .globl	map_exp2_double
.visible .entry map_exp2_double(
	.param .u32 map_exp2_double_param_0,
	.param .u32 map_exp2_double_param_1,
	.param .u64 map_exp2_double_param_2,
	.param .u32 map_exp2_double_param_3,
	.param .u64 map_exp2_double_param_4,
	.param .u32 map_exp2_double_param_5
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<46>;
	.reg .f64 	%fd<42>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r13, [map_exp2_double_param_0];
	ld.param.u32 	%r14, [map_exp2_double_param_1];
	ld.param.u64 	%rd1, [map_exp2_double_param_2];
	ld.param.u32 	%r15, [map_exp2_double_param_3];
	ld.param.u64 	%rd2, [map_exp2_double_param_4];
	ld.param.u32 	%r16, [map_exp2_double_param_5];
	mov.u32 	%r17, %tid.x;
	mov.u32 	%r18, %ntid.x;
	mov.u32 	%r19, %ctaid.x;
	mad.lo.s32 	%r44, %r18, %r19, %r17;
	setp.ge.s32	%p1, %r44, %r14;
	@%p1 bra 	BB26_9;

	mov.u32 	%r20, %ntid.y;
	mov.u32 	%r21, %nctaid.y;
	mul.lo.s32 	%r2, %r21, %r20;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd6, %rd1;

BB26_2:
	mov.u32 	%r22, %ctaid.y;
	mov.u32 	%r24, %tid.y;
	mad.lo.s32 	%r45, %r20, %r22, %r24;
	setp.ge.s32	%p2, %r45, %r13;
	@%p2 bra 	BB26_8;

	mul.lo.s32 	%r4, %r44, %r15;

BB26_4:
	mad.lo.s32 	%r29, %r44, %r16, %r45;
	mul.wide.s32 	%rd4, %r29, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	mov.f64 	%fd6, 0d4338000000000000;
	add.rn.f64 	%fd7, %fd1, %fd6;
	mov.f64 	%fd8, 0dC338000000000000;
	add.rn.f64 	%fd9, %fd7, %fd8;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r7, %temp}, %fd7;
	}
	sub.f64 	%fd10, %fd1, %fd9;
	mul.f64 	%fd11, %fd10, 0d3C7ABC9E3B39803F;
	mov.f64 	%fd12, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd13, %fd10, %fd12, %fd11;
	mov.f64 	%fd14, 0d3E928AF3FCA213EA;
	mov.f64 	%fd15, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd16, %fd15, %fd13, %fd14;
	mov.f64 	%fd17, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd18, %fd16, %fd13, %fd17;
	mov.f64 	%fd19, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd20, %fd18, %fd13, %fd19;
	mov.f64 	%fd21, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd22, %fd20, %fd13, %fd21;
	mov.f64 	%fd23, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd24, %fd22, %fd13, %fd23;
	mov.f64 	%fd25, 0d3F81111111122322;
	fma.rn.f64 	%fd26, %fd24, %fd13, %fd25;
	mov.f64 	%fd27, 0d3FA55555555502A1;
	fma.rn.f64 	%fd28, %fd26, %fd13, %fd27;
	mov.f64 	%fd29, 0d3FC5555555555511;
	fma.rn.f64 	%fd30, %fd28, %fd13, %fd29;
	mov.f64 	%fd31, 0d3FE000000000000B;
	fma.rn.f64 	%fd32, %fd30, %fd13, %fd31;
	mov.f64 	%fd33, 0d3FF0000000000000;
	fma.rn.f64 	%fd34, %fd32, %fd13, %fd33;
	fma.rn.f64 	%fd35, %fd34, %fd13, %fd33;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r8, %temp}, %fd35;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd35;
	}
	shl.b32 	%r30, %r7, 20;
	add.s32 	%r31, %r9, %r30;
	mov.b64 	%fd41, {%r8, %r31};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd1;
	}
	mov.b32 	 %f2, %r10;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p3, %f1, 0f408FF000;
	@%p3 bra 	BB26_7;

	setp.lt.s32	%p4, %r10, 0;
	selp.f64	%fd36, 0d0000000000000000, 0d7FF0000000000000, %p4;
	abs.f64 	%fd37, %fd1;
	setp.gtu.f64	%p5, %fd37, 0d7FF0000000000000;
	add.f64 	%fd38, %fd1, %fd1;
	selp.f64	%fd41, %fd38, %fd36, %p5;
	setp.geu.f32	%p6, %f1, 0f4090CC00;
	@%p6 bra 	BB26_7;

	shr.u32 	%r32, %r7, 31;
	add.s32 	%r33, %r7, %r32;
	shr.s32 	%r34, %r33, 1;
	shl.b32 	%r35, %r34, 20;
	add.s32 	%r36, %r35, %r9;
	mov.b64 	%fd39, {%r8, %r36};
	sub.s32 	%r37, %r7, %r34;
	shl.b32 	%r38, %r37, 20;
	add.s32 	%r39, %r38, 1072693248;
	mov.u32 	%r40, 0;
	mov.b64 	%fd40, {%r40, %r39};
	mul.f64 	%fd41, %fd39, %fd40;

BB26_7:
	add.s32 	%r41, %r45, %r4;
	mul.wide.s32 	%rd7, %r41, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd41;
	add.s32 	%r45, %r2, %r45;
	setp.lt.s32	%p7, %r45, %r13;
	@%p7 bra 	BB26_4;

BB26_8:
	mov.u32 	%r42, %nctaid.x;
	mad.lo.s32 	%r44, %r42, %r18, %r44;
	setp.lt.s32	%p8, %r44, %r14;
	@%p8 bra 	BB26_2;

BB26_9:
	ret;
}

	// .globl	map_exp_double
.visible .entry map_exp_double(
	.param .u32 map_exp_double_param_0,
	.param .u32 map_exp_double_param_1,
	.param .u64 map_exp_double_param_2,
	.param .u32 map_exp_double_param_3,
	.param .u64 map_exp_double_param_4,
	.param .u32 map_exp_double_param_5
)
{
	.reg .pred 	%p<8>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<47>;
	.reg .f64 	%fd<41>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r13, [map_exp_double_param_0];
	ld.param.u32 	%r14, [map_exp_double_param_1];
	ld.param.u64 	%rd1, [map_exp_double_param_2];
	ld.param.u32 	%r15, [map_exp_double_param_3];
	ld.param.u64 	%rd2, [map_exp_double_param_4];
	ld.param.u32 	%r16, [map_exp_double_param_5];
	mov.u32 	%r17, %tid.x;
	mov.u32 	%r18, %ntid.x;
	mov.u32 	%r19, %ctaid.x;
	mad.lo.s32 	%r45, %r18, %r19, %r17;
	setp.ge.s32	%p1, %r45, %r14;
	@%p1 bra 	BB27_9;

	mov.u32 	%r20, %ntid.y;
	mov.u32 	%r21, %nctaid.y;
	mul.lo.s32 	%r2, %r21, %r20;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd6, %rd1;

BB27_2:
	mov.u32 	%r22, %ctaid.y;
	mov.u32 	%r24, %tid.y;
	mad.lo.s32 	%r46, %r20, %r22, %r24;
	setp.ge.s32	%p2, %r46, %r13;
	@%p2 bra 	BB27_8;

	mul.lo.s32 	%r4, %r45, %r16;
	mul.lo.s32 	%r5, %r45, %r15;

BB27_4:
	add.s32 	%r29, %r46, %r4;
	mul.wide.s32 	%rd4, %r29, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	mov.f64 	%fd6, 0d4338000000000000;
	mov.f64 	%fd7, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd8, %fd1, %fd7, %fd6;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r8, %temp}, %fd8;
	}
	mov.f64 	%fd9, 0dC338000000000000;
	add.rn.f64 	%fd10, %fd8, %fd9;
	mov.f64 	%fd11, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd12, %fd10, %fd11, %fd1;
	mov.f64 	%fd13, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd14, %fd10, %fd13, %fd12;
	mov.f64 	%fd15, 0d3E928AF3FCA213EA;
	mov.f64 	%fd16, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd17, %fd16, %fd14, %fd15;
	mov.f64 	%fd18, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd19, %fd17, %fd14, %fd18;
	mov.f64 	%fd20, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd21, %fd19, %fd14, %fd20;
	mov.f64 	%fd22, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd23, %fd21, %fd14, %fd22;
	mov.f64 	%fd24, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd25, %fd23, %fd14, %fd24;
	mov.f64 	%fd26, 0d3F81111111122322;
	fma.rn.f64 	%fd27, %fd25, %fd14, %fd26;
	mov.f64 	%fd28, 0d3FA55555555502A1;
	fma.rn.f64 	%fd29, %fd27, %fd14, %fd28;
	mov.f64 	%fd30, 0d3FC5555555555511;
	fma.rn.f64 	%fd31, %fd29, %fd14, %fd30;
	mov.f64 	%fd32, 0d3FE000000000000B;
	fma.rn.f64 	%fd33, %fd31, %fd14, %fd32;
	mov.f64 	%fd34, 0d3FF0000000000000;
	fma.rn.f64 	%fd35, %fd33, %fd14, %fd34;
	fma.rn.f64 	%fd36, %fd35, %fd14, %fd34;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r9, %temp}, %fd36;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd36;
	}
	shl.b32 	%r30, %r8, 20;
	add.s32 	%r31, %r10, %r30;
	mov.b64 	%fd40, {%r9, %r31};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd1;
	}
	mov.b32 	 %f2, %r32;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p3, %f1, 0f4086232B;
	@%p3 bra 	BB27_7;

	setp.lt.f64	%p4, %fd1, 0d0000000000000000;
	add.f64 	%fd37, %fd1, 0d7FF0000000000000;
	selp.f64	%fd40, 0d0000000000000000, %fd37, %p4;
	setp.geu.f32	%p5, %f1, 0f40874800;
	@%p5 bra 	BB27_7;

	shr.u32 	%r33, %r8, 31;
	add.s32 	%r34, %r8, %r33;
	shr.s32 	%r35, %r34, 1;
	shl.b32 	%r36, %r35, 20;
	add.s32 	%r37, %r36, %r10;
	mov.b64 	%fd38, {%r9, %r37};
	sub.s32 	%r38, %r8, %r35;
	shl.b32 	%r39, %r38, 20;
	add.s32 	%r40, %r39, 1072693248;
	mov.u32 	%r41, 0;
	mov.b64 	%fd39, {%r41, %r40};
	mul.f64 	%fd40, %fd38, %fd39;

BB27_7:
	add.s32 	%r42, %r46, %r5;
	mul.wide.s32 	%rd7, %r42, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd40;
	add.s32 	%r46, %r2, %r46;
	setp.lt.s32	%p6, %r46, %r13;
	@%p6 bra 	BB27_4;

BB27_8:
	mov.u32 	%r43, %nctaid.x;
	mad.lo.s32 	%r45, %r43, %r18, %r45;
	setp.lt.s32	%p7, %r45, %r14;
	@%p7 bra 	BB27_2;

BB27_9:
	ret;
}

	// .globl	map_expm1_double
.visible .entry map_expm1_double(
	.param .u32 map_expm1_double_param_0,
	.param .u32 map_expm1_double_param_1,
	.param .u64 map_expm1_double_param_2,
	.param .u32 map_expm1_double_param_3,
	.param .u64 map_expm1_double_param_4,
	.param .u32 map_expm1_double_param_5
)
{
	.reg .pred 	%p<13>;
	.reg .b32 	%r<37>;
	.reg .f64 	%fd<48>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r11, [map_expm1_double_param_0];
	ld.param.u32 	%r12, [map_expm1_double_param_1];
	ld.param.u64 	%rd3, [map_expm1_double_param_2];
	ld.param.u32 	%r13, [map_expm1_double_param_3];
	ld.param.u64 	%rd4, [map_expm1_double_param_4];
	ld.param.u32 	%r14, [map_expm1_double_param_5];
	mov.u32 	%r15, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r35, %r15, %r16, %r17;
	setp.ge.s32	%p1, %r35, %r12;
	@%p1 bra 	BB28_9;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r2, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.y;
	mul.lo.s32 	%r3, %r21, %r19;

BB28_2:
	setp.ge.s32	%p2, %r2, %r11;
	@%p2 bra 	BB28_8;

	mul.lo.s32 	%r5, %r35, %r14;
	mul.lo.s32 	%r6, %r35, %r13;
	mov.u32 	%r36, %r2;

BB28_4:
	mov.u32 	%r7, %r36;
	add.s32 	%r22, %r7, %r5;
	mul.wide.s32 	%rd5, %r22, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd1;
	}
	setp.lt.u32	%p3, %r8, 1082535491;
	setp.lt.s32	%p4, %r8, -1068859392;
	or.pred  	%p5, %p3, %p4;
	@%p5 bra 	BB28_6;
	bra.uni 	BB28_5;

BB28_6:
	mov.f64 	%fd8, 0d4338000000000000;
	mov.f64 	%fd9, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd10, %fd1, %fd9, %fd8;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r23, %temp}, %fd10;
	}
	mov.f64 	%fd11, 0dC338000000000000;
	add.rn.f64 	%fd12, %fd10, %fd11;
	mov.f64 	%fd13, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd14, %fd12, %fd13, %fd1;
	mov.f64 	%fd15, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd16, %fd12, %fd15, %fd14;
	add.s32 	%r24, %r8, %r8;
	setp.lt.u32	%p8, %r24, 2142496327;
	selp.b32	%r25, 0, %r23, %p8;
	selp.f64	%fd17, %fd1, %fd16, %p8;
	mov.f64 	%fd18, 0d3E5AF86D8EBD13CD;
	mov.f64 	%fd19, 0d3E21F4076ACD15B6;
	fma.rn.f64 	%fd20, %fd19, %fd17, %fd18;
	mov.f64 	%fd21, 0d3E927E5092BA033D;
	fma.rn.f64 	%fd22, %fd20, %fd17, %fd21;
	mov.f64 	%fd23, 0d3EC71DDE6C5F9DA1;
	fma.rn.f64 	%fd24, %fd22, %fd17, %fd23;
	mov.f64 	%fd25, 0d3EFA01A018D034E6;
	fma.rn.f64 	%fd26, %fd24, %fd17, %fd25;
	mov.f64 	%fd27, 0d3F2A01A01B3B6940;
	fma.rn.f64 	%fd28, %fd26, %fd17, %fd27;
	mov.f64 	%fd29, 0d3F56C16C16C1B5DD;
	fma.rn.f64 	%fd30, %fd28, %fd17, %fd29;
	mov.f64 	%fd31, 0d3F8111111110F74D;
	fma.rn.f64 	%fd32, %fd30, %fd17, %fd31;
	mov.f64 	%fd33, 0d3FA555555555554D;
	fma.rn.f64 	%fd34, %fd32, %fd17, %fd33;
	mov.f64 	%fd35, 0d3FC5555555555557;
	fma.rn.f64 	%fd36, %fd34, %fd17, %fd35;
	mov.f64 	%fd37, 0d3FE0000000000000;
	fma.rn.f64 	%fd38, %fd36, %fd17, %fd37;
	mul.f64 	%fd39, %fd17, %fd38;
	fma.rn.f64 	%fd40, %fd39, %fd17, %fd17;
	setp.eq.s32	%p9, %r25, 1024;
	selp.b32	%r26, -1, 0, %p9;
	add.s32 	%r27, %r26, %r25;
	shl.b32 	%r28, %r27, 20;
	add.s32 	%r29, %r28, 1072693248;
	mov.u32 	%r30, 0;
	mov.b64 	%fd41, {%r30, %r29};
	mov.u32 	%r31, 1072693248;
	mov.b64 	%fd42, {%r30, %r31};
	sub.f64 	%fd43, %fd41, %fd42;
	fma.rn.f64 	%fd44, %fd40, %fd41, %fd43;
	add.f64 	%fd45, %fd44, %fd44;
	selp.f64	%fd46, %fd45, %fd44, %p9;
	setp.eq.s32	%p10, %r24, 0;
	selp.f64	%fd47, %fd17, %fd46, %p10;
	bra.uni 	BB28_7;

BB28_5:
	setp.lt.s32	%p6, %r8, 0;
	selp.f64	%fd5, 0dBFF0000000000000, 0d7FF0000000000000, %p6;
	abs.f64 	%fd6, %fd1;
	setp.gtu.f64	%p7, %fd6, 0d7FF0000000000000;
	add.f64 	%fd7, %fd1, %fd1;
	selp.f64	%fd47, %fd7, %fd5, %p7;

BB28_7:
	add.s32 	%r32, %r7, %r6;
	mul.wide.s32 	%rd7, %r32, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd47;
	add.s32 	%r9, %r3, %r7;
	setp.lt.s32	%p11, %r9, %r11;
	mov.u32 	%r36, %r9;
	@%p11 bra 	BB28_4;

BB28_8:
	mov.u32 	%r33, %nctaid.x;
	mad.lo.s32 	%r35, %r33, %r15, %r35;
	setp.lt.s32	%p12, %r35, %r12;
	@%p12 bra 	BB28_2;

BB28_9:
	ret;
}

	// .globl	map_fabs_double
.visible .entry map_fabs_double(
	.param .u32 map_fabs_double_param_0,
	.param .u32 map_fabs_double_param_1,
	.param .u64 map_fabs_double_param_2,
	.param .u32 map_fabs_double_param_3,
	.param .u64 map_fabs_double_param_4,
	.param .u32 map_fabs_double_param_5
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map_fabs_double_param_0];
	ld.param.u32 	%r13, [map_fabs_double_param_1];
	ld.param.u64 	%rd3, [map_fabs_double_param_2];
	ld.param.u32 	%r14, [map_fabs_double_param_3];
	ld.param.u64 	%rd4, [map_fabs_double_param_4];
	ld.param.u32 	%r15, [map_fabs_double_param_5];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB29_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB29_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB29_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB29_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	abs.f64 	%fd2, %fd1;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd2;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB29_4;

BB29_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB29_2;

BB29_6:
	ret;
}

	// .globl	map_floor_double
.visible .entry map_floor_double(
	.param .u32 map_floor_double_param_0,
	.param .u32 map_floor_double_param_1,
	.param .u64 map_floor_double_param_2,
	.param .u32 map_floor_double_param_3,
	.param .u64 map_floor_double_param_4,
	.param .u32 map_floor_double_param_5
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map_floor_double_param_0];
	ld.param.u32 	%r13, [map_floor_double_param_1];
	ld.param.u64 	%rd3, [map_floor_double_param_2];
	ld.param.u32 	%r14, [map_floor_double_param_3];
	ld.param.u64 	%rd4, [map_floor_double_param_4];
	ld.param.u32 	%r15, [map_floor_double_param_5];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB30_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB30_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB30_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB30_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	cvt.rmi.f64.f64	%fd2, %fd1;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd2;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB30_4;

BB30_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB30_2;

BB30_6:
	ret;
}

	// .globl	map_j0_double
.visible .entry map_j0_double(
	.param .u32 map_j0_double_param_0,
	.param .u32 map_j0_double_param_1,
	.param .u64 map_j0_double_param_2,
	.param .u32 map_j0_double_param_3,
	.param .u64 map_j0_double_param_4,
	.param .u32 map_j0_double_param_5
)
{
	.local .align 4 .b8 	__local_depot31[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<16>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<217>;
	.reg .b64 	%rd<21>;


	mov.u64 	%rd20, __local_depot31;
	cvta.local.u64 	%SP, %rd20;
	ld.param.u32 	%r15, [map_j0_double_param_0];
	ld.param.u32 	%r16, [map_j0_double_param_1];
	ld.param.u64 	%rd1, [map_j0_double_param_2];
	ld.param.u64 	%rd2, [map_j0_double_param_4];
	mov.u32 	%r19, %ntid.x;
	mov.u32 	%r20, %ctaid.x;
	mov.u32 	%r21, %tid.x;
	mad.lo.s32 	%r53, %r19, %r20, %r21;
	setp.ge.s32	%p1, %r53, %r16;
	@%p1 bra 	BB31_25;

	mov.u32 	%r22, %ntid.y;
	mov.u32 	%r23, %nctaid.y;
	mul.lo.s32 	%r2, %r23, %r22;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd17, %rd1;

BB31_2:
	mov.u32 	%r51, %ntid.y;
	mov.u32 	%r24, %ctaid.y;
	mov.u32 	%r26, %tid.y;
	mad.lo.s32 	%r54, %r51, %r24, %r26;
	setp.ge.s32	%p2, %r54, %r15;
	@%p2 bra 	BB31_24;

BB31_3:
	ld.param.u32 	%r52, [map_j0_double_param_5];
	mad.lo.s32 	%r31, %r53, %r52, %r54;
	mul.wide.s32 	%rd4, %r31, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd25, [%rd5];
	abs.f64 	%fd1, %fd25;
	setp.gtu.f64	%p3, %fd1, 0d400FB319F277BBE5;
	@%p3 bra 	BB31_5;
	bra.uni 	BB31_4;

BB31_5:
	setp.gtu.f64	%p4, %fd1, 0d401C58FD1A62F5EC;
	@%p4 bra 	BB31_7;
	bra.uni 	BB31_6;

BB31_7:
	setp.gtu.f64	%p5, %fd1, 0d402471FCB6A7A8C0;
	@%p5 bra 	BB31_9;
	bra.uni 	BB31_8;

BB31_9:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd1;
	}
	and.b32  	%r33, %r32, 2147483647;
	setp.ne.s32	%p6, %r33, 2146435072;
	@%p6 bra 	BB31_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r34, %temp}, %fd1;
	}
	setp.eq.s32	%p7, %r34, 0;
	mov.f64 	%fd216, 0d0000000000000000;
	@%p7 bra 	BB31_23;

BB31_11:
	// inline asm
	rcp.approx.ftz.f64 %fd132,%fd1;
	// inline asm
	neg.f64 	%fd134, %fd1;
	mov.f64 	%fd135, 0d3FF0000000000000;
	fma.rn.f64 	%fd136, %fd134, %fd132, %fd135;
	fma.rn.f64 	%fd137, %fd136, %fd136, %fd136;
	fma.rn.f64 	%fd138, %fd137, %fd132, %fd132;
	mul.f64 	%fd139, %fd138, %fd138;
	mov.f64 	%fd140, 0d409927467A655012;
	mov.f64 	%fd141, 0dC0D115CB8C11A9DC;
	fma.rn.f64 	%fd142, %fd141, %fd139, %fd140;
	mov.f64 	%fd143, 0dC05751787E247BD4;
	fma.rn.f64 	%fd144, %fd142, %fd139, %fd143;
	mov.f64 	%fd145, 0d401704C4E5FC36B2;
	fma.rn.f64 	%fd146, %fd144, %fd139, %fd145;
	mov.f64 	%fd147, 0dBFE15B747A2FD531;
	fma.rn.f64 	%fd148, %fd146, %fd139, %fd147;
	mov.f64 	%fd149, 0d3FBA7FEACF6CB79B;
	fma.rn.f64 	%fd150, %fd148, %fd139, %fd149;
	mov.f64 	%fd151, 0dBFAFFFFFEDDCF548;
	fma.rn.f64 	%fd152, %fd150, %fd139, %fd151;
	mov.f64 	%fd153, 0d3FEFFFFFFFFFC9E5;
	fma.rn.f64 	%fd154, %fd152, %fd139, %fd153;
	mov.f64 	%fd155, 0d410ECD4523B12B84;
	mov.f64 	%fd156, 0dC14602FE1C34685E;
	fma.rn.f64 	%fd157, %fd156, %fd139, %fd155;
	mov.f64 	%fd158, 0dC0C7A2FC1972F05A;
	fma.rn.f64 	%fd159, %fd157, %fd139, %fd158;
	mov.f64 	%fd160, 0d407EBA131F7E5BEB;
	fma.rn.f64 	%fd161, %fd159, %fd139, %fd160;
	mov.f64 	%fd162, 0dC0373B92E6E7CC7D;
	fma.rn.f64 	%fd163, %fd161, %fd139, %fd162;
	mov.f64 	%fd164, 0d3FFA31BEE63A2F08;
	fma.rn.f64 	%fd165, %fd163, %fd139, %fd164;
	mov.f64 	%fd166, 0dBFCAD320104D5D05;
	fma.rn.f64 	%fd167, %fd165, %fd139, %fd166;
	mov.f64 	%fd168, 0d3FB0AAAA9C76D07E;
	fma.rn.f64 	%fd169, %fd167, %fd139, %fd168;
	mov.f64 	%fd170, 0dBFBFFFFFFFFDACEC;
	fma.rn.f64 	%fd171, %fd169, %fd139, %fd170;
	fma.rn.f64 	%fd5, %fd171, %fd138, %fd1;
	rsqrt.approx.f64 	%fd172, %fd1;
	mul.f64 	%fd173, %fd172, 0d3FE9884533D43651;
	mul.f64 	%fd6, %fd154, %fd173;
	mul.f64 	%fd174, %fd5, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r55, %fd174;
	add.u64 	%rd6, %SP, 4;
	cvta.to.local.u64 	%rd7, %rd6;
	st.local.u32 	[%rd7], %r55;
	cvt.rn.f64.s32	%fd175, %r55;
	neg.f64 	%fd176, %fd175;
	mov.f64 	%fd177, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd178, %fd176, %fd177, %fd5;
	mov.f64 	%fd179, 0d3C91A62633145C00;
	fma.rn.f64 	%fd180, %fd176, %fd179, %fd178;
	mov.f64 	%fd181, 0d397B839A252049C0;
	fma.rn.f64 	%fd212, %fd176, %fd181, %fd180;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd5;
	}
	and.b32  	%r36, %r35, 2145386496;
	setp.lt.u32	%p8, %r36, 1105199104;
	@%p8 bra 	BB31_13;

	// Callseq Start 3
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd5;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd6;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd212, [retval0+0];
	
	//{
	}// Callseq End 3
	ld.local.u32 	%r55, [%rd7];

BB31_13:
	and.b32  	%r37, %r55, 3;
	cvt.rn.f64.s32	%fd182, %r37;
	add.f64 	%fd183, %fd212, 0dBFE921FB54442D18;
	fma.rn.f64 	%fd213, %fd182, 0d3FF921FB54442D18, %fd183;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd213;
	}
	and.b32  	%r39, %r38, 2147483647;
	setp.ne.s32	%p9, %r39, 2146435072;
	@%p9 bra 	BB31_16;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r40, %temp}, %fd213;
	}
	setp.ne.s32	%p10, %r40, 0;
	@%p10 bra 	BB31_16;

	mov.f64 	%fd184, 0d0000000000000000;
	mul.rn.f64 	%fd213, %fd213, %fd184;

BB31_16:
	mov.f64 	%fd210, 0d397B839A252049C0;
	mov.f64 	%fd209, 0d3C91A62633145C00;
	mov.f64 	%fd208, 0d3FF921FB54442D18;
	mul.f64 	%fd185, %fd213, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r56, %fd185;
	add.u64 	%rd10, %SP, 0;
	cvta.to.local.u64 	%rd11, %rd10;
	st.local.u32 	[%rd11], %r56;
	cvt.rn.f64.s32	%fd186, %r56;
	neg.f64 	%fd187, %fd186;
	fma.rn.f64 	%fd189, %fd187, %fd208, %fd213;
	fma.rn.f64 	%fd191, %fd187, %fd209, %fd189;
	fma.rn.f64 	%fd214, %fd187, %fd210, %fd191;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r41}, %fd213;
	}
	and.b32  	%r42, %r41, 2145386496;
	setp.lt.u32	%p11, %r42, 1105199104;
	@%p11 bra 	BB31_18;

	// Callseq Start 4
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd213;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd10;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd214, [retval0+0];
	
	//{
	}// Callseq End 4
	ld.local.u32 	%r56, [%rd11];

BB31_18:
	add.s32 	%r12, %r56, 1;
	and.b32  	%r43, %r12, 1;
	shl.b32 	%r44, %r43, 3;
	setp.eq.s32	%p12, %r43, 0;
	selp.f64	%fd193, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p12;
	mul.wide.u32 	%rd14, %r44, 8;
	mov.u64 	%rd15, __cudart_sin_cos_coeffs;
	add.s64 	%rd16, %rd14, %rd15;
	ld.const.f64 	%fd194, [%rd16+8];
	mul.rn.f64 	%fd16, %fd214, %fd214;
	fma.rn.f64 	%fd195, %fd193, %fd16, %fd194;
	ld.const.f64 	%fd196, [%rd16+16];
	fma.rn.f64 	%fd197, %fd195, %fd16, %fd196;
	ld.const.f64 	%fd198, [%rd16+24];
	fma.rn.f64 	%fd199, %fd197, %fd16, %fd198;
	ld.const.f64 	%fd200, [%rd16+32];
	fma.rn.f64 	%fd201, %fd199, %fd16, %fd200;
	ld.const.f64 	%fd202, [%rd16+40];
	fma.rn.f64 	%fd203, %fd201, %fd16, %fd202;
	ld.const.f64 	%fd204, [%rd16+48];
	fma.rn.f64 	%fd17, %fd203, %fd16, %fd204;
	fma.rn.f64 	%fd215, %fd17, %fd214, %fd214;
	@%p12 bra 	BB31_20;

	mov.f64 	%fd211, 0d3FF0000000000000;
	fma.rn.f64 	%fd215, %fd17, %fd16, %fd211;

BB31_20:
	and.b32  	%r45, %r12, 2;
	setp.eq.s32	%p13, %r45, 0;
	@%p13 bra 	BB31_22;

	mov.f64 	%fd206, 0d0000000000000000;
	mov.f64 	%fd207, 0dBFF0000000000000;
	fma.rn.f64 	%fd215, %fd215, %fd207, %fd206;

BB31_22:
	mul.f64 	%fd216, %fd6, %fd215;
	bra.uni 	BB31_23;

BB31_4:
	add.f64 	%fd26, %fd1, 0dC0033D152E971B40;
	add.f64 	%fd27, %fd26, 0d3CA0F539D7DA258E;
	mov.f64 	%fd28, 0dBCFCF8F9A8C294BC;
	mov.f64 	%fd29, 0dBCC0D18564C48C61;
	fma.rn.f64 	%fd30, %fd29, %fd27, %fd28;
	mov.f64 	%fd31, 0d3D3FAB983CAE498B;
	fma.rn.f64 	%fd32, %fd30, %fd27, %fd31;
	mov.f64 	%fd33, 0d3D7CD7C018579B88;
	fma.rn.f64 	%fd34, %fd32, %fd27, %fd33;
	mov.f64 	%fd35, 0dBDBBDD2342D64FDD;
	fma.rn.f64 	%fd36, %fd34, %fd27, %fd35;
	mov.f64 	%fd37, 0dBDF5C2D9416B1E2B;
	fma.rn.f64 	%fd38, %fd36, %fd27, %fd37;
	mov.f64 	%fd39, 0d3E32951D73174DD5;
	fma.rn.f64 	%fd40, %fd38, %fd27, %fd39;
	mov.f64 	%fd41, 0d3E67FF99802CAEB5;
	fma.rn.f64 	%fd42, %fd40, %fd27, %fd41;
	mov.f64 	%fd43, 0dBEA1CCE305C4C9F7;
	fma.rn.f64 	%fd44, %fd42, %fd27, %fd43;
	mov.f64 	%fd45, 0dBED232C77E29E1BB;
	fma.rn.f64 	%fd46, %fd44, %fd27, %fd45;
	mov.f64 	%fd47, 0d3F06ED3B9F0EF757;
	fma.rn.f64 	%fd48, %fd46, %fd27, %fd47;
	mov.f64 	%fd49, 0d3F315382BA096A62;
	fma.rn.f64 	%fd50, %fd48, %fd27, %fd49;
	mov.f64 	%fd51, 0dBF61F992590D1AE4;
	fma.rn.f64 	%fd52, %fd50, %fd27, %fd51;
	mov.f64 	%fd53, 0dBF81BB1CBE1A465F;
	fma.rn.f64 	%fd54, %fd52, %fd27, %fd53;
	mov.f64 	%fd55, 0d3FACFAE864368D84;
	fma.rn.f64 	%fd56, %fd54, %fd27, %fd55;
	mov.f64 	%fd57, 0d3FBBA1DEEA0294A3;
	fma.rn.f64 	%fd58, %fd56, %fd27, %fd57;
	mov.f64 	%fd59, 0dBFE09CDB36551280;
	fma.rn.f64 	%fd60, %fd58, %fd27, %fd59;
	mul.f64 	%fd216, %fd27, %fd60;
	bra.uni 	BB31_23;

BB31_6:
	add.f64 	%fd61, %fd1, 0dC016148F5B2C2E45;
	add.f64 	%fd62, %fd61, 0dBC975054CD60A517;
	mov.f64 	%fd63, 0d3CF83FD1F333EB61;
	mov.f64 	%fd64, 0d3CBCB0A8F126B343;
	fma.rn.f64 	%fd65, %fd64, %fd62, %fd63;
	mov.f64 	%fd66, 0dBD4100E33E3FB413;
	fma.rn.f64 	%fd67, %fd65, %fd62, %fd66;
	mov.f64 	%fd68, 0dBD7846076D004627;
	fma.rn.f64 	%fd69, %fd67, %fd62, %fd68;
	mov.f64 	%fd70, 0d3DBE2F1D4F90720D;
	fma.rn.f64 	%fd71, %fd69, %fd62, %fd70;
	mov.f64 	%fd72, 0d3DF1D03B1E4A119B;
	fma.rn.f64 	%fd73, %fd71, %fd62, %fd72;
	mov.f64 	%fd74, 0dBE341D72B1B3BCE9;
	fma.rn.f64 	%fd75, %fd73, %fd62, %fd74;
	mov.f64 	%fd76, 0dBE62DA37CE2A9EF8;
	fma.rn.f64 	%fd77, %fd75, %fd62, %fd76;
	mov.f64 	%fd78, 0d3EA32E6D9974F763;
	fma.rn.f64 	%fd79, %fd77, %fd62, %fd78;
	mov.f64 	%fd80, 0d3ECAD77D744A1879;
	fma.rn.f64 	%fd81, %fd79, %fd62, %fd80;
	mov.f64 	%fd82, 0dBF0863F481A37337;
	fma.rn.f64 	%fd83, %fd81, %fd62, %fd82;
	mov.f64 	%fd84, 0dBF26F641F418F0F4;
	fma.rn.f64 	%fd85, %fd83, %fd62, %fd84;
	mov.f64 	%fd86, 0d3F627E31FE9A969E;
	fma.rn.f64 	%fd87, %fd85, %fd62, %fd86;
	mov.f64 	%fd88, 0d3F72F7FFE9025628;
	fma.rn.f64 	%fd89, %fd87, %fd62, %fd88;
	mov.f64 	%fd90, 0dBFAB2150CB41E8BF;
	fma.rn.f64 	%fd91, %fd89, %fd62, %fd90;
	mov.f64 	%fd92, 0dBF9F8F72E7A848DE;
	fma.rn.f64 	%fd93, %fd91, %fd62, %fd92;
	mov.f64 	%fd94, 0d3FD5C6E60A097823;
	fma.rn.f64 	%fd95, %fd93, %fd62, %fd94;
	mul.f64 	%fd216, %fd62, %fd95;
	bra.uni 	BB31_23;

BB31_8:
	add.f64 	%fd96, %fd1, 0dC0214EB56CCCDECA;
	add.f64 	%fd97, %fd96, 0d3CB51970714C7C25;
	mov.f64 	%fd98, 0dBCF4B3A71AAAC629;
	mov.f64 	%fd99, 0dBCBDB7FFCF659E24;
	fma.rn.f64 	%fd100, %fd99, %fd97, %fd98;
	mov.f64 	%fd101, 0d3D417EC150ECDCE7;
	fma.rn.f64 	%fd102, %fd100, %fd97, %fd101;
	mov.f64 	%fd103, 0d3D7438F5EA1D10B2;
	fma.rn.f64 	%fd104, %fd102, %fd97, %fd103;
	mov.f64 	%fd105, 0dBDBEDAE7EC2C9E87;
	fma.rn.f64 	%fd106, %fd104, %fd97, %fd105;
	mov.f64 	%fd107, 0dBDECADD2C4B91F58;
	fma.rn.f64 	%fd108, %fd106, %fd97, %fd107;
	mov.f64 	%fd109, 0d3E34582C8EE12204;
	fma.rn.f64 	%fd110, %fd108, %fd97, %fd109;
	mov.f64 	%fd111, 0d3E5CEDA451DD20F8;
	fma.rn.f64 	%fd112, %fd110, %fd97, %fd111;
	mov.f64 	%fd113, 0dBEA30E8CC3165E2F;
	fma.rn.f64 	%fd114, %fd112, %fd97, %fd113;
	mov.f64 	%fd115, 0dBEC3324842BB1A2E;
	fma.rn.f64 	%fd116, %fd114, %fd97, %fd115;
	mov.f64 	%fd117, 0d3F07800BC54FBDDB;
	fma.rn.f64 	%fd118, %fd116, %fd97, %fd117;
	mov.f64 	%fd119, 0d3F1D79605276949A;
	fma.rn.f64 	%fd120, %fd118, %fd97, %fd119;
	mov.f64 	%fd121, 0dBF60E0D60385A629;
	fma.rn.f64 	%fd122, %fd120, %fd97, %fd121;
	mov.f64 	%fd123, 0dBF648E63600D82F3;
	fma.rn.f64 	%fd124, %fd122, %fd97, %fd123;
	mov.f64 	%fd125, 0d3FA68B984EC6493A;
	fma.rn.f64 	%fd126, %fd124, %fd97, %fd125;
	mov.f64 	%fd127, 0d3F900F7FCF183E0B;
	fma.rn.f64 	%fd128, %fd126, %fd97, %fd127;
	mov.f64 	%fd129, 0dBFD15F7977A772D4;
	fma.rn.f64 	%fd130, %fd128, %fd97, %fd129;
	mul.f64 	%fd216, %fd97, %fd130;

BB31_23:
	ld.param.u32 	%r49, [map_j0_double_param_3];
	mad.lo.s32 	%r46, %r53, %r49, %r54;
	mul.wide.s32 	%rd18, %r46, 8;
	add.s64 	%rd19, %rd17, %rd18;
	st.global.f64 	[%rd19], %fd216;
	add.s32 	%r54, %r2, %r54;
	setp.lt.s32	%p14, %r54, %r15;
	@%p14 bra 	BB31_3;

BB31_24:
	mov.u32 	%r50, %ntid.x;
	mov.u32 	%r47, %nctaid.x;
	mad.lo.s32 	%r53, %r47, %r50, %r53;
	setp.lt.s32	%p15, %r53, %r16;
	@%p15 bra 	BB31_2;

BB31_25:
	ret;
}

	// .globl	map_j1_double
.visible .entry map_j1_double(
	.param .u32 map_j1_double_param_0,
	.param .u32 map_j1_double_param_1,
	.param .u64 map_j1_double_param_2,
	.param .u32 map_j1_double_param_3,
	.param .u64 map_j1_double_param_4,
	.param .u32 map_j1_double_param_5
)
{
	.local .align 4 .b8 	__local_depot32[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<18>;
	.reg .b32 	%r<55>;
	.reg .f64 	%fd<215>;
	.reg .b64 	%rd<21>;


	mov.u64 	%rd20, __local_depot32;
	cvta.local.u64 	%SP, %rd20;
	ld.param.u32 	%r14, [map_j1_double_param_0];
	ld.param.u32 	%r15, [map_j1_double_param_1];
	ld.param.u64 	%rd1, [map_j1_double_param_2];
	ld.param.u64 	%rd2, [map_j1_double_param_4];
	mov.u32 	%r18, %ntid.x;
	mov.u32 	%r19, %ctaid.x;
	mov.u32 	%r20, %tid.x;
	mad.lo.s32 	%r51, %r18, %r19, %r20;
	setp.ge.s32	%p1, %r51, %r15;
	@%p1 bra 	BB32_25;

	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd17, %rd1;

BB32_2:
	mov.u32 	%r21, %ctaid.y;
	mov.u32 	%r22, %ntid.y;
	mov.u32 	%r23, %tid.y;
	mad.lo.s32 	%r52, %r22, %r21, %r23;
	setp.ge.s32	%p2, %r52, %r14;
	@%p2 bra 	BB32_24;

BB32_3:
	ld.param.u32 	%r50, [map_j1_double_param_5];
	mad.lo.s32 	%r28, %r51, %r50, %r52;
	mul.wide.s32 	%rd4, %r28, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	abs.f64 	%fd2, %fd1;
	setp.gtu.f64	%p3, %fd2, 0d400353AABAD7B784;
	@%p3 bra 	BB32_5;
	bra.uni 	BB32_4;

BB32_5:
	setp.gtu.f64	%p4, %fd2, 0d4015B1D0574614EA;
	@%p4 bra 	BB32_7;
	bra.uni 	BB32_6;

BB32_7:
	setp.gtu.f64	%p5, %fd2, 0d40213065E54C1AA9;
	@%p5 bra 	BB32_9;
	bra.uni 	BB32_8;

BB32_9:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd2;
	}
	and.b32  	%r30, %r29, 2147483647;
	setp.ne.s32	%p6, %r30, 2146435072;
	@%p6 bra 	BB32_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r31, %temp}, %fd2;
	}
	setp.eq.s32	%p7, %r31, 0;
	mov.f64 	%fd214, 0d0000000000000000;
	@%p7 bra 	BB32_23;

BB32_11:
	// inline asm
	rcp.approx.ftz.f64 %fd124,%fd2;
	// inline asm
	neg.f64 	%fd126, %fd2;
	mov.f64 	%fd127, 0d3FF0000000000000;
	fma.rn.f64 	%fd128, %fd126, %fd124, %fd127;
	fma.rn.f64 	%fd129, %fd128, %fd128, %fd128;
	fma.rn.f64 	%fd130, %fd129, %fd124, %fd124;
	mul.f64 	%fd131, %fd130, %fd130;
	mov.f64 	%fd132, 0dC099C06322A3F8BE;
	mov.f64 	%fd133, 0d40CD02EA3F2F6751;
	fma.rn.f64 	%fd134, %fd133, %fd131, %fd132;
	mov.f64 	%fd135, 0d405B89354DA77324;
	fma.rn.f64 	%fd136, %fd134, %fd131, %fd135;
	mov.f64 	%fd137, 0dC01E352294653188;
	fma.rn.f64 	%fd138, %fd136, %fd131, %fd137;
	mov.f64 	%fd139, 0d3FE9BC7DB16BD7A7;
	fma.rn.f64 	%fd140, %fd138, %fd131, %fd139;
	mov.f64 	%fd141, 0dBFC8BFE1C3A4F741;
	fma.rn.f64 	%fd142, %fd140, %fd131, %fd141;
	mov.f64 	%fd143, 0d3FC7FFFFF0D00BE2;
	fma.rn.f64 	%fd144, %fd142, %fd131, %fd143;
	mov.f64 	%fd145, 0d3FF00000000068CC;
	fma.rn.f64 	%fd146, %fd144, %fd131, %fd145;
	mov.f64 	%fd147, 0d415A30AC6857BEE0;
	mov.f64 	%fd148, 0dC18DA26B212FDC9A;
	fma.rn.f64 	%fd149, %fd148, %fd131, %fd147;
	mov.f64 	%fd150, 0dC11764222AD7C910;
	fma.rn.f64 	%fd151, %fd149, %fd131, %fd150;
	mov.f64 	%fd152, 0d40CEB02E0C306857;
	fma.rn.f64 	%fd153, %fd151, %fd131, %fd152;
	mov.f64 	%fd154, 0dC08351859FA2B23B;
	fma.rn.f64 	%fd155, %fd153, %fd131, %fd154;
	mov.f64 	%fd156, 0d403E65A07AF51F42;
	fma.rn.f64 	%fd157, %fd155, %fd131, %fd156;
	mov.f64 	%fd158, 0dC002F2B817F77A57;
	fma.rn.f64 	%fd159, %fd157, %fd131, %fd158;
	mov.f64 	%fd160, 0d3FD7BCC34DA069FD;
	fma.rn.f64 	%fd161, %fd159, %fd131, %fd160;
	mov.f64 	%fd162, 0dBFC4FFFFF8A44463;
	fma.rn.f64 	%fd163, %fd161, %fd131, %fd162;
	mov.f64 	%fd164, 0d3FD7FFFFFFFF5CD7;
	fma.rn.f64 	%fd165, %fd163, %fd131, %fd164;
	fma.rn.f64 	%fd6, %fd165, %fd130, %fd2;
	rsqrt.approx.f64 	%fd166, %fd2;
	mul.f64 	%fd167, %fd166, 0d3FE9884533D43651;
	mul.f64 	%fd7, %fd146, %fd167;
	mul.f64 	%fd168, %fd6, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r53, %fd168;
	add.u64 	%rd6, %SP, 4;
	cvta.to.local.u64 	%rd7, %rd6;
	st.local.u32 	[%rd7], %r53;
	cvt.rn.f64.s32	%fd169, %r53;
	neg.f64 	%fd170, %fd169;
	mov.f64 	%fd171, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd172, %fd170, %fd171, %fd6;
	mov.f64 	%fd173, 0d3C91A62633145C00;
	fma.rn.f64 	%fd174, %fd170, %fd173, %fd172;
	mov.f64 	%fd175, 0d397B839A252049C0;
	fma.rn.f64 	%fd210, %fd170, %fd175, %fd174;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd6;
	}
	and.b32  	%r33, %r32, 2145386496;
	setp.lt.u32	%p8, %r33, 1105199104;
	@%p8 bra 	BB32_13;

	// Callseq Start 5
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd6;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd6;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd210, [retval0+0];
	
	//{
	}// Callseq End 5
	ld.local.u32 	%r53, [%rd7];

BB32_13:
	and.b32  	%r34, %r53, 3;
	cvt.rn.f64.s32	%fd176, %r34;
	add.f64 	%fd177, %fd210, 0dC002D97C7F3321D2;
	fma.rn.f64 	%fd211, %fd176, 0d3FF921FB54442D18, %fd177;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd211;
	}
	and.b32  	%r36, %r35, 2147483647;
	setp.ne.s32	%p9, %r36, 2146435072;
	@%p9 bra 	BB32_16;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd211;
	}
	setp.ne.s32	%p10, %r37, 0;
	@%p10 bra 	BB32_16;

	mov.f64 	%fd178, 0d0000000000000000;
	mul.rn.f64 	%fd211, %fd211, %fd178;

BB32_16:
	mov.f64 	%fd208, 0d397B839A252049C0;
	mov.f64 	%fd207, 0d3C91A62633145C00;
	mov.f64 	%fd206, 0d3FF921FB54442D18;
	mul.f64 	%fd179, %fd211, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r54, %fd179;
	add.u64 	%rd10, %SP, 0;
	cvta.to.local.u64 	%rd11, %rd10;
	st.local.u32 	[%rd11], %r54;
	cvt.rn.f64.s32	%fd180, %r54;
	neg.f64 	%fd181, %fd180;
	fma.rn.f64 	%fd183, %fd181, %fd206, %fd211;
	fma.rn.f64 	%fd185, %fd181, %fd207, %fd183;
	fma.rn.f64 	%fd212, %fd181, %fd208, %fd185;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd211;
	}
	and.b32  	%r39, %r38, 2145386496;
	setp.lt.u32	%p11, %r39, 1105199104;
	@%p11 bra 	BB32_18;

	// Callseq Start 6
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd211;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd10;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd212, [retval0+0];
	
	//{
	}// Callseq End 6
	ld.local.u32 	%r54, [%rd11];

BB32_18:
	add.s32 	%r11, %r54, 1;
	and.b32  	%r40, %r11, 1;
	shl.b32 	%r41, %r40, 3;
	setp.eq.s32	%p12, %r40, 0;
	selp.f64	%fd187, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p12;
	mul.wide.u32 	%rd14, %r41, 8;
	mov.u64 	%rd15, __cudart_sin_cos_coeffs;
	add.s64 	%rd16, %rd14, %rd15;
	ld.const.f64 	%fd188, [%rd16+8];
	mul.rn.f64 	%fd17, %fd212, %fd212;
	fma.rn.f64 	%fd189, %fd187, %fd17, %fd188;
	ld.const.f64 	%fd190, [%rd16+16];
	fma.rn.f64 	%fd191, %fd189, %fd17, %fd190;
	ld.const.f64 	%fd192, [%rd16+24];
	fma.rn.f64 	%fd193, %fd191, %fd17, %fd192;
	ld.const.f64 	%fd194, [%rd16+32];
	fma.rn.f64 	%fd195, %fd193, %fd17, %fd194;
	ld.const.f64 	%fd196, [%rd16+40];
	fma.rn.f64 	%fd197, %fd195, %fd17, %fd196;
	ld.const.f64 	%fd198, [%rd16+48];
	fma.rn.f64 	%fd18, %fd197, %fd17, %fd198;
	fma.rn.f64 	%fd213, %fd18, %fd212, %fd212;
	@%p12 bra 	BB32_20;

	mov.f64 	%fd209, 0d3FF0000000000000;
	fma.rn.f64 	%fd213, %fd18, %fd17, %fd209;

BB32_20:
	and.b32  	%r42, %r11, 2;
	setp.eq.s32	%p13, %r42, 0;
	@%p13 bra 	BB32_22;

	mov.f64 	%fd200, 0d0000000000000000;
	mov.f64 	%fd201, 0dBFF0000000000000;
	fma.rn.f64 	%fd213, %fd213, %fd201, %fd200;

BB32_22:
	mul.f64 	%fd214, %fd7, %fd213;
	bra.uni 	BB32_23;

BB32_4:
	mov.f64 	%fd26, 0dBD4DD167A0DC3F55;
	mov.f64 	%fd27, 0d3D020E4ADCDE2AD3;
	fma.rn.f64 	%fd28, %fd27, %fd2, %fd26;
	mov.f64 	%fd29, 0d3D5503F5A491E487;
	fma.rn.f64 	%fd30, %fd28, %fd2, %fd29;
	mov.f64 	%fd31, 0d3DC1F29940C2403A;
	fma.rn.f64 	%fd32, %fd30, %fd2, %fd31;
	mov.f64 	%fd33, 0d3D84CF9302EACDEF;
	fma.rn.f64 	%fd34, %fd32, %fd2, %fd33;
	mov.f64 	%fd35, 0dBE384A53DBBCA436;
	fma.rn.f64 	%fd36, %fd34, %fd2, %fd35;
	mov.f64 	%fd37, 0d3D9779BEE4F63BCC;
	fma.rn.f64 	%fd38, %fd36, %fd2, %fd37;
	mov.f64 	%fd39, 0d3EA6C160E414F3F0;
	fma.rn.f64 	%fd40, %fd38, %fd2, %fd39;
	mov.f64 	%fd41, 0d3D8F3D2F12430699;
	fma.rn.f64 	%fd42, %fd40, %fd2, %fd41;
	mov.f64 	%fd43, 0dBF0C71C72C0CED04;
	fma.rn.f64 	%fd44, %fd42, %fd2, %fd43;
	mov.f64 	%fd45, 0d3D659BCA506F1128;
	fma.rn.f64 	%fd46, %fd44, %fd2, %fd45;
	mov.f64 	%fd47, 0d3F65555555506982;
	fma.rn.f64 	%fd48, %fd46, %fd2, %fd47;
	mov.f64 	%fd49, 0d3D15BA0B425F1BFB;
	fma.rn.f64 	%fd50, %fd48, %fd2, %fd49;
	mov.f64 	%fd51, 0dBFB0000000000065;
	fma.rn.f64 	%fd52, %fd50, %fd2, %fd51;
	mov.f64 	%fd53, 0d3C8729A7253FB679;
	fma.rn.f64 	%fd54, %fd52, %fd2, %fd53;
	mov.f64 	%fd55, 0d3FE0000000000000;
	fma.rn.f64 	%fd56, %fd54, %fd2, %fd55;
	mul.f64 	%fd214, %fd2, %fd56;
	bra.uni 	BB32_23;

BB32_6:
	add.f64 	%fd57, %fd2, 0dC00EA75575AF6F09;
	add.f64 	%fd58, %fd57, 0d3CA60155A9D1B256;
	mov.f64 	%fd59, 0d3D41011A1DF02DAD;
	mov.f64 	%fd60, 0dBCF8D3CDBB60175E;
	fma.rn.f64 	%fd61, %fd60, %fd58, %fd59;
	mov.f64 	%fd62, 0d3D76013AC1E5E222;
	fma.rn.f64 	%fd63, %fd61, %fd58, %fd62;
	mov.f64 	%fd64, 0dBDBEC315D96D5F03;
	fma.rn.f64 	%fd65, %fd63, %fd58, %fd64;
	mov.f64 	%fd66, 0dBDF03BE1B4B57207;
	fma.rn.f64 	%fd67, %fd65, %fd58, %fd66;
	mov.f64 	%fd68, 0d3E345695F8B660F7;
	fma.rn.f64 	%fd69, %fd67, %fd58, %fd68;
	mov.f64 	%fd70, 0d3E617069FCFCFFF4;
	fma.rn.f64 	%fd71, %fd69, %fd58, %fd70;
	mov.f64 	%fd72, 0dBEA33825C36745EB;
	fma.rn.f64 	%fd73, %fd71, %fd58, %fd72;
	mov.f64 	%fd74, 0dBEC9799D4F90931B;
	fma.rn.f64 	%fd75, %fd73, %fd58, %fd74;
	mov.f64 	%fd76, 0d3F083A06E2F7DF13;
	fma.rn.f64 	%fd77, %fd75, %fd58, %fd76;
	mov.f64 	%fd78, 0d3F26E4C2D53A7CF6;
	fma.rn.f64 	%fd79, %fd77, %fd58, %fd78;
	mov.f64 	%fd80, 0dBF624B3409957B1C;
	fma.rn.f64 	%fd81, %fd79, %fd58, %fd80;
	mov.f64 	%fd82, 0dBF7537544C3325DF;
	fma.rn.f64 	%fd83, %fd81, %fd58, %fd82;
	mov.f64 	%fd84, 0d3FAB589D1DA138E2;
	fma.rn.f64 	%fd85, %fd83, %fd58, %fd84;
	mov.f64 	%fd86, 0d3FAAE8A39F51AD13;
	fma.rn.f64 	%fd87, %fd85, %fd58, %fd86;
	mov.f64 	%fd88, 0dBFD9C6CF582CBF7F;
	fma.rn.f64 	%fd89, %fd87, %fd58, %fd88;
	mul.f64 	%fd214, %fd58, %fd89;
	bra.uni 	BB32_23;

BB32_8:
	add.f64 	%fd90, %fd2, 0dC01C0FF5F3B47250;
	add.f64 	%fd91, %fd90, 0d3C9B226D9D243827;
	mov.f64 	%fd92, 0dBD40E8363DB649A9;
	mov.f64 	%fd93, 0d3CF3EB867515FAD6;
	fma.rn.f64 	%fd94, %fd93, %fd91, %fd92;
	mov.f64 	%fd95, 0dBD73B7DD4A6608FB;
	fma.rn.f64 	%fd96, %fd94, %fd91, %fd95;
	mov.f64 	%fd97, 0d3DBEC5E01482C750;
	fma.rn.f64 	%fd98, %fd96, %fd91, %fd97;
	mov.f64 	%fd99, 0d3DEC62BB9E882103;
	fma.rn.f64 	%fd100, %fd98, %fd91, %fd99;
	mov.f64 	%fd101, 0dBE34462EED732A23;
	fma.rn.f64 	%fd102, %fd100, %fd91, %fd101;
	mov.f64 	%fd103, 0dBE5D48DCAD7DC59B;
	fma.rn.f64 	%fd104, %fd102, %fd91, %fd103;
	mov.f64 	%fd105, 0d3EA3026DF29167E9;
	fma.rn.f64 	%fd106, %fd104, %fd91, %fd105;
	mov.f64 	%fd107, 0d3EC4255B0119666C;
	fma.rn.f64 	%fd108, %fd106, %fd91, %fd107;
	mov.f64 	%fd109, 0dBF0796A751B32693;
	fma.rn.f64 	%fd110, %fd108, %fd91, %fd109;
	mov.f64 	%fd111, 0dBF207358BBDBA284;
	fma.rn.f64 	%fd112, %fd110, %fd91, %fd111;
	mov.f64 	%fd113, 0d3F613FBC7D6927B1;
	fma.rn.f64 	%fd114, %fd112, %fd91, %fd113;
	mov.f64 	%fd115, 0d3F69A4B292E3DD75;
	fma.rn.f64 	%fd116, %fd114, %fd91, %fd115;
	mov.f64 	%fd117, 0dBFA80C83BDEEE4FB;
	fma.rn.f64 	%fd118, %fd116, %fd91, %fd117;
	mov.f64 	%fd119, 0dBF95E70DC60362BF;
	fma.rn.f64 	%fd120, %fd118, %fd91, %fd119;
	mov.f64 	%fd121, 0d3FD33518B3874E8A;
	fma.rn.f64 	%fd122, %fd120, %fd91, %fd121;
	mul.f64 	%fd214, %fd91, %fd122;

BB32_23:
	mov.u32 	%r49, %ntid.y;
	ld.param.u32 	%r48, [map_j1_double_param_3];
	neg.f64 	%fd202, %fd214;
	setp.lt.f64	%p14, %fd1, 0d0000000000000000;
	selp.f64	%fd203, %fd202, %fd214, %p14;
	mul.f64 	%fd204, %fd1, 0d3FE0000000000000;
	setp.lt.f64	%p15, %fd2, 0d39B4484BFEEBC2A0;
	selp.f64	%fd205, %fd204, %fd203, %p15;
	mad.lo.s32 	%r43, %r51, %r48, %r52;
	mul.wide.s32 	%rd18, %r43, 8;
	add.s64 	%rd19, %rd17, %rd18;
	st.global.f64 	[%rd19], %fd205;
	mov.u32 	%r45, %nctaid.y;
	mad.lo.s32 	%r52, %r45, %r49, %r52;
	setp.lt.s32	%p16, %r52, %r14;
	@%p16 bra 	BB32_3;

BB32_24:
	mov.u32 	%r46, %nctaid.x;
	mad.lo.s32 	%r51, %r46, %r18, %r51;
	setp.lt.s32	%p17, %r51, %r15;
	@%p17 bra 	BB32_2;

BB32_25:
	ret;
}

	// .globl	map_lgamma_double
.visible .entry map_lgamma_double(
	.param .u32 map_lgamma_double_param_0,
	.param .u32 map_lgamma_double_param_1,
	.param .u64 map_lgamma_double_param_2,
	.param .u32 map_lgamma_double_param_3,
	.param .u64 map_lgamma_double_param_4,
	.param .u32 map_lgamma_double_param_5
)
{
	.reg .pred 	%p<17>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<62>;
	.reg .f64 	%fd<105>;
	.reg .b64 	%rd<14>;


	ld.param.u32 	%r19, [map_lgamma_double_param_0];
	ld.param.u32 	%r20, [map_lgamma_double_param_1];
	ld.param.u64 	%rd1, [map_lgamma_double_param_2];
	ld.param.u32 	%r21, [map_lgamma_double_param_3];
	ld.param.u64 	%rd2, [map_lgamma_double_param_4];
	ld.param.u32 	%r22, [map_lgamma_double_param_5];
	mov.u32 	%r23, %tid.x;
	mov.u32 	%r24, %ntid.x;
	mov.u32 	%r25, %ctaid.x;
	mad.lo.s32 	%r56, %r24, %r25, %r23;
	setp.ge.s32	%p1, %r56, %r20;
	@%p1 bra 	BB33_23;

	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd11, %rd1;

BB33_2:
	mov.u32 	%r26, %ctaid.y;
	mov.u32 	%r27, %ntid.y;
	mov.u32 	%r28, %tid.y;
	mad.lo.s32 	%r57, %r27, %r26, %r28;
	setp.ge.s32	%p2, %r57, %r19;
	@%p2 bra 	BB33_22;

BB33_3:
	mad.lo.s32 	%r33, %r56, %r22, %r57;
	mul.wide.s32 	%rd4, %r33, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	abs.f64 	%fd101, %fd1;
	setp.gtu.f64	%p3, %fd101, 0d7FF0000000000000;
	@%p3 bra 	BB33_20;
	bra.uni 	BB33_4;

BB33_20:
	add.f64 	%fd104, %fd1, %fd1;
	bra.uni 	BB33_21;

BB33_4:
	// Callseq Start 7
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd101;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_lgamma_pos, 
	(
	param0
	);
	ld.param.f64	%fd3, [retval0+0];
	
	//{
	}// Callseq End 7
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd1;
	}
	setp.gt.s32	%p4, %r34, -1;
	mov.f64 	%fd104, %fd3;
	@%p4 bra 	BB33_21;

	cvt.rzi.f64.f64	%fd25, %fd101;
	setp.eq.f64	%p5, %fd101, %fd25;
	mov.f64 	%fd24, 0d7FF0000000000000;
	mov.f64 	%fd104, %fd24;
	@%p5 bra 	BB33_21;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd101;
	}
	setp.lt.s32	%p6, %r5, 1006632960;
	@%p6 bra 	BB33_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r35, %temp}, %fd101;
	}
	add.s32 	%r36, %r5, 1048576;
	mov.b64 	%fd26, {%r35, %r36};
	cvt.rni.f64.f64	%fd27, %fd26;
	cvt.rzi.s64.f64	%rd6, %fd27;
	cvt.u32.u64	%r6, %rd6;
	neg.f64 	%fd28, %fd27;
	mov.f64 	%fd29, 0d3FE0000000000000;
	fma.rn.f64 	%fd30, %fd28, %fd29, %fd101;
	mul.f64 	%fd31, %fd30, 0d3CA1A62633145C07;
	mov.f64 	%fd32, 0d400921FB54442D18;
	fma.rn.f64 	%fd33, %fd30, %fd32, %fd31;
	and.b64  	%rd7, %rd6, 1;
	mul.rn.f64 	%fd4, %fd33, %fd33;
	setp.eq.b64	%p7, %rd7, 1;
	not.pred 	%p8, %p7;
	selp.f64	%fd34, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p8;
	shl.b64 	%rd8, %rd7, 6;
	mov.u64 	%rd9, __cudart_sin_cos_coeffs;
	add.s64 	%rd10, %rd8, %rd9;
	ld.const.f64 	%fd35, [%rd10+8];
	fma.rn.f64 	%fd36, %fd34, %fd4, %fd35;
	ld.const.f64 	%fd37, [%rd10+16];
	fma.rn.f64 	%fd38, %fd36, %fd4, %fd37;
	ld.const.f64 	%fd39, [%rd10+24];
	fma.rn.f64 	%fd40, %fd38, %fd4, %fd39;
	ld.const.f64 	%fd41, [%rd10+32];
	fma.rn.f64 	%fd42, %fd40, %fd4, %fd41;
	ld.const.f64 	%fd43, [%rd10+40];
	fma.rn.f64 	%fd44, %fd42, %fd4, %fd43;
	ld.const.f64 	%fd45, [%rd10+48];
	fma.rn.f64 	%fd5, %fd44, %fd4, %fd45;
	fma.rn.f64 	%fd100, %fd5, %fd33, %fd33;
	@%p8 bra 	BB33_9;

	mov.f64 	%fd46, 0d3FF0000000000000;
	fma.rn.f64 	%fd100, %fd5, %fd4, %fd46;

BB33_9:
	and.b32  	%r37, %r6, 2;
	setp.eq.s32	%p9, %r37, 0;
	@%p9 bra 	BB33_11;

	mov.f64 	%fd47, 0d0000000000000000;
	mov.f64 	%fd48, 0dBFF0000000000000;
	fma.rn.f64 	%fd100, %fd100, %fd48, %fd47;

BB33_11:
	abs.f64 	%fd49, %fd100;
	mul.f64 	%fd50, %fd101, %fd49;
	div.rn.f64 	%fd101, %fd32, %fd50;

BB33_12:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r59, %temp}, %fd101;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r58}, %fd101;
	}
	mov.u32 	%r60, -1023;
	setp.gt.s32	%p10, %r58, 1048575;
	@%p10 bra 	BB33_14;

	mul.f64 	%fd101, %fd101, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r58}, %fd101;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r59, %temp}, %fd101;
	}
	mov.u32 	%r60, -1077;

BB33_14:
	add.s32 	%r40, %r58, -1;
	setp.lt.u32	%p11, %r40, 2146435071;
	@%p11 bra 	BB33_16;
	bra.uni 	BB33_15;

BB33_16:
	shr.u32 	%r42, %r58, 20;
	add.s32 	%r61, %r60, %r42;
	and.b32  	%r43, %r58, -2146435073;
	or.b32  	%r44, %r43, 1072693248;
	mov.b64 	%fd102, {%r59, %r44};
	setp.lt.s32	%p13, %r44, 1073127583;
	@%p13 bra 	BB33_18;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r45, %temp}, %fd102;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r46}, %fd102;
	}
	add.s32 	%r47, %r46, -1048576;
	mov.b64 	%fd102, {%r45, %r47};
	add.s32 	%r61, %r61, 1;

BB33_18:
	add.f64 	%fd55, %fd102, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd54,%fd55;
	// inline asm
	neg.f64 	%fd56, %fd55;
	mov.f64 	%fd57, 0d3FF0000000000000;
	fma.rn.f64 	%fd58, %fd56, %fd54, %fd57;
	fma.rn.f64 	%fd59, %fd58, %fd58, %fd58;
	fma.rn.f64 	%fd60, %fd59, %fd54, %fd54;
	add.f64 	%fd61, %fd102, 0dBFF0000000000000;
	mul.f64 	%fd62, %fd61, %fd60;
	fma.rn.f64 	%fd63, %fd61, %fd60, %fd62;
	mul.f64 	%fd64, %fd63, %fd63;
	mov.f64 	%fd65, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd66, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd67, %fd66, %fd64, %fd65;
	mov.f64 	%fd68, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd69, %fd67, %fd64, %fd68;
	mov.f64 	%fd70, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd71, %fd69, %fd64, %fd70;
	mov.f64 	%fd72, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd73, %fd71, %fd64, %fd72;
	mov.f64 	%fd74, 0d3F624924923BE72D;
	fma.rn.f64 	%fd75, %fd73, %fd64, %fd74;
	mov.f64 	%fd76, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd77, %fd75, %fd64, %fd76;
	mov.f64 	%fd78, 0d3FB5555555555554;
	fma.rn.f64 	%fd79, %fd77, %fd64, %fd78;
	sub.f64 	%fd80, %fd61, %fd63;
	add.f64 	%fd81, %fd80, %fd80;
	neg.f64 	%fd82, %fd63;
	fma.rn.f64 	%fd83, %fd82, %fd61, %fd81;
	mul.f64 	%fd84, %fd60, %fd83;
	mul.f64 	%fd85, %fd64, %fd79;
	fma.rn.f64 	%fd86, %fd85, %fd63, %fd84;
	xor.b32  	%r48, %r61, -2147483648;
	mov.u32 	%r49, 1127219200;
	mov.b64 	%fd87, {%r48, %r49};
	mov.u32 	%r50, -2147483648;
	mov.b64 	%fd88, {%r50, %r49};
	sub.f64 	%fd89, %fd87, %fd88;
	mov.f64 	%fd90, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd91, %fd89, %fd90, %fd63;
	neg.f64 	%fd92, %fd89;
	fma.rn.f64 	%fd93, %fd92, %fd90, %fd91;
	sub.f64 	%fd94, %fd93, %fd63;
	sub.f64 	%fd95, %fd86, %fd94;
	mov.f64 	%fd96, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd97, %fd89, %fd96, %fd95;
	add.f64 	%fd103, %fd91, %fd97;
	bra.uni 	BB33_19;

BB33_15:
	mov.f64 	%fd52, 0d7FF0000000000000;
	fma.rn.f64 	%fd53, %fd101, %fd52, %fd52;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r41}, %fd101;
	}
	mov.b32 	 %f1, %r41;
	setp.eq.f32	%p12, %f1, 0f00000000;
	selp.f64	%fd103, 0dFFF0000000000000, %fd53, %p12;

BB33_19:
	sub.f64 	%fd98, %fd103, %fd3;
	neg.f64 	%fd99, %fd103;
	selp.f64	%fd104, %fd99, %fd98, %p6;

BB33_21:
	mad.lo.s32 	%r51, %r56, %r21, %r57;
	mul.wide.s32 	%rd12, %r51, 8;
	add.s64 	%rd13, %rd11, %rd12;
	st.global.f64 	[%rd13], %fd104;
	mov.u32 	%r53, %nctaid.y;
	mad.lo.s32 	%r57, %r53, %r27, %r57;
	setp.lt.s32	%p15, %r57, %r19;
	@%p15 bra 	BB33_3;

BB33_22:
	mov.u32 	%r54, %nctaid.x;
	mad.lo.s32 	%r56, %r54, %r24, %r56;
	setp.lt.s32	%p16, %r56, %r20;
	@%p16 bra 	BB33_2;

BB33_23:
	ret;
}

	// .globl	map_log10_double
.visible .entry map_log10_double(
	.param .u32 map_log10_double_param_0,
	.param .u32 map_log10_double_param_1,
	.param .u64 map_log10_double_param_2,
	.param .u32 map_log10_double_param_3,
	.param .u64 map_log10_double_param_4,
	.param .u32 map_log10_double_param_5
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<54>;
	.reg .f64 	%fd<62>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r20, [map_log10_double_param_0];
	ld.param.u32 	%r21, [map_log10_double_param_1];
	ld.param.u64 	%rd2, [map_log10_double_param_2];
	ld.param.u32 	%r22, [map_log10_double_param_3];
	ld.param.u64 	%rd3, [map_log10_double_param_4];
	ld.param.u32 	%r23, [map_log10_double_param_5];
	mov.u32 	%r24, %ntid.x;
	mov.u32 	%r25, %ctaid.x;
	mov.u32 	%r26, %tid.x;
	mad.lo.s32 	%r48, %r24, %r25, %r26;
	setp.ge.s32	%p1, %r48, %r21;
	@%p1 bra 	BB34_13;

	cvta.to.global.u64 	%rd1, %rd3;
	mov.u32 	%r27, %tid.y;
	mov.u32 	%r28, %ntid.y;
	mov.u32 	%r29, %ctaid.y;
	mad.lo.s32 	%r2, %r28, %r29, %r27;
	mov.u32 	%r30, %nctaid.y;
	mul.lo.s32 	%r3, %r30, %r28;
	cvta.to.global.u64 	%rd6, %rd2;

BB34_2:
	setp.ge.s32	%p2, %r2, %r20;
	@%p2 bra 	BB34_12;

	mul.lo.s32 	%r5, %r48, %r23;
	mul.lo.s32 	%r6, %r48, %r22;
	mov.u32 	%r49, %r2;

BB34_4:
	mov.u32 	%r7, %r49;
	add.s32 	%r32, %r7, %r5;
	mul.wide.s32 	%rd4, %r32, 8;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.f64 	%fd59, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd59;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r51, %temp}, %fd59;
	}
	mov.u32 	%r52, -1023;
	setp.gt.s32	%p3, %r50, 1048575;
	@%p3 bra 	BB34_6;

	mul.f64 	%fd59, %fd59, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd59;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r51, %temp}, %fd59;
	}
	mov.u32 	%r52, -1077;

BB34_6:
	add.s32 	%r34, %r50, -1;
	setp.lt.u32	%p4, %r34, 2146435071;
	@%p4 bra 	BB34_8;
	bra.uni 	BB34_7;

BB34_8:
	shr.u32 	%r36, %r50, 20;
	add.s32 	%r53, %r52, %r36;
	and.b32  	%r37, %r50, -2146435073;
	or.b32  	%r38, %r37, 1072693248;
	mov.b64 	%fd60, {%r51, %r38};
	setp.lt.s32	%p6, %r38, 1073127583;
	@%p6 bra 	BB34_10;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r39, %temp}, %fd60;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r40}, %fd60;
	}
	add.s32 	%r41, %r40, -1048576;
	mov.b64 	%fd60, {%r39, %r41};
	add.s32 	%r53, %r53, 1;

BB34_10:
	add.f64 	%fd13, %fd60, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd12,%fd13;
	// inline asm
	neg.f64 	%fd14, %fd13;
	mov.f64 	%fd15, 0d3FF0000000000000;
	fma.rn.f64 	%fd16, %fd14, %fd12, %fd15;
	fma.rn.f64 	%fd17, %fd16, %fd16, %fd16;
	fma.rn.f64 	%fd18, %fd17, %fd12, %fd12;
	add.f64 	%fd19, %fd60, 0dBFF0000000000000;
	mul.f64 	%fd20, %fd19, %fd18;
	fma.rn.f64 	%fd21, %fd19, %fd18, %fd20;
	mul.f64 	%fd22, %fd21, %fd21;
	mov.f64 	%fd23, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd24, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd25, %fd24, %fd22, %fd23;
	mov.f64 	%fd26, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd27, %fd25, %fd22, %fd26;
	mov.f64 	%fd28, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd29, %fd27, %fd22, %fd28;
	mov.f64 	%fd30, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd31, %fd29, %fd22, %fd30;
	mov.f64 	%fd32, 0d3F624924923BE72D;
	fma.rn.f64 	%fd33, %fd31, %fd22, %fd32;
	mov.f64 	%fd34, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd35, %fd33, %fd22, %fd34;
	mov.f64 	%fd36, 0d3FB5555555555554;
	fma.rn.f64 	%fd37, %fd35, %fd22, %fd36;
	sub.f64 	%fd38, %fd19, %fd21;
	add.f64 	%fd39, %fd38, %fd38;
	neg.f64 	%fd40, %fd21;
	fma.rn.f64 	%fd41, %fd40, %fd19, %fd39;
	mul.f64 	%fd42, %fd18, %fd41;
	mul.f64 	%fd43, %fd22, %fd37;
	fma.rn.f64 	%fd44, %fd43, %fd21, %fd42;
	xor.b32  	%r42, %r53, -2147483648;
	mov.u32 	%r43, 1127219200;
	mov.b64 	%fd45, {%r42, %r43};
	mov.u32 	%r44, -2147483648;
	mov.b64 	%fd46, {%r44, %r43};
	sub.f64 	%fd47, %fd45, %fd46;
	mov.f64 	%fd48, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd49, %fd47, %fd48, %fd21;
	neg.f64 	%fd50, %fd47;
	fma.rn.f64 	%fd51, %fd50, %fd48, %fd49;
	sub.f64 	%fd52, %fd51, %fd21;
	sub.f64 	%fd53, %fd44, %fd52;
	mov.f64 	%fd54, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd55, %fd47, %fd54, %fd53;
	add.f64 	%fd61, %fd49, %fd55;
	bra.uni 	BB34_11;

BB34_7:
	mov.f64 	%fd10, 0d7FF0000000000000;
	fma.rn.f64 	%fd11, %fd59, %fd10, %fd10;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd59;
	}
	mov.b32 	 %f1, %r35;
	setp.eq.f32	%p5, %f1, 0f00000000;
	selp.f64	%fd61, 0dFFF0000000000000, %fd11, %p5;

BB34_11:
	mul.f64 	%fd56, %fd61, 0d3C695355BAAAFAD3;
	mov.f64 	%fd57, 0d3FDBCB7B1526E50E;
	fma.rn.f64 	%fd58, %fd61, %fd57, %fd56;
	add.s32 	%r45, %r7, %r6;
	mul.wide.s32 	%rd7, %r45, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd58;
	add.s32 	%r18, %r3, %r7;
	setp.lt.s32	%p7, %r18, %r20;
	mov.u32 	%r49, %r18;
	@%p7 bra 	BB34_4;

BB34_12:
	mov.u32 	%r46, %nctaid.x;
	mad.lo.s32 	%r48, %r46, %r24, %r48;
	setp.lt.s32	%p8, %r48, %r21;
	@%p8 bra 	BB34_2;

BB34_13:
	ret;
}

	// .globl	map_log1p_double
.visible .entry map_log1p_double(
	.param .u32 map_log1p_double_param_0,
	.param .u32 map_log1p_double_param_1,
	.param .u64 map_log1p_double_param_2,
	.param .u32 map_log1p_double_param_3,
	.param .u64 map_log1p_double_param_4,
	.param .u32 map_log1p_double_param_5
)
{
	.reg .pred 	%p<12>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<55>;
	.reg .f64 	%fd<84>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r20, [map_log1p_double_param_0];
	ld.param.u32 	%r21, [map_log1p_double_param_1];
	ld.param.u64 	%rd2, [map_log1p_double_param_2];
	ld.param.u32 	%r22, [map_log1p_double_param_3];
	ld.param.u64 	%rd3, [map_log1p_double_param_4];
	ld.param.u32 	%r23, [map_log1p_double_param_5];
	mov.u32 	%r24, %ntid.x;
	mov.u32 	%r25, %ctaid.x;
	mov.u32 	%r26, %tid.x;
	mad.lo.s32 	%r49, %r24, %r25, %r26;
	setp.ge.s32	%p1, %r49, %r21;
	@%p1 bra 	BB35_15;

	cvta.to.global.u64 	%rd1, %rd3;
	mov.u32 	%r27, %tid.y;
	mov.u32 	%r28, %ntid.y;
	mov.u32 	%r29, %ctaid.y;
	mad.lo.s32 	%r2, %r28, %r29, %r27;
	mov.u32 	%r30, %nctaid.y;
	mul.lo.s32 	%r3, %r30, %r28;
	cvta.to.global.u64 	%rd6, %rd2;

BB35_2:
	setp.ge.s32	%p2, %r2, %r20;
	@%p2 bra 	BB35_14;

	mul.lo.s32 	%r5, %r49, %r23;
	mul.lo.s32 	%r6, %r49, %r22;
	mov.u32 	%r50, %r2;

BB35_4:
	mov.u32 	%r7, %r50;
	add.s32 	%r31, %r7, %r5;
	mul.wide.s32 	%rd4, %r31, 8;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd1;
	}
	setp.lt.u32	%p3, %r32, 1071994197;
	setp.lt.s32	%p4, %r32, -1076258407;
	or.pred  	%p5, %p3, %p4;
	@%p5 bra 	BB35_12;
	bra.uni 	BB35_5;

BB35_12:
	add.f64 	%fd58, %fd1, 0d4000000000000000;
	div.rn.f64 	%fd59, %fd1, %fd58;
	mul.f64 	%fd60, %fd1, %fd59;
	neg.f64 	%fd61, %fd60;
	sub.f64 	%fd62, %fd1, %fd60;
	mul.f64 	%fd63, %fd62, %fd62;
	mov.f64 	%fd64, 0d3ED087FFCEB2DC44;
	mov.f64 	%fd65, 0d3EB372FB2FBE14B5;
	fma.rn.f64 	%fd66, %fd65, %fd63, %fd64;
	mov.f64 	%fd67, 0d3EF3B9FF890F468C;
	fma.rn.f64 	%fd68, %fd66, %fd63, %fd67;
	mov.f64 	%fd69, 0d3F17457EFD51BAF8;
	fma.rn.f64 	%fd70, %fd68, %fd63, %fd69;
	mov.f64 	%fd71, 0d3F3C71C8DE3CE825;
	fma.rn.f64 	%fd72, %fd70, %fd63, %fd71;
	mov.f64 	%fd73, 0d3F6249248FA4661F;
	fma.rn.f64 	%fd74, %fd72, %fd63, %fd73;
	mov.f64 	%fd75, 0d3F899999999D70C4;
	fma.rn.f64 	%fd76, %fd74, %fd63, %fd75;
	mov.f64 	%fd77, 0d3FB5555555555462;
	fma.rn.f64 	%fd78, %fd76, %fd63, %fd77;
	mul.f64 	%fd79, %fd63, %fd78;
	fma.rn.f64 	%fd80, %fd79, %fd62, %fd61;
	add.f64 	%fd83, %fd1, %fd80;
	bra.uni 	BB35_13;

BB35_5:
	add.f64 	%fd81, %fd1, 0d3FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r51}, %fd81;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r52, %temp}, %fd81;
	}
	mov.u32 	%r53, -1023;
	setp.gt.s32	%p6, %r51, 1048575;
	@%p6 bra 	BB35_7;

	mul.f64 	%fd81, %fd81, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r51}, %fd81;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r52, %temp}, %fd81;
	}
	mov.u32 	%r53, -1077;

BB35_7:
	add.s32 	%r35, %r51, -1;
	setp.lt.u32	%p7, %r35, 2146435071;
	@%p7 bra 	BB35_9;
	bra.uni 	BB35_8;

BB35_9:
	shr.u32 	%r37, %r51, 20;
	add.s32 	%r54, %r53, %r37;
	and.b32  	%r38, %r51, -2146435073;
	or.b32  	%r39, %r38, 1072693248;
	mov.b64 	%fd82, {%r52, %r39};
	setp.lt.s32	%p9, %r39, 1073127583;
	@%p9 bra 	BB35_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r40, %temp}, %fd82;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r41}, %fd82;
	}
	add.s32 	%r42, %r41, -1048576;
	mov.b64 	%fd82, {%r40, %r42};
	add.s32 	%r54, %r54, 1;

BB35_11:
	add.f64 	%fd15, %fd82, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd14,%fd15;
	// inline asm
	neg.f64 	%fd16, %fd15;
	mov.f64 	%fd17, 0d3FF0000000000000;
	fma.rn.f64 	%fd18, %fd16, %fd14, %fd17;
	fma.rn.f64 	%fd19, %fd18, %fd18, %fd18;
	fma.rn.f64 	%fd20, %fd19, %fd14, %fd14;
	add.f64 	%fd21, %fd82, 0dBFF0000000000000;
	mul.f64 	%fd22, %fd21, %fd20;
	fma.rn.f64 	%fd23, %fd21, %fd20, %fd22;
	mul.f64 	%fd24, %fd23, %fd23;
	mov.f64 	%fd25, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd26, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd27, %fd26, %fd24, %fd25;
	mov.f64 	%fd28, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd29, %fd27, %fd24, %fd28;
	mov.f64 	%fd30, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd31, %fd29, %fd24, %fd30;
	mov.f64 	%fd32, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd33, %fd31, %fd24, %fd32;
	mov.f64 	%fd34, 0d3F624924923BE72D;
	fma.rn.f64 	%fd35, %fd33, %fd24, %fd34;
	mov.f64 	%fd36, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd37, %fd35, %fd24, %fd36;
	mov.f64 	%fd38, 0d3FB5555555555554;
	fma.rn.f64 	%fd39, %fd37, %fd24, %fd38;
	sub.f64 	%fd40, %fd21, %fd23;
	add.f64 	%fd41, %fd40, %fd40;
	neg.f64 	%fd42, %fd23;
	fma.rn.f64 	%fd43, %fd42, %fd21, %fd41;
	mul.f64 	%fd44, %fd20, %fd43;
	mul.f64 	%fd45, %fd24, %fd39;
	fma.rn.f64 	%fd46, %fd45, %fd23, %fd44;
	xor.b32  	%r43, %r54, -2147483648;
	mov.u32 	%r44, 1127219200;
	mov.b64 	%fd47, {%r43, %r44};
	mov.u32 	%r45, -2147483648;
	mov.b64 	%fd48, {%r45, %r44};
	sub.f64 	%fd49, %fd47, %fd48;
	mov.f64 	%fd50, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd51, %fd49, %fd50, %fd23;
	neg.f64 	%fd52, %fd49;
	fma.rn.f64 	%fd53, %fd52, %fd50, %fd51;
	sub.f64 	%fd54, %fd53, %fd23;
	sub.f64 	%fd55, %fd46, %fd54;
	mov.f64 	%fd56, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd57, %fd49, %fd56, %fd55;
	add.f64 	%fd83, %fd51, %fd57;
	bra.uni 	BB35_13;

BB35_8:
	mov.f64 	%fd12, 0d7FF0000000000000;
	fma.rn.f64 	%fd13, %fd81, %fd12, %fd12;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd81;
	}
	mov.b32 	 %f1, %r36;
	setp.eq.f32	%p8, %f1, 0f00000000;
	selp.f64	%fd83, 0dFFF0000000000000, %fd13, %p8;

BB35_13:
	add.s32 	%r46, %r7, %r6;
	mul.wide.s32 	%rd7, %r46, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd83;
	add.s32 	%r18, %r3, %r7;
	setp.lt.s32	%p10, %r18, %r20;
	mov.u32 	%r50, %r18;
	@%p10 bra 	BB35_4;

BB35_14:
	mov.u32 	%r47, %nctaid.x;
	mad.lo.s32 	%r49, %r47, %r24, %r49;
	setp.lt.s32	%p11, %r49, %r21;
	@%p11 bra 	BB35_2;

BB35_15:
	ret;
}

	// .globl	map_log2_double
.visible .entry map_log2_double(
	.param .u32 map_log2_double_param_0,
	.param .u32 map_log2_double_param_1,
	.param .u64 map_log2_double_param_2,
	.param .u32 map_log2_double_param_3,
	.param .u64 map_log2_double_param_4,
	.param .u32 map_log2_double_param_5
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<54>;
	.reg .f64 	%fd<62>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r20, [map_log2_double_param_0];
	ld.param.u32 	%r21, [map_log2_double_param_1];
	ld.param.u64 	%rd2, [map_log2_double_param_2];
	ld.param.u32 	%r22, [map_log2_double_param_3];
	ld.param.u64 	%rd3, [map_log2_double_param_4];
	ld.param.u32 	%r23, [map_log2_double_param_5];
	mov.u32 	%r24, %ntid.x;
	mov.u32 	%r25, %ctaid.x;
	mov.u32 	%r26, %tid.x;
	mad.lo.s32 	%r48, %r24, %r25, %r26;
	setp.ge.s32	%p1, %r48, %r21;
	@%p1 bra 	BB36_13;

	cvta.to.global.u64 	%rd1, %rd3;
	mov.u32 	%r27, %tid.y;
	mov.u32 	%r28, %ntid.y;
	mov.u32 	%r29, %ctaid.y;
	mad.lo.s32 	%r2, %r28, %r29, %r27;
	mov.u32 	%r30, %nctaid.y;
	mul.lo.s32 	%r3, %r30, %r28;
	cvta.to.global.u64 	%rd6, %rd2;

BB36_2:
	setp.ge.s32	%p2, %r2, %r20;
	@%p2 bra 	BB36_12;

	mul.lo.s32 	%r5, %r48, %r23;
	mul.lo.s32 	%r6, %r48, %r22;
	mov.u32 	%r49, %r2;

BB36_4:
	mov.u32 	%r7, %r49;
	add.s32 	%r32, %r7, %r5;
	mul.wide.s32 	%rd4, %r32, 8;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.f64 	%fd59, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd59;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r51, %temp}, %fd59;
	}
	mov.u32 	%r52, -1023;
	setp.gt.s32	%p3, %r50, 1048575;
	@%p3 bra 	BB36_6;

	mul.f64 	%fd59, %fd59, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd59;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r51, %temp}, %fd59;
	}
	mov.u32 	%r52, -1077;

BB36_6:
	add.s32 	%r34, %r50, -1;
	setp.lt.u32	%p4, %r34, 2146435071;
	@%p4 bra 	BB36_8;
	bra.uni 	BB36_7;

BB36_8:
	shr.u32 	%r36, %r50, 20;
	add.s32 	%r53, %r52, %r36;
	and.b32  	%r37, %r50, -2146435073;
	or.b32  	%r38, %r37, 1072693248;
	mov.b64 	%fd60, {%r51, %r38};
	setp.lt.s32	%p6, %r38, 1073127583;
	@%p6 bra 	BB36_10;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r39, %temp}, %fd60;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r40}, %fd60;
	}
	add.s32 	%r41, %r40, -1048576;
	mov.b64 	%fd60, {%r39, %r41};
	add.s32 	%r53, %r53, 1;

BB36_10:
	add.f64 	%fd13, %fd60, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd12,%fd13;
	// inline asm
	neg.f64 	%fd14, %fd13;
	mov.f64 	%fd15, 0d3FF0000000000000;
	fma.rn.f64 	%fd16, %fd14, %fd12, %fd15;
	fma.rn.f64 	%fd17, %fd16, %fd16, %fd16;
	fma.rn.f64 	%fd18, %fd17, %fd12, %fd12;
	add.f64 	%fd19, %fd60, 0dBFF0000000000000;
	mul.f64 	%fd20, %fd19, %fd18;
	fma.rn.f64 	%fd21, %fd19, %fd18, %fd20;
	mul.f64 	%fd22, %fd21, %fd21;
	mov.f64 	%fd23, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd24, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd25, %fd24, %fd22, %fd23;
	mov.f64 	%fd26, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd27, %fd25, %fd22, %fd26;
	mov.f64 	%fd28, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd29, %fd27, %fd22, %fd28;
	mov.f64 	%fd30, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd31, %fd29, %fd22, %fd30;
	mov.f64 	%fd32, 0d3F624924923BE72D;
	fma.rn.f64 	%fd33, %fd31, %fd22, %fd32;
	mov.f64 	%fd34, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd35, %fd33, %fd22, %fd34;
	mov.f64 	%fd36, 0d3FB5555555555554;
	fma.rn.f64 	%fd37, %fd35, %fd22, %fd36;
	sub.f64 	%fd38, %fd19, %fd21;
	add.f64 	%fd39, %fd38, %fd38;
	neg.f64 	%fd40, %fd21;
	fma.rn.f64 	%fd41, %fd40, %fd19, %fd39;
	mul.f64 	%fd42, %fd18, %fd41;
	mul.f64 	%fd43, %fd22, %fd37;
	fma.rn.f64 	%fd44, %fd43, %fd21, %fd42;
	xor.b32  	%r42, %r53, -2147483648;
	mov.u32 	%r43, 1127219200;
	mov.b64 	%fd45, {%r42, %r43};
	mov.u32 	%r44, -2147483648;
	mov.b64 	%fd46, {%r44, %r43};
	sub.f64 	%fd47, %fd45, %fd46;
	mov.f64 	%fd48, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd49, %fd47, %fd48, %fd21;
	neg.f64 	%fd50, %fd47;
	fma.rn.f64 	%fd51, %fd50, %fd48, %fd49;
	sub.f64 	%fd52, %fd51, %fd21;
	sub.f64 	%fd53, %fd44, %fd52;
	mov.f64 	%fd54, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd55, %fd47, %fd54, %fd53;
	add.f64 	%fd61, %fd49, %fd55;
	bra.uni 	BB36_11;

BB36_7:
	mov.f64 	%fd10, 0d7FF0000000000000;
	fma.rn.f64 	%fd11, %fd59, %fd10, %fd10;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd59;
	}
	mov.b32 	 %f1, %r35;
	setp.eq.f32	%p5, %f1, 0f00000000;
	selp.f64	%fd61, 0dFFF0000000000000, %fd11, %p5;

BB36_11:
	mul.f64 	%fd56, %fd61, 0d3C7777D0FFDA0D24;
	mov.f64 	%fd57, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd58, %fd61, %fd57, %fd56;
	add.s32 	%r45, %r7, %r6;
	mul.wide.s32 	%rd7, %r45, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd58;
	add.s32 	%r18, %r3, %r7;
	setp.lt.s32	%p7, %r18, %r20;
	mov.u32 	%r49, %r18;
	@%p7 bra 	BB36_4;

BB36_12:
	mov.u32 	%r46, %nctaid.x;
	mad.lo.s32 	%r48, %r46, %r24, %r48;
	setp.lt.s32	%p8, %r48, %r21;
	@%p8 bra 	BB36_2;

BB36_13:
	ret;
}

	// .globl	map_logb_double
.visible .entry map_logb_double(
	.param .u32 map_logb_double_param_0,
	.param .u32 map_logb_double_param_1,
	.param .u64 map_logb_double_param_2,
	.param .u32 map_logb_double_param_3,
	.param .u64 map_logb_double_param_4,
	.param .u32 map_logb_double_param_5
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<34>;
	.reg .f64 	%fd<9>;
	.reg .b64 	%rd<13>;


	ld.param.u32 	%r13, [map_logb_double_param_0];
	ld.param.u32 	%r14, [map_logb_double_param_1];
	ld.param.u64 	%rd3, [map_logb_double_param_2];
	ld.param.u32 	%r15, [map_logb_double_param_3];
	ld.param.u64 	%rd4, [map_logb_double_param_4];
	ld.param.u32 	%r16, [map_logb_double_param_5];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r32, %r1, %r17, %r18;
	setp.ge.s32	%p1, %r32, %r14;
	@%p1 bra 	BB37_13;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r19, %tid.y;
	mov.u32 	%r20, %ntid.y;
	mov.u32 	%r21, %ctaid.y;
	mad.lo.s32 	%r3, %r20, %r21, %r19;
	mov.u32 	%r22, %nctaid.x;
	mul.lo.s32 	%r4, %r22, %r1;
	mov.u32 	%r23, %nctaid.y;
	mul.lo.s32 	%r5, %r23, %r20;

BB37_2:
	setp.ge.s32	%p2, %r3, %r13;
	@%p2 bra 	BB37_12;

	mul.lo.s32 	%r7, %r32, %r16;
	mul.lo.s32 	%r8, %r32, %r15;
	mov.u32 	%r33, %r3;

BB37_4:
	mov.u32 	%r9, %r33;
	add.s32 	%r24, %r9, %r7;
	mul.wide.s32 	%rd5, %r24, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	abs.f64 	%fd2, %fd1;
	setp.gtu.f64	%p3, %fd2, 0d7FF0000000000000;
	@%p3 bra 	BB37_10;
	bra.uni 	BB37_5;

BB37_10:
	add.f64 	%fd8, %fd1, %fd1;
	bra.uni 	BB37_11;

BB37_5:
	setp.eq.f64	%p4, %fd2, 0d7FF0000000000000;
	mov.f64 	%fd8, %fd2;
	@%p4 bra 	BB37_11;

	setp.eq.f64	%p5, %fd2, 0d0000000000000000;
	mov.f64 	%fd7, 0dFFF0000000000000;
	mov.f64 	%fd8, %fd7;
	@%p5 bra 	BB37_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd2;
	}
	setp.gt.u32	%p6, %r10, 1048575;
	@%p6 bra 	BB37_9;
	bra.uni 	BB37_8;

BB37_9:
	shr.u32 	%r29, %r10, 20;
	add.s32 	%r30, %r29, -1023;
	cvt.rn.f64.s32	%fd8, %r30;
	bra.uni 	BB37_11;

BB37_8:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r25, %temp}, %fd2;
	}
	cvt.u64.u32	%rd7, %r10;
	shl.b64 	%rd8, %rd7, 32;
	cvt.u64.u32	%rd9, %r25;
	or.b64  	%rd10, %rd8, %rd9;
	clz.b64 	%r26, %rd10;
	mov.u32 	%r27, -1011;
	sub.s32 	%r28, %r27, %r26;
	cvt.rn.f64.s32	%fd8, %r28;

BB37_11:
	add.s32 	%r31, %r9, %r8;
	mul.wide.s32 	%rd11, %r31, 8;
	add.s64 	%rd12, %rd1, %rd11;
	st.global.f64 	[%rd12], %fd8;
	add.s32 	%r11, %r5, %r9;
	setp.lt.s32	%p7, %r11, %r13;
	mov.u32 	%r33, %r11;
	@%p7 bra 	BB37_4;

BB37_12:
	add.s32 	%r32, %r4, %r32;
	setp.lt.s32	%p8, %r32, %r14;
	@%p8 bra 	BB37_2;

BB37_13:
	ret;
}

	// .globl	map_log_double
.visible .entry map_log_double(
	.param .u32 map_log_double_param_0,
	.param .u32 map_log_double_param_1,
	.param .u64 map_log_double_param_2,
	.param .u32 map_log_double_param_3,
	.param .u64 map_log_double_param_4,
	.param .u32 map_log_double_param_5
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<54>;
	.reg .f64 	%fd<59>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r20, [map_log_double_param_0];
	ld.param.u32 	%r21, [map_log_double_param_1];
	ld.param.u64 	%rd2, [map_log_double_param_2];
	ld.param.u32 	%r22, [map_log_double_param_3];
	ld.param.u64 	%rd3, [map_log_double_param_4];
	ld.param.u32 	%r23, [map_log_double_param_5];
	mov.u32 	%r24, %ntid.x;
	mov.u32 	%r25, %ctaid.x;
	mov.u32 	%r26, %tid.x;
	mad.lo.s32 	%r48, %r24, %r25, %r26;
	setp.ge.s32	%p1, %r48, %r21;
	@%p1 bra 	BB38_13;

	cvta.to.global.u64 	%rd1, %rd3;
	mov.u32 	%r27, %tid.y;
	mov.u32 	%r28, %ntid.y;
	mov.u32 	%r29, %ctaid.y;
	mad.lo.s32 	%r2, %r28, %r29, %r27;
	mov.u32 	%r30, %nctaid.y;
	mul.lo.s32 	%r3, %r30, %r28;
	cvta.to.global.u64 	%rd6, %rd2;

BB38_2:
	setp.ge.s32	%p2, %r2, %r20;
	@%p2 bra 	BB38_12;

	mul.lo.s32 	%r5, %r48, %r23;
	mul.lo.s32 	%r6, %r48, %r22;
	mov.u32 	%r49, %r2;

BB38_4:
	mov.u32 	%r7, %r49;
	add.s32 	%r32, %r7, %r5;
	mul.wide.s32 	%rd4, %r32, 8;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.f64 	%fd56, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd56;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r51, %temp}, %fd56;
	}
	mov.u32 	%r52, -1023;
	setp.gt.s32	%p3, %r50, 1048575;
	@%p3 bra 	BB38_6;

	mul.f64 	%fd56, %fd56, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd56;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r51, %temp}, %fd56;
	}
	mov.u32 	%r52, -1077;

BB38_6:
	add.s32 	%r34, %r50, -1;
	setp.lt.u32	%p4, %r34, 2146435071;
	@%p4 bra 	BB38_8;
	bra.uni 	BB38_7;

BB38_8:
	shr.u32 	%r36, %r50, 20;
	add.s32 	%r53, %r52, %r36;
	and.b32  	%r37, %r50, -2146435073;
	or.b32  	%r38, %r37, 1072693248;
	mov.b64 	%fd57, {%r51, %r38};
	setp.lt.s32	%p6, %r38, 1073127583;
	@%p6 bra 	BB38_10;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r39, %temp}, %fd57;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r40}, %fd57;
	}
	add.s32 	%r41, %r40, -1048576;
	mov.b64 	%fd57, {%r39, %r41};
	add.s32 	%r53, %r53, 1;

BB38_10:
	add.f64 	%fd13, %fd57, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd12,%fd13;
	// inline asm
	neg.f64 	%fd14, %fd13;
	mov.f64 	%fd15, 0d3FF0000000000000;
	fma.rn.f64 	%fd16, %fd14, %fd12, %fd15;
	fma.rn.f64 	%fd17, %fd16, %fd16, %fd16;
	fma.rn.f64 	%fd18, %fd17, %fd12, %fd12;
	add.f64 	%fd19, %fd57, 0dBFF0000000000000;
	mul.f64 	%fd20, %fd19, %fd18;
	fma.rn.f64 	%fd21, %fd19, %fd18, %fd20;
	mul.f64 	%fd22, %fd21, %fd21;
	mov.f64 	%fd23, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd24, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd25, %fd24, %fd22, %fd23;
	mov.f64 	%fd26, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd27, %fd25, %fd22, %fd26;
	mov.f64 	%fd28, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd29, %fd27, %fd22, %fd28;
	mov.f64 	%fd30, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd31, %fd29, %fd22, %fd30;
	mov.f64 	%fd32, 0d3F624924923BE72D;
	fma.rn.f64 	%fd33, %fd31, %fd22, %fd32;
	mov.f64 	%fd34, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd35, %fd33, %fd22, %fd34;
	mov.f64 	%fd36, 0d3FB5555555555554;
	fma.rn.f64 	%fd37, %fd35, %fd22, %fd36;
	sub.f64 	%fd38, %fd19, %fd21;
	add.f64 	%fd39, %fd38, %fd38;
	neg.f64 	%fd40, %fd21;
	fma.rn.f64 	%fd41, %fd40, %fd19, %fd39;
	mul.f64 	%fd42, %fd18, %fd41;
	mul.f64 	%fd43, %fd22, %fd37;
	fma.rn.f64 	%fd44, %fd43, %fd21, %fd42;
	xor.b32  	%r42, %r53, -2147483648;
	mov.u32 	%r43, 1127219200;
	mov.b64 	%fd45, {%r42, %r43};
	mov.u32 	%r44, -2147483648;
	mov.b64 	%fd46, {%r44, %r43};
	sub.f64 	%fd47, %fd45, %fd46;
	mov.f64 	%fd48, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd49, %fd47, %fd48, %fd21;
	neg.f64 	%fd50, %fd47;
	fma.rn.f64 	%fd51, %fd50, %fd48, %fd49;
	sub.f64 	%fd52, %fd51, %fd21;
	sub.f64 	%fd53, %fd44, %fd52;
	mov.f64 	%fd54, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd55, %fd47, %fd54, %fd53;
	add.f64 	%fd58, %fd49, %fd55;
	bra.uni 	BB38_11;

BB38_7:
	mov.f64 	%fd10, 0d7FF0000000000000;
	fma.rn.f64 	%fd11, %fd56, %fd10, %fd10;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd56;
	}
	mov.b32 	 %f1, %r35;
	setp.eq.f32	%p5, %f1, 0f00000000;
	selp.f64	%fd58, 0dFFF0000000000000, %fd11, %p5;

BB38_11:
	add.s32 	%r45, %r7, %r6;
	mul.wide.s32 	%rd7, %r45, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd58;
	add.s32 	%r18, %r3, %r7;
	setp.lt.s32	%p7, %r18, %r20;
	mov.u32 	%r49, %r18;
	@%p7 bra 	BB38_4;

BB38_12:
	mov.u32 	%r46, %nctaid.x;
	mad.lo.s32 	%r48, %r46, %r24, %r48;
	setp.lt.s32	%p8, %r48, %r21;
	@%p8 bra 	BB38_2;

BB38_13:
	ret;
}

	// .globl	map_nearbyint_double
.visible .entry map_nearbyint_double(
	.param .u32 map_nearbyint_double_param_0,
	.param .u32 map_nearbyint_double_param_1,
	.param .u64 map_nearbyint_double_param_2,
	.param .u32 map_nearbyint_double_param_3,
	.param .u64 map_nearbyint_double_param_4,
	.param .u32 map_nearbyint_double_param_5
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map_nearbyint_double_param_0];
	ld.param.u32 	%r13, [map_nearbyint_double_param_1];
	ld.param.u64 	%rd3, [map_nearbyint_double_param_2];
	ld.param.u32 	%r14, [map_nearbyint_double_param_3];
	ld.param.u64 	%rd4, [map_nearbyint_double_param_4];
	ld.param.u32 	%r15, [map_nearbyint_double_param_5];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB39_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB39_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB39_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB39_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	cvt.rni.f64.f64	%fd2, %fd1;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd2;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB39_4;

BB39_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB39_2;

BB39_6:
	ret;
}

	// .globl	map_normcdf_double
.visible .entry map_normcdf_double(
	.param .u32 map_normcdf_double_param_0,
	.param .u32 map_normcdf_double_param_1,
	.param .u64 map_normcdf_double_param_2,
	.param .u32 map_normcdf_double_param_3,
	.param .u64 map_normcdf_double_param_4,
	.param .u32 map_normcdf_double_param_5
)
{
	.reg .pred 	%p<14>;
	.reg .b32 	%r<56>;
	.reg .f64 	%fd<144>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r10, [map_normcdf_double_param_0];
	ld.param.u32 	%r11, [map_normcdf_double_param_1];
	ld.param.u64 	%rd1, [map_normcdf_double_param_2];
	ld.param.u64 	%rd2, [map_normcdf_double_param_4];
	mov.u32 	%r14, %tid.x;
	mov.u32 	%r15, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mad.lo.s32 	%r54, %r15, %r16, %r14;
	setp.ge.s32	%p1, %r54, %r11;
	@%p1 bra 	BB40_12;

	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd6, %rd1;

BB40_2:
	mov.u32 	%r17, %ctaid.y;
	mov.u32 	%r18, %ntid.y;
	mov.u32 	%r19, %tid.y;
	mad.lo.s32 	%r55, %r18, %r17, %r19;
	setp.ge.s32	%p2, %r55, %r10;
	@%p2 bra 	BB40_11;

BB40_3:
	ld.param.u32 	%r53, [map_normcdf_double_param_5];
	mad.lo.s32 	%r24, %r54, %r53, %r55;
	mul.wide.s32 	%rd4, %r24, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd142, [%rd5];
	abs.f64 	%fd12, %fd142;
	setp.leu.f64	%p3, %fd12, 0d4043400000000000;
	@%p3 bra 	BB40_5;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r25}, %fd142;
	}
	and.b32  	%r26, %r25, -2147483648;
	mov.f64 	%fd13, 0d4043400000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd13;
	}
	and.b32  	%r28, %r27, 2147483647;
	or.b32  	%r29, %r28, %r26;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r30, %temp}, %fd13;
	}
	mov.b64 	%fd142, {%r30, %r29};

BB40_5:
	mov.f64 	%fd14, 0dBFE6A09E667F3BCD;
	mul.rn.f64 	%fd4, %fd142, %fd14;
	neg.f64 	%fd15, %fd4;
	fma.rn.f64 	%fd16, %fd142, %fd14, %fd15;
	mov.f64 	%fd17, 0d3C8BDD3413B26456;
	fma.rn.f64 	%fd5, %fd142, %fd17, %fd16;
	add.rn.f64 	%fd6, %fd4, %fd5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd6;
	}
	and.b32  	%r6, %r5, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r7, %temp}, %fd6;
	}
	setp.lt.u32	%p4, %r6, 2146435072;
	@%p4 bra 	BB40_7;
	bra.uni 	BB40_6;

BB40_7:
	setp.lt.s32	%p9, %r5, 0;
	mov.b64 	%fd24, {%r7, %r6};
	add.f64 	%fd25, %fd24, 0dC010000000000000;
	add.f64 	%fd21, %fd24, 0d4010000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd20,%fd21;
	// inline asm
	neg.f64 	%fd26, %fd21;
	mov.f64 	%fd27, 0d3FF0000000000000;
	fma.rn.f64 	%fd28, %fd26, %fd20, %fd27;
	fma.rn.f64 	%fd29, %fd28, %fd28, %fd28;
	fma.rn.f64 	%fd30, %fd29, %fd20, %fd20;
	mul.f64 	%fd31, %fd25, %fd30;
	add.rn.f64 	%fd32, %fd31, %fd27;
	mov.f64 	%fd33, 0dC010000000000000;
	fma.rn.f64 	%fd34, %fd33, %fd32, %fd24;
	neg.f64 	%fd35, %fd31;
	fma.rn.f64 	%fd36, %fd35, %fd24, %fd34;
	fma.rn.f64 	%fd37, %fd30, %fd36, %fd31;
	mov.f64 	%fd38, 0dBE44E1C6FD03D328;
	mov.f64 	%fd39, 0dBDF8774AD4E0BFD7;
	fma.rn.f64 	%fd40, %fd39, %fd37, %fd38;
	mov.f64 	%fd41, 0dBE4330149F7A56B6;
	fma.rn.f64 	%fd42, %fd40, %fd37, %fd41;
	mov.f64 	%fd43, 0d3E7BEDDED8376273;
	fma.rn.f64 	%fd44, %fd42, %fd37, %fd43;
	mov.f64 	%fd45, 0d3E6F9254C3ABF22B;
	fma.rn.f64 	%fd46, %fd44, %fd37, %fd45;
	mov.f64 	%fd47, 0dBEAB9068C2148CF0;
	fma.rn.f64 	%fd48, %fd46, %fd37, %fd47;
	mov.f64 	%fd49, 0d3E94C6454DB34009;
	fma.rn.f64 	%fd50, %fd48, %fd37, %fd49;
	mov.f64 	%fd51, 0d3ED7F1C378F2311D;
	fma.rn.f64 	%fd52, %fd50, %fd37, %fd51;
	mov.f64 	%fd53, 0dBEE78E051C6D5C58;
	fma.rn.f64 	%fd54, %fd52, %fd37, %fd53;
	mov.f64 	%fd55, 0dBEF995B4EAD14A90;
	fma.rn.f64 	%fd56, %fd54, %fd37, %fd55;
	mov.f64 	%fd57, 0d3F23BE27CF0A29B2;
	fma.rn.f64 	%fd58, %fd56, %fd37, %fd57;
	mov.f64 	%fd59, 0dBF2A1DEF3E81672E;
	fma.rn.f64 	%fd60, %fd58, %fd37, %fd59;
	mov.f64 	%fd61, 0dBF48D4ABE68C1713;
	fma.rn.f64 	%fd62, %fd60, %fd37, %fd61;
	mov.f64 	%fd63, 0d3F749C67210DD6B4;
	fma.rn.f64 	%fd64, %fd62, %fd37, %fd63;
	mov.f64 	%fd65, 0dBF9096238568E357;
	fma.rn.f64 	%fd66, %fd64, %fd37, %fd65;
	mov.f64 	%fd67, 0d3FA3079EDF8C2DC9;
	fma.rn.f64 	%fd68, %fd66, %fd37, %fd67;
	mov.f64 	%fd69, 0dBFB0FB06DFF601FC;
	fma.rn.f64 	%fd70, %fd68, %fd37, %fd69;
	mov.f64 	%fd71, 0d3FB7FEE004DFBCDC;
	fma.rn.f64 	%fd72, %fd70, %fd37, %fd71;
	mov.f64 	%fd73, 0dBFB9DDB23C3DB8C6;
	fma.rn.f64 	%fd74, %fd72, %fd37, %fd73;
	mov.f64 	%fd75, 0d3FB16ECEFCFA5FDA;
	fma.rn.f64 	%fd76, %fd74, %fd37, %fd75;
	mov.f64 	%fd77, 0d3F8F7F5DF66FB6D6;
	fma.rn.f64 	%fd78, %fd76, %fd37, %fd77;
	mov.f64 	%fd79, 0dBFC1DF1AD154A29D;
	fma.rn.f64 	%fd80, %fd78, %fd37, %fd79;
	mov.f64 	%fd81, 0d3FF3BA5916E9FD7F;
	fma.rn.f64 	%fd82, %fd80, %fd37, %fd81;
	mov.f64 	%fd83, 0d4000000000000000;
	fma.rn.f64 	%fd23, %fd83, %fd24, %fd27;
	// inline asm
	rcp.approx.ftz.f64 %fd22,%fd23;
	// inline asm
	neg.f64 	%fd84, %fd23;
	fma.rn.f64 	%fd85, %fd84, %fd22, %fd27;
	fma.rn.f64 	%fd86, %fd85, %fd85, %fd85;
	fma.rn.f64 	%fd87, %fd86, %fd22, %fd22;
	mul.f64 	%fd88, %fd82, %fd87;
	mul.f64 	%fd89, %fd88, 0dC000000000000000;
	fma.rn.f64 	%fd90, %fd24, %fd89, %fd82;
	neg.f64 	%fd91, %fd88;
	add.rn.f64 	%fd92, %fd90, %fd91;
	fma.rn.f64 	%fd93, %fd92, %fd87, %fd88;
	mul.f64 	%fd94, %fd24, %fd24;
	neg.f64 	%fd95, %fd94;
	mov.f64 	%fd96, 0d4338000000000000;
	mov.f64 	%fd97, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd98, %fd95, %fd97, %fd96;
	mov.f64 	%fd99, 0dC338000000000000;
	add.rn.f64 	%fd100, %fd98, %fd99;
	mov.f64 	%fd101, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd102, %fd100, %fd101, %fd95;
	mov.f64 	%fd103, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd104, %fd100, %fd103, %fd102;
	mov.f64 	%fd105, 0d3E928AF3FCA213EA;
	mov.f64 	%fd106, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd107, %fd106, %fd104, %fd105;
	mov.f64 	%fd108, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd109, %fd107, %fd104, %fd108;
	mov.f64 	%fd110, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd111, %fd109, %fd104, %fd110;
	mov.f64 	%fd112, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd113, %fd111, %fd104, %fd112;
	mov.f64 	%fd114, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd115, %fd113, %fd104, %fd114;
	mov.f64 	%fd116, 0d3F81111111122322;
	fma.rn.f64 	%fd117, %fd115, %fd104, %fd116;
	mov.f64 	%fd118, 0d3FA55555555502A1;
	fma.rn.f64 	%fd119, %fd117, %fd104, %fd118;
	mov.f64 	%fd120, 0d3FC5555555555511;
	fma.rn.f64 	%fd121, %fd119, %fd104, %fd120;
	mov.f64 	%fd122, 0d3FE000000000000B;
	fma.rn.f64 	%fd123, %fd121, %fd104, %fd122;
	fma.rn.f64 	%fd124, %fd123, %fd104, %fd27;
	fma.rn.f64 	%fd125, %fd124, %fd104, %fd27;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r31, %temp}, %fd98;
	}
	shr.u32 	%r32, %r31, 31;
	add.s32 	%r33, %r31, %r32;
	shr.s32 	%r34, %r33, 1;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r35, %temp}, %fd125;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd125;
	}
	shl.b32 	%r37, %r34, 20;
	add.s32 	%r38, %r36, %r37;
	mov.b64 	%fd126, {%r35, %r38};
	sub.s32 	%r39, %r31, %r34;
	shl.b32 	%r40, %r39, 20;
	add.s32 	%r41, %r40, 1072693248;
	mov.u32 	%r42, 0;
	mov.b64 	%fd127, {%r42, %r41};
	mul.f64 	%fd128, %fd126, %fd127;
	neg.f64 	%fd129, %fd24;
	fma.rn.f64 	%fd130, %fd129, %fd24, %fd94;
	fma.rn.f64 	%fd131, %fd128, %fd130, %fd128;
	mul.f64 	%fd132, %fd93, %fd131;
	setp.gt.u32	%p10, %r6, 1077624832;
	selp.f64	%fd133, 0d0000000000000000, %fd132, %p10;
	sub.f64 	%fd134, %fd83, %fd133;
	selp.f64	%fd143, %fd134, %fd133, %p9;
	bra.uni 	BB40_8;

BB40_6:
	setp.lt.s32	%p5, %r5, 0;
	setp.eq.s32	%p6, %r7, 0;
	setp.eq.s32	%p7, %r6, 2146435072;
	and.pred  	%p8, %p7, %p6;
	selp.f64	%fd18, 0d4000000000000000, 0d0000000000000000, %p5;
	add.f64 	%fd19, %fd6, %fd6;
	selp.f64	%fd143, %fd18, %fd19, %p8;

BB40_8:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd142;
	}
	setp.lt.u32	%p11, %r43, -1074790399;
	@%p11 bra 	BB40_10;

	mov.f64 	%fd141, 0dBFE6A09E667F3BCD;
	mul.rn.f64 	%fd140, %fd142, %fd141;
	sub.f64 	%fd135, %fd140, %fd6;
	add.rn.f64 	%fd136, %fd135, %fd5;
	mul.f64 	%fd137, %fd6, 0dC000000000000000;
	mul.f64 	%fd138, %fd137, %fd143;
	fma.rn.f64 	%fd143, %fd138, %fd136, %fd143;

BB40_10:
	mov.u32 	%r50, %ntid.y;
	ld.param.u32 	%r49, [map_normcdf_double_param_3];
	mad.lo.s32 	%r44, %r54, %r49, %r55;
	mul.wide.s32 	%rd7, %r44, 8;
	add.s64 	%rd8, %rd6, %rd7;
	mul.f64 	%fd139, %fd143, 0d3FE0000000000000;
	st.global.f64 	[%rd8], %fd139;
	mov.u32 	%r46, %nctaid.y;
	mad.lo.s32 	%r55, %r46, %r50, %r55;
	setp.lt.s32	%p12, %r55, %r10;
	@%p12 bra 	BB40_3;

BB40_11:
	ld.param.u32 	%r52, [map_normcdf_double_param_1];
	mov.u32 	%r51, %ntid.x;
	mov.u32 	%r47, %nctaid.x;
	mad.lo.s32 	%r54, %r47, %r51, %r54;
	setp.lt.s32	%p13, %r54, %r52;
	@%p13 bra 	BB40_2;

BB40_12:
	ret;
}

	// .globl	map_normcdfinv_double
.visible .entry map_normcdfinv_double(
	.param .u32 map_normcdfinv_double_param_0,
	.param .u32 map_normcdfinv_double_param_1,
	.param .u64 map_normcdfinv_double_param_2,
	.param .u32 map_normcdfinv_double_param_3,
	.param .u64 map_normcdfinv_double_param_4,
	.param .u32 map_normcdfinv_double_param_5
)
{
	.reg .pred 	%p<15>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<78>;
	.reg .f64 	%fd<274>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r21, [map_normcdfinv_double_param_0];
	ld.param.u32 	%r22, [map_normcdfinv_double_param_1];
	ld.param.u64 	%rd1, [map_normcdfinv_double_param_2];
	ld.param.u64 	%rd2, [map_normcdfinv_double_param_4];
	mov.u32 	%r25, %tid.x;
	mov.u32 	%r26, %ntid.x;
	mov.u32 	%r27, %ctaid.x;
	mad.lo.s32 	%r72, %r26, %r27, %r25;
	setp.ge.s32	%p1, %r72, %r22;
	@%p1 bra 	BB41_19;

	mov.u32 	%r28, %tid.y;
	mov.u32 	%r29, %ntid.y;
	mov.u32 	%r30, %ctaid.y;
	mad.lo.s32 	%r2, %r29, %r30, %r28;
	mov.u32 	%r31, %nctaid.y;
	mul.lo.s32 	%r3, %r31, %r29;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd6, %rd1;

BB41_2:
	setp.ge.s32	%p2, %r2, %r21;
	@%p2 bra 	BB41_18;

	ld.param.u32 	%r69, [map_normcdfinv_double_param_5];
	mov.u32 	%r73, %r2;

BB41_4:
	mov.u32 	%r7, %r73;
	mul.lo.s32 	%r71, %r72, %r69;
	add.s32 	%r32, %r7, %r71;
	mul.wide.s32 	%rd4, %r32, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd19, [%rd5];
	add.f64 	%fd1, %fd19, %fd19;
	neg.f64 	%fd2, %fd1;
	mov.f64 	%fd20, 0d4000000000000000;
	add.rn.f64 	%fd3, %fd20, %fd2;
	setp.le.f64	%p3, %fd1, 0d3FFFFC0B65AA4E0E;
	setp.ge.f64	%p4, %fd1, 0d3F4FA4D2AD8F904D;
	and.pred  	%p5, %p4, %p3;
	@%p5 bra 	BB41_16;
	bra.uni 	BB41_5;

BB41_16:
	mul.rn.f64 	%fd175, %fd3, %fd1;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r53}, %fd175;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r54, %temp}, %fd175;
	}
	shr.u32 	%r55, %r53, 20;
	and.b32  	%r56, %r55, 2046;
	add.s32 	%r57, %r56, 2147482626;
	mov.u32 	%r58, 1127219200;
	mov.b64 	%fd176, {%r57, %r58};
	mov.u32 	%r59, -2147483648;
	mov.b64 	%fd177, {%r59, %r58};
	sub.f64 	%fd178, %fd176, %fd177;
	and.b32  	%r60, %r53, -2145386497;
	add.s32 	%r61, %r60, 1071644672;
	mov.b64 	%fd179, {%r54, %r61};
	add.f64 	%fd180, %fd179, 0dBFF0000000000000;
	add.f64 	%fd174, %fd179, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd173,%fd174;
	// inline asm
	neg.f64 	%fd181, %fd174;
	mov.f64 	%fd182, 0d3FF0000000000000;
	fma.rn.f64 	%fd183, %fd181, %fd173, %fd182;
	fma.rn.f64 	%fd184, %fd183, %fd183, %fd183;
	fma.rn.f64 	%fd185, %fd184, %fd173, %fd173;
	mul.f64 	%fd186, %fd180, %fd185;
	mov.f64 	%fd187, 0dC000000000000000;
	fma.rn.f64 	%fd188, %fd187, %fd186, %fd180;
	neg.f64 	%fd189, %fd186;
	fma.rn.f64 	%fd190, %fd189, %fd180, %fd188;
	fma.rn.f64 	%fd191, %fd190, %fd185, %fd186;
	mul.f64 	%fd192, %fd191, %fd191;
	mov.f64 	%fd193, 0d3FA55CF59CDC5D89;
	mov.f64 	%fd194, 0d3FB5C5C218C775C9;
	fma.rn.f64 	%fd195, %fd194, %fd192, %fd193;
	mov.f64 	%fd196, 0d3FAEFD18CF6EBB9C;
	fma.rn.f64 	%fd197, %fd195, %fd192, %fd196;
	mov.f64 	%fd198, 0d3FB10682EDCB8D1B;
	fma.rn.f64 	%fd199, %fd197, %fd192, %fd198;
	mov.f64 	%fd200, 0d3FB3B1DD3AC7FC96;
	fma.rn.f64 	%fd201, %fd199, %fd192, %fd200;
	mov.f64 	%fd202, 0d3FB745CB459B54A6;
	fma.rn.f64 	%fd203, %fd201, %fd192, %fd202;
	mov.f64 	%fd204, 0d3FBC71C741A0669F;
	fma.rn.f64 	%fd205, %fd203, %fd192, %fd204;
	mov.f64 	%fd206, 0d3FC249249209112E;
	fma.rn.f64 	%fd207, %fd205, %fd192, %fd206;
	mov.f64 	%fd208, 0d3FC99999999A06C1;
	fma.rn.f64 	%fd209, %fd207, %fd192, %fd208;
	mov.f64 	%fd210, 0d3FD5555555555535;
	fma.rn.f64 	%fd211, %fd209, %fd192, %fd210;
	mul.f64 	%fd212, %fd192, %fd211;
	fma.rn.f64 	%fd213, %fd212, %fd191, %fd191;
	add.f64 	%fd214, %fd213, %fd213;
	mov.f64 	%fd215, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd216, %fd178, %fd215, %fd214;
	mov.f64 	%fd217, 0dC009000000000000;
	sub.f64 	%fd218, %fd217, %fd216;
	mov.f64 	%fd219, 0dBC08DDF93324D327;
	mov.f64 	%fd220, 0dBBB135D2E746E627;
	fma.rn.f64 	%fd221, %fd220, %fd218, %fd219;
	mov.f64 	%fd222, 0d3C37B83EEF0B7C9F;
	fma.rn.f64 	%fd223, %fd221, %fd218, %fd222;
	mov.f64 	%fd224, 0d3C69BA72CD589B91;
	fma.rn.f64 	%fd225, %fd223, %fd218, %fd224;
	mov.f64 	%fd226, 0dBCA33689090A6B96;
	fma.rn.f64 	%fd227, %fd225, %fd218, %fd226;
	mov.f64 	%fd228, 0d3C782E11898132E0;
	fma.rn.f64 	%fd229, %fd227, %fd218, %fd228;
	mov.f64 	%fd230, 0d3CFDE4ACFD9E26BA;
	fma.rn.f64 	%fd231, %fd229, %fd218, %fd230;
	mov.f64 	%fd232, 0dBD26D33EED66C487;
	fma.rn.f64 	%fd233, %fd231, %fd218, %fd232;
	mov.f64 	%fd234, 0dBD36F2167040D8E2;
	fma.rn.f64 	%fd235, %fd233, %fd218, %fd234;
	mov.f64 	%fd236, 0d3D872A22C2D77E20;
	fma.rn.f64 	%fd237, %fd235, %fd218, %fd236;
	mov.f64 	%fd238, 0dBDAC8859C4E5C0AF;
	fma.rn.f64 	%fd239, %fd237, %fd218, %fd238;
	mov.f64 	%fd240, 0dBDCDC583D118A561;
	fma.rn.f64 	%fd241, %fd239, %fd218, %fd240;
	mov.f64 	%fd242, 0d3E120F47CCF46B3C;
	fma.rn.f64 	%fd243, %fd241, %fd218, %fd242;
	mov.f64 	%fd244, 0dBE31A9E38DC84D60;
	fma.rn.f64 	%fd245, %fd243, %fd218, %fd244;
	mov.f64 	%fd246, 0dBE5F36CD6D3D46A9;
	fma.rn.f64 	%fd247, %fd245, %fd218, %fd246;
	mov.f64 	%fd248, 0d3E9C6B4F5D03B787;
	fma.rn.f64 	%fd249, %fd247, %fd218, %fd248;
	mov.f64 	%fd250, 0dBEB6E8A5434AE8A2;
	fma.rn.f64 	%fd251, %fd249, %fd218, %fd250;
	mov.f64 	%fd252, 0dBEED1D1F7B8736F6;
	fma.rn.f64 	%fd253, %fd251, %fd218, %fd252;
	mov.f64 	%fd254, 0d3F2879C2A212F024;
	fma.rn.f64 	%fd255, %fd253, %fd218, %fd254;
	mov.f64 	%fd256, 0dBF4845769484FCA8;
	fma.rn.f64 	%fd257, %fd255, %fd218, %fd256;
	mov.f64 	%fd258, 0dBF78B6C33114F909;
	fma.rn.f64 	%fd259, %fd257, %fd218, %fd258;
	mov.f64 	%fd260, 0d3FCEBD80D9B13E28;
	fma.rn.f64 	%fd261, %fd259, %fd218, %fd260;
	mov.f64 	%fd262, 0d3FFA755E7C99AE86;
	fma.rn.f64 	%fd263, %fd261, %fd218, %fd262;
	fma.rn.f64 	%fd273, %fd263, %fd2, %fd263;
	bra.uni 	BB41_17;

BB41_5:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd1;
	}
	setp.gt.s32	%p6, %r8, 1072693247;
	selp.f64	%fd269, %fd3, %fd1, %p6;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r74}, %fd269;
	}
	mov.b32 	 %f1, %r74;
	setp.ltu.f32	%p7, %f1, 0f2B2BFF2F;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r75, %temp}, %fd269;
	}
	@%p7 bra 	BB41_7;
	bra.uni 	BB41_6;

BB41_7:
	mov.u32 	%r76, -1023;
	setp.gt.s32	%p8, %r74, 1048575;
	@%p8 bra 	BB41_9;

	mul.f64 	%fd269, %fd269, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r74}, %fd269;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r75, %temp}, %fd269;
	}
	mov.u32 	%r76, -1077;

BB41_9:
	add.s32 	%r42, %r74, -1;
	setp.lt.u32	%p9, %r42, 2146435071;
	@%p9 bra 	BB41_11;
	bra.uni 	BB41_10;

BB41_11:
	shr.u32 	%r44, %r74, 20;
	add.s32 	%r77, %r76, %r44;
	and.b32  	%r45, %r74, -2146435073;
	or.b32  	%r46, %r45, 1072693248;
	mov.b64 	%fd270, {%r75, %r46};
	setp.lt.s32	%p11, %r46, 1073127583;
	@%p11 bra 	BB41_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd270;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r48}, %fd270;
	}
	add.s32 	%r49, %r48, -1048576;
	mov.b64 	%fd270, {%r47, %r49};
	add.s32 	%r77, %r77, 1;

BB41_13:
	add.f64 	%fd108, %fd270, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd107,%fd108;
	// inline asm
	neg.f64 	%fd109, %fd108;
	mov.f64 	%fd110, 0d3FF0000000000000;
	fma.rn.f64 	%fd111, %fd109, %fd107, %fd110;
	fma.rn.f64 	%fd112, %fd111, %fd111, %fd111;
	fma.rn.f64 	%fd113, %fd112, %fd107, %fd107;
	add.f64 	%fd114, %fd270, 0dBFF0000000000000;
	mul.f64 	%fd115, %fd114, %fd113;
	fma.rn.f64 	%fd116, %fd114, %fd113, %fd115;
	mul.f64 	%fd117, %fd116, %fd116;
	mov.f64 	%fd118, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd119, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd120, %fd119, %fd117, %fd118;
	mov.f64 	%fd121, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd122, %fd120, %fd117, %fd121;
	mov.f64 	%fd123, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd124, %fd122, %fd117, %fd123;
	mov.f64 	%fd125, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd126, %fd124, %fd117, %fd125;
	mov.f64 	%fd127, 0d3F624924923BE72D;
	fma.rn.f64 	%fd128, %fd126, %fd117, %fd127;
	mov.f64 	%fd129, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd130, %fd128, %fd117, %fd129;
	mov.f64 	%fd131, 0d3FB5555555555554;
	fma.rn.f64 	%fd132, %fd130, %fd117, %fd131;
	sub.f64 	%fd133, %fd114, %fd116;
	add.f64 	%fd134, %fd133, %fd133;
	neg.f64 	%fd135, %fd116;
	fma.rn.f64 	%fd136, %fd135, %fd114, %fd134;
	mul.f64 	%fd137, %fd113, %fd136;
	mul.f64 	%fd138, %fd117, %fd132;
	fma.rn.f64 	%fd139, %fd138, %fd116, %fd137;
	xor.b32  	%r50, %r77, -2147483648;
	mov.u32 	%r51, 1127219200;
	mov.b64 	%fd140, {%r50, %r51};
	mov.u32 	%r52, -2147483648;
	mov.b64 	%fd141, {%r52, %r51};
	sub.f64 	%fd142, %fd140, %fd141;
	mov.f64 	%fd143, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd144, %fd142, %fd143, %fd116;
	neg.f64 	%fd145, %fd142;
	fma.rn.f64 	%fd146, %fd145, %fd143, %fd144;
	sub.f64 	%fd147, %fd146, %fd116;
	sub.f64 	%fd148, %fd139, %fd147;
	mov.f64 	%fd149, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd150, %fd142, %fd149, %fd148;
	add.f64 	%fd271, %fd144, %fd150;
	bra.uni 	BB41_14;

BB41_6:
	shr.u32 	%r33, %r74, 20;
	and.b32  	%r34, %r33, 2046;
	add.s32 	%r35, %r34, 2147482626;
	mov.u32 	%r36, 1127219200;
	mov.b64 	%fd25, {%r35, %r36};
	mov.u32 	%r37, -2147483648;
	mov.b64 	%fd26, {%r37, %r36};
	sub.f64 	%fd27, %fd25, %fd26;
	and.b32  	%r38, %r74, -2145386497;
	add.s32 	%r39, %r38, 1071644672;
	mov.b64 	%fd28, {%r75, %r39};
	add.f64 	%fd29, %fd28, 0dBFF0000000000000;
	add.f64 	%fd22, %fd28, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd21,%fd22;
	// inline asm
	neg.f64 	%fd30, %fd22;
	mov.f64 	%fd31, 0d3FF0000000000000;
	fma.rn.f64 	%fd32, %fd30, %fd21, %fd31;
	fma.rn.f64 	%fd33, %fd32, %fd32, %fd32;
	fma.rn.f64 	%fd34, %fd33, %fd21, %fd21;
	mul.f64 	%fd35, %fd29, %fd34;
	mov.f64 	%fd36, 0dC000000000000000;
	fma.rn.f64 	%fd37, %fd36, %fd35, %fd29;
	neg.f64 	%fd38, %fd35;
	fma.rn.f64 	%fd39, %fd38, %fd29, %fd37;
	fma.rn.f64 	%fd40, %fd39, %fd34, %fd35;
	mul.f64 	%fd41, %fd40, %fd40;
	mov.f64 	%fd42, 0d3FA55CF59CDC5D89;
	mov.f64 	%fd43, 0d3FB5C5C218C775C9;
	fma.rn.f64 	%fd44, %fd43, %fd41, %fd42;
	mov.f64 	%fd45, 0d3FAEFD18CF6EBB9C;
	fma.rn.f64 	%fd46, %fd44, %fd41, %fd45;
	mov.f64 	%fd47, 0d3FB10682EDCB8D1B;
	fma.rn.f64 	%fd48, %fd46, %fd41, %fd47;
	mov.f64 	%fd49, 0d3FB3B1DD3AC7FC96;
	fma.rn.f64 	%fd50, %fd48, %fd41, %fd49;
	mov.f64 	%fd51, 0d3FB745CB459B54A6;
	fma.rn.f64 	%fd52, %fd50, %fd41, %fd51;
	mov.f64 	%fd53, 0d3FBC71C741A0669F;
	fma.rn.f64 	%fd54, %fd52, %fd41, %fd53;
	mov.f64 	%fd55, 0d3FC249249209112E;
	fma.rn.f64 	%fd56, %fd54, %fd41, %fd55;
	mov.f64 	%fd57, 0d3FC99999999A06C1;
	fma.rn.f64 	%fd58, %fd56, %fd41, %fd57;
	mov.f64 	%fd59, 0d3FD5555555555535;
	fma.rn.f64 	%fd60, %fd58, %fd41, %fd59;
	mul.f64 	%fd61, %fd41, %fd60;
	fma.rn.f64 	%fd62, %fd61, %fd40, %fd40;
	add.f64 	%fd63, %fd62, %fd62;
	mov.f64 	%fd64, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd65, %fd27, %fd64, %fd63;
	neg.f64 	%fd24, %fd65;
	// inline asm
	rsqrt.approx.ftz.f64 %fd23, %fd24;
	// inline asm
	mul.rn.f64 	%fd66, %fd23, %fd23;
	neg.f64 	%fd67, %fd66;
	fma.rn.f64 	%fd68, %fd24, %fd67, %fd31;
	mov.f64 	%fd69, 0d3FE0000000000000;
	mov.f64 	%fd70, 0d3FD8000000000000;
	fma.rn.f64 	%fd71, %fd70, %fd68, %fd69;
	mul.rn.f64 	%fd72, %fd68, %fd23;
	fma.rn.f64 	%fd73, %fd71, %fd72, %fd23;
	mov.f64 	%fd74, 0d4000A0E7333839AA;
	mov.f64 	%fd75, 0d3FEBE9222591AFAB;
	fma.rn.f64 	%fd76, %fd75, %fd73, %fd74;
	mov.f64 	%fd77, 0d4008768CF7E57D5C;
	fma.rn.f64 	%fd78, %fd76, %fd73, %fd77;
	mov.f64 	%fd79, 0d400B77E7E28DA583;
	fma.rn.f64 	%fd80, %fd78, %fd73, %fd79;
	mov.f64 	%fd81, 0d3FF34F26A4F99CF9;
	fma.rn.f64 	%fd82, %fd80, %fd73, %fd81;
	mov.f64 	%fd83, 0d3FC1F674ADB019ED;
	fma.rn.f64 	%fd84, %fd82, %fd73, %fd83;
	mov.f64 	%fd85, 0d3F75DDAE9506431D;
	fma.rn.f64 	%fd86, %fd84, %fd73, %fd85;
	mov.f64 	%fd87, 0d3F0ADA49AA32489C;
	fma.rn.f64 	%fd88, %fd86, %fd73, %fd87;
	add.f64 	%fd89, %fd73, 0d4001E90FF51C2197;
	mov.f64 	%fd90, 0d40111EA3A7CF3820;
	fma.rn.f64 	%fd91, %fd89, %fd73, %fd90;
	mov.f64 	%fd92, 0d4011A0E4A4749594;
	fma.rn.f64 	%fd93, %fd91, %fd73, %fd92;
	mov.f64 	%fd94, 0d400D4E977D38C14D;
	fma.rn.f64 	%fd95, %fd93, %fd73, %fd94;
	mov.f64 	%fd96, 0d3FF37FD567EC0D5F;
	fma.rn.f64 	%fd97, %fd95, %fd73, %fd96;
	mov.f64 	%fd98, 0d3FC1FB9D7F676033;
	fma.rn.f64 	%fd99, %fd97, %fd73, %fd98;
	mov.f64 	%fd100, 0d3F75DDCDF98946E4;
	fma.rn.f64 	%fd101, %fd99, %fd73, %fd100;
	mov.f64 	%fd102, 0d3F0ADA42D79D8DBB;
	fma.rn.f64 	%fd103, %fd101, %fd73, %fd102;
	mul.f64 	%fd104, %fd73, %fd103;
	div.rn.f64 	%fd272, %fd88, %fd104;
	bra.uni 	BB41_15;

BB41_10:
	mov.f64 	%fd105, 0d7FF0000000000000;
	fma.rn.f64 	%fd106, %fd269, %fd105, %fd105;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd269;
	}
	mov.b32 	 %f2, %r43;
	setp.eq.f32	%p10, %f2, 0f00000000;
	selp.f64	%fd271, 0dFFF0000000000000, %fd106, %p10;

BB41_14:
	neg.f64 	%fd151, %fd271;
	rsqrt.approx.f64 	%fd152, %fd151;
	mov.f64 	%fd153, 0d3FFA2013964E259C;
	mov.f64 	%fd154, 0d3FE8E2101C71B0BF;
	fma.rn.f64 	%fd155, %fd154, %fd152, %fd153;
	mov.f64 	%fd156, 0d3FDABFE90921BE68;
	fma.rn.f64 	%fd157, %fd155, %fd152, %fd156;
	mov.f64 	%fd158, 0d3F97E41314DE00D4;
	fma.rn.f64 	%fd159, %fd157, %fd152, %fd158;
	mov.f64 	%fd160, 0d3F311BD487102E94;
	fma.rn.f64 	%fd161, %fd159, %fd152, %fd160;
	add.f64 	%fd162, %fd152, 0d3FF59895C30BAA54;
	mov.f64 	%fd163, 0d3FFAE8E5956A143F;
	fma.rn.f64 	%fd164, %fd162, %fd152, %fd163;
	mov.f64 	%fd165, 0d3FDACCE85FF7383D;
	fma.rn.f64 	%fd166, %fd164, %fd152, %fd165;
	mov.f64 	%fd167, 0d3F97E43B6CAC34FE;
	fma.rn.f64 	%fd168, %fd166, %fd152, %fd167;
	mov.f64 	%fd169, 0d3F311BD08289EB12;
	fma.rn.f64 	%fd170, %fd168, %fd152, %fd169;
	mul.f64 	%fd171, %fd152, %fd170;
	div.rn.f64 	%fd272, %fd161, %fd171;

BB41_15:
	neg.f64 	%fd172, %fd272;
	selp.f64	%fd273, %fd172, %fd272, %p6;

BB41_17:
	ld.param.u32 	%r66, [map_normcdfinv_double_param_3];
	mul.lo.s32 	%r65, %r72, %r66;
	mul.f64 	%fd264, %fd273, 0dBCA21165F626CDD5;
	mov.f64 	%fd265, 0dBFF6A09E667F3BCC;
	fma.rn.f64 	%fd266, %fd265, %fd273, %fd264;
	mov.f64 	%fd267, 0d0000000000000000;
	add.rn.f64 	%fd268, %fd266, %fd267;
	add.s32 	%r62, %r7, %r65;
	mul.wide.s32 	%rd7, %r62, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd268;
	add.s32 	%r19, %r3, %r7;
	setp.lt.s32	%p13, %r19, %r21;
	mov.u32 	%r73, %r19;
	@%p13 bra 	BB41_4;

BB41_18:
	ld.param.u32 	%r68, [map_normcdfinv_double_param_1];
	mov.u32 	%r67, %ntid.x;
	mov.u32 	%r63, %nctaid.x;
	mad.lo.s32 	%r72, %r63, %r67, %r72;
	setp.lt.s32	%p14, %r72, %r68;
	@%p14 bra 	BB41_2;

BB41_19:
	ret;
}

	// .globl	map_rcbrt_double
.visible .entry map_rcbrt_double(
	.param .u32 map_rcbrt_double_param_0,
	.param .u32 map_rcbrt_double_param_1,
	.param .u64 map_rcbrt_double_param_2,
	.param .u32 map_rcbrt_double_param_3,
	.param .u64 map_rcbrt_double_param_4,
	.param .u32 map_rcbrt_double_param_5
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<7>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<31>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r21, [map_rcbrt_double_param_0];
	ld.param.u32 	%r22, [map_rcbrt_double_param_1];
	ld.param.u64 	%rd1, [map_rcbrt_double_param_2];
	ld.param.u32 	%r23, [map_rcbrt_double_param_3];
	ld.param.u64 	%rd2, [map_rcbrt_double_param_4];
	ld.param.u32 	%r24, [map_rcbrt_double_param_5];
	mov.u32 	%r25, %tid.x;
	mov.u32 	%r26, %ntid.x;
	mov.u32 	%r27, %ctaid.x;
	mad.lo.s32 	%r51, %r26, %r27, %r25;
	setp.ge.s32	%p1, %r51, %r22;
	@%p1 bra 	BB42_11;

	mov.u32 	%r28, %tid.y;
	mov.u32 	%r29, %ntid.y;
	mov.u32 	%r30, %ctaid.y;
	mad.lo.s32 	%r2, %r29, %r30, %r28;
	mov.u32 	%r31, %nctaid.y;
	mul.lo.s32 	%r3, %r31, %r29;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd6, %rd1;

BB42_2:
	setp.ge.s32	%p2, %r2, %r21;
	@%p2 bra 	BB42_10;

	mul.lo.s32 	%r5, %r51, %r24;
	mul.lo.s32 	%r6, %r51, %r23;
	mov.u32 	%r52, %r2;

BB42_4:
	mov.u32 	%r7, %r52;
	add.s32 	%r32, %r7, %r5;
	mul.wide.s32 	%rd4, %r32, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%r53, %temp}, %fd1;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd1;
	}
	and.b32  	%r54, %r9, 2147483647;
	setp.neu.f64	%p3, %fd1, 0d0000000000000000;
	setp.lt.u32	%p4, %r54, 2146435072;
	and.pred  	%p5, %p3, %p4;
	@%p5 bra 	BB42_6;
	bra.uni 	BB42_5;

BB42_6:
	shr.u32 	%r55, %r54, 20;
	mov.u32 	%r56, 0;
	setp.ne.s32	%p7, %r55, 0;
	@%p7 bra 	BB42_8;

	mov.b64 	%fd8, {%r53, %r54};
	mul.f64 	%fd9, %fd8, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r53, %temp}, %fd9;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r54}, %fd9;
	}
	shr.u32 	%r55, %r54, 20;
	mov.u32 	%r56, 18;

BB42_8:
	add.s32 	%r36, %r55, -1022;
	cvt.rn.f32.s32	%f5, %r36;
	mul.f32 	%f6, %f5, 0f3EAAAAAB;
	cvt.rni.s32.f32	%r37, %f6;
	mad.lo.s32 	%r38, %r37, -3145728, %r54;
	mov.b64 	%fd10, {%r53, %r38};
	cvt.rn.f32.f64	%f2, %fd10;
	// inline asm
	lg2.approx.ftz.f32 %f1,%f2;
	// inline asm
	mul.f32 	%f4, %f1, 0fBEAAAAAB;
	// inline asm
	ex2.approx.ftz.f32 %f3,%f4;
	// inline asm
	cvt.f64.f32	%fd11, %f3;
	mul.rn.f64 	%fd12, %fd11, %fd11;
	mul.rn.f64 	%fd13, %fd10, %fd11;
	neg.f64 	%fd14, %fd13;
	mov.f64 	%fd15, 0d3FF0000000000000;
	fma.rn.f64 	%fd16, %fd12, %fd14, %fd15;
	fma.rn.f64 	%fd17, %fd10, %fd11, %fd14;
	neg.f64 	%fd18, %fd17;
	fma.rn.f64 	%fd19, %fd12, %fd18, %fd16;
	neg.f64 	%fd20, %fd12;
	fma.rn.f64 	%fd21, %fd11, %fd11, %fd20;
	neg.f64 	%fd22, %fd21;
	fma.rn.f64 	%fd23, %fd13, %fd22, %fd19;
	mov.f64 	%fd24, 0d3FD5555555555555;
	mov.f64 	%fd25, 0d3FCC71C71C71C71C;
	fma.rn.f64 	%fd26, %fd25, %fd23, %fd24;
	mul.rn.f64 	%fd27, %fd23, %fd11;
	fma.rn.f64 	%fd28, %fd26, %fd27, %fd11;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r39, %temp}, %fd28;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r40}, %fd28;
	}
	sub.s32 	%r41, %r56, %r37;
	shl.b32 	%r42, %r41, 20;
	add.s32 	%r43, %r40, %r42;
	mov.b64 	%fd30, {%r39, %r43};
	bra.uni 	BB42_9;

BB42_5:
	xor.b32  	%r33, %r54, 2146435072;
	mov.b64 	%fd5, {%r53, %r33};
	abs.f64 	%fd6, %fd1;
	setp.gtu.f64	%p6, %fd6, 0d7FF0000000000000;
	add.f64 	%fd7, %fd1, %fd1;
	selp.f64	%fd30, %fd7, %fd5, %p6;

BB42_9:
	and.b32  	%r44, %r9, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r45}, %fd30;
	}
	or.b32  	%r46, %r45, %r44;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd30;
	}
	mov.b64 	%fd29, {%r47, %r46};
	add.s32 	%r48, %r7, %r6;
	mul.wide.s32 	%rd7, %r48, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd29;
	add.s32 	%r19, %r3, %r7;
	setp.lt.s32	%p8, %r19, %r21;
	mov.u32 	%r52, %r19;
	@%p8 bra 	BB42_4;

BB42_10:
	mov.u32 	%r49, %nctaid.x;
	mad.lo.s32 	%r51, %r49, %r26, %r51;
	setp.lt.s32	%p9, %r51, %r22;
	@%p9 bra 	BB42_2;

BB42_11:
	ret;
}

	// .globl	map_rint_double
.visible .entry map_rint_double(
	.param .u32 map_rint_double_param_0,
	.param .u32 map_rint_double_param_1,
	.param .u64 map_rint_double_param_2,
	.param .u32 map_rint_double_param_3,
	.param .u64 map_rint_double_param_4,
	.param .u32 map_rint_double_param_5
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map_rint_double_param_0];
	ld.param.u32 	%r13, [map_rint_double_param_1];
	ld.param.u64 	%rd3, [map_rint_double_param_2];
	ld.param.u32 	%r14, [map_rint_double_param_3];
	ld.param.u64 	%rd4, [map_rint_double_param_4];
	ld.param.u32 	%r15, [map_rint_double_param_5];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB43_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB43_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB43_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB43_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	cvt.rni.f64.f64	%fd2, %fd1;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd2;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB43_4;

BB43_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB43_2;

BB43_6:
	ret;
}

	// .globl	map_round_double
.visible .entry map_round_double(
	.param .u32 map_round_double_param_0,
	.param .u32 map_round_double_param_1,
	.param .u64 map_round_double_param_2,
	.param .u32 map_round_double_param_3,
	.param .u64 map_round_double_param_4,
	.param .u32 map_round_double_param_5
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<32>;
	.reg .f64 	%fd<9>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r10, [map_round_double_param_0];
	ld.param.u32 	%r11, [map_round_double_param_1];
	ld.param.u64 	%rd3, [map_round_double_param_2];
	ld.param.u32 	%r12, [map_round_double_param_3];
	ld.param.u64 	%rd4, [map_round_double_param_4];
	ld.param.u32 	%r13, [map_round_double_param_5];
	mov.u32 	%r14, %ntid.x;
	mov.u32 	%r15, %ctaid.x;
	mov.u32 	%r16, %tid.x;
	mad.lo.s32 	%r30, %r14, %r15, %r16;
	setp.ge.s32	%p1, %r30, %r11;
	@%p1 bra 	BB44_8;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r17, %tid.y;
	mov.u32 	%r18, %ntid.y;
	mov.u32 	%r19, %ctaid.y;
	mad.lo.s32 	%r2, %r18, %r19, %r17;
	mov.u32 	%r20, %nctaid.y;
	mul.lo.s32 	%r3, %r20, %r18;

BB44_2:
	setp.ge.s32	%p2, %r2, %r10;
	@%p2 bra 	BB44_7;

	mul.lo.s32 	%r5, %r30, %r13;
	mul.lo.s32 	%r6, %r30, %r12;
	mov.u32 	%r31, %r2;

BB44_4:
	mov.u32 	%r7, %r31;
	add.s32 	%r21, %r7, %r5;
	mul.wide.s32 	%rd5, %r21, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd8, [%rd6];
	abs.f64 	%fd2, %fd8;
	setp.ge.f64	%p3, %fd2, 0d4330000000000000;
	@%p3 bra 	BB44_6;

	add.f64 	%fd5, %fd2, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd6, %fd5;
	setp.lt.f64	%p4, %fd2, 0d3FE0000000000000;
	selp.f64	%fd7, 0d0000000000000000, %fd6, %p4;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd7;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd7;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r24}, %fd8;
	}
	and.b32  	%r25, %r24, -2147483648;
	or.b32  	%r26, %r23, %r25;
	mov.b64 	%fd8, {%r22, %r26};

BB44_6:
	add.s32 	%r27, %r7, %r6;
	mul.wide.s32 	%rd7, %r27, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd8;
	add.s32 	%r8, %r3, %r7;
	setp.lt.s32	%p5, %r8, %r10;
	mov.u32 	%r31, %r8;
	@%p5 bra 	BB44_4;

BB44_7:
	mov.u32 	%r28, %nctaid.x;
	mad.lo.s32 	%r30, %r28, %r14, %r30;
	setp.lt.s32	%p6, %r30, %r11;
	@%p6 bra 	BB44_2;

BB44_8:
	ret;
}

	// .globl	map_rsqrt_double
.visible .entry map_rsqrt_double(
	.param .u32 map_rsqrt_double_param_0,
	.param .u32 map_rsqrt_double_param_1,
	.param .u64 map_rsqrt_double_param_2,
	.param .u32 map_rsqrt_double_param_3,
	.param .u64 map_rsqrt_double_param_4,
	.param .u32 map_rsqrt_double_param_5
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map_rsqrt_double_param_0];
	ld.param.u32 	%r13, [map_rsqrt_double_param_1];
	ld.param.u64 	%rd3, [map_rsqrt_double_param_2];
	ld.param.u32 	%r14, [map_rsqrt_double_param_3];
	ld.param.u64 	%rd4, [map_rsqrt_double_param_4];
	ld.param.u32 	%r15, [map_rsqrt_double_param_5];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB45_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB45_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB45_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB45_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	rsqrt.approx.f64 	%fd2, %fd1;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd2;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB45_4;

BB45_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB45_2;

BB45_6:
	ret;
}

	// .globl	map_sin_double
.visible .entry map_sin_double(
	.param .u32 map_sin_double_param_0,
	.param .u32 map_sin_double_param_1,
	.param .u64 map_sin_double_param_2,
	.param .u32 map_sin_double_param_3,
	.param .u64 map_sin_double_param_4,
	.param .u32 map_sin_double_param_5
)
{
	.local .align 4 .b8 	__local_depot46[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<41>;
	.reg .b64 	%rd<17>;


	mov.u64 	%rd16, __local_depot46;
	cvta.local.u64 	%SP, %rd16;
	ld.param.u32 	%r13, [map_sin_double_param_0];
	ld.param.u32 	%r14, [map_sin_double_param_1];
	ld.param.u64 	%rd1, [map_sin_double_param_2];
	ld.param.u32 	%r15, [map_sin_double_param_3];
	ld.param.u64 	%rd2, [map_sin_double_param_4];
	ld.param.u32 	%r16, [map_sin_double_param_5];
	mov.u32 	%r17, %ntid.x;
	mov.u32 	%r18, %ctaid.x;
	mov.u32 	%r19, %tid.x;
	mad.lo.s32 	%r41, %r17, %r18, %r19;
	setp.ge.s32	%p1, %r41, %r14;
	@%p1 bra 	BB46_15;

	mov.u32 	%r20, %ntid.y;
	mov.u32 	%r21, %nctaid.y;
	mul.lo.s32 	%r2, %r21, %r20;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd13, %rd1;

BB46_2:
	mov.u32 	%r22, %ctaid.y;
	mov.u32 	%r24, %tid.y;
	mad.lo.s32 	%r42, %r20, %r22, %r24;
	setp.ge.s32	%p2, %r42, %r13;
	@%p2 bra 	BB46_14;

	mul.lo.s32 	%r4, %r41, %r16;
	mul.lo.s32 	%r5, %r41, %r15;

BB46_4:
	add.s32 	%r29, %r42, %r4;
	mul.wide.s32 	%rd4, %r29, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd38, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r30}, %fd38;
	}
	and.b32  	%r31, %r30, 2147483647;
	setp.ne.s32	%p3, %r31, 2146435072;
	@%p3 bra 	BB46_7;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r32, %temp}, %fd38;
	}
	setp.ne.s32	%p4, %r32, 0;
	@%p4 bra 	BB46_7;

	mov.f64 	%fd14, 0d0000000000000000;
	mul.rn.f64 	%fd38, %fd38, %fd14;

BB46_7:
	mul.f64 	%fd15, %fd38, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r43, %fd15;
	add.u64 	%rd6, %SP, 0;
	cvta.to.local.u64 	%rd7, %rd6;
	st.local.u32 	[%rd7], %r43;
	cvt.rn.f64.s32	%fd16, %r43;
	neg.f64 	%fd17, %fd16;
	mov.f64 	%fd18, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd19, %fd17, %fd18, %fd38;
	mov.f64 	%fd20, 0d3C91A62633145C00;
	fma.rn.f64 	%fd21, %fd17, %fd20, %fd19;
	mov.f64 	%fd22, 0d397B839A252049C0;
	fma.rn.f64 	%fd39, %fd17, %fd22, %fd21;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd38;
	}
	and.b32  	%r34, %r33, 2145386496;
	setp.lt.u32	%p5, %r34, 1105199104;
	@%p5 bra 	BB46_9;

	// Callseq Start 8
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd38;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd6;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd39, [retval0+0];
	
	//{
	}// Callseq End 8
	ld.local.u32 	%r43, [%rd7];

BB46_9:
	and.b32  	%r35, %r43, 1;
	shl.b32 	%r36, %r35, 3;
	setp.eq.s32	%p6, %r35, 0;
	selp.f64	%fd23, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p6;
	mul.wide.u32 	%rd10, %r36, 8;
	mov.u64 	%rd11, __cudart_sin_cos_coeffs;
	add.s64 	%rd12, %rd10, %rd11;
	ld.const.f64 	%fd24, [%rd12+8];
	mul.rn.f64 	%fd7, %fd39, %fd39;
	fma.rn.f64 	%fd25, %fd23, %fd7, %fd24;
	ld.const.f64 	%fd26, [%rd12+16];
	fma.rn.f64 	%fd27, %fd25, %fd7, %fd26;
	ld.const.f64 	%fd28, [%rd12+24];
	fma.rn.f64 	%fd29, %fd27, %fd7, %fd28;
	ld.const.f64 	%fd30, [%rd12+32];
	fma.rn.f64 	%fd31, %fd29, %fd7, %fd30;
	ld.const.f64 	%fd32, [%rd12+40];
	fma.rn.f64 	%fd33, %fd31, %fd7, %fd32;
	ld.const.f64 	%fd34, [%rd12+48];
	fma.rn.f64 	%fd8, %fd33, %fd7, %fd34;
	fma.rn.f64 	%fd40, %fd8, %fd39, %fd39;
	@%p6 bra 	BB46_11;

	mov.f64 	%fd35, 0d3FF0000000000000;
	fma.rn.f64 	%fd40, %fd8, %fd7, %fd35;

BB46_11:
	and.b32  	%r37, %r43, 2;
	setp.eq.s32	%p7, %r37, 0;
	@%p7 bra 	BB46_13;

	mov.f64 	%fd36, 0d0000000000000000;
	mov.f64 	%fd37, 0dBFF0000000000000;
	fma.rn.f64 	%fd40, %fd40, %fd37, %fd36;

BB46_13:
	add.s32 	%r38, %r42, %r5;
	mul.wide.s32 	%rd14, %r38, 8;
	add.s64 	%rd15, %rd13, %rd14;
	st.global.f64 	[%rd15], %fd40;
	add.s32 	%r42, %r2, %r42;
	setp.lt.s32	%p8, %r42, %r13;
	@%p8 bra 	BB46_4;

BB46_14:
	mov.u32 	%r39, %nctaid.x;
	mad.lo.s32 	%r41, %r39, %r17, %r41;
	setp.lt.s32	%p9, %r41, %r14;
	@%p9 bra 	BB46_2;

BB46_15:
	ret;
}

	// .globl	map_sinh_double
.visible .entry map_sinh_double(
	.param .u32 map_sinh_double_param_0,
	.param .u32 map_sinh_double_param_1,
	.param .u64 map_sinh_double_param_2,
	.param .u32 map_sinh_double_param_3,
	.param .u64 map_sinh_double_param_4,
	.param .u32 map_sinh_double_param_5
)
{
	.reg .pred 	%p<10>;
	.reg .b32 	%r<47>;
	.reg .f64 	%fd<68>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r11, [map_sinh_double_param_0];
	ld.param.u32 	%r12, [map_sinh_double_param_1];
	ld.param.u64 	%rd3, [map_sinh_double_param_2];
	ld.param.u64 	%rd4, [map_sinh_double_param_4];
	mov.u32 	%r15, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r45, %r15, %r16, %r17;
	setp.ge.s32	%p1, %r45, %r12;
	@%p1 bra 	BB47_9;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r2, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.y;
	mul.lo.s32 	%r3, %r21, %r19;

BB47_2:
	setp.ge.s32	%p2, %r2, %r11;
	@%p2 bra 	BB47_8;

	ld.param.u32 	%r44, [map_sinh_double_param_3];
	ld.param.u32 	%r43, [map_sinh_double_param_5];
	mul.lo.s32 	%r5, %r45, %r43;
	mul.lo.s32 	%r6, %r45, %r44;
	mov.u32 	%r46, %r2;

BB47_4:
	mov.u32 	%r7, %r46;
	add.s32 	%r22, %r7, %r5;
	mul.wide.s32 	%rd5, %r22, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd5, [%rd6];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd5;
	}
	and.b32  	%r23, %r8, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r24, %temp}, %fd5;
	}
	mov.b64 	%fd1, {%r24, %r23};
	setp.lt.u32	%p3, %r23, 1072693248;
	@%p3 bra 	BB47_6;
	bra.uni 	BB47_5;

BB47_6:
	mul.f64 	%fd51, %fd1, %fd1;
	mov.f64 	%fd52, 0d3DE611A561D87DEF;
	mov.f64 	%fd53, 0d3D6B4C75AB274C53;
	fma.rn.f64 	%fd54, %fd53, %fd51, %fd52;
	mov.f64 	%fd55, 0d3E5AE64671B18F5C;
	fma.rn.f64 	%fd56, %fd54, %fd51, %fd55;
	mov.f64 	%fd57, 0d3EC71DE3A465B1E4;
	fma.rn.f64 	%fd58, %fd56, %fd51, %fd57;
	mov.f64 	%fd59, 0d3F2A01A01A02899D;
	fma.rn.f64 	%fd60, %fd58, %fd51, %fd59;
	mov.f64 	%fd61, 0d3F811111111110A6;
	fma.rn.f64 	%fd62, %fd60, %fd51, %fd61;
	mov.f64 	%fd63, 0d3FC5555555555556;
	fma.rn.f64 	%fd64, %fd62, %fd51, %fd63;
	mul.f64 	%fd65, %fd51, %fd64;
	fma.rn.f64 	%fd67, %fd65, %fd1, %fd1;
	bra.uni 	BB47_7;

BB47_5:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r25}, %fd1;
	}
	mov.f64 	%fd6, 0d4338000000000000;
	mov.f64 	%fd7, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd8, %fd1, %fd7, %fd6;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r26, %temp}, %fd8;
	}
	add.s32 	%r27, %r26, -1;
	mov.f64 	%fd9, 0dC338000000000000;
	add.rn.f64 	%fd10, %fd8, %fd9;
	mov.f64 	%fd11, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd12, %fd10, %fd11, %fd1;
	mov.f64 	%fd13, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd14, %fd10, %fd13, %fd12;
	add.s32 	%r28, %r25, %r25;
	setp.lt.u32	%p4, %r28, 2142496327;
	selp.b32	%r29, 0, %r27, %p4;
	selp.f64	%fd15, %fd1, %fd14, %p4;
	mov.f64 	%fd16, 0d3E5AF86D8EBD13CD;
	mov.f64 	%fd17, 0d3E21F4076ACD15B6;
	fma.rn.f64 	%fd18, %fd17, %fd15, %fd16;
	mov.f64 	%fd19, 0d3E927E5092BA033D;
	fma.rn.f64 	%fd20, %fd18, %fd15, %fd19;
	mov.f64 	%fd21, 0d3EC71DDE6C5F9DA1;
	fma.rn.f64 	%fd22, %fd20, %fd15, %fd21;
	mov.f64 	%fd23, 0d3EFA01A018D034E6;
	fma.rn.f64 	%fd24, %fd22, %fd15, %fd23;
	mov.f64 	%fd25, 0d3F2A01A01B3B6940;
	fma.rn.f64 	%fd26, %fd24, %fd15, %fd25;
	mov.f64 	%fd27, 0d3F56C16C16C1B5DD;
	fma.rn.f64 	%fd28, %fd26, %fd15, %fd27;
	mov.f64 	%fd29, 0d3F8111111110F74D;
	fma.rn.f64 	%fd30, %fd28, %fd15, %fd29;
	mov.f64 	%fd31, 0d3FA555555555554D;
	fma.rn.f64 	%fd32, %fd30, %fd15, %fd31;
	mov.f64 	%fd33, 0d3FC5555555555557;
	fma.rn.f64 	%fd34, %fd32, %fd15, %fd33;
	mov.f64 	%fd35, 0d3FE0000000000000;
	fma.rn.f64 	%fd36, %fd34, %fd15, %fd35;
	mul.f64 	%fd37, %fd15, %fd36;
	fma.rn.f64 	%fd38, %fd37, %fd15, %fd15;
	setp.eq.s32	%p5, %r29, 1024;
	selp.b32	%r30, -1, 0, %p5;
	add.s32 	%r31, %r30, %r29;
	shl.b32 	%r32, %r31, 20;
	add.s32 	%r33, %r32, 1072693248;
	mov.u32 	%r34, 0;
	mov.b64 	%fd39, {%r34, %r33};
	mov.u32 	%r35, 1071644672;
	mov.b64 	%fd40, {%r34, %r35};
	sub.f64 	%fd41, %fd39, %fd40;
	fma.rn.f64 	%fd42, %fd38, %fd39, %fd41;
	add.f64 	%fd43, %fd42, %fd42;
	selp.f64	%fd44, %fd43, %fd42, %p5;
	setp.eq.s32	%p6, %r28, 0;
	selp.f64	%fd45, %fd15, %fd44, %p6;
	mov.f64 	%fd46, 0d3FF0000000000000;
	mov.f64 	%fd47, 0d4000000000000000;
	fma.rn.f64 	%fd48, %fd47, %fd45, %fd46;
	div.rn.f64 	%fd49, %fd45, %fd48;
	add.f64 	%fd50, %fd49, %fd45;
	setp.ltu.f64	%p7, %fd1, 0d408633CE8FB9F87E;
	selp.f64	%fd67, %fd50, 0d7FF0000000000000, %p7;

BB47_7:
	and.b32  	%r36, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r37}, %fd67;
	}
	or.b32  	%r38, %r37, %r36;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r39, %temp}, %fd67;
	}
	mov.b64 	%fd66, {%r39, %r38};
	add.s32 	%r40, %r7, %r6;
	mul.wide.s32 	%rd7, %r40, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd66;
	add.s32 	%r9, %r3, %r7;
	setp.lt.s32	%p8, %r9, %r11;
	mov.u32 	%r46, %r9;
	@%p8 bra 	BB47_4;

BB47_8:
	mov.u32 	%r41, %nctaid.x;
	mad.lo.s32 	%r45, %r41, %r15, %r45;
	setp.lt.s32	%p9, %r45, %r12;
	@%p9 bra 	BB47_2;

BB47_9:
	ret;
}

	// .globl	map_sinpi_double
.visible .entry map_sinpi_double(
	.param .u32 map_sinpi_double_param_0,
	.param .u32 map_sinpi_double_param_1,
	.param .u64 map_sinpi_double_param_2,
	.param .u32 map_sinpi_double_param_3,
	.param .u64 map_sinpi_double_param_4,
	.param .u32 map_sinpi_double_param_5
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<36>;
	.reg .f64 	%fd<37>;
	.reg .b64 	%rd<14>;


	ld.param.u32 	%r10, [map_sinpi_double_param_0];
	ld.param.u32 	%r11, [map_sinpi_double_param_1];
	ld.param.u64 	%rd1, [map_sinpi_double_param_2];
	ld.param.u32 	%r12, [map_sinpi_double_param_3];
	ld.param.u64 	%rd2, [map_sinpi_double_param_4];
	ld.param.u32 	%r13, [map_sinpi_double_param_5];
	mov.u32 	%r14, %tid.x;
	mov.u32 	%r15, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mad.lo.s32 	%r34, %r15, %r16, %r14;
	setp.ge.s32	%p1, %r34, %r11;
	@%p1 bra 	BB48_12;

	mov.u32 	%r17, %ntid.y;
	mov.u32 	%r18, %nctaid.y;
	mul.lo.s32 	%r2, %r18, %r17;
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd11, %rd1;

BB48_2:
	mov.u32 	%r19, %ctaid.y;
	mov.u32 	%r21, %tid.y;
	mad.lo.s32 	%r35, %r17, %r19, %r21;
	setp.ge.s32	%p2, %r35, %r10;
	@%p2 bra 	BB48_11;

	mul.lo.s32 	%r4, %r34, %r12;

BB48_4:
	mad.lo.s32 	%r26, %r34, %r13, %r35;
	mul.wide.s32 	%rd4, %r26, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%r27, %temp}, %fd1;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd1;
	}
	add.s32 	%r29, %r28, 1048576;
	mov.b64 	%fd11, {%r27, %r29};
	cvt.rni.f64.f64	%fd12, %fd11;
	cvt.rzi.s64.f64	%rd6, %fd12;
	cvt.u32.u64	%r7, %rd6;
	neg.f64 	%fd13, %fd12;
	mov.f64 	%fd14, 0d3FE0000000000000;
	fma.rn.f64 	%fd15, %fd13, %fd14, %fd1;
	mul.f64 	%fd16, %fd15, 0d3CA1A62633145C07;
	mov.f64 	%fd17, 0d400921FB54442D18;
	fma.rn.f64 	%fd18, %fd15, %fd17, %fd16;
	and.b64  	%rd7, %rd6, 1;
	mul.rn.f64 	%fd2, %fd18, %fd18;
	setp.eq.b64	%p3, %rd7, 1;
	not.pred 	%p4, %p3;
	selp.f64	%fd19, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p4;
	shl.b64 	%rd8, %rd7, 6;
	mov.u64 	%rd9, __cudart_sin_cos_coeffs;
	add.s64 	%rd10, %rd8, %rd9;
	ld.const.f64 	%fd20, [%rd10+8];
	fma.rn.f64 	%fd21, %fd19, %fd2, %fd20;
	ld.const.f64 	%fd22, [%rd10+16];
	fma.rn.f64 	%fd23, %fd21, %fd2, %fd22;
	ld.const.f64 	%fd24, [%rd10+24];
	fma.rn.f64 	%fd25, %fd23, %fd2, %fd24;
	ld.const.f64 	%fd26, [%rd10+32];
	fma.rn.f64 	%fd27, %fd25, %fd2, %fd26;
	ld.const.f64 	%fd28, [%rd10+40];
	fma.rn.f64 	%fd29, %fd27, %fd2, %fd28;
	ld.const.f64 	%fd30, [%rd10+48];
	fma.rn.f64 	%fd3, %fd29, %fd2, %fd30;
	fma.rn.f64 	%fd36, %fd3, %fd18, %fd18;
	@%p4 bra 	BB48_6;

	mov.f64 	%fd31, 0d3FF0000000000000;
	fma.rn.f64 	%fd36, %fd3, %fd2, %fd31;

BB48_6:
	and.b32  	%r30, %r7, 2;
	setp.eq.s32	%p5, %r30, 0;
	@%p5 bra 	BB48_8;

	mov.f64 	%fd32, 0d0000000000000000;
	mov.f64 	%fd33, 0dBFF0000000000000;
	fma.rn.f64 	%fd36, %fd36, %fd33, %fd32;

BB48_8:
	cvt.rzi.f64.f64	%fd34, %fd1;
	setp.neu.f64	%p6, %fd34, %fd1;
	@%p6 bra 	BB48_10;

	mov.f64 	%fd35, 0d0000000000000000;
	mul.rn.f64 	%fd36, %fd1, %fd35;

BB48_10:
	add.s32 	%r31, %r35, %r4;
	mul.wide.s32 	%rd12, %r31, 8;
	add.s64 	%rd13, %rd11, %rd12;
	st.global.f64 	[%rd13], %fd36;
	add.s32 	%r35, %r2, %r35;
	setp.lt.s32	%p7, %r35, %r10;
	@%p7 bra 	BB48_4;

BB48_11:
	mov.u32 	%r32, %nctaid.x;
	mad.lo.s32 	%r34, %r32, %r15, %r34;
	setp.lt.s32	%p8, %r34, %r11;
	@%p8 bra 	BB48_2;

BB48_12:
	ret;
}

	// .globl	map_sqrt_double
.visible .entry map_sqrt_double(
	.param .u32 map_sqrt_double_param_0,
	.param .u32 map_sqrt_double_param_1,
	.param .u64 map_sqrt_double_param_2,
	.param .u32 map_sqrt_double_param_3,
	.param .u64 map_sqrt_double_param_4,
	.param .u32 map_sqrt_double_param_5
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map_sqrt_double_param_0];
	ld.param.u32 	%r13, [map_sqrt_double_param_1];
	ld.param.u64 	%rd3, [map_sqrt_double_param_2];
	ld.param.u32 	%r14, [map_sqrt_double_param_3];
	ld.param.u64 	%rd4, [map_sqrt_double_param_4];
	ld.param.u32 	%r15, [map_sqrt_double_param_5];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB49_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB49_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB49_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB49_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	sqrt.rn.f64 	%fd2, %fd1;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd2;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB49_4;

BB49_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB49_2;

BB49_6:
	ret;
}

	// .globl	map_tan_double
.visible .entry map_tan_double(
	.param .u32 map_tan_double_param_0,
	.param .u32 map_tan_double_param_1,
	.param .u64 map_tan_double_param_2,
	.param .u32 map_tan_double_param_3,
	.param .u64 map_tan_double_param_4,
	.param .u32 map_tan_double_param_5
)
{
	.local .align 4 .b8 	__local_depot50[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<9>;
	.reg .b32 	%r<42>;
	.reg .f64 	%fd<66>;
	.reg .b64 	%rd<13>;


	mov.u64 	%rd12, __local_depot50;
	cvta.local.u64 	%SP, %rd12;
	ld.param.u32 	%r13, [map_tan_double_param_0];
	ld.param.u32 	%r14, [map_tan_double_param_1];
	ld.param.u64 	%rd2, [map_tan_double_param_2];
	ld.param.u32 	%r15, [map_tan_double_param_3];
	ld.param.u64 	%rd3, [map_tan_double_param_4];
	ld.param.u32 	%r16, [map_tan_double_param_5];
	add.u64 	%rd4, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd4;
	mov.u32 	%r17, %ntid.x;
	mov.u32 	%r18, %ctaid.x;
	mov.u32 	%r19, %tid.x;
	mad.lo.s32 	%r39, %r17, %r18, %r19;
	setp.ge.s32	%p1, %r39, %r14;
	@%p1 bra 	BB50_13;

	mov.u32 	%r20, %ntid.y;
	mov.u32 	%r21, %nctaid.y;
	mul.lo.s32 	%r2, %r21, %r20;
	cvta.to.global.u64 	%rd5, %rd3;
	cvta.to.global.u64 	%rd9, %rd2;

BB50_2:
	mov.u32 	%r22, %ctaid.y;
	mov.u32 	%r24, %tid.y;
	mad.lo.s32 	%r40, %r20, %r22, %r24;
	setp.ge.s32	%p2, %r40, %r13;
	@%p2 bra 	BB50_12;

	mul.lo.s32 	%r4, %r39, %r16;
	mul.lo.s32 	%r5, %r39, %r15;

BB50_4:
	add.s32 	%r29, %r40, %r4;
	mul.wide.s32 	%rd6, %r29, 8;
	add.s64 	%rd7, %rd5, %rd6;
	ld.global.f64 	%fd63, [%rd7];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r30}, %fd63;
	}
	and.b32  	%r31, %r30, 2147483647;
	setp.ne.s32	%p3, %r31, 2146435072;
	@%p3 bra 	BB50_7;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r32, %temp}, %fd63;
	}
	setp.ne.s32	%p4, %r32, 0;
	@%p4 bra 	BB50_7;

	mov.f64 	%fd11, 0d0000000000000000;
	mul.rn.f64 	%fd63, %fd63, %fd11;

BB50_7:
	mul.f64 	%fd12, %fd63, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r41, %fd12;
	st.local.u32 	[%rd1], %r41;
	cvt.rn.f64.s32	%fd13, %r41;
	neg.f64 	%fd14, %fd13;
	mov.f64 	%fd15, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd16, %fd14, %fd15, %fd63;
	mov.f64 	%fd17, 0d3C91A62633145C00;
	fma.rn.f64 	%fd18, %fd14, %fd17, %fd16;
	mov.f64 	%fd19, 0d397B839A252049C0;
	fma.rn.f64 	%fd64, %fd14, %fd19, %fd18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd63;
	}
	and.b32  	%r34, %r33, 2145386496;
	setp.lt.u32	%p5, %r34, 1105199104;
	@%p5 bra 	BB50_9;

	// Callseq Start 9
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd63;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd4;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd64, [retval0+0];
	
	//{
	}// Callseq End 9
	ld.local.u32 	%r41, [%rd1];

BB50_9:
	mul.f64 	%fd20, %fd64, %fd64;
	mov.f64 	%fd21, 0dBEF9757C5B27EBB1;
	mov.f64 	%fd22, 0d3EE48DAC2799BCB9;
	fma.rn.f64 	%fd23, %fd22, %fd20, %fd21;
	mov.f64 	%fd24, 0d3F0980E90FD91E04;
	fma.rn.f64 	%fd25, %fd23, %fd20, %fd24;
	mov.f64 	%fd26, 0dBEFAE2B0417D7E1D;
	fma.rn.f64 	%fd27, %fd25, %fd20, %fd26;
	mov.f64 	%fd28, 0d3F119F5341BFBA57;
	fma.rn.f64 	%fd29, %fd27, %fd20, %fd28;
	mov.f64 	%fd30, 0d3F15E791A00F6919;
	fma.rn.f64 	%fd31, %fd29, %fd20, %fd30;
	mov.f64 	%fd32, 0d3F2FF2E7FADEC73A;
	fma.rn.f64 	%fd33, %fd31, %fd20, %fd32;
	mov.f64 	%fd34, 0d3F434BC1B206DA62;
	fma.rn.f64 	%fd35, %fd33, %fd20, %fd34;
	mov.f64 	%fd36, 0d3F57DB18EF2F83F9;
	fma.rn.f64 	%fd37, %fd35, %fd20, %fd36;
	mov.f64 	%fd38, 0d3F6D6D2E7AE49FBC;
	fma.rn.f64 	%fd39, %fd37, %fd20, %fd38;
	mov.f64 	%fd40, 0d3F8226E3A816A776;
	fma.rn.f64 	%fd41, %fd39, %fd20, %fd40;
	mov.f64 	%fd42, 0d3F9664F485D25660;
	fma.rn.f64 	%fd43, %fd41, %fd20, %fd42;
	mov.f64 	%fd44, 0d3FABA1BA1BABF31D;
	fma.rn.f64 	%fd45, %fd43, %fd20, %fd44;
	mov.f64 	%fd46, 0d3FC11111111105D2;
	fma.rn.f64 	%fd47, %fd45, %fd20, %fd46;
	mov.f64 	%fd48, 0d3FD555555555555E;
	fma.rn.f64 	%fd49, %fd47, %fd20, %fd48;
	mul.f64 	%fd7, %fd20, %fd49;
	fma.rn.f64 	%fd65, %fd7, %fd64, %fd64;
	and.b32  	%r35, %r41, 1;
	setp.eq.b32	%p6, %r35, 1;
	@!%p6 bra 	BB50_11;
	bra.uni 	BB50_10;

BB50_10:
	sub.f64 	%fd52, %fd65, %fd64;
	neg.f64 	%fd53, %fd52;
	fma.rn.f64 	%fd54, %fd7, %fd64, %fd53;
	// inline asm
	rcp.approx.ftz.f64 %fd50,%fd65;
	// inline asm
	neg.f64 	%fd55, %fd65;
	mov.f64 	%fd56, 0d3FF0000000000000;
	fma.rn.f64 	%fd57, %fd55, %fd50, %fd56;
	fma.rn.f64 	%fd58, %fd57, %fd57, %fd57;
	fma.rn.f64 	%fd59, %fd58, %fd50, %fd50;
	neg.f64 	%fd60, %fd59;
	fma.rn.f64 	%fd61, %fd65, %fd60, %fd56;
	fma.rn.f64 	%fd62, %fd60, %fd54, %fd61;
	fma.rn.f64 	%fd65, %fd62, %fd60, %fd60;

BB50_11:
	add.s32 	%r36, %r40, %r5;
	mul.wide.s32 	%rd10, %r36, 8;
	add.s64 	%rd11, %rd9, %rd10;
	st.global.f64 	[%rd11], %fd65;
	add.s32 	%r40, %r2, %r40;
	setp.lt.s32	%p7, %r40, %r13;
	@%p7 bra 	BB50_4;

BB50_12:
	mov.u32 	%r37, %nctaid.x;
	mad.lo.s32 	%r39, %r37, %r17, %r39;
	setp.lt.s32	%p8, %r39, %r14;
	@%p8 bra 	BB50_2;

BB50_13:
	ret;
}

	// .globl	map_tanh_double
.visible .entry map_tanh_double(
	.param .u32 map_tanh_double_param_0,
	.param .u32 map_tanh_double_param_1,
	.param .u64 map_tanh_double_param_2,
	.param .u32 map_tanh_double_param_3,
	.param .u64 map_tanh_double_param_4,
	.param .u32 map_tanh_double_param_5
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<38>;
	.reg .f64 	%fd<74>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map_tanh_double_param_0];
	ld.param.u32 	%r13, [map_tanh_double_param_1];
	ld.param.u64 	%rd2, [map_tanh_double_param_2];
	ld.param.u32 	%r14, [map_tanh_double_param_3];
	ld.param.u64 	%rd3, [map_tanh_double_param_4];
	ld.param.u32 	%r15, [map_tanh_double_param_5];
	mov.u32 	%r16, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r36, %r16, %r17, %r18;
	setp.ge.s32	%p1, %r36, %r13;
	@%p1 bra 	BB51_9;

	cvta.to.global.u64 	%rd1, %rd3;
	mov.u32 	%r19, %tid.y;
	mov.u32 	%r20, %ntid.y;
	mov.u32 	%r21, %ctaid.y;
	mad.lo.s32 	%r2, %r20, %r21, %r19;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r3, %r22, %r20;
	cvta.to.global.u64 	%rd6, %rd2;

BB51_2:
	setp.ge.s32	%p2, %r2, %r12;
	@%p2 bra 	BB51_8;

	mul.lo.s32 	%r5, %r36, %r15;
	mul.lo.s32 	%r6, %r36, %r14;
	mov.u32 	%r37, %r2;

BB51_4:
	mov.u32 	%r7, %r37;
	add.s32 	%r23, %r7, %r5;
	mul.wide.s32 	%rd4, %r23, 8;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd1;
	}
	and.b32  	%r9, %r8, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r24, %temp}, %fd1;
	}
	mov.b64 	%fd2, {%r24, %r9};
	setp.ltu.f64	%p3, %fd2, 0d3FE1C7A398201CD6;
	@%p3 bra 	BB51_6;
	bra.uni 	BB51_5;

BB51_6:
	mul.f64 	%fd51, %fd1, %fd1;
	mov.f64 	%fd52, 0dBF2B9093D89F0E23;
	mov.f64 	%fd53, 0d3F0ABFFC9B5786C4;
	fma.rn.f64 	%fd54, %fd53, %fd51, %fd52;
	mov.f64 	%fd55, 0d3F42FA2744C30B61;
	fma.rn.f64 	%fd56, %fd54, %fd51, %fd55;
	mov.f64 	%fd57, 0dBF57CF3B9C1E491D;
	fma.rn.f64 	%fd58, %fd56, %fd51, %fd57;
	mov.f64 	%fd59, 0d3F6D6C61D450119A;
	fma.rn.f64 	%fd60, %fd58, %fd51, %fd59;
	mov.f64 	%fd61, 0dBF8226DDD44294F5;
	fma.rn.f64 	%fd62, %fd60, %fd51, %fd61;
	mov.f64 	%fd63, 0d3F9664F45C2B04A6;
	fma.rn.f64 	%fd64, %fd62, %fd51, %fd63;
	mov.f64 	%fd65, 0dBFABA1BA1AD70754;
	fma.rn.f64 	%fd66, %fd64, %fd51, %fd65;
	mov.f64 	%fd67, 0d3FC111111110295E;
	fma.rn.f64 	%fd68, %fd66, %fd51, %fd67;
	mov.f64 	%fd69, 0dBFD555555555549F;
	fma.rn.f64 	%fd70, %fd68, %fd51, %fd69;
	mul.f64 	%fd71, %fd51, %fd70;
	fma.rn.f64 	%fd73, %fd71, %fd1, %fd1;
	bra.uni 	BB51_7;

BB51_5:
	add.f64 	%fd8, %fd2, %fd2;
	mov.f64 	%fd9, 0d4338000000000000;
	mov.f64 	%fd10, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd11, %fd8, %fd10, %fd9;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r25, %temp}, %fd11;
	}
	mov.f64 	%fd12, 0dC338000000000000;
	add.rn.f64 	%fd13, %fd11, %fd12;
	mov.f64 	%fd14, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd15, %fd13, %fd14, %fd8;
	mov.f64 	%fd16, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd17, %fd13, %fd16, %fd15;
	mov.f64 	%fd18, 0d3E5AF86D8EBD13CD;
	mov.f64 	%fd19, 0d3E21F4076ACD15B6;
	fma.rn.f64 	%fd20, %fd19, %fd17, %fd18;
	mov.f64 	%fd21, 0d3E927E5092BA033D;
	fma.rn.f64 	%fd22, %fd20, %fd17, %fd21;
	mov.f64 	%fd23, 0d3EC71DDE6C5F9DA1;
	fma.rn.f64 	%fd24, %fd22, %fd17, %fd23;
	mov.f64 	%fd25, 0d3EFA01A018D034E6;
	fma.rn.f64 	%fd26, %fd24, %fd17, %fd25;
	mov.f64 	%fd27, 0d3F2A01A01B3B6940;
	fma.rn.f64 	%fd28, %fd26, %fd17, %fd27;
	mov.f64 	%fd29, 0d3F56C16C16C1B5DD;
	fma.rn.f64 	%fd30, %fd28, %fd17, %fd29;
	mov.f64 	%fd31, 0d3F8111111110F74D;
	fma.rn.f64 	%fd32, %fd30, %fd17, %fd31;
	mov.f64 	%fd33, 0d3FA555555555554D;
	fma.rn.f64 	%fd34, %fd32, %fd17, %fd33;
	mov.f64 	%fd35, 0d3FC5555555555557;
	fma.rn.f64 	%fd36, %fd34, %fd17, %fd35;
	mov.f64 	%fd37, 0d3FE0000000000000;
	fma.rn.f64 	%fd38, %fd36, %fd17, %fd37;
	mul.f64 	%fd39, %fd17, %fd38;
	fma.rn.f64 	%fd40, %fd39, %fd17, %fd17;
	shl.b32 	%r26, %r25, 20;
	add.s32 	%r27, %r26, 1072693248;
	mov.u32 	%r28, 0;
	mov.b64 	%fd41, {%r28, %r27};
	fma.rn.f64 	%fd42, %fd40, %fd41, %fd41;
	add.f64 	%fd7, %fd42, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd6,%fd7;
	// inline asm
	neg.f64 	%fd43, %fd7;
	mov.f64 	%fd44, 0d3FF0000000000000;
	fma.rn.f64 	%fd45, %fd43, %fd6, %fd44;
	fma.rn.f64 	%fd46, %fd45, %fd45, %fd45;
	fma.rn.f64 	%fd47, %fd46, %fd6, %fd6;
	neg.f64 	%fd48, %fd47;
	mov.f64 	%fd49, 0d4000000000000000;
	fma.rn.f64 	%fd50, %fd49, %fd48, %fd44;
	setp.gt.u32	%p4, %r9, 1077936127;
	selp.f64	%fd73, 0d3FF0000000000000, %fd50, %p4;

BB51_7:
	and.b32  	%r29, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r30}, %fd73;
	}
	or.b32  	%r31, %r30, %r29;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r32, %temp}, %fd73;
	}
	mov.b64 	%fd72, {%r32, %r31};
	add.s32 	%r33, %r7, %r6;
	mul.wide.s32 	%rd7, %r33, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd72;
	add.s32 	%r10, %r3, %r7;
	setp.lt.s32	%p5, %r10, %r12;
	mov.u32 	%r37, %r10;
	@%p5 bra 	BB51_4;

BB51_8:
	mov.u32 	%r34, %nctaid.x;
	mad.lo.s32 	%r36, %r34, %r16, %r36;
	setp.lt.s32	%p6, %r36, %r13;
	@%p6 bra 	BB51_2;

BB51_9:
	ret;
}

	// .globl	map_tgamma_double
.visible .entry map_tgamma_double(
	.param .u32 map_tgamma_double_param_0,
	.param .u32 map_tgamma_double_param_1,
	.param .u64 map_tgamma_double_param_2,
	.param .u32 map_tgamma_double_param_3,
	.param .u64 map_tgamma_double_param_4,
	.param .u32 map_tgamma_double_param_5
)
{
	.reg .pred 	%p<33>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<99>;
	.reg .f64 	%fd<427>;
	.reg .b64 	%rd<14>;


	ld.param.u32 	%r29, [map_tgamma_double_param_0];
	ld.param.u32 	%r30, [map_tgamma_double_param_1];
	ld.param.u64 	%rd1, [map_tgamma_double_param_2];
	ld.param.u64 	%rd2, [map_tgamma_double_param_4];
	mov.u32 	%r33, %tid.x;
	mov.u32 	%r34, %ntid.x;
	mov.u32 	%r35, %ctaid.x;
	mad.lo.s32 	%r92, %r34, %r35, %r33;
	setp.ge.s32	%p1, %r92, %r30;
	@%p1 bra 	BB52_47;

	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd11, %rd1;

BB52_2:
	mov.u32 	%r36, %ctaid.y;
	mov.u32 	%r37, %ntid.y;
	mov.u32 	%r38, %tid.y;
	mad.lo.s32 	%r93, %r37, %r36, %r38;
	setp.ge.s32	%p2, %r93, %r29;
	@%p2 bra 	BB52_46;
	bra.uni 	BB52_3;

BB52_24:
	setp.lt.u32	%p19, %r20, -1066983424;
	@%p19 bra 	BB52_26;
	bra.uni 	BB52_25;

BB52_26:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r68, %temp}, %fd1;
	}
	add.s32 	%r69, %r20, 1048576;
	mov.b64 	%fd271, {%r68, %r69};
	cvt.rni.f64.f64	%fd272, %fd271;
	cvt.rzi.s64.f64	%rd6, %fd272;
	cvt.u32.u64	%r21, %rd6;
	neg.f64 	%fd273, %fd272;
	mov.f64 	%fd274, 0d3FE0000000000000;
	fma.rn.f64 	%fd275, %fd273, %fd274, %fd1;
	mul.f64 	%fd276, %fd275, 0d3CA1A62633145C07;
	mov.f64 	%fd277, 0d400921FB54442D18;
	fma.rn.f64 	%fd278, %fd275, %fd277, %fd276;
	and.b64  	%rd7, %rd6, 1;
	mul.rn.f64 	%fd27, %fd278, %fd278;
	setp.eq.b64	%p21, %rd7, 1;
	not.pred 	%p22, %p21;
	selp.f64	%fd279, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p22;
	shl.b64 	%rd8, %rd7, 6;
	mov.u64 	%rd9, __cudart_sin_cos_coeffs;
	add.s64 	%rd10, %rd8, %rd9;
	ld.const.f64 	%fd280, [%rd10+8];
	fma.rn.f64 	%fd281, %fd279, %fd27, %fd280;
	ld.const.f64 	%fd282, [%rd10+16];
	fma.rn.f64 	%fd283, %fd281, %fd27, %fd282;
	ld.const.f64 	%fd284, [%rd10+24];
	fma.rn.f64 	%fd285, %fd283, %fd27, %fd284;
	ld.const.f64 	%fd286, [%rd10+32];
	fma.rn.f64 	%fd287, %fd285, %fd27, %fd286;
	ld.const.f64 	%fd288, [%rd10+40];
	fma.rn.f64 	%fd289, %fd287, %fd27, %fd288;
	ld.const.f64 	%fd290, [%rd10+48];
	fma.rn.f64 	%fd28, %fd289, %fd27, %fd290;
	fma.rn.f64 	%fd402, %fd28, %fd278, %fd278;
	@%p22 bra 	BB52_28;

	mov.f64 	%fd291, 0d3FF0000000000000;
	fma.rn.f64 	%fd402, %fd28, %fd27, %fd291;

BB52_28:
	and.b32  	%r70, %r21, 2;
	setp.eq.s32	%p23, %r70, 0;
	@%p23 bra 	BB52_30;

	mov.f64 	%fd292, 0d0000000000000000;
	mov.f64 	%fd293, 0dBFF0000000000000;
	fma.rn.f64 	%fd402, %fd402, %fd293, %fd292;

BB52_30:
	abs.f64 	%fd295, %fd1;
	// inline asm
	rcp.approx.ftz.f64 %fd294,%fd295;
	// inline asm
	neg.f64 	%fd296, %fd295;
	mov.f64 	%fd297, 0d3FF0000000000000;
	fma.rn.f64 	%fd298, %fd296, %fd294, %fd297;
	fma.rn.f64 	%fd299, %fd298, %fd298, %fd298;
	fma.rn.f64 	%fd300, %fd299, %fd294, %fd294;
	mov.f64 	%fd301, 0d3F73C25DA81303D5;
	mov.f64 	%fd302, 0dBF64BEE47C38A637;
	fma.rn.f64 	%fd303, %fd302, %fd300, %fd301;
	mov.f64 	%fd304, 0dBF6B7C37A96CFC72;
	fma.rn.f64 	%fd305, %fd303, %fd300, %fd304;
	mov.f64 	%fd306, 0d3F35A85ABDE1E324;
	fma.rn.f64 	%fd307, %fd305, %fd300, %fd306;
	mov.f64 	%fd308, 0d3F4A8B28F07B3F05;
	fma.rn.f64 	%fd309, %fd307, %fd300, %fd308;
	mov.f64 	%fd310, 0dBF0A15D1D45A282F;
	fma.rn.f64 	%fd311, %fd309, %fd300, %fd310;
	mov.f64 	%fd312, 0dBF4367D3468CB5BE;
	fma.rn.f64 	%fd313, %fd311, %fd300, %fd312;
	mov.f64 	%fd314, 0d3F12471B0E9F1005;
	fma.rn.f64 	%fd315, %fd313, %fd300, %fd314;
	mov.f64 	%fd316, 0d3F49B1004744D5C4;
	fma.rn.f64 	%fd317, %fd315, %fd300, %fd316;
	mov.f64 	%fd318, 0dBF2E13CE69AB4B7F;
	fma.rn.f64 	%fd319, %fd317, %fd300, %fd318;
	mov.f64 	%fd320, 0dBF65F7268ECF8A01;
	fma.rn.f64 	%fd321, %fd319, %fd300, %fd320;
	mov.f64 	%fd322, 0d3F6C71C71C71ACE0;
	fma.rn.f64 	%fd323, %fd321, %fd300, %fd322;
	mov.f64 	%fd324, 0d3FB5555555555556;
	fma.rn.f64 	%fd325, %fd323, %fd300, %fd324;
	mul.f64 	%fd326, %fd300, %fd325;
	fma.rn.f64 	%fd35, %fd326, %fd402, %fd402;
	mov.f64 	%fd327, 0d4338000000000000;
	mov.f64 	%fd328, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd329, %fd295, %fd328, %fd327;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd329;
	}
	mov.f64 	%fd330, 0dC338000000000000;
	add.rn.f64 	%fd331, %fd329, %fd330;
	mov.f64 	%fd332, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd333, %fd331, %fd332, %fd295;
	mov.f64 	%fd334, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd335, %fd331, %fd334, %fd333;
	mov.f64 	%fd336, 0d3E928AF3FCA213EA;
	mov.f64 	%fd337, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd338, %fd337, %fd335, %fd336;
	mov.f64 	%fd339, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd340, %fd338, %fd335, %fd339;
	mov.f64 	%fd341, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd342, %fd340, %fd335, %fd341;
	mov.f64 	%fd343, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd344, %fd342, %fd335, %fd343;
	mov.f64 	%fd345, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd346, %fd344, %fd335, %fd345;
	mov.f64 	%fd347, 0d3F81111111122322;
	fma.rn.f64 	%fd348, %fd346, %fd335, %fd347;
	mov.f64 	%fd349, 0d3FA55555555502A1;
	fma.rn.f64 	%fd350, %fd348, %fd335, %fd349;
	mov.f64 	%fd351, 0d3FC5555555555511;
	fma.rn.f64 	%fd352, %fd350, %fd335, %fd351;
	mov.f64 	%fd353, 0d3FE000000000000B;
	fma.rn.f64 	%fd354, %fd352, %fd335, %fd353;
	fma.rn.f64 	%fd355, %fd354, %fd335, %fd297;
	fma.rn.f64 	%fd403, %fd355, %fd335, %fd297;
	abs.s32 	%r71, %r22;
	setp.lt.s32	%p24, %r71, 1023;
	@%p24 bra 	BB52_32;
	bra.uni 	BB52_31;

BB52_32:
	shl.b32 	%r77, %r22, 20;
	add.s32 	%r98, %r77, 1072693248;
	bra.uni 	BB52_33;

BB52_25:
	cvt.rmi.f64.f64	%fd267, %fd1;
	mul.f64 	%fd268, %fd267, 0d3FE0000000000000;
	cvt.rmi.f64.f64	%fd269, %fd268;
	fma.rn.f64 	%fd270, %fd269, 0dC000000000000000, %fd267;
	setp.eq.f64	%p20, %fd270, 0d3FF0000000000000;
	selp.f64	%fd426, 0d8000000000000000, 0d0000000000000000, %p20;
	bra.uni 	BB52_45;

BB52_31:
	add.s32 	%r72, %r22, 2046;
	shl.b32 	%r73, %r72, 19;
	and.b32  	%r74, %r73, -1048576;
	shl.b32 	%r75, %r72, 20;
	sub.s32 	%r98, %r75, %r74;
	mov.u32 	%r76, 0;
	mov.b64 	%fd356, {%r76, %r74};
	mul.f64 	%fd403, %fd403, %fd356;

BB52_33:
	mul.f64 	%fd357, %fd295, %fd35;
	mov.u32 	%r78, 0;
	mov.b64 	%fd358, {%r78, %r98};
	mul.f64 	%fd359, %fd403, %fd358;
	mul.f64 	%fd360, %fd359, 0dBC9A6A0D6F814637;
	mov.f64 	%fd361, 0d3FF40D931FF62706;
	fma.rn.f64 	%fd362, %fd359, %fd361, %fd360;
	div.rn.f64 	%fd39, %fd362, %fd357;
	add.f64 	%fd404, %fd295, 0dBFE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r26}, %fd295;
	}
	setp.lt.s32	%p25, %r26, 1080157184;
	@%p25 bra 	BB52_35;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r79, %temp}, %fd404;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r80}, %fd404;
	}
	add.s32 	%r81, %r80, -1048576;
	mov.b64 	%fd404, {%r79, %r81};

BB52_35:
	neg.f64 	%fd363, %fd404;
	// Callseq Start 10
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd295;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd363;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd364, [retval0+0];
	
	//{
	}// Callseq End 10
	mul.f64 	%fd365, %fd39, %fd364;
	setp.gt.s32	%p26, %r26, 1080157183;
	selp.f64	%fd366, %fd365, %fd39, %p26;
	mul.f64 	%fd426, %fd364, %fd366;
	bra.uni 	BB52_45;

BB52_3:
	ld.param.u32 	%r91, [map_tgamma_double_param_5];
	mad.lo.s32 	%r43, %r92, %r91, %r93;
	mul.wide.s32 	%rd4, %r43, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	setp.ltu.f64	%p3, %fd1, 0d0000000000000000;
	@%p3 bra 	BB52_20;
	bra.uni 	BB52_4;

BB52_20:
	setp.lt.f64	%p16, %fd1, 0d0000000000000000;
	@%p16 bra 	BB52_22;
	bra.uni 	BB52_21;

BB52_22:
	cvt.rzi.f64.f64	%fd266, %fd1;
	setp.eq.f64	%p17, %fd266, %fd1;
	mov.f64 	%fd426, 0dFFF8000000000000;
	@%p17 bra 	BB52_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd1;
	}
	setp.lt.u32	%p18, %r20, -1072693248;
	@%p18 bra 	BB52_36;
	bra.uni 	BB52_24;

BB52_36:
	setp.lt.u32	%p27, %r20, -1072955392;
	mov.f64 	%fd422, %fd1;
	mov.f64 	%fd421, %fd1;
	@%p27 bra 	BB52_38;

	fma.rn.f64 	%fd422, %fd1, %fd1, %fd1;
	add.f64 	%fd421, %fd1, 0d3FF0000000000000;

BB52_38:
	mov.f64 	%fd419, %fd421;
	mov.f64 	%fd420, %fd422;
	setp.lt.u32	%p28, %r20, -1073479680;
	@%p28 bra 	BB52_40;

	fma.rn.f64 	%fd420, %fd419, %fd420, %fd420;
	add.f64 	%fd419, %fd419, 0d3FF0000000000000;

BB52_40:
	mov.f64 	%fd417, %fd419;
	mov.f64 	%fd418, %fd420;
	setp.lt.u32	%p29, %r20, -1074266112;
	@%p29 bra 	BB52_42;

	fma.rn.f64 	%fd418, %fd417, %fd418, %fd418;
	add.f64 	%fd417, %fd417, 0d3FF0000000000000;

BB52_42:
	mov.f64 	%fd415, %fd417;
	mov.f64 	%fd416, %fd418;
	setp.lt.u32	%p30, %r20, -1075838976;
	@%p30 bra 	BB52_44;

	fma.rn.f64 	%fd416, %fd415, %fd416, %fd416;
	add.f64 	%fd415, %fd415, 0d3FF0000000000000;

BB52_44:
	mov.f64 	%fd367, 0dBE8AF7049AE8A594;
	mov.f64 	%fd368, 0d3E381B4960FCF5C9;
	fma.rn.f64 	%fd369, %fd368, %fd415, %fd367;
	mov.f64 	%fd370, 0d3EB301D46D4B22F5;
	fma.rn.f64 	%fd371, %fd369, %fd415, %fd370;
	mov.f64 	%fd372, 0dBEB50272AEED0FC4;
	fma.rn.f64 	%fd373, %fd371, %fd415, %fd372;
	mov.f64 	%fd374, 0dBEF51CE1A40516F8;
	fma.rn.f64 	%fd375, %fd373, %fd415, %fd374;
	mov.f64 	%fd376, 0d3F20C8AA7419084C;
	fma.rn.f64 	%fd377, %fd375, %fd415, %fd376;
	mov.f64 	%fd378, 0dBF2C3650196BAD8A;
	fma.rn.f64 	%fd379, %fd377, %fd415, %fd378;
	mov.f64 	%fd380, 0dBF531711365A3E26;
	fma.rn.f64 	%fd381, %fd379, %fd415, %fd380;
	mov.f64 	%fd382, 0d3F7D919C52A7DF35;
	fma.rn.f64 	%fd383, %fd381, %fd415, %fd382;
	mov.f64 	%fd384, 0dBF83B4AF28386F4D;
	fma.rn.f64 	%fd385, %fd383, %fd415, %fd384;
	mov.f64 	%fd386, 0dBFA59AF103C37B4D;
	fma.rn.f64 	%fd387, %fd385, %fd415, %fd386;
	mov.f64 	%fd388, 0d3FC5512320B439EF;
	fma.rn.f64 	%fd389, %fd387, %fd415, %fd388;
	mov.f64 	%fd390, 0dBFA5815E8FA26F4F;
	fma.rn.f64 	%fd391, %fd389, %fd415, %fd390;
	mov.f64 	%fd392, 0dBFE4FCF4026AFA2B;
	fma.rn.f64 	%fd393, %fd391, %fd415, %fd392;
	mov.f64 	%fd394, 0d3FE2788CFC6FB619;
	fma.rn.f64 	%fd395, %fd393, %fd415, %fd394;
	mov.f64 	%fd396, 0d3FF0000000000000;
	fma.rn.f64 	%fd397, %fd395, %fd415, %fd396;
	mul.f64 	%fd398, %fd416, %fd397;
	rcp.rn.f64 	%fd426, %fd398;
	bra.uni 	BB52_45;

BB52_4:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r95}, %fd1;
	}
	setp.lt.s32	%p4, %r95, 1074790400;
	@%p4 bra 	BB52_13;
	bra.uni 	BB52_5;

BB52_13:
	mov.f64 	%fd401, 0d3FF0000000000000;
	setp.lt.s32	%p11, %r95, 1074528256;
	mov.f64 	%fd425, %fd1;
	@%p11 bra 	BB52_15;

	mov.f64 	%fd226, 0dBFF0000000000000;
	mov.f64 	%fd227, 0d3FF0000000000000;
	fma.rn.f64 	%fd401, %fd1, %fd227, %fd226;
	add.f64 	%fd13, %fd1, 0dBFF0000000000000;
	mov.f64 	%fd425, %fd13;

BB52_15:
	mov.f64 	%fd407, %fd425;
	mov.f64 	%fd424, %fd407;
	setp.lt.s32	%p12, %r95, 1074003968;
	@%p12 bra 	BB52_17;

	neg.f64 	%fd228, %fd401;
	fma.rn.f64 	%fd401, %fd424, %fd401, %fd228;
	add.f64 	%fd424, %fd424, 0dBFF0000000000000;

BB52_17:
	mov.f64 	%fd423, %fd424;
	setp.lt.s32	%p13, %r95, 1073217536;
	@%p13 bra 	BB52_19;

	neg.f64 	%fd229, %fd401;
	fma.rn.f64 	%fd401, %fd423, %fd401, %fd229;
	add.f64 	%fd423, %fd423, 0dBFF0000000000000;

BB52_19:
	add.f64 	%fd230, %fd423, 0dBFF0000000000000;
	setp.gt.s32	%p14, %r95, 1071644671;
	selp.f64	%fd231, %fd230, %fd423, %p14;
	mov.f64 	%fd232, 0dBE8AF7049AE8A594;
	mov.f64 	%fd233, 0d3E381B4960FCF5C9;
	fma.rn.f64 	%fd234, %fd233, %fd231, %fd232;
	mov.f64 	%fd235, 0d3EB301D46D4B22F5;
	fma.rn.f64 	%fd236, %fd234, %fd231, %fd235;
	mov.f64 	%fd237, 0dBEB50272AEED0FC4;
	fma.rn.f64 	%fd238, %fd236, %fd231, %fd237;
	mov.f64 	%fd239, 0dBEF51CE1A40516F8;
	fma.rn.f64 	%fd240, %fd238, %fd231, %fd239;
	mov.f64 	%fd241, 0d3F20C8AA7419084C;
	fma.rn.f64 	%fd242, %fd240, %fd231, %fd241;
	mov.f64 	%fd243, 0dBF2C3650196BAD8A;
	fma.rn.f64 	%fd244, %fd242, %fd231, %fd243;
	mov.f64 	%fd245, 0dBF531711365A3E26;
	fma.rn.f64 	%fd246, %fd244, %fd231, %fd245;
	mov.f64 	%fd247, 0d3F7D919C52A7DF35;
	fma.rn.f64 	%fd248, %fd246, %fd231, %fd247;
	mov.f64 	%fd249, 0dBF83B4AF28386F4D;
	fma.rn.f64 	%fd250, %fd248, %fd231, %fd249;
	mov.f64 	%fd251, 0dBFA59AF103C37B4D;
	fma.rn.f64 	%fd252, %fd250, %fd231, %fd251;
	mov.f64 	%fd253, 0d3FC5512320B439EF;
	fma.rn.f64 	%fd254, %fd252, %fd231, %fd253;
	mov.f64 	%fd255, 0dBFA5815E8FA26F4F;
	fma.rn.f64 	%fd256, %fd254, %fd231, %fd255;
	mov.f64 	%fd257, 0dBFE4FCF4026AFA2B;
	fma.rn.f64 	%fd258, %fd256, %fd231, %fd257;
	mov.f64 	%fd259, 0d3FE2788CFC6FB619;
	fma.rn.f64 	%fd260, %fd258, %fd231, %fd259;
	mov.f64 	%fd261, 0d3FF0000000000000;
	fma.rn.f64 	%fd262, %fd260, %fd231, %fd261;
	mul.f64 	%fd263, %fd1, %fd262;
	setp.lt.s32	%p15, %r95, 1071644672;
	selp.f64	%fd264, %fd263, %fd262, %p15;
	div.rn.f64 	%fd426, %fd401, %fd264;
	bra.uni 	BB52_45;

BB52_21:
	add.f64 	%fd426, %fd1, %fd1;
	bra.uni 	BB52_45;

BB52_5:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r94, %temp}, %fd1;
	}
	shr.u32 	%r96, %r95, 20;
	setp.ne.s32	%p5, %r96, 0;
	@%p5 bra 	BB52_7;

	mul.f64 	%fd62, %fd1, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r95}, %fd62;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r94, %temp}, %fd62;
	}
	shr.u32 	%r44, %r95, 20;
	add.s32 	%r96, %r44, -54;

BB52_7:
	and.b32  	%r45, %r95, -2146435073;
	or.b32  	%r46, %r45, 1072693248;
	mov.b64 	%fd399, {%r94, %r46};
	add.s32 	%r97, %r96, -1023;
	setp.lt.u32	%p6, %r46, 1073127583;
	@%p6 bra 	BB52_9;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd399;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r48}, %fd399;
	}
	add.s32 	%r49, %r48, -1048576;
	mov.b64 	%fd399, {%r47, %r49};
	add.s32 	%r97, %r96, -1022;

BB52_9:
	add.f64 	%fd64, %fd399, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd63,%fd64;
	// inline asm
	neg.f64 	%fd65, %fd64;
	mov.f64 	%fd66, 0d3FF0000000000000;
	fma.rn.f64 	%fd67, %fd65, %fd63, %fd66;
	fma.rn.f64 	%fd68, %fd67, %fd67, %fd67;
	fma.rn.f64 	%fd69, %fd68, %fd63, %fd63;
	add.f64 	%fd70, %fd399, 0dBFF0000000000000;
	mul.f64 	%fd71, %fd70, %fd69;
	fma.rn.f64 	%fd72, %fd70, %fd69, %fd71;
	mul.f64 	%fd73, %fd72, %fd72;
	mov.f64 	%fd74, 0d3ED0F5D241AD3B5A;
	mov.f64 	%fd75, 0d3EB0F5FF7D2CAFE2;
	fma.rn.f64 	%fd76, %fd75, %fd73, %fd74;
	mov.f64 	%fd77, 0d3EF3B20A75488A3F;
	fma.rn.f64 	%fd78, %fd76, %fd73, %fd77;
	mov.f64 	%fd79, 0d3F1745CDE4FAECD5;
	fma.rn.f64 	%fd80, %fd78, %fd73, %fd79;
	mov.f64 	%fd81, 0d3F3C71C7258A578B;
	fma.rn.f64 	%fd82, %fd80, %fd73, %fd81;
	mov.f64 	%fd83, 0d3F6249249242B910;
	fma.rn.f64 	%fd84, %fd82, %fd73, %fd83;
	mov.f64 	%fd85, 0d3F89999999999DFB;
	fma.rn.f64 	%fd86, %fd84, %fd73, %fd85;
	sub.f64 	%fd87, %fd70, %fd72;
	add.f64 	%fd88, %fd87, %fd87;
	neg.f64 	%fd89, %fd72;
	fma.rn.f64 	%fd90, %fd89, %fd70, %fd88;
	mul.f64 	%fd91, %fd69, %fd90;
	fma.rn.f64 	%fd92, %fd73, %fd86, 0d3FB5555555555555;
	mov.f64 	%fd93, 0d3FB5555555555555;
	sub.f64 	%fd94, %fd93, %fd92;
	fma.rn.f64 	%fd95, %fd73, %fd86, %fd94;
	add.f64 	%fd96, %fd95, 0d0000000000000000;
	add.f64 	%fd97, %fd96, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd98, %fd92, %fd97;
	sub.f64 	%fd99, %fd92, %fd98;
	add.f64 	%fd100, %fd97, %fd99;
	mul.rn.f64 	%fd101, %fd72, %fd72;
	neg.f64 	%fd102, %fd101;
	fma.rn.f64 	%fd103, %fd72, %fd72, %fd102;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r50, %temp}, %fd91;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r51}, %fd91;
	}
	add.s32 	%r52, %r51, 1048576;
	mov.b64 	%fd104, {%r50, %r52};
	fma.rn.f64 	%fd105, %fd72, %fd104, %fd103;
	mul.rn.f64 	%fd106, %fd101, %fd72;
	neg.f64 	%fd107, %fd106;
	fma.rn.f64 	%fd108, %fd101, %fd72, %fd107;
	fma.rn.f64 	%fd109, %fd101, %fd91, %fd108;
	fma.rn.f64 	%fd110, %fd105, %fd72, %fd109;
	mul.rn.f64 	%fd111, %fd98, %fd106;
	neg.f64 	%fd112, %fd111;
	fma.rn.f64 	%fd113, %fd98, %fd106, %fd112;
	fma.rn.f64 	%fd114, %fd98, %fd110, %fd113;
	fma.rn.f64 	%fd115, %fd100, %fd106, %fd114;
	add.f64 	%fd116, %fd111, %fd115;
	sub.f64 	%fd117, %fd111, %fd116;
	add.f64 	%fd118, %fd115, %fd117;
	add.f64 	%fd119, %fd72, %fd116;
	sub.f64 	%fd120, %fd72, %fd119;
	add.f64 	%fd121, %fd116, %fd120;
	add.f64 	%fd122, %fd118, %fd121;
	add.f64 	%fd123, %fd91, %fd122;
	add.f64 	%fd124, %fd119, %fd123;
	sub.f64 	%fd125, %fd119, %fd124;
	add.f64 	%fd126, %fd123, %fd125;
	xor.b32  	%r53, %r97, -2147483648;
	mov.u32 	%r54, 1127219200;
	mov.b64 	%fd127, {%r53, %r54};
	mov.u32 	%r55, -2147483648;
	mov.b64 	%fd128, {%r55, %r54};
	sub.f64 	%fd129, %fd127, %fd128;
	mov.f64 	%fd130, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd131, %fd129, %fd130, %fd124;
	neg.f64 	%fd132, %fd129;
	fma.rn.f64 	%fd133, %fd132, %fd130, %fd131;
	sub.f64 	%fd134, %fd133, %fd124;
	sub.f64 	%fd135, %fd126, %fd134;
	mov.f64 	%fd136, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd137, %fd129, %fd136, %fd135;
	add.f64 	%fd138, %fd131, %fd137;
	sub.f64 	%fd139, %fd131, %fd138;
	add.f64 	%fd140, %fd137, %fd139;
	add.f64 	%fd141, %fd1, 0dBFE0000000000000;
	mul.rn.f64 	%fd142, %fd138, %fd141;
	neg.f64 	%fd143, %fd142;
	fma.rn.f64 	%fd144, %fd138, %fd141, %fd143;
	fma.rn.f64 	%fd145, %fd140, %fd141, %fd144;
	add.f64 	%fd146, %fd142, %fd145;
	sub.f64 	%fd147, %fd142, %fd146;
	add.f64 	%fd148, %fd145, %fd147;
	sub.f64 	%fd149, %fd146, %fd1;
	sub.f64 	%fd150, %fd146, %fd149;
	sub.f64 	%fd151, %fd150, %fd1;
	add.f64 	%fd152, %fd148, %fd151;
	add.f64 	%fd5, %fd149, %fd152;
	sub.f64 	%fd153, %fd149, %fd5;
	add.f64 	%fd6, %fd152, %fd153;
	mov.f64 	%fd154, 0d4338000000000000;
	mov.f64 	%fd155, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd156, %fd5, %fd155, %fd154;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r17, %temp}, %fd156;
	}
	mov.f64 	%fd157, 0dC338000000000000;
	add.rn.f64 	%fd158, %fd156, %fd157;
	mov.f64 	%fd159, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd160, %fd158, %fd159, %fd5;
	mov.f64 	%fd161, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd162, %fd158, %fd161, %fd160;
	mov.f64 	%fd163, 0d3E928AF3FCA213EA;
	mov.f64 	%fd164, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd165, %fd164, %fd162, %fd163;
	mov.f64 	%fd166, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd167, %fd165, %fd162, %fd166;
	mov.f64 	%fd168, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd169, %fd167, %fd162, %fd168;
	mov.f64 	%fd170, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd171, %fd169, %fd162, %fd170;
	mov.f64 	%fd172, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd173, %fd171, %fd162, %fd172;
	mov.f64 	%fd174, 0d3F81111111122322;
	fma.rn.f64 	%fd175, %fd173, %fd162, %fd174;
	mov.f64 	%fd176, 0d3FA55555555502A1;
	fma.rn.f64 	%fd177, %fd175, %fd162, %fd176;
	mov.f64 	%fd178, 0d3FC5555555555511;
	fma.rn.f64 	%fd179, %fd177, %fd162, %fd178;
	mov.f64 	%fd180, 0d3FE000000000000B;
	fma.rn.f64 	%fd181, %fd179, %fd162, %fd180;
	fma.rn.f64 	%fd182, %fd181, %fd162, %fd66;
	fma.rn.f64 	%fd183, %fd182, %fd162, %fd66;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd183;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r19}, %fd183;
	}
	shl.b32 	%r56, %r17, 20;
	add.s32 	%r57, %r19, %r56;
	mov.b64 	%fd400, {%r18, %r57};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r58}, %fd5;
	}
	mov.b32 	 %f2, %r58;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p7, %f1, 0f4086232B;
	@%p7 bra 	BB52_12;

	setp.lt.f64	%p8, %fd5, 0d0000000000000000;
	add.f64 	%fd184, %fd5, 0d7FF0000000000000;
	selp.f64	%fd400, 0d0000000000000000, %fd184, %p8;
	setp.geu.f32	%p9, %f1, 0f40874800;
	@%p9 bra 	BB52_12;

	shr.u32 	%r59, %r17, 31;
	add.s32 	%r60, %r17, %r59;
	shr.s32 	%r61, %r60, 1;
	shl.b32 	%r62, %r61, 20;
	add.s32 	%r63, %r62, %r19;
	mov.b64 	%fd185, {%r18, %r63};
	sub.s32 	%r64, %r17, %r61;
	shl.b32 	%r65, %r64, 20;
	add.s32 	%r66, %r65, 1072693248;
	mov.u32 	%r67, 0;
	mov.b64 	%fd186, {%r67, %r66};
	mul.f64 	%fd400, %fd185, %fd186;

BB52_12:
	fma.rn.f64 	%fd189, %fd6, %fd400, %fd400;
	mul.f64 	%fd190, %fd189, 0dBCAA6A0D6F814637;
	mov.f64 	%fd191, 0d40040D931FF62706;
	fma.rn.f64 	%fd192, %fd189, %fd191, %fd190;
	// inline asm
	rcp.approx.ftz.f64 %fd187,%fd1;
	// inline asm
	neg.f64 	%fd193, %fd1;
	fma.rn.f64 	%fd195, %fd193, %fd187, %fd66;
	fma.rn.f64 	%fd196, %fd195, %fd195, %fd195;
	fma.rn.f64 	%fd197, %fd196, %fd187, %fd187;
	mov.f64 	%fd198, 0d3F73C25DA81303D5;
	mov.f64 	%fd199, 0dBF64BEE47C38A637;
	fma.rn.f64 	%fd200, %fd199, %fd197, %fd198;
	mov.f64 	%fd201, 0dBF6B7C37A96CFC72;
	fma.rn.f64 	%fd202, %fd200, %fd197, %fd201;
	mov.f64 	%fd203, 0d3F35A85ABDE1E324;
	fma.rn.f64 	%fd204, %fd202, %fd197, %fd203;
	mov.f64 	%fd205, 0d3F4A8B28F07B3F05;
	fma.rn.f64 	%fd206, %fd204, %fd197, %fd205;
	mov.f64 	%fd207, 0dBF0A15D1D45A282F;
	fma.rn.f64 	%fd208, %fd206, %fd197, %fd207;
	mov.f64 	%fd209, 0dBF4367D3468CB5BE;
	fma.rn.f64 	%fd210, %fd208, %fd197, %fd209;
	mov.f64 	%fd211, 0d3F12471B0E9F1005;
	fma.rn.f64 	%fd212, %fd210, %fd197, %fd211;
	mov.f64 	%fd213, 0d3F49B1004744D5C4;
	fma.rn.f64 	%fd214, %fd212, %fd197, %fd213;
	mov.f64 	%fd215, 0dBF2E13CE69AB4B7F;
	fma.rn.f64 	%fd216, %fd214, %fd197, %fd215;
	mov.f64 	%fd217, 0dBF65F7268ECF8A01;
	fma.rn.f64 	%fd218, %fd216, %fd197, %fd217;
	mov.f64 	%fd219, 0d3F6C71C71C71ACE0;
	fma.rn.f64 	%fd220, %fd218, %fd197, %fd219;
	mov.f64 	%fd221, 0d3FB5555555555556;
	fma.rn.f64 	%fd222, %fd220, %fd197, %fd221;
	mul.f64 	%fd223, %fd197, %fd222;
	fma.rn.f64 	%fd224, %fd223, %fd192, %fd192;
	setp.ltu.f64	%p10, %fd1, 0d406573FAE561F648;
	selp.f64	%fd426, %fd224, 0d7FF0000000000000, %p10;

BB52_45:
	mov.u32 	%r88, %ntid.y;
	ld.param.u32 	%r87, [map_tgamma_double_param_3];
	mad.lo.s32 	%r82, %r92, %r87, %r93;
	mul.wide.s32 	%rd12, %r82, 8;
	add.s64 	%rd13, %rd11, %rd12;
	st.global.f64 	[%rd13], %fd426;
	mov.u32 	%r84, %nctaid.y;
	mad.lo.s32 	%r93, %r84, %r88, %r93;
	setp.lt.s32	%p31, %r93, %r29;
	@%p31 bra 	BB52_3;

BB52_46:
	ld.param.u32 	%r90, [map_tgamma_double_param_1];
	mov.u32 	%r89, %ntid.x;
	mov.u32 	%r85, %nctaid.x;
	mad.lo.s32 	%r92, %r85, %r89, %r92;
	setp.lt.s32	%p32, %r92, %r90;
	@%p32 bra 	BB52_2;

BB52_47:
	ret;
}

	// .globl	map_trunc_double
.visible .entry map_trunc_double(
	.param .u32 map_trunc_double_param_0,
	.param .u32 map_trunc_double_param_1,
	.param .u64 map_trunc_double_param_2,
	.param .u32 map_trunc_double_param_3,
	.param .u64 map_trunc_double_param_4,
	.param .u32 map_trunc_double_param_5
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map_trunc_double_param_0];
	ld.param.u32 	%r13, [map_trunc_double_param_1];
	ld.param.u64 	%rd3, [map_trunc_double_param_2];
	ld.param.u32 	%r14, [map_trunc_double_param_3];
	ld.param.u64 	%rd4, [map_trunc_double_param_4];
	ld.param.u32 	%r15, [map_trunc_double_param_5];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB53_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB53_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB53_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB53_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	cvt.rzi.f64.f64	%fd2, %fd1;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd2;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB53_4;

BB53_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB53_2;

BB53_6:
	ret;
}

	// .globl	map_y0_double
.visible .entry map_y0_double(
	.param .u32 map_y0_double_param_0,
	.param .u32 map_y0_double_param_1,
	.param .u64 map_y0_double_param_2,
	.param .u32 map_y0_double_param_3,
	.param .u64 map_y0_double_param_4,
	.param .u32 map_y0_double_param_5
)
{
	.local .align 4 .b8 	__local_depot54[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<33>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<105>;
	.reg .f64 	%fd<541>;
	.reg .b64 	%rd<36>;


	mov.u64 	%rd35, __local_depot54;
	cvta.local.u64 	%SP, %rd35;
	ld.param.u32 	%r31, [map_y0_double_param_0];
	ld.param.u32 	%r32, [map_y0_double_param_1];
	ld.param.u64 	%rd1, [map_y0_double_param_2];
	ld.param.u64 	%rd2, [map_y0_double_param_4];
	mov.u32 	%r35, %ntid.x;
	mov.u32 	%r36, %ctaid.x;
	mov.u32 	%r37, %tid.x;
	mad.lo.s32 	%r95, %r35, %r36, %r37;
	setp.ge.s32	%p1, %r95, %r32;
	@%p1 bra 	BB54_54;

	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd28, %rd1;

BB54_2:
	mov.u32 	%r38, %ctaid.y;
	mov.u32 	%r39, %ntid.y;
	mov.u32 	%r40, %tid.y;
	mad.lo.s32 	%r96, %r39, %r38, %r40;
	setp.ge.s32	%p2, %r96, %r31;
	@%p2 bra 	BB54_53;

BB54_3:
	ld.param.u32 	%r94, [map_y0_double_param_5];
	mad.lo.s32 	%r45, %r95, %r94, %r96;
	mul.wide.s32 	%rd4, %r45, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	abs.f64 	%fd2, %fd1;
	setp.gtu.f64	%p3, %fd2, 0d3FE97F4A8F9D3F28;
	@%p3 bra 	BB54_32;
	bra.uni 	BB54_4;

BB54_32:
	setp.gtu.f64	%p19, %fd2, 0d4000347C4AB37B18;
	@%p19 bra 	BB54_34;
	bra.uni 	BB54_33;

BB54_34:
	setp.gtu.f64	%p20, %fd2, 0d40161663B5D9A628;
	@%p20 bra 	BB54_36;
	bra.uni 	BB54_35;

BB54_36:
	setp.gtu.f64	%p21, %fd2, 0d40214EF30C0C06ED;
	@%p21 bra 	BB54_38;
	bra.uni 	BB54_37;

BB54_38:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r73}, %fd2;
	}
	and.b32  	%r74, %r73, 2147483647;
	setp.ne.s32	%p22, %r74, 2146435072;
	@%p22 bra 	BB54_40;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r75, %temp}, %fd2;
	}
	setp.eq.s32	%p23, %r75, 0;
	mov.f64 	%fd540, 0d0000000000000000;
	@%p23 bra 	BB54_52;

BB54_40:
	// inline asm
	rcp.approx.ftz.f64 %fd441,%fd2;
	// inline asm
	neg.f64 	%fd443, %fd2;
	mov.f64 	%fd444, 0d3FF0000000000000;
	fma.rn.f64 	%fd445, %fd443, %fd441, %fd444;
	fma.rn.f64 	%fd446, %fd445, %fd445, %fd445;
	fma.rn.f64 	%fd447, %fd446, %fd441, %fd441;
	mul.f64 	%fd448, %fd447, %fd447;
	mov.f64 	%fd449, 0d4093F56A049CDDE7;
	mov.f64 	%fd450, 0dC0C5E91E6AC3AD03;
	fma.rn.f64 	%fd451, %fd450, %fd448, %fd449;
	mov.f64 	%fd452, 0dC05572D39DFB8433;
	fma.rn.f64 	%fd453, %fd451, %fd448, %fd452;
	mov.f64 	%fd454, 0d4016A6041CAA59E5;
	fma.rn.f64 	%fd455, %fd453, %fd448, %fd454;
	mov.f64 	%fd456, 0dBFE155E3A0493880;
	fma.rn.f64 	%fd457, %fd455, %fd448, %fd456;
	mov.f64 	%fd458, 0d3FBA7FB92F417F7F;
	fma.rn.f64 	%fd459, %fd457, %fd448, %fd458;
	mov.f64 	%fd460, 0dBFAFFFFFB12E32F5;
	fma.rn.f64 	%fd461, %fd459, %fd448, %fd460;
	mov.f64 	%fd462, 0d3FEFFFFFFFFECED5;
	fma.rn.f64 	%fd463, %fd461, %fd448, %fd462;
	mov.f64 	%fd464, 0dC15709C79AAC5813;
	mov.f64 	%fd465, 0d418A86A64BE101DC;
	fma.rn.f64 	%fd466, %fd465, %fd448, %fd464;
	mov.f64 	%fd467, 0d41142A31C980A287;
	fma.rn.f64 	%fd468, %fd466, %fd448, %fd467;
	mov.f64 	%fd469, 0dC0C9CBE68930485D;
	fma.rn.f64 	%fd470, %fd468, %fd448, %fd469;
	mov.f64 	%fd471, 0d407F583E14E8A4E8;
	fma.rn.f64 	%fd472, %fd470, %fd448, %fd471;
	mov.f64 	%fd473, 0dC0374A629C650680;
	fma.rn.f64 	%fd474, %fd472, %fd448, %fd473;
	mov.f64 	%fd475, 0d3FFA32A7AF17FAE9;
	fma.rn.f64 	%fd476, %fd474, %fd448, %fd475;
	mov.f64 	%fd477, 0dBFCAD32497785CD6;
	fma.rn.f64 	%fd478, %fd476, %fd448, %fd477;
	mov.f64 	%fd479, 0d3FB0AAAA9FB75F7B;
	fma.rn.f64 	%fd480, %fd478, %fd448, %fd479;
	mov.f64 	%fd481, 0dBFBFFFFFFFFE320F;
	fma.rn.f64 	%fd482, %fd480, %fd448, %fd481;
	fma.rn.f64 	%fd40, %fd482, %fd447, %fd2;
	rsqrt.approx.f64 	%fd483, %fd2;
	mul.f64 	%fd484, %fd483, 0d3FE9884533D43651;
	mul.f64 	%fd41, %fd463, %fd484;
	mul.f64 	%fd485, %fd40, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r103, %fd485;
	add.u64 	%rd17, %SP, 0;
	cvta.to.local.u64 	%rd18, %rd17;
	st.local.u32 	[%rd18], %r103;
	cvt.rn.f64.s32	%fd486, %r103;
	neg.f64 	%fd487, %fd486;
	mov.f64 	%fd488, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd489, %fd487, %fd488, %fd40;
	mov.f64 	%fd490, 0d3C91A62633145C00;
	fma.rn.f64 	%fd491, %fd487, %fd490, %fd489;
	mov.f64 	%fd492, 0d397B839A252049C0;
	fma.rn.f64 	%fd536, %fd487, %fd492, %fd491;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r76}, %fd40;
	}
	and.b32  	%r77, %r76, 2145386496;
	setp.lt.u32	%p24, %r77, 1105199104;
	@%p24 bra 	BB54_42;

	add.u64 	%rd34, %SP, 0;
	// Callseq Start 13
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd40;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd536, [retval0+0];
	
	//{
	}// Callseq End 13
	ld.local.u32 	%r103, [%rd18];

BB54_42:
	and.b32  	%r78, %r103, 3;
	cvt.rn.f64.s32	%fd493, %r78;
	add.f64 	%fd494, %fd536, 0dC002D97C7F3321D2;
	fma.rn.f64 	%fd537, %fd493, 0d3FF921FB54442D18, %fd494;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r79}, %fd537;
	}
	and.b32  	%r80, %r79, 2147483647;
	setp.ne.s32	%p25, %r80, 2146435072;
	@%p25 bra 	BB54_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r81, %temp}, %fd537;
	}
	setp.ne.s32	%p26, %r81, 0;
	@%p26 bra 	BB54_45;

	mov.f64 	%fd495, 0d0000000000000000;
	mul.rn.f64 	%fd537, %fd537, %fd495;

BB54_45:
	mov.f64 	%fd526, 0d397B839A252049C0;
	mov.f64 	%fd525, 0d3C91A62633145C00;
	mov.f64 	%fd524, 0d3FF921FB54442D18;
	mul.f64 	%fd496, %fd537, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r104, %fd496;
	st.local.u32 	[%rd18], %r104;
	cvt.rn.f64.s32	%fd497, %r104;
	neg.f64 	%fd498, %fd497;
	fma.rn.f64 	%fd500, %fd498, %fd524, %fd537;
	fma.rn.f64 	%fd502, %fd498, %fd525, %fd500;
	fma.rn.f64 	%fd538, %fd498, %fd526, %fd502;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r82}, %fd537;
	}
	and.b32  	%r83, %r82, 2145386496;
	setp.lt.u32	%p27, %r83, 1105199104;
	@%p27 bra 	BB54_47;

	add.u64 	%rd33, %SP, 0;
	// Callseq Start 14
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd537;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd33;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd538, [retval0+0];
	
	//{
	}// Callseq End 14
	ld.local.u32 	%r104, [%rd18];

BB54_47:
	add.s32 	%r28, %r104, 1;
	and.b32  	%r84, %r28, 1;
	shl.b32 	%r85, %r84, 3;
	setp.eq.s32	%p28, %r84, 0;
	selp.f64	%fd504, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p28;
	mul.wide.u32 	%rd25, %r85, 8;
	mov.u64 	%rd26, __cudart_sin_cos_coeffs;
	add.s64 	%rd27, %rd25, %rd26;
	ld.const.f64 	%fd505, [%rd27+8];
	mul.rn.f64 	%fd51, %fd538, %fd538;
	fma.rn.f64 	%fd506, %fd504, %fd51, %fd505;
	ld.const.f64 	%fd507, [%rd27+16];
	fma.rn.f64 	%fd508, %fd506, %fd51, %fd507;
	ld.const.f64 	%fd509, [%rd27+24];
	fma.rn.f64 	%fd510, %fd508, %fd51, %fd509;
	ld.const.f64 	%fd511, [%rd27+32];
	fma.rn.f64 	%fd512, %fd510, %fd51, %fd511;
	ld.const.f64 	%fd513, [%rd27+40];
	fma.rn.f64 	%fd514, %fd512, %fd51, %fd513;
	ld.const.f64 	%fd515, [%rd27+48];
	fma.rn.f64 	%fd52, %fd514, %fd51, %fd515;
	fma.rn.f64 	%fd539, %fd52, %fd538, %fd538;
	@%p28 bra 	BB54_49;

	mov.f64 	%fd527, 0d3FF0000000000000;
	fma.rn.f64 	%fd539, %fd52, %fd51, %fd527;

BB54_49:
	and.b32  	%r86, %r28, 2;
	setp.eq.s32	%p29, %r86, 0;
	@%p29 bra 	BB54_51;

	mov.f64 	%fd517, 0d0000000000000000;
	mov.f64 	%fd518, 0dBFF0000000000000;
	fma.rn.f64 	%fd539, %fd539, %fd518, %fd517;

BB54_51:
	mul.f64 	%fd540, %fd41, %fd539;
	bra.uni 	BB54_52;

BB54_4:
	mul.f64 	%fd60, %fd2, %fd2;
	mov.f64 	%fd61, 0dBD13098C51C18514;
	mov.f64 	%fd62, 0d3C8EFBD0A1B77C65;
	fma.rn.f64 	%fd63, %fd62, %fd60, %fd61;
	mov.f64 	%fd64, 0d3D923102D2F5F2F5;
	fma.rn.f64 	%fd65, %fd63, %fd60, %fd64;
	mov.f64 	%fd66, 0dBE0A5F2DEE7D526E;
	fma.rn.f64 	%fd67, %fd65, %fd60, %fd66;
	mov.f64 	%fd68, 0d3E7BB77E758B38AF;
	fma.rn.f64 	%fd69, %fd67, %fd60, %fd68;
	mov.f64 	%fd70, 0dBEE3D1A206EC4F36;
	fma.rn.f64 	%fd71, %fd69, %fd60, %fd70;
	mov.f64 	%fd72, 0d3F4183DCD3ED6294;
	fma.rn.f64 	%fd73, %fd71, %fd60, %fd72;
	mov.f64 	%fd74, 0dBF903921CF04F123;
	fma.rn.f64 	%fd75, %fd73, %fd60, %fd74;
	mov.f64 	%fd76, 0d3FC5DB69D7753176;
	fma.rn.f64 	%fd77, %fd75, %fd60, %fd76;
	add.f64 	%fd78, %fd60, 0dBFDBA96740000000;
	add.f64 	%fd79, %fd78, 0d3E15A30C80000000;
	mul.f64 	%fd3, %fd79, %fd77;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r98, %temp}, %fd2;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r97}, %fd2;
	}
	mov.u32 	%r99, -1023;
	setp.gt.s32	%p4, %r97, 1048575;
	mov.f64 	%fd528, %fd2;
	@%p4 bra 	BB54_6;

	mul.f64 	%fd4, %fd2, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r97}, %fd4;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r98, %temp}, %fd4;
	}
	mov.u32 	%r99, -1077;
	mov.f64 	%fd528, %fd4;

BB54_6:
	mov.f64 	%fd5, %fd528;
	add.s32 	%r48, %r97, -1;
	setp.lt.u32	%p5, %r48, 2146435071;
	@%p5 bra 	BB54_8;
	bra.uni 	BB54_7;

BB54_8:
	shr.u32 	%r50, %r97, 20;
	add.s32 	%r100, %r99, %r50;
	and.b32  	%r51, %r97, -2146435073;
	or.b32  	%r52, %r51, 1072693248;
	mov.b64 	%fd529, {%r98, %r52};
	setp.lt.s32	%p7, %r52, 1073127583;
	@%p7 bra 	BB54_10;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r53, %temp}, %fd529;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r54}, %fd529;
	}
	add.s32 	%r55, %r54, -1048576;
	mov.b64 	%fd529, {%r53, %r55};
	add.s32 	%r100, %r100, 1;

BB54_10:
	add.f64 	%fd83, %fd529, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd82,%fd83;
	// inline asm
	neg.f64 	%fd84, %fd83;
	mov.f64 	%fd85, 0d3FF0000000000000;
	fma.rn.f64 	%fd86, %fd84, %fd82, %fd85;
	fma.rn.f64 	%fd87, %fd86, %fd86, %fd86;
	fma.rn.f64 	%fd88, %fd87, %fd82, %fd82;
	add.f64 	%fd89, %fd529, 0dBFF0000000000000;
	mul.f64 	%fd90, %fd89, %fd88;
	fma.rn.f64 	%fd91, %fd89, %fd88, %fd90;
	mul.f64 	%fd92, %fd91, %fd91;
	mov.f64 	%fd93, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd94, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd95, %fd94, %fd92, %fd93;
	mov.f64 	%fd96, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd97, %fd95, %fd92, %fd96;
	mov.f64 	%fd98, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd99, %fd97, %fd92, %fd98;
	mov.f64 	%fd100, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd101, %fd99, %fd92, %fd100;
	mov.f64 	%fd102, 0d3F624924923BE72D;
	fma.rn.f64 	%fd103, %fd101, %fd92, %fd102;
	mov.f64 	%fd104, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd105, %fd103, %fd92, %fd104;
	mov.f64 	%fd106, 0d3FB5555555555554;
	fma.rn.f64 	%fd107, %fd105, %fd92, %fd106;
	sub.f64 	%fd108, %fd89, %fd91;
	add.f64 	%fd109, %fd108, %fd108;
	neg.f64 	%fd110, %fd91;
	fma.rn.f64 	%fd111, %fd110, %fd89, %fd109;
	mul.f64 	%fd112, %fd88, %fd111;
	mul.f64 	%fd113, %fd92, %fd107;
	fma.rn.f64 	%fd114, %fd113, %fd91, %fd112;
	xor.b32  	%r56, %r100, -2147483648;
	mov.u32 	%r57, 1127219200;
	mov.b64 	%fd115, {%r56, %r57};
	mov.u32 	%r58, -2147483648;
	mov.b64 	%fd116, {%r58, %r57};
	sub.f64 	%fd117, %fd115, %fd116;
	mov.f64 	%fd118, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd119, %fd117, %fd118, %fd91;
	neg.f64 	%fd120, %fd117;
	fma.rn.f64 	%fd121, %fd120, %fd118, %fd119;
	sub.f64 	%fd122, %fd121, %fd91;
	sub.f64 	%fd123, %fd114, %fd122;
	mov.f64 	%fd124, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd125, %fd117, %fd124, %fd123;
	add.f64 	%fd530, %fd119, %fd125;
	bra.uni 	BB54_11;

BB54_33:
	add.f64 	%fd309, %fd2, 0dBFEC982EB8D417EA;
	add.f64 	%fd310, %fd309, 0dBC7EA9D270347F83;
	mov.f64 	%fd311, 0d3F3D054B05D3C52D;
	mov.f64 	%fd312, 0dBF01630132D75FC3;
	fma.rn.f64 	%fd313, %fd312, %fd310, %fd311;
	mov.f64 	%fd314, 0dBF66DAC0B314B2E5;
	fma.rn.f64 	%fd315, %fd313, %fd310, %fd314;
	mov.f64 	%fd316, 0d3F86A5D1DE76263F;
	fma.rn.f64 	%fd317, %fd315, %fd310, %fd316;
	mov.f64 	%fd318, 0dBF9FD16652824592;
	fma.rn.f64 	%fd319, %fd317, %fd310, %fd318;
	mov.f64 	%fd320, 0d3FB0F69A9CC79FBD;
	fma.rn.f64 	%fd321, %fd319, %fd310, %fd320;
	mov.f64 	%fd322, 0dBFBCCE40EF15583E;
	fma.rn.f64 	%fd323, %fd321, %fd310, %fd322;
	mov.f64 	%fd324, 0d3FC446B11780E4FC;
	fma.rn.f64 	%fd325, %fd323, %fd310, %fd324;
	mov.f64 	%fd326, 0dBFC89AE7E19621F7;
	fma.rn.f64 	%fd327, %fd325, %fd310, %fd326;
	mov.f64 	%fd328, 0d3FCACBA1B38EF7B8;
	fma.rn.f64 	%fd329, %fd327, %fd310, %fd328;
	mov.f64 	%fd330, 0dBFCB4166A03BBFA5;
	fma.rn.f64 	%fd331, %fd329, %fd310, %fd330;
	mov.f64 	%fd332, 0d3FCACCA4D5D4889A;
	fma.rn.f64 	%fd333, %fd331, %fd310, %fd332;
	mov.f64 	%fd334, 0dBFCA1455932B9392;
	fma.rn.f64 	%fd335, %fd333, %fd310, %fd334;
	mov.f64 	%fd336, 0d3FC96D8DB8D844EC;
	fma.rn.f64 	%fd337, %fd335, %fd310, %fd336;
	mov.f64 	%fd338, 0dBFC8F7FB77522EDF;
	fma.rn.f64 	%fd339, %fd337, %fd310, %fd338;
	mov.f64 	%fd340, 0d3FC8C0926ABC9AB0;
	fma.rn.f64 	%fd341, %fd339, %fd310, %fd340;
	mov.f64 	%fd342, 0dBFC8D35B8FEA468C;
	fma.rn.f64 	%fd343, %fd341, %fd310, %fd342;
	mov.f64 	%fd344, 0d3FC9424B8A0C8F94;
	fma.rn.f64 	%fd345, %fd343, %fd310, %fd344;
	mov.f64 	%fd346, 0dBFCA396A7F3403EF;
	fma.rn.f64 	%fd347, %fd345, %fd310, %fd346;
	mov.f64 	%fd348, 0d3FCC068086C37055;
	fma.rn.f64 	%fd349, %fd347, %fd310, %fd348;
	mov.f64 	%fd350, 0dBFCCF18E6A4C5C4E;
	fma.rn.f64 	%fd351, %fd349, %fd310, %fd350;
	mov.f64 	%fd352, 0d3FCC3B1338AF4239;
	fma.rn.f64 	%fd353, %fd351, %fd310, %fd352;
	mov.f64 	%fd354, 0dBFDF7E38A46D70DB;
	fma.rn.f64 	%fd355, %fd353, %fd310, %fd354;
	mov.f64 	%fd356, 0d3FEC24371844B88A;
	fma.rn.f64 	%fd357, %fd355, %fd310, %fd356;
	mul.f64 	%fd540, %fd310, %fd357;
	bra.uni 	BB54_52;

BB54_7:
	mov.f64 	%fd80, 0d7FF0000000000000;
	fma.rn.f64 	%fd81, %fd5, %fd80, %fd80;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r49}, %fd5;
	}
	mov.b32 	 %f1, %r49;
	setp.eq.f32	%p6, %f1, 0f00000000;
	selp.f64	%fd530, 0dFFF0000000000000, %fd81, %p6;

BB54_11:
	abs.f64 	%fd12, %fd2;
	setp.gtu.f64	%p8, %fd12, 0d400FB319F277BBE5;
	@%p8 bra 	BB54_13;
	bra.uni 	BB54_12;

BB54_13:
	setp.gtu.f64	%p9, %fd12, 0d401C58FD1A62F5EC;
	@%p9 bra 	BB54_15;
	bra.uni 	BB54_14;

BB54_15:
	setp.gtu.f64	%p10, %fd12, 0d402471FCB6A7A8C0;
	@%p10 bra 	BB54_17;
	bra.uni 	BB54_16;

BB54_17:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r59}, %fd12;
	}
	and.b32  	%r60, %r59, 2147483647;
	setp.ne.s32	%p11, %r60, 2146435072;
	@%p11 bra 	BB54_19;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r61, %temp}, %fd12;
	}
	setp.eq.s32	%p12, %r61, 0;
	mov.f64 	%fd535, 0d0000000000000000;
	@%p12 bra 	BB54_31;

BB54_19:
	// inline asm
	rcp.approx.ftz.f64 %fd232,%fd12;
	// inline asm
	neg.f64 	%fd234, %fd12;
	mov.f64 	%fd235, 0d3FF0000000000000;
	fma.rn.f64 	%fd236, %fd234, %fd232, %fd235;
	fma.rn.f64 	%fd237, %fd236, %fd236, %fd236;
	fma.rn.f64 	%fd238, %fd237, %fd232, %fd232;
	mul.f64 	%fd239, %fd238, %fd238;
	mov.f64 	%fd240, 0d409927467A655012;
	mov.f64 	%fd241, 0dC0D115CB8C11A9DC;
	fma.rn.f64 	%fd242, %fd241, %fd239, %fd240;
	mov.f64 	%fd243, 0dC05751787E247BD4;
	fma.rn.f64 	%fd244, %fd242, %fd239, %fd243;
	mov.f64 	%fd245, 0d401704C4E5FC36B2;
	fma.rn.f64 	%fd246, %fd244, %fd239, %fd245;
	mov.f64 	%fd247, 0dBFE15B747A2FD531;
	fma.rn.f64 	%fd248, %fd246, %fd239, %fd247;
	mov.f64 	%fd249, 0d3FBA7FEACF6CB79B;
	fma.rn.f64 	%fd250, %fd248, %fd239, %fd249;
	mov.f64 	%fd251, 0dBFAFFFFFEDDCF548;
	fma.rn.f64 	%fd252, %fd250, %fd239, %fd251;
	mov.f64 	%fd253, 0d3FEFFFFFFFFFC9E5;
	fma.rn.f64 	%fd254, %fd252, %fd239, %fd253;
	mov.f64 	%fd255, 0d410ECD4523B12B84;
	mov.f64 	%fd256, 0dC14602FE1C34685E;
	fma.rn.f64 	%fd257, %fd256, %fd239, %fd255;
	mov.f64 	%fd258, 0dC0C7A2FC1972F05A;
	fma.rn.f64 	%fd259, %fd257, %fd239, %fd258;
	mov.f64 	%fd260, 0d407EBA131F7E5BEB;
	fma.rn.f64 	%fd261, %fd259, %fd239, %fd260;
	mov.f64 	%fd262, 0dC0373B92E6E7CC7D;
	fma.rn.f64 	%fd263, %fd261, %fd239, %fd262;
	mov.f64 	%fd264, 0d3FFA31BEE63A2F08;
	fma.rn.f64 	%fd265, %fd263, %fd239, %fd264;
	mov.f64 	%fd266, 0dBFCAD320104D5D05;
	fma.rn.f64 	%fd267, %fd265, %fd239, %fd266;
	mov.f64 	%fd268, 0d3FB0AAAA9C76D07E;
	fma.rn.f64 	%fd269, %fd267, %fd239, %fd268;
	mov.f64 	%fd270, 0dBFBFFFFFFFFDACEC;
	fma.rn.f64 	%fd271, %fd269, %fd239, %fd270;
	fma.rn.f64 	%fd16, %fd271, %fd238, %fd12;
	rsqrt.approx.f64 	%fd272, %fd12;
	mul.f64 	%fd273, %fd272, 0d3FE9884533D43651;
	mul.f64 	%fd17, %fd254, %fd273;
	mul.f64 	%fd274, %fd16, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r101, %fd274;
	add.u64 	%rd6, %SP, 0;
	cvta.to.local.u64 	%rd7, %rd6;
	st.local.u32 	[%rd7], %r101;
	cvt.rn.f64.s32	%fd275, %r101;
	neg.f64 	%fd276, %fd275;
	mov.f64 	%fd277, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd278, %fd276, %fd277, %fd16;
	mov.f64 	%fd279, 0d3C91A62633145C00;
	fma.rn.f64 	%fd280, %fd276, %fd279, %fd278;
	mov.f64 	%fd281, 0d397B839A252049C0;
	fma.rn.f64 	%fd531, %fd276, %fd281, %fd280;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r62}, %fd16;
	}
	and.b32  	%r63, %r62, 2145386496;
	setp.lt.u32	%p13, %r63, 1105199104;
	@%p13 bra 	BB54_21;

	add.u64 	%rd32, %SP, 0;
	// Callseq Start 11
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd16;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd32;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd531, [retval0+0];
	
	//{
	}// Callseq End 11
	ld.local.u32 	%r101, [%rd7];

BB54_21:
	and.b32  	%r64, %r101, 3;
	cvt.rn.f64.s32	%fd282, %r64;
	add.f64 	%fd283, %fd531, 0dBFE921FB54442D18;
	fma.rn.f64 	%fd532, %fd282, 0d3FF921FB54442D18, %fd283;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r65}, %fd532;
	}
	and.b32  	%r66, %r65, 2147483647;
	setp.ne.s32	%p14, %r66, 2146435072;
	@%p14 bra 	BB54_24;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r67, %temp}, %fd532;
	}
	setp.ne.s32	%p15, %r67, 0;
	@%p15 bra 	BB54_24;

	mov.f64 	%fd284, 0d0000000000000000;
	mul.rn.f64 	%fd532, %fd532, %fd284;

BB54_24:
	mov.f64 	%fd522, 0d397B839A252049C0;
	mov.f64 	%fd521, 0d3C91A62633145C00;
	mov.f64 	%fd520, 0d3FF921FB54442D18;
	mul.f64 	%fd285, %fd532, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r102, %fd285;
	st.local.u32 	[%rd7], %r102;
	cvt.rn.f64.s32	%fd286, %r102;
	neg.f64 	%fd287, %fd286;
	fma.rn.f64 	%fd289, %fd287, %fd520, %fd532;
	fma.rn.f64 	%fd291, %fd287, %fd521, %fd289;
	fma.rn.f64 	%fd533, %fd287, %fd522, %fd291;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r68}, %fd532;
	}
	and.b32  	%r69, %r68, 2145386496;
	setp.lt.u32	%p16, %r69, 1105199104;
	@%p16 bra 	BB54_26;

	add.u64 	%rd31, %SP, 0;
	// Callseq Start 12
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd532;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd31;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd533, [retval0+0];
	
	//{
	}// Callseq End 12
	ld.local.u32 	%r102, [%rd7];

BB54_26:
	add.s32 	%r21, %r102, 1;
	and.b32  	%r70, %r21, 1;
	shl.b32 	%r71, %r70, 3;
	setp.eq.s32	%p17, %r70, 0;
	selp.f64	%fd293, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p17;
	mul.wide.u32 	%rd14, %r71, 8;
	mov.u64 	%rd15, __cudart_sin_cos_coeffs;
	add.s64 	%rd16, %rd14, %rd15;
	ld.const.f64 	%fd294, [%rd16+8];
	mul.rn.f64 	%fd27, %fd533, %fd533;
	fma.rn.f64 	%fd295, %fd293, %fd27, %fd294;
	ld.const.f64 	%fd296, [%rd16+16];
	fma.rn.f64 	%fd297, %fd295, %fd27, %fd296;
	ld.const.f64 	%fd298, [%rd16+24];
	fma.rn.f64 	%fd299, %fd297, %fd27, %fd298;
	ld.const.f64 	%fd300, [%rd16+32];
	fma.rn.f64 	%fd301, %fd299, %fd27, %fd300;
	ld.const.f64 	%fd302, [%rd16+40];
	fma.rn.f64 	%fd303, %fd301, %fd27, %fd302;
	ld.const.f64 	%fd304, [%rd16+48];
	fma.rn.f64 	%fd28, %fd303, %fd27, %fd304;
	fma.rn.f64 	%fd534, %fd28, %fd533, %fd533;
	@%p17 bra 	BB54_28;

	mov.f64 	%fd523, 0d3FF0000000000000;
	fma.rn.f64 	%fd534, %fd28, %fd27, %fd523;

BB54_28:
	and.b32  	%r72, %r21, 2;
	setp.eq.s32	%p18, %r72, 0;
	@%p18 bra 	BB54_30;

	mov.f64 	%fd306, 0d0000000000000000;
	mov.f64 	%fd307, 0dBFF0000000000000;
	fma.rn.f64 	%fd534, %fd534, %fd307, %fd306;

BB54_30:
	mul.f64 	%fd535, %fd17, %fd534;
	bra.uni 	BB54_31;

BB54_12:
	add.f64 	%fd126, %fd12, 0dC0033D152E971B40;
	add.f64 	%fd127, %fd126, 0d3CA0F539D7DA258E;
	mov.f64 	%fd128, 0dBCFCF8F9A8C294BC;
	mov.f64 	%fd129, 0dBCC0D18564C48C61;
	fma.rn.f64 	%fd130, %fd129, %fd127, %fd128;
	mov.f64 	%fd131, 0d3D3FAB983CAE498B;
	fma.rn.f64 	%fd132, %fd130, %fd127, %fd131;
	mov.f64 	%fd133, 0d3D7CD7C018579B88;
	fma.rn.f64 	%fd134, %fd132, %fd127, %fd133;
	mov.f64 	%fd135, 0dBDBBDD2342D64FDD;
	fma.rn.f64 	%fd136, %fd134, %fd127, %fd135;
	mov.f64 	%fd137, 0dBDF5C2D9416B1E2B;
	fma.rn.f64 	%fd138, %fd136, %fd127, %fd137;
	mov.f64 	%fd139, 0d3E32951D73174DD5;
	fma.rn.f64 	%fd140, %fd138, %fd127, %fd139;
	mov.f64 	%fd141, 0d3E67FF99802CAEB5;
	fma.rn.f64 	%fd142, %fd140, %fd127, %fd141;
	mov.f64 	%fd143, 0dBEA1CCE305C4C9F7;
	fma.rn.f64 	%fd144, %fd142, %fd127, %fd143;
	mov.f64 	%fd145, 0dBED232C77E29E1BB;
	fma.rn.f64 	%fd146, %fd144, %fd127, %fd145;
	mov.f64 	%fd147, 0d3F06ED3B9F0EF757;
	fma.rn.f64 	%fd148, %fd146, %fd127, %fd147;
	mov.f64 	%fd149, 0d3F315382BA096A62;
	fma.rn.f64 	%fd150, %fd148, %fd127, %fd149;
	mov.f64 	%fd151, 0dBF61F992590D1AE4;
	fma.rn.f64 	%fd152, %fd150, %fd127, %fd151;
	mov.f64 	%fd153, 0dBF81BB1CBE1A465F;
	fma.rn.f64 	%fd154, %fd152, %fd127, %fd153;
	mov.f64 	%fd155, 0d3FACFAE864368D84;
	fma.rn.f64 	%fd156, %fd154, %fd127, %fd155;
	mov.f64 	%fd157, 0d3FBBA1DEEA0294A3;
	fma.rn.f64 	%fd158, %fd156, %fd127, %fd157;
	mov.f64 	%fd159, 0dBFE09CDB36551280;
	fma.rn.f64 	%fd160, %fd158, %fd127, %fd159;
	mul.f64 	%fd535, %fd127, %fd160;
	bra.uni 	BB54_31;

BB54_35:
	add.f64 	%fd358, %fd2, 0dC00FA9534D98569C;
	add.f64 	%fd359, %fd358, 0d3C9F06AE7804384E;
	mov.f64 	%fd360, 0dBCD2434958151AC7;
	mov.f64 	%fd361, 0dBCDAEA62AC8BDA68;
	fma.rn.f64 	%fd362, %fd361, %fd359, %fd360;
	mov.f64 	%fd363, 0d3D11C24A40D33FE1;
	fma.rn.f64 	%fd364, %fd362, %fd359, %fd363;
	mov.f64 	%fd365, 0d3D237CD62FA08CA4;
	fma.rn.f64 	%fd366, %fd364, %fd359, %fd365;
	mov.f64 	%fd367, 0dBD43902E0298C52A;
	fma.rn.f64 	%fd368, %fd366, %fd359, %fd367;
	mov.f64 	%fd369, 0dBD1DDAAD11CAB40F;
	fma.rn.f64 	%fd370, %fd368, %fd359, %fd369;
	mov.f64 	%fd371, 0dBD5209D9F06D7DE4;
	fma.rn.f64 	%fd372, %fd370, %fd359, %fd371;
	mov.f64 	%fd373, 0d3D8BB9F464468E1A;
	fma.rn.f64 	%fd374, %fd372, %fd359, %fd373;
	mov.f64 	%fd375, 0dBDA8F67B07D1B440;
	fma.rn.f64 	%fd376, %fd374, %fd359, %fd375;
	mov.f64 	%fd377, 0d3DC7C8D60F9EAECF;
	fma.rn.f64 	%fd378, %fd376, %fd359, %fd377;
	mov.f64 	%fd379, 0dBDE9703405B49A8D;
	fma.rn.f64 	%fd380, %fd378, %fd359, %fd379;
	mov.f64 	%fd381, 0d3E0A6B64E76417E4;
	fma.rn.f64 	%fd382, %fd380, %fd359, %fd381;
	mov.f64 	%fd383, 0dBE2F6B5AFB2F1359;
	fma.rn.f64 	%fd384, %fd382, %fd359, %fd383;
	mov.f64 	%fd385, 0d3E54526B71C21EC1;
	fma.rn.f64 	%fd386, %fd384, %fd359, %fd385;
	mov.f64 	%fd387, 0dBE5776DBCBBC8E1D;
	fma.rn.f64 	%fd388, %fd386, %fd359, %fd387;
	mov.f64 	%fd389, 0dBE93B211FC2DF90E;
	fma.rn.f64 	%fd390, %fd388, %fd359, %fd389;
	mov.f64 	%fd391, 0dBED486372E8562DC;
	fma.rn.f64 	%fd392, %fd390, %fd359, %fd391;
	mov.f64 	%fd393, 0d3F0AB2C1FBC3A254;
	fma.rn.f64 	%fd394, %fd392, %fd359, %fd393;
	mov.f64 	%fd395, 0d3F299827653353B8;
	fma.rn.f64 	%fd396, %fd394, %fd359, %fd395;
	mov.f64 	%fd397, 0dBF61E32BC4ED7084;
	fma.rn.f64 	%fd398, %fd396, %fd359, %fd397;
	mov.f64 	%fd399, 0dBF7C116FDC599A09;
	fma.rn.f64 	%fd400, %fd398, %fd359, %fd399;
	mov.f64 	%fd401, 0d3FADF6D59BF50C77;
	fma.rn.f64 	%fd402, %fd400, %fd359, %fd401;
	mov.f64 	%fd403, 0d3FAA09C92903680B;
	fma.rn.f64 	%fd404, %fd402, %fd359, %fd403;
	mov.f64 	%fd405, 0dBFD9C34256A12A0B;
	fma.rn.f64 	%fd406, %fd404, %fd359, %fd405;
	mul.f64 	%fd540, %fd359, %fd406;
	bra.uni 	BB54_52;

BB54_14:
	add.f64 	%fd161, %fd12, 0dC016148F5B2C2E45;
	add.f64 	%fd162, %fd161, 0dBC975054CD60A517;
	mov.f64 	%fd163, 0d3CF83FD1F333EB61;
	mov.f64 	%fd164, 0d3CBCB0A8F126B343;
	fma.rn.f64 	%fd165, %fd164, %fd162, %fd163;
	mov.f64 	%fd166, 0dBD4100E33E3FB413;
	fma.rn.f64 	%fd167, %fd165, %fd162, %fd166;
	mov.f64 	%fd168, 0dBD7846076D004627;
	fma.rn.f64 	%fd169, %fd167, %fd162, %fd168;
	mov.f64 	%fd170, 0d3DBE2F1D4F90720D;
	fma.rn.f64 	%fd171, %fd169, %fd162, %fd170;
	mov.f64 	%fd172, 0d3DF1D03B1E4A119B;
	fma.rn.f64 	%fd173, %fd171, %fd162, %fd172;
	mov.f64 	%fd174, 0dBE341D72B1B3BCE9;
	fma.rn.f64 	%fd175, %fd173, %fd162, %fd174;
	mov.f64 	%fd176, 0dBE62DA37CE2A9EF8;
	fma.rn.f64 	%fd177, %fd175, %fd162, %fd176;
	mov.f64 	%fd178, 0d3EA32E6D9974F763;
	fma.rn.f64 	%fd179, %fd177, %fd162, %fd178;
	mov.f64 	%fd180, 0d3ECAD77D744A1879;
	fma.rn.f64 	%fd181, %fd179, %fd162, %fd180;
	mov.f64 	%fd182, 0dBF0863F481A37337;
	fma.rn.f64 	%fd183, %fd181, %fd162, %fd182;
	mov.f64 	%fd184, 0dBF26F641F418F0F4;
	fma.rn.f64 	%fd185, %fd183, %fd162, %fd184;
	mov.f64 	%fd186, 0d3F627E31FE9A969E;
	fma.rn.f64 	%fd187, %fd185, %fd162, %fd186;
	mov.f64 	%fd188, 0d3F72F7FFE9025628;
	fma.rn.f64 	%fd189, %fd187, %fd162, %fd188;
	mov.f64 	%fd190, 0dBFAB2150CB41E8BF;
	fma.rn.f64 	%fd191, %fd189, %fd162, %fd190;
	mov.f64 	%fd192, 0dBF9F8F72E7A848DE;
	fma.rn.f64 	%fd193, %fd191, %fd162, %fd192;
	mov.f64 	%fd194, 0d3FD5C6E60A097823;
	fma.rn.f64 	%fd195, %fd193, %fd162, %fd194;
	mul.f64 	%fd535, %fd162, %fd195;
	bra.uni 	BB54_31;

BB54_37:
	add.f64 	%fd407, %fd2, 0dC01C581DC4E72103;
	add.f64 	%fd408, %fd407, 0d3C99774A495F56CF;
	mov.f64 	%fd409, 0dBD3F443BB4F53D75;
	mov.f64 	%fd410, 0d3CF1CB3ABA718B8E;
	fma.rn.f64 	%fd411, %fd410, %fd408, %fd409;
	mov.f64 	%fd412, 0dBD770F737BD6A786;
	fma.rn.f64 	%fd413, %fd411, %fd408, %fd412;
	mov.f64 	%fd414, 0d3DBF0E9A20459E14;
	fma.rn.f64 	%fd415, %fd413, %fd408, %fd414;
	mov.f64 	%fd416, 0d3DEFA6B137D5E108;
	fma.rn.f64 	%fd417, %fd415, %fd408, %fd416;
	mov.f64 	%fd418, 0dBE344296729FB7FA;
	fma.rn.f64 	%fd419, %fd417, %fd408, %fd418;
	mov.f64 	%fd420, 0dBE60A2813A80DFAA;
	fma.rn.f64 	%fd421, %fd419, %fd408, %fd420;
	mov.f64 	%fd422, 0d3EA34AA737A83EB4;
	fma.rn.f64 	%fd423, %fd421, %fd408, %fd422;
	mov.f64 	%fd424, 0d3EC6A9227332D03C;
	fma.rn.f64 	%fd425, %fd423, %fd408, %fd424;
	mov.f64 	%fd426, 0dBF08177E4F93C81E;
	fma.rn.f64 	%fd427, %fd425, %fd408, %fd426;
	mov.f64 	%fd428, 0dBF226DD71E391775;
	fma.rn.f64 	%fd429, %fd427, %fd408, %fd428;
	mov.f64 	%fd430, 0d3F61D35E85FD7B22;
	fma.rn.f64 	%fd431, %fd429, %fd408, %fd430;
	mov.f64 	%fd432, 0d3F6B2F14A955285C;
	fma.rn.f64 	%fd433, %fd431, %fd408, %fd432;
	mov.f64 	%fd434, 0dBFA8969C64CBF388;
	fma.rn.f64 	%fd435, %fd433, %fd408, %fd434;
	mov.f64 	%fd436, 0dBF95AEF611FC4D5A;
	fma.rn.f64 	%fd437, %fd435, %fd408, %fd436;
	mov.f64 	%fd438, 0d3FD334CCA0697A5A;
	fma.rn.f64 	%fd439, %fd437, %fd408, %fd438;
	mul.f64 	%fd540, %fd408, %fd439;
	bra.uni 	BB54_52;

BB54_16:
	add.f64 	%fd196, %fd12, 0dC0214EB56CCCDECA;
	add.f64 	%fd197, %fd196, 0d3CB51970714C7C25;
	mov.f64 	%fd198, 0dBCF4B3A71AAAC629;
	mov.f64 	%fd199, 0dBCBDB7FFCF659E24;
	fma.rn.f64 	%fd200, %fd199, %fd197, %fd198;
	mov.f64 	%fd201, 0d3D417EC150ECDCE7;
	fma.rn.f64 	%fd202, %fd200, %fd197, %fd201;
	mov.f64 	%fd203, 0d3D7438F5EA1D10B2;
	fma.rn.f64 	%fd204, %fd202, %fd197, %fd203;
	mov.f64 	%fd205, 0dBDBEDAE7EC2C9E87;
	fma.rn.f64 	%fd206, %fd204, %fd197, %fd205;
	mov.f64 	%fd207, 0dBDECADD2C4B91F58;
	fma.rn.f64 	%fd208, %fd206, %fd197, %fd207;
	mov.f64 	%fd209, 0d3E34582C8EE12204;
	fma.rn.f64 	%fd210, %fd208, %fd197, %fd209;
	mov.f64 	%fd211, 0d3E5CEDA451DD20F8;
	fma.rn.f64 	%fd212, %fd210, %fd197, %fd211;
	mov.f64 	%fd213, 0dBEA30E8CC3165E2F;
	fma.rn.f64 	%fd214, %fd212, %fd197, %fd213;
	mov.f64 	%fd215, 0dBEC3324842BB1A2E;
	fma.rn.f64 	%fd216, %fd214, %fd197, %fd215;
	mov.f64 	%fd217, 0d3F07800BC54FBDDB;
	fma.rn.f64 	%fd218, %fd216, %fd197, %fd217;
	mov.f64 	%fd219, 0d3F1D79605276949A;
	fma.rn.f64 	%fd220, %fd218, %fd197, %fd219;
	mov.f64 	%fd221, 0dBF60E0D60385A629;
	fma.rn.f64 	%fd222, %fd220, %fd197, %fd221;
	mov.f64 	%fd223, 0dBF648E63600D82F3;
	fma.rn.f64 	%fd224, %fd222, %fd197, %fd223;
	mov.f64 	%fd225, 0d3FA68B984EC6493A;
	fma.rn.f64 	%fd226, %fd224, %fd197, %fd225;
	mov.f64 	%fd227, 0d3F900F7FCF183E0B;
	fma.rn.f64 	%fd228, %fd226, %fd197, %fd227;
	mov.f64 	%fd229, 0dBFD15F7977A772D4;
	fma.rn.f64 	%fd230, %fd228, %fd197, %fd229;
	mul.f64 	%fd535, %fd197, %fd230;

BB54_31:
	mul.f64 	%fd308, %fd530, 0d3FE45F306DC9C883;
	fma.rn.f64 	%fd540, %fd308, %fd535, %fd3;

BB54_52:
	mov.u32 	%r93, %ntid.y;
	ld.param.u32 	%r92, [map_y0_double_param_3];
	setp.lt.f64	%p30, %fd1, 0d0000000000000000;
	selp.f64	%fd519, 0dFFF8000000000000, %fd540, %p30;
	mad.lo.s32 	%r87, %r95, %r92, %r96;
	mul.wide.s32 	%rd29, %r87, 8;
	add.s64 	%rd30, %rd28, %rd29;
	st.global.f64 	[%rd30], %fd519;
	mov.u32 	%r89, %nctaid.y;
	mad.lo.s32 	%r96, %r89, %r93, %r96;
	setp.lt.s32	%p31, %r96, %r31;
	@%p31 bra 	BB54_3;

BB54_53:
	mov.u32 	%r90, %nctaid.x;
	mad.lo.s32 	%r95, %r90, %r35, %r95;
	setp.lt.s32	%p32, %r95, %r32;
	@%p32 bra 	BB54_2;

BB54_54:
	ret;
}

	// .globl	map_y1_double
.visible .entry map_y1_double(
	.param .u32 map_y1_double_param_0,
	.param .u32 map_y1_double_param_1,
	.param .u64 map_y1_double_param_2,
	.param .u32 map_y1_double_param_3,
	.param .u64 map_y1_double_param_4,
	.param .u32 map_y1_double_param_5
)
{
	.local .align 4 .b8 	__local_depot55[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<37>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<107>;
	.reg .f64 	%fd<534>;
	.reg .b64 	%rd<36>;


	mov.u64 	%rd35, __local_depot55;
	cvta.local.u64 	%SP, %rd35;
	ld.param.u32 	%r31, [map_y1_double_param_0];
	ld.param.u32 	%r32, [map_y1_double_param_1];
	ld.param.u64 	%rd1, [map_y1_double_param_2];
	ld.param.u64 	%rd2, [map_y1_double_param_4];
	mov.u32 	%r35, %ntid.x;
	mov.u32 	%r36, %ctaid.x;
	mov.u32 	%r37, %tid.x;
	mad.lo.s32 	%r97, %r35, %r36, %r37;
	setp.ge.s32	%p1, %r97, %r32;
	@%p1 bra 	BB55_58;

	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd28, %rd1;

BB55_2:
	mov.u32 	%r38, %ctaid.y;
	mov.u32 	%r39, %ntid.y;
	mov.u32 	%r40, %tid.y;
	mad.lo.s32 	%r98, %r39, %r38, %r40;
	setp.ge.s32	%p2, %r98, %r31;
	@%p2 bra 	BB55_57;

BB55_3:
	ld.param.u32 	%r94, [map_y1_double_param_5];
	mad.lo.s32 	%r45, %r97, %r94, %r98;
	mul.wide.s32 	%rd4, %r45, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	abs.f64 	%fd2, %fd1;
	setp.lt.f64	%p3, %fd2, 0d000730D67819E8D2;
	@%p3 bra 	BB55_53;
	bra.uni 	BB55_4;

BB55_53:
	mov.f64 	%fd512, 0dBFE45F306DC9C883;
	div.rn.f64 	%fd533, %fd512, %fd2;
	bra.uni 	BB55_54;

BB55_4:
	setp.gtu.f64	%p4, %fd2, 0d3FF4C6F208132576;
	@%p4 bra 	BB55_33;
	bra.uni 	BB55_5;

BB55_33:
	setp.gtu.f64	%p22, %fd2, 0d4009B510EC2ADC83;
	@%p22 bra 	BB55_35;
	bra.uni 	BB55_34;

BB55_35:
	setp.gtu.f64	%p23, %fd2, 0d401C0D26D5A541CB;
	@%p23 bra 	BB55_37;
	bra.uni 	BB55_36;

BB55_37:
	setp.gtu.f64	%p24, %fd2, 0d4022585C739ACDDD;
	@%p24 bra 	BB55_39;
	bra.uni 	BB55_38;

BB55_39:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r73}, %fd2;
	}
	and.b32  	%r74, %r73, 2147483647;
	setp.ne.s32	%p25, %r74, 2146435072;
	@%p25 bra 	BB55_41;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r75, %temp}, %fd2;
	}
	setp.eq.s32	%p26, %r75, 0;
	mov.f64 	%fd533, 0d0000000000000000;
	@%p26 bra 	BB55_54;

BB55_41:
	// inline asm
	rcp.approx.ftz.f64 %fd434,%fd2;
	// inline asm
	neg.f64 	%fd436, %fd2;
	mov.f64 	%fd437, 0d3FF0000000000000;
	fma.rn.f64 	%fd438, %fd436, %fd434, %fd437;
	fma.rn.f64 	%fd439, %fd438, %fd438, %fd438;
	fma.rn.f64 	%fd440, %fd439, %fd434, %fd434;
	mul.f64 	%fd441, %fd440, %fd440;
	mov.f64 	%fd442, 0dC09C26E89385D5B1;
	mov.f64 	%fd443, 0d40D13DB326ECEBFE;
	fma.rn.f64 	%fd444, %fd443, %fd441, %fd442;
	mov.f64 	%fd445, 0d405C6AB923C6F55E;
	fma.rn.f64 	%fd446, %fd444, %fd441, %fd445;
	mov.f64 	%fd447, 0dC01E61EAF3BD2FA1;
	fma.rn.f64 	%fd448, %fd446, %fd441, %fd447;
	mov.f64 	%fd449, 0d3FE9BF15D9B97DD1;
	fma.rn.f64 	%fd450, %fd448, %fd441, %fd449;
	mov.f64 	%fd451, 0dBFC8BFECF93D7D19;
	fma.rn.f64 	%fd452, %fd450, %fd441, %fd451;
	mov.f64 	%fd453, 0d3FC7FFFFF756AA6C;
	fma.rn.f64 	%fd454, %fd452, %fd441, %fd453;
	mov.f64 	%fd455, 0d3FF0000000003646;
	fma.rn.f64 	%fd456, %fd454, %fd441, %fd455;
	mov.f64 	%fd457, 0d416024E99BA46E7B;
	mov.f64 	%fd458, 0dC1943281A050209C;
	fma.rn.f64 	%fd459, %fd458, %fd441, %fd457;
	mov.f64 	%fd460, 0dC11A6875D7DFBD65;
	fma.rn.f64 	%fd461, %fd459, %fd441, %fd460;
	mov.f64 	%fd462, 0d40D032C041790233;
	fma.rn.f64 	%fd463, %fd461, %fd441, %fd462;
	mov.f64 	%fd464, 0dC0839F895BC22946;
	fma.rn.f64 	%fd465, %fd463, %fd441, %fd464;
	mov.f64 	%fd466, 0d403E77CC78ECD2D8;
	fma.rn.f64 	%fd467, %fd465, %fd441, %fd466;
	mov.f64 	%fd468, 0dC002F368D0117BE9;
	fma.rn.f64 	%fd469, %fd467, %fd441, %fd468;
	mov.f64 	%fd470, 0d3FD7BCC786009A25;
	fma.rn.f64 	%fd471, %fd469, %fd441, %fd470;
	mov.f64 	%fd472, 0dBFC4FFFFFC51BC7A;
	fma.rn.f64 	%fd473, %fd471, %fd441, %fd472;
	mov.f64 	%fd474, 0d3FD7FFFFFFFFB5EA;
	fma.rn.f64 	%fd475, %fd473, %fd441, %fd474;
	fma.rn.f64 	%fd40, %fd475, %fd440, %fd2;
	rsqrt.approx.f64 	%fd476, %fd2;
	mul.f64 	%fd477, %fd476, 0d3FE9884533D43651;
	mul.f64 	%fd41, %fd456, %fd477;
	mul.f64 	%fd478, %fd40, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r105, %fd478;
	add.u64 	%rd17, %SP, 0;
	cvta.to.local.u64 	%rd18, %rd17;
	st.local.u32 	[%rd18], %r105;
	cvt.rn.f64.s32	%fd479, %r105;
	neg.f64 	%fd480, %fd479;
	mov.f64 	%fd481, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd482, %fd480, %fd481, %fd40;
	mov.f64 	%fd483, 0d3C91A62633145C00;
	fma.rn.f64 	%fd484, %fd480, %fd483, %fd482;
	mov.f64 	%fd485, 0d397B839A252049C0;
	fma.rn.f64 	%fd529, %fd480, %fd485, %fd484;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r76}, %fd40;
	}
	and.b32  	%r77, %r76, 2145386496;
	setp.lt.u32	%p27, %r77, 1105199104;
	@%p27 bra 	BB55_43;

	add.u64 	%rd34, %SP, 0;
	// Callseq Start 17
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd40;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd529, [retval0+0];
	
	//{
	}// Callseq End 17
	ld.local.u32 	%r105, [%rd18];

BB55_43:
	and.b32  	%r78, %r105, 3;
	cvt.rn.f64.s32	%fd486, %r78;
	add.f64 	%fd487, %fd529, 0dC00F6A7A2955385E;
	fma.rn.f64 	%fd530, %fd486, 0d3FF921FB54442D18, %fd487;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r79}, %fd530;
	}
	and.b32  	%r80, %r79, 2147483647;
	setp.ne.s32	%p28, %r80, 2146435072;
	@%p28 bra 	BB55_46;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r81, %temp}, %fd530;
	}
	setp.ne.s32	%p29, %r81, 0;
	@%p29 bra 	BB55_46;

	mov.f64 	%fd488, 0d0000000000000000;
	mul.rn.f64 	%fd530, %fd530, %fd488;

BB55_46:
	mov.f64 	%fd519, 0d397B839A252049C0;
	mov.f64 	%fd518, 0d3C91A62633145C00;
	mov.f64 	%fd517, 0d3FF921FB54442D18;
	mul.f64 	%fd489, %fd530, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r106, %fd489;
	st.local.u32 	[%rd18], %r106;
	cvt.rn.f64.s32	%fd490, %r106;
	neg.f64 	%fd491, %fd490;
	fma.rn.f64 	%fd493, %fd491, %fd517, %fd530;
	fma.rn.f64 	%fd495, %fd491, %fd518, %fd493;
	fma.rn.f64 	%fd531, %fd491, %fd519, %fd495;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r82}, %fd530;
	}
	and.b32  	%r83, %r82, 2145386496;
	setp.lt.u32	%p30, %r83, 1105199104;
	@%p30 bra 	BB55_48;

	add.u64 	%rd33, %SP, 0;
	// Callseq Start 18
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd530;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd33;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd531, [retval0+0];
	
	//{
	}// Callseq End 18
	ld.local.u32 	%r106, [%rd18];

BB55_48:
	add.s32 	%r28, %r106, 1;
	and.b32  	%r84, %r28, 1;
	shl.b32 	%r85, %r84, 3;
	setp.eq.s32	%p31, %r84, 0;
	selp.f64	%fd497, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p31;
	mul.wide.u32 	%rd25, %r85, 8;
	mov.u64 	%rd26, __cudart_sin_cos_coeffs;
	add.s64 	%rd27, %rd25, %rd26;
	ld.const.f64 	%fd498, [%rd27+8];
	mul.rn.f64 	%fd51, %fd531, %fd531;
	fma.rn.f64 	%fd499, %fd497, %fd51, %fd498;
	ld.const.f64 	%fd500, [%rd27+16];
	fma.rn.f64 	%fd501, %fd499, %fd51, %fd500;
	ld.const.f64 	%fd502, [%rd27+24];
	fma.rn.f64 	%fd503, %fd501, %fd51, %fd502;
	ld.const.f64 	%fd504, [%rd27+32];
	fma.rn.f64 	%fd505, %fd503, %fd51, %fd504;
	ld.const.f64 	%fd506, [%rd27+40];
	fma.rn.f64 	%fd507, %fd505, %fd51, %fd506;
	ld.const.f64 	%fd508, [%rd27+48];
	fma.rn.f64 	%fd52, %fd507, %fd51, %fd508;
	fma.rn.f64 	%fd532, %fd52, %fd531, %fd531;
	@%p31 bra 	BB55_50;

	mov.f64 	%fd520, 0d3FF0000000000000;
	fma.rn.f64 	%fd532, %fd52, %fd51, %fd520;

BB55_50:
	and.b32  	%r86, %r28, 2;
	setp.eq.s32	%p32, %r86, 0;
	@%p32 bra 	BB55_52;

	mov.f64 	%fd510, 0d0000000000000000;
	mov.f64 	%fd511, 0dBFF0000000000000;
	fma.rn.f64 	%fd532, %fd532, %fd511, %fd510;

BB55_52:
	mul.f64 	%fd533, %fd41, %fd532;
	bra.uni 	BB55_54;

BB55_5:
	mul.f64 	%fd63, %fd2, %fd2;
	mov.f64 	%fd64, 0dBDCF0B5B1FB7B95E;
	mov.f64 	%fd65, 0d3D5249F90687428C;
	fma.rn.f64 	%fd66, %fd65, %fd63, %fd64;
	mov.f64 	%fd67, 0d3E432E589311FA14;
	fma.rn.f64 	%fd68, %fd66, %fd63, %fd67;
	mov.f64 	%fd69, 0dBEB0A780AA4A92E9;
	fma.rn.f64 	%fd70, %fd68, %fd63, %fd69;
	mov.f64 	%fd71, 0d3F12C7DBFFCAEC2B;
	fma.rn.f64 	%fd72, %fd70, %fd63, %fd71;
	mov.f64 	%fd73, 0dBF6835B97894BA4A;
	fma.rn.f64 	%fd74, %fd72, %fd63, %fd73;
	mov.f64 	%fd75, 0d3FABD3975C75B4A3;
	fma.rn.f64 	%fd76, %fd74, %fd63, %fd75;
	mov.f64 	%fd77, 0dBFC91866143CBC8A;
	fma.rn.f64 	%fd3, %fd76, %fd63, %fd77;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd2;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r99}, %fd2;
	}
	mov.u32 	%r101, -1023;
	setp.gt.s32	%p5, %r99, 1048575;
	mov.f64 	%fd521, %fd2;
	@%p5 bra 	BB55_7;

	mul.f64 	%fd4, %fd2, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r99}, %fd4;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd4;
	}
	mov.u32 	%r101, -1077;
	mov.f64 	%fd521, %fd4;

BB55_7:
	mov.f64 	%fd5, %fd521;
	add.s32 	%r48, %r99, -1;
	setp.lt.u32	%p6, %r48, 2146435071;
	@%p6 bra 	BB55_9;
	bra.uni 	BB55_8;

BB55_9:
	shr.u32 	%r50, %r99, 20;
	add.s32 	%r102, %r101, %r50;
	and.b32  	%r51, %r99, -2146435073;
	or.b32  	%r52, %r51, 1072693248;
	mov.b64 	%fd522, {%r100, %r52};
	setp.lt.s32	%p8, %r52, 1073127583;
	@%p8 bra 	BB55_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r53, %temp}, %fd522;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r54}, %fd522;
	}
	add.s32 	%r55, %r54, -1048576;
	mov.b64 	%fd522, {%r53, %r55};
	add.s32 	%r102, %r102, 1;

BB55_11:
	add.f64 	%fd81, %fd522, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd80,%fd81;
	// inline asm
	neg.f64 	%fd82, %fd81;
	mov.f64 	%fd83, 0d3FF0000000000000;
	fma.rn.f64 	%fd84, %fd82, %fd80, %fd83;
	fma.rn.f64 	%fd85, %fd84, %fd84, %fd84;
	fma.rn.f64 	%fd86, %fd85, %fd80, %fd80;
	add.f64 	%fd87, %fd522, 0dBFF0000000000000;
	mul.f64 	%fd88, %fd87, %fd86;
	fma.rn.f64 	%fd89, %fd87, %fd86, %fd88;
	mul.f64 	%fd90, %fd89, %fd89;
	mov.f64 	%fd91, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd92, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd93, %fd92, %fd90, %fd91;
	mov.f64 	%fd94, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd95, %fd93, %fd90, %fd94;
	mov.f64 	%fd96, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd97, %fd95, %fd90, %fd96;
	mov.f64 	%fd98, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd99, %fd97, %fd90, %fd98;
	mov.f64 	%fd100, 0d3F624924923BE72D;
	fma.rn.f64 	%fd101, %fd99, %fd90, %fd100;
	mov.f64 	%fd102, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd103, %fd101, %fd90, %fd102;
	mov.f64 	%fd104, 0d3FB5555555555554;
	fma.rn.f64 	%fd105, %fd103, %fd90, %fd104;
	sub.f64 	%fd106, %fd87, %fd89;
	add.f64 	%fd107, %fd106, %fd106;
	neg.f64 	%fd108, %fd89;
	fma.rn.f64 	%fd109, %fd108, %fd87, %fd107;
	mul.f64 	%fd110, %fd86, %fd109;
	mul.f64 	%fd111, %fd90, %fd105;
	fma.rn.f64 	%fd112, %fd111, %fd89, %fd110;
	xor.b32  	%r56, %r102, -2147483648;
	mov.u32 	%r57, 1127219200;
	mov.b64 	%fd113, {%r56, %r57};
	mov.u32 	%r58, -2147483648;
	mov.b64 	%fd114, {%r58, %r57};
	sub.f64 	%fd115, %fd113, %fd114;
	mov.f64 	%fd116, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd117, %fd115, %fd116, %fd89;
	neg.f64 	%fd118, %fd115;
	fma.rn.f64 	%fd119, %fd118, %fd116, %fd117;
	sub.f64 	%fd120, %fd119, %fd89;
	sub.f64 	%fd121, %fd112, %fd120;
	mov.f64 	%fd122, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd123, %fd115, %fd122, %fd121;
	add.f64 	%fd523, %fd117, %fd123;
	bra.uni 	BB55_12;

BB55_34:
	add.f64 	%fd308, %fd2, 0dC00193BED4DFF243;
	add.f64 	%fd309, %fd308, 0d3C8BD1E50D219BFD;
	mov.f64 	%fd310, 0d3E4833AAE4D8B975;
	mov.f64 	%fd311, 0dBE2B87B0BE2AA150;
	fma.rn.f64 	%fd312, %fd311, %fd309, %fd310;
	mov.f64 	%fd313, 0dBE44E279B423E68F;
	fma.rn.f64 	%fd314, %fd312, %fd309, %fd313;
	mov.f64 	%fd315, 0d3E129DC6A747EB4F;
	fma.rn.f64 	%fd316, %fd314, %fd309, %fd315;
	mov.f64 	%fd317, 0dBE61D15534496CD8;
	fma.rn.f64 	%fd318, %fd316, %fd309, %fd317;
	mov.f64 	%fd319, 0d3E7EEC8D48FECE00;
	fma.rn.f64 	%fd320, %fd318, %fd309, %fd319;
	mov.f64 	%fd321, 0dBE8D1180AF70A134;
	fma.rn.f64 	%fd322, %fd320, %fd309, %fd321;
	mov.f64 	%fd323, 0d3E9C8386A0EA1388;
	fma.rn.f64 	%fd324, %fd322, %fd309, %fd323;
	mov.f64 	%fd325, 0dBEB01A014E7F3250;
	fma.rn.f64 	%fd326, %fd324, %fd309, %fd325;
	mov.f64 	%fd327, 0d3EC1FB752010A320;
	fma.rn.f64 	%fd328, %fd326, %fd309, %fd327;
	mov.f64 	%fd329, 0dBED3AA0AFF4E332B;
	fma.rn.f64 	%fd330, %fd328, %fd309, %fd329;
	mov.f64 	%fd331, 0d3EE584A6C77F6700;
	fma.rn.f64 	%fd332, %fd330, %fd309, %fd331;
	mov.f64 	%fd333, 0dBEF794C520FC2EBB;
	fma.rn.f64 	%fd334, %fd332, %fd309, %fd333;
	mov.f64 	%fd335, 0d3F09D18D2D35CC71;
	fma.rn.f64 	%fd336, %fd334, %fd309, %fd335;
	mov.f64 	%fd337, 0dBF1C3FB7315C4599;
	fma.rn.f64 	%fd338, %fd336, %fd309, %fd337;
	mov.f64 	%fd339, 0d3F2EEA7ADECCE927;
	fma.rn.f64 	%fd340, %fd338, %fd309, %fd339;
	mov.f64 	%fd341, 0dBF40B2D85257446F;
	fma.rn.f64 	%fd342, %fd340, %fd309, %fd341;
	mov.f64 	%fd343, 0d3F517AB4B1FE5D5B;
	fma.rn.f64 	%fd344, %fd342, %fd309, %fd343;
	mov.f64 	%fd345, 0dBF65429DC6516C0D;
	fma.rn.f64 	%fd346, %fd344, %fd309, %fd345;
	mov.f64 	%fd347, 0d3F7E671C7D0B090B;
	fma.rn.f64 	%fd348, %fd346, %fd309, %fd347;
	mov.f64 	%fd349, 0dBF73A6DEC36FB27C;
	fma.rn.f64 	%fd350, %fd348, %fd309, %fd349;
	mov.f64 	%fd351, 0dBFA0D2AF4E931FD1;
	fma.rn.f64 	%fd352, %fd350, %fd309, %fd351;
	mov.f64 	%fd353, 0dBFBE56F82217B964;
	fma.rn.f64 	%fd354, %fd352, %fd309, %fd353;
	mov.f64 	%fd355, 0d3FE0AA48442F014B;
	fma.rn.f64 	%fd356, %fd354, %fd309, %fd355;
	mul.f64 	%fd533, %fd309, %fd356;
	bra.uni 	BB55_54;

BB55_8:
	mov.f64 	%fd78, 0d7FF0000000000000;
	fma.rn.f64 	%fd79, %fd5, %fd78, %fd78;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r49}, %fd5;
	}
	mov.b32 	 %f1, %r49;
	setp.eq.f32	%p7, %f1, 0f00000000;
	selp.f64	%fd523, 0dFFF0000000000000, %fd79, %p7;

BB55_12:
	abs.f64 	%fd12, %fd2;
	setp.gtu.f64	%p9, %fd12, 0d400353AABAD7B784;
	@%p9 bra 	BB55_14;
	bra.uni 	BB55_13;

BB55_14:
	setp.gtu.f64	%p10, %fd12, 0d4015B1D0574614EA;
	@%p10 bra 	BB55_16;
	bra.uni 	BB55_15;

BB55_16:
	setp.gtu.f64	%p11, %fd12, 0d40213065E54C1AA9;
	@%p11 bra 	BB55_18;
	bra.uni 	BB55_17;

BB55_18:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r59}, %fd12;
	}
	and.b32  	%r60, %r59, 2147483647;
	setp.ne.s32	%p12, %r60, 2146435072;
	@%p12 bra 	BB55_20;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r61, %temp}, %fd12;
	}
	setp.eq.s32	%p13, %r61, 0;
	mov.f64 	%fd528, 0d0000000000000000;
	@%p13 bra 	BB55_32;

BB55_20:
	// inline asm
	rcp.approx.ftz.f64 %fd222,%fd12;
	// inline asm
	neg.f64 	%fd224, %fd12;
	mov.f64 	%fd225, 0d3FF0000000000000;
	fma.rn.f64 	%fd226, %fd224, %fd222, %fd225;
	fma.rn.f64 	%fd227, %fd226, %fd226, %fd226;
	fma.rn.f64 	%fd228, %fd227, %fd222, %fd222;
	mul.f64 	%fd229, %fd228, %fd228;
	mov.f64 	%fd230, 0dC099C06322A3F8BE;
	mov.f64 	%fd231, 0d40CD02EA3F2F6751;
	fma.rn.f64 	%fd232, %fd231, %fd229, %fd230;
	mov.f64 	%fd233, 0d405B89354DA77324;
	fma.rn.f64 	%fd234, %fd232, %fd229, %fd233;
	mov.f64 	%fd235, 0dC01E352294653188;
	fma.rn.f64 	%fd236, %fd234, %fd229, %fd235;
	mov.f64 	%fd237, 0d3FE9BC7DB16BD7A7;
	fma.rn.f64 	%fd238, %fd236, %fd229, %fd237;
	mov.f64 	%fd239, 0dBFC8BFE1C3A4F741;
	fma.rn.f64 	%fd240, %fd238, %fd229, %fd239;
	mov.f64 	%fd241, 0d3FC7FFFFF0D00BE2;
	fma.rn.f64 	%fd242, %fd240, %fd229, %fd241;
	mov.f64 	%fd243, 0d3FF00000000068CC;
	fma.rn.f64 	%fd244, %fd242, %fd229, %fd243;
	mov.f64 	%fd245, 0d415A30AC6857BEE0;
	mov.f64 	%fd246, 0dC18DA26B212FDC9A;
	fma.rn.f64 	%fd247, %fd246, %fd229, %fd245;
	mov.f64 	%fd248, 0dC11764222AD7C910;
	fma.rn.f64 	%fd249, %fd247, %fd229, %fd248;
	mov.f64 	%fd250, 0d40CEB02E0C306857;
	fma.rn.f64 	%fd251, %fd249, %fd229, %fd250;
	mov.f64 	%fd252, 0dC08351859FA2B23B;
	fma.rn.f64 	%fd253, %fd251, %fd229, %fd252;
	mov.f64 	%fd254, 0d403E65A07AF51F42;
	fma.rn.f64 	%fd255, %fd253, %fd229, %fd254;
	mov.f64 	%fd256, 0dC002F2B817F77A57;
	fma.rn.f64 	%fd257, %fd255, %fd229, %fd256;
	mov.f64 	%fd258, 0d3FD7BCC34DA069FD;
	fma.rn.f64 	%fd259, %fd257, %fd229, %fd258;
	mov.f64 	%fd260, 0dBFC4FFFFF8A44463;
	fma.rn.f64 	%fd261, %fd259, %fd229, %fd260;
	mov.f64 	%fd262, 0d3FD7FFFFFFFF5CD7;
	fma.rn.f64 	%fd263, %fd261, %fd229, %fd262;
	fma.rn.f64 	%fd16, %fd263, %fd228, %fd12;
	rsqrt.approx.f64 	%fd264, %fd12;
	mul.f64 	%fd265, %fd264, 0d3FE9884533D43651;
	mul.f64 	%fd17, %fd244, %fd265;
	mul.f64 	%fd266, %fd16, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r103, %fd266;
	add.u64 	%rd6, %SP, 0;
	cvta.to.local.u64 	%rd7, %rd6;
	st.local.u32 	[%rd7], %r103;
	cvt.rn.f64.s32	%fd267, %r103;
	neg.f64 	%fd268, %fd267;
	mov.f64 	%fd269, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd270, %fd268, %fd269, %fd16;
	mov.f64 	%fd271, 0d3C91A62633145C00;
	fma.rn.f64 	%fd272, %fd268, %fd271, %fd270;
	mov.f64 	%fd273, 0d397B839A252049C0;
	fma.rn.f64 	%fd524, %fd268, %fd273, %fd272;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r62}, %fd16;
	}
	and.b32  	%r63, %r62, 2145386496;
	setp.lt.u32	%p14, %r63, 1105199104;
	@%p14 bra 	BB55_22;

	add.u64 	%rd32, %SP, 0;
	// Callseq Start 15
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd16;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd32;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd524, [retval0+0];
	
	//{
	}// Callseq End 15
	ld.local.u32 	%r103, [%rd7];

BB55_22:
	and.b32  	%r64, %r103, 3;
	cvt.rn.f64.s32	%fd274, %r64;
	add.f64 	%fd275, %fd524, 0dC002D97C7F3321D2;
	fma.rn.f64 	%fd525, %fd274, 0d3FF921FB54442D18, %fd275;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r65}, %fd525;
	}
	and.b32  	%r66, %r65, 2147483647;
	setp.ne.s32	%p15, %r66, 2146435072;
	@%p15 bra 	BB55_25;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r67, %temp}, %fd525;
	}
	setp.ne.s32	%p16, %r67, 0;
	@%p16 bra 	BB55_25;

	mov.f64 	%fd276, 0d0000000000000000;
	mul.rn.f64 	%fd525, %fd525, %fd276;

BB55_25:
	mov.f64 	%fd515, 0d397B839A252049C0;
	mov.f64 	%fd514, 0d3C91A62633145C00;
	mov.f64 	%fd513, 0d3FF921FB54442D18;
	mul.f64 	%fd277, %fd525, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r104, %fd277;
	st.local.u32 	[%rd7], %r104;
	cvt.rn.f64.s32	%fd278, %r104;
	neg.f64 	%fd279, %fd278;
	fma.rn.f64 	%fd281, %fd279, %fd513, %fd525;
	fma.rn.f64 	%fd283, %fd279, %fd514, %fd281;
	fma.rn.f64 	%fd526, %fd279, %fd515, %fd283;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r68}, %fd525;
	}
	and.b32  	%r69, %r68, 2145386496;
	setp.lt.u32	%p17, %r69, 1105199104;
	@%p17 bra 	BB55_27;

	add.u64 	%rd31, %SP, 0;
	// Callseq Start 16
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd525;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd31;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd526, [retval0+0];
	
	//{
	}// Callseq End 16
	ld.local.u32 	%r104, [%rd7];

BB55_27:
	add.s32 	%r21, %r104, 1;
	and.b32  	%r70, %r21, 1;
	shl.b32 	%r71, %r70, 3;
	setp.eq.s32	%p18, %r70, 0;
	selp.f64	%fd285, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p18;
	mul.wide.u32 	%rd14, %r71, 8;
	mov.u64 	%rd15, __cudart_sin_cos_coeffs;
	add.s64 	%rd16, %rd14, %rd15;
	ld.const.f64 	%fd286, [%rd16+8];
	mul.rn.f64 	%fd27, %fd526, %fd526;
	fma.rn.f64 	%fd287, %fd285, %fd27, %fd286;
	ld.const.f64 	%fd288, [%rd16+16];
	fma.rn.f64 	%fd289, %fd287, %fd27, %fd288;
	ld.const.f64 	%fd290, [%rd16+24];
	fma.rn.f64 	%fd291, %fd289, %fd27, %fd290;
	ld.const.f64 	%fd292, [%rd16+32];
	fma.rn.f64 	%fd293, %fd291, %fd27, %fd292;
	ld.const.f64 	%fd294, [%rd16+40];
	fma.rn.f64 	%fd295, %fd293, %fd27, %fd294;
	ld.const.f64 	%fd296, [%rd16+48];
	fma.rn.f64 	%fd28, %fd295, %fd27, %fd296;
	fma.rn.f64 	%fd527, %fd28, %fd526, %fd526;
	@%p18 bra 	BB55_29;

	mov.f64 	%fd516, 0d3FF0000000000000;
	fma.rn.f64 	%fd527, %fd28, %fd27, %fd516;

BB55_29:
	and.b32  	%r72, %r21, 2;
	setp.eq.s32	%p19, %r72, 0;
	@%p19 bra 	BB55_31;

	mov.f64 	%fd298, 0d0000000000000000;
	mov.f64 	%fd299, 0dBFF0000000000000;
	fma.rn.f64 	%fd527, %fd527, %fd299, %fd298;

BB55_31:
	mul.f64 	%fd528, %fd17, %fd527;
	bra.uni 	BB55_32;

BB55_13:
	mov.f64 	%fd124, 0dBD4DD167A0DC3F55;
	mov.f64 	%fd125, 0d3D020E4ADCDE2AD3;
	fma.rn.f64 	%fd126, %fd125, %fd12, %fd124;
	mov.f64 	%fd127, 0d3D5503F5A491E487;
	fma.rn.f64 	%fd128, %fd126, %fd12, %fd127;
	mov.f64 	%fd129, 0d3DC1F29940C2403A;
	fma.rn.f64 	%fd130, %fd128, %fd12, %fd129;
	mov.f64 	%fd131, 0d3D84CF9302EACDEF;
	fma.rn.f64 	%fd132, %fd130, %fd12, %fd131;
	mov.f64 	%fd133, 0dBE384A53DBBCA436;
	fma.rn.f64 	%fd134, %fd132, %fd12, %fd133;
	mov.f64 	%fd135, 0d3D9779BEE4F63BCC;
	fma.rn.f64 	%fd136, %fd134, %fd12, %fd135;
	mov.f64 	%fd137, 0d3EA6C160E414F3F0;
	fma.rn.f64 	%fd138, %fd136, %fd12, %fd137;
	mov.f64 	%fd139, 0d3D8F3D2F12430699;
	fma.rn.f64 	%fd140, %fd138, %fd12, %fd139;
	mov.f64 	%fd141, 0dBF0C71C72C0CED04;
	fma.rn.f64 	%fd142, %fd140, %fd12, %fd141;
	mov.f64 	%fd143, 0d3D659BCA506F1128;
	fma.rn.f64 	%fd144, %fd142, %fd12, %fd143;
	mov.f64 	%fd145, 0d3F65555555506982;
	fma.rn.f64 	%fd146, %fd144, %fd12, %fd145;
	mov.f64 	%fd147, 0d3D15BA0B425F1BFB;
	fma.rn.f64 	%fd148, %fd146, %fd12, %fd147;
	mov.f64 	%fd149, 0dBFB0000000000065;
	fma.rn.f64 	%fd150, %fd148, %fd12, %fd149;
	mov.f64 	%fd151, 0d3C8729A7253FB679;
	fma.rn.f64 	%fd152, %fd150, %fd12, %fd151;
	mov.f64 	%fd153, 0d3FE0000000000000;
	fma.rn.f64 	%fd154, %fd152, %fd12, %fd153;
	mul.f64 	%fd528, %fd12, %fd154;
	bra.uni 	BB55_32;

BB55_36:
	add.f64 	%fd357, %fd2, 0dC015B7FE4E87B02E;
	add.f64 	%fd358, %fd357, 0dBCBDFE7BAC228E8C;
	mov.f64 	%fd359, 0d3CC69A30996793E2;
	mov.f64 	%fd360, 0d3CBA3C76069F1D8C;
	fma.rn.f64 	%fd361, %fd360, %fd358, %fd359;
	mov.f64 	%fd362, 0dBCDDD8432FE756E7;
	fma.rn.f64 	%fd363, %fd361, %fd358, %fd362;
	mov.f64 	%fd364, 0dBD143158EEE220F7;
	fma.rn.f64 	%fd365, %fd363, %fd358, %fd364;
	mov.f64 	%fd366, 0d3D28D44491230F5A;
	fma.rn.f64 	%fd367, %fd365, %fd358, %fd366;
	mov.f64 	%fd368, 0dBD438842EAF4EDBC;
	fma.rn.f64 	%fd369, %fd367, %fd358, %fd368;
	mov.f64 	%fd370, 0d3D74958DAFBFAF5A;
	fma.rn.f64 	%fd371, %fd369, %fd358, %fd370;
	mov.f64 	%fd372, 0dBD9449A60E664848;
	fma.rn.f64 	%fd373, %fd371, %fd358, %fd372;
	mov.f64 	%fd374, 0d3D838BC8CD594A76;
	fma.rn.f64 	%fd375, %fd373, %fd358, %fd374;
	mov.f64 	%fd376, 0dBDFA798002141323;
	fma.rn.f64 	%fd377, %fd375, %fd358, %fd376;
	mov.f64 	%fd378, 0d3E380B4198956AAA;
	fma.rn.f64 	%fd379, %fd377, %fd358, %fd378;
	mov.f64 	%fd380, 0d3E5B62B5F21BACD4;
	fma.rn.f64 	%fd381, %fd379, %fd358, %fd380;
	mov.f64 	%fd382, 0dBEA255E729FB6AAE;
	fma.rn.f64 	%fd383, %fd381, %fd358, %fd382;
	mov.f64 	%fd384, 0dBEC80618F6BAE5AA;
	fma.rn.f64 	%fd385, %fd383, %fd358, %fd384;
	mov.f64 	%fd386, 0d3F085B940F8E8D36;
	fma.rn.f64 	%fd387, %fd385, %fd358, %fd386;
	mov.f64 	%fd388, 0d3F2337C7E10E14E8;
	fma.rn.f64 	%fd389, %fd387, %fd358, %fd388;
	mov.f64 	%fd390, 0dBF61BE6DB99332CA;
	fma.rn.f64 	%fd391, %fd389, %fd358, %fd390;
	mov.f64 	%fd392, 0dBF710A329E2BE9B8;
	fma.rn.f64 	%fd393, %fd391, %fd358, %fd392;
	mov.f64 	%fd394, 0d3FAA15D92DFE3FCF;
	fma.rn.f64 	%fd395, %fd393, %fd358, %fd394;
	mov.f64 	%fd396, 0d3FA00B9F8571C9BE;
	fma.rn.f64 	%fd397, %fd395, %fd358, %fd396;
	mov.f64 	%fd398, 0dBFD5C7C556F0C19A;
	fma.rn.f64 	%fd399, %fd397, %fd358, %fd398;
	mul.f64 	%fd533, %fd358, %fd399;
	bra.uni 	BB55_54;

BB55_15:
	add.f64 	%fd155, %fd12, 0dC00EA75575AF6F09;
	add.f64 	%fd156, %fd155, 0d3CA60155A9D1B256;
	mov.f64 	%fd157, 0d3D41011A1DF02DAD;
	mov.f64 	%fd158, 0dBCF8D3CDBB60175E;
	fma.rn.f64 	%fd159, %fd158, %fd156, %fd157;
	mov.f64 	%fd160, 0d3D76013AC1E5E222;
	fma.rn.f64 	%fd161, %fd159, %fd156, %fd160;
	mov.f64 	%fd162, 0dBDBEC315D96D5F03;
	fma.rn.f64 	%fd163, %fd161, %fd156, %fd162;
	mov.f64 	%fd164, 0dBDF03BE1B4B57207;
	fma.rn.f64 	%fd165, %fd163, %fd156, %fd164;
	mov.f64 	%fd166, 0d3E345695F8B660F7;
	fma.rn.f64 	%fd167, %fd165, %fd156, %fd166;
	mov.f64 	%fd168, 0d3E617069FCFCFFF4;
	fma.rn.f64 	%fd169, %fd167, %fd156, %fd168;
	mov.f64 	%fd170, 0dBEA33825C36745EB;
	fma.rn.f64 	%fd171, %fd169, %fd156, %fd170;
	mov.f64 	%fd172, 0dBEC9799D4F90931B;
	fma.rn.f64 	%fd173, %fd171, %fd156, %fd172;
	mov.f64 	%fd174, 0d3F083A06E2F7DF13;
	fma.rn.f64 	%fd175, %fd173, %fd156, %fd174;
	mov.f64 	%fd176, 0d3F26E4C2D53A7CF6;
	fma.rn.f64 	%fd177, %fd175, %fd156, %fd176;
	mov.f64 	%fd178, 0dBF624B3409957B1C;
	fma.rn.f64 	%fd179, %fd177, %fd156, %fd178;
	mov.f64 	%fd180, 0dBF7537544C3325DF;
	fma.rn.f64 	%fd181, %fd179, %fd156, %fd180;
	mov.f64 	%fd182, 0d3FAB589D1DA138E2;
	fma.rn.f64 	%fd183, %fd181, %fd156, %fd182;
	mov.f64 	%fd184, 0d3FAAE8A39F51AD13;
	fma.rn.f64 	%fd185, %fd183, %fd156, %fd184;
	mov.f64 	%fd186, 0dBFD9C6CF582CBF7F;
	fma.rn.f64 	%fd187, %fd185, %fd156, %fd186;
	mul.f64 	%fd528, %fd156, %fd187;
	bra.uni 	BB55_32;

BB55_38:
	add.f64 	%fd400, %fd2, 0dC0213127AE6169B4;
	add.f64 	%fd401, %fd400, 0dBCB479CC068D9046;
	mov.f64 	%fd402, 0dBD43515F67644276;
	mov.f64 	%fd403, 0d3CB09CCC22945996;
	fma.rn.f64 	%fd404, %fd403, %fd401, %fd402;
	mov.f64 	%fd405, 0dBD72C5B978E9F5C7;
	fma.rn.f64 	%fd406, %fd404, %fd401, %fd405;
	mov.f64 	%fd407, 0d3DBEC1151613913C;
	fma.rn.f64 	%fd408, %fd406, %fd401, %fd407;
	mov.f64 	%fd409, 0d3DE9E38D13C4A824;
	fma.rn.f64 	%fd410, %fd408, %fd401, %fd409;
	mov.f64 	%fd411, 0dBE341E75E1088EB5;
	fma.rn.f64 	%fd412, %fd410, %fd401, %fd411;
	mov.f64 	%fd413, 0dBE5A384EBB13CFE1;
	fma.rn.f64 	%fd414, %fd412, %fd401, %fd413;
	mov.f64 	%fd415, 0d3EA2BECB27F8C8F8;
	fma.rn.f64 	%fd416, %fd414, %fd401, %fd415;
	mov.f64 	%fd417, 0d3EC176E72B989FD8;
	fma.rn.f64 	%fd418, %fd416, %fd401, %fd417;
	mov.f64 	%fd419, 0dBF06F7BAB102F822;
	fma.rn.f64 	%fd420, %fd418, %fd401, %fd419;
	mov.f64 	%fd421, 0dBF1B50D7E1D278E1;
	fma.rn.f64 	%fd422, %fd420, %fd401, %fd421;
	mov.f64 	%fd423, 0d3F607A678D60004F;
	fma.rn.f64 	%fd424, %fd422, %fd401, %fd423;
	mov.f64 	%fd425, 0d3F63CED2A2E69115;
	fma.rn.f64 	%fd426, %fd424, %fd401, %fd425;
	mov.f64 	%fd427, 0dBFA6395DFE49FCD4;
	fma.rn.f64 	%fd428, %fd426, %fd401, %fd427;
	mov.f64 	%fd429, 0dBF902B3933CF21B1;
	fma.rn.f64 	%fd430, %fd428, %fd401, %fd429;
	mov.f64 	%fd431, 0d3FD15F993FCEAB5C;
	fma.rn.f64 	%fd432, %fd430, %fd401, %fd431;
	mul.f64 	%fd533, %fd401, %fd432;
	bra.uni 	BB55_54;

BB55_17:
	add.f64 	%fd188, %fd12, 0dC01C0FF5F3B47250;
	add.f64 	%fd189, %fd188, 0d3C9B226D9D243827;
	mov.f64 	%fd190, 0dBD40E8363DB649A9;
	mov.f64 	%fd191, 0d3CF3EB867515FAD6;
	fma.rn.f64 	%fd192, %fd191, %fd189, %fd190;
	mov.f64 	%fd193, 0dBD73B7DD4A6608FB;
	fma.rn.f64 	%fd194, %fd192, %fd189, %fd193;
	mov.f64 	%fd195, 0d3DBEC5E01482C750;
	fma.rn.f64 	%fd196, %fd194, %fd189, %fd195;
	mov.f64 	%fd197, 0d3DEC62BB9E882103;
	fma.rn.f64 	%fd198, %fd196, %fd189, %fd197;
	mov.f64 	%fd199, 0dBE34462EED732A23;
	fma.rn.f64 	%fd200, %fd198, %fd189, %fd199;
	mov.f64 	%fd201, 0dBE5D48DCAD7DC59B;
	fma.rn.f64 	%fd202, %fd200, %fd189, %fd201;
	mov.f64 	%fd203, 0d3EA3026DF29167E9;
	fma.rn.f64 	%fd204, %fd202, %fd189, %fd203;
	mov.f64 	%fd205, 0d3EC4255B0119666C;
	fma.rn.f64 	%fd206, %fd204, %fd189, %fd205;
	mov.f64 	%fd207, 0dBF0796A751B32693;
	fma.rn.f64 	%fd208, %fd206, %fd189, %fd207;
	mov.f64 	%fd209, 0dBF207358BBDBA284;
	fma.rn.f64 	%fd210, %fd208, %fd189, %fd209;
	mov.f64 	%fd211, 0d3F613FBC7D6927B1;
	fma.rn.f64 	%fd212, %fd210, %fd189, %fd211;
	mov.f64 	%fd213, 0d3F69A4B292E3DD75;
	fma.rn.f64 	%fd214, %fd212, %fd189, %fd213;
	mov.f64 	%fd215, 0dBFA80C83BDEEE4FB;
	fma.rn.f64 	%fd216, %fd214, %fd189, %fd215;
	mov.f64 	%fd217, 0dBF95E70DC60362BF;
	fma.rn.f64 	%fd218, %fd216, %fd189, %fd217;
	mov.f64 	%fd219, 0d3FD33518B3874E8A;
	fma.rn.f64 	%fd220, %fd218, %fd189, %fd219;
	mul.f64 	%fd528, %fd189, %fd220;

BB55_32:
	neg.f64 	%fd300, %fd528;
	setp.lt.f64	%p20, %fd2, 0d0000000000000000;
	selp.f64	%fd301, %fd300, %fd528, %p20;
	mul.f64 	%fd302, %fd2, 0d3FE0000000000000;
	setp.lt.f64	%p21, %fd12, 0d39B4484BFEEBC2A0;
	selp.f64	%fd303, %fd302, %fd301, %p21;
	mov.f64 	%fd304, 0dBFF0000000000000;
	div.rn.f64 	%fd305, %fd304, %fd2;
	fma.rn.f64 	%fd306, %fd523, %fd303, %fd305;
	mul.f64 	%fd307, %fd306, 0d3FE45F306DC9C883;
	fma.rn.f64 	%fd533, %fd2, %fd3, %fd307;

BB55_54:
	setp.gtu.f64	%p33, %fd1, 0d0000000000000000;
	@%p33 bra 	BB55_56;

	setp.eq.f64	%p34, %fd1, 0d0000000000000000;
	selp.f64	%fd533, 0dFFF0000000000000, 0dFFF8000000000000, %p34;

BB55_56:
	mov.u32 	%r93, %ntid.y;
	ld.param.u32 	%r92, [map_y1_double_param_3];
	mad.lo.s32 	%r87, %r97, %r92, %r98;
	mul.wide.s32 	%rd29, %r87, 8;
	add.s64 	%rd30, %rd28, %rd29;
	st.global.f64 	[%rd30], %fd533;
	mov.u32 	%r89, %nctaid.y;
	mad.lo.s32 	%r98, %r89, %r93, %r98;
	setp.lt.s32	%p35, %r98, %r31;
	@%p35 bra 	BB55_3;

BB55_57:
	ld.param.u32 	%r96, [map_y1_double_param_1];
	mov.u32 	%r95, %ntid.x;
	mov.u32 	%r90, %nctaid.x;
	mad.lo.s32 	%r97, %r90, %r95, %r97;
	setp.lt.s32	%p36, %r97, %r96;
	@%p36 bra 	BB55_2;

BB55_58:
	ret;
}

	// .globl	map2_add_double
.visible .entry map2_add_double(
	.param .u32 map2_add_double_param_0,
	.param .u32 map2_add_double_param_1,
	.param .u64 map2_add_double_param_2,
	.param .u32 map2_add_double_param_3,
	.param .u64 map2_add_double_param_4,
	.param .u32 map2_add_double_param_5,
	.param .u64 map2_add_double_param_6,
	.param .u32 map2_add_double_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<30>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<13>;


	ld.param.u32 	%r13, [map2_add_double_param_0];
	ld.param.u32 	%r14, [map2_add_double_param_1];
	ld.param.u64 	%rd4, [map2_add_double_param_2];
	ld.param.u32 	%r15, [map2_add_double_param_3];
	ld.param.u64 	%rd5, [map2_add_double_param_4];
	ld.param.u32 	%r16, [map2_add_double_param_5];
	ld.param.u64 	%rd6, [map2_add_double_param_6];
	ld.param.u32 	%r17, [map2_add_double_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r18, %ctaid.x;
	mov.u32 	%r19, %tid.x;
	mad.lo.s32 	%r28, %r1, %r18, %r19;
	setp.ge.s32	%p1, %r28, %r14;
	@%p1 bra 	BB56_6;

	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd6;
	cvta.to.global.u64 	%rd3, %rd5;
	mov.u32 	%r20, %tid.y;
	mov.u32 	%r21, %ntid.y;
	mov.u32 	%r22, %ctaid.y;
	mad.lo.s32 	%r3, %r21, %r22, %r20;
	mov.u32 	%r23, %nctaid.x;
	mul.lo.s32 	%r4, %r23, %r1;
	mov.u32 	%r24, %nctaid.y;
	mul.lo.s32 	%r5, %r24, %r21;

BB56_2:
	setp.ge.s32	%p2, %r3, %r13;
	@%p2 bra 	BB56_5;

	mul.lo.s32 	%r7, %r28, %r16;
	mul.lo.s32 	%r8, %r28, %r17;
	mul.lo.s32 	%r9, %r28, %r15;
	mov.u32 	%r29, %r3;

BB56_4:
	mov.u32 	%r10, %r29;
	add.s32 	%r25, %r10, %r7;
	mul.wide.s32 	%rd7, %r25, 8;
	add.s64 	%rd8, %rd3, %rd7;
	add.s32 	%r26, %r10, %r8;
	mul.wide.s32 	%rd9, %r26, 8;
	add.s64 	%rd10, %rd2, %rd9;
	ld.global.f64 	%fd1, [%rd10];
	ld.global.f64 	%fd2, [%rd8];
	add.f64 	%fd3, %fd2, %fd1;
	add.s32 	%r27, %r10, %r9;
	mul.wide.s32 	%rd11, %r27, 8;
	add.s64 	%rd12, %rd1, %rd11;
	st.global.f64 	[%rd12], %fd3;
	add.s32 	%r11, %r5, %r10;
	setp.lt.s32	%p3, %r11, %r13;
	mov.u32 	%r29, %r11;
	@%p3 bra 	BB56_4;

BB56_5:
	add.s32 	%r28, %r4, %r28;
	setp.lt.s32	%p4, %r28, %r14;
	@%p4 bra 	BB56_2;

BB56_6:
	ret;
}

	// .globl	map2_v_s_add_double
.visible .entry map2_v_s_add_double(
	.param .u32 map2_v_s_add_double_param_0,
	.param .u32 map2_v_s_add_double_param_1,
	.param .u64 map2_v_s_add_double_param_2,
	.param .u32 map2_v_s_add_double_param_3,
	.param .u64 map2_v_s_add_double_param_4,
	.param .u32 map2_v_s_add_double_param_5,
	.param .f64 map2_v_s_add_double_param_6
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map2_v_s_add_double_param_0];
	ld.param.u32 	%r13, [map2_v_s_add_double_param_1];
	ld.param.u64 	%rd3, [map2_v_s_add_double_param_2];
	ld.param.u32 	%r14, [map2_v_s_add_double_param_3];
	ld.param.u64 	%rd4, [map2_v_s_add_double_param_4];
	ld.param.u32 	%r15, [map2_v_s_add_double_param_5];
	ld.param.f64 	%fd1, [map2_v_s_add_double_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB57_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB57_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB57_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB57_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd2, [%rd6];
	add.f64 	%fd3, %fd2, %fd1;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd3;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB57_4;

BB57_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB57_2;

BB57_6:
	ret;
}

	// .globl	map2_s_v_add_double
.visible .entry map2_s_v_add_double(
	.param .u32 map2_s_v_add_double_param_0,
	.param .u32 map2_s_v_add_double_param_1,
	.param .u64 map2_s_v_add_double_param_2,
	.param .u32 map2_s_v_add_double_param_3,
	.param .f64 map2_s_v_add_double_param_4,
	.param .u64 map2_s_v_add_double_param_5,
	.param .u32 map2_s_v_add_double_param_6
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map2_s_v_add_double_param_0];
	ld.param.u32 	%r13, [map2_s_v_add_double_param_1];
	ld.param.u64 	%rd3, [map2_s_v_add_double_param_2];
	ld.param.u32 	%r14, [map2_s_v_add_double_param_3];
	ld.param.f64 	%fd1, [map2_s_v_add_double_param_4];
	ld.param.u64 	%rd4, [map2_s_v_add_double_param_5];
	ld.param.u32 	%r15, [map2_s_v_add_double_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB58_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB58_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB58_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB58_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd2, [%rd6];
	add.f64 	%fd3, %fd2, %fd1;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd3;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB58_4;

BB58_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB58_2;

BB58_6:
	ret;
}

	// .globl	map2_transpose_add_double
.visible .entry map2_transpose_add_double(
	.param .u32 map2_transpose_add_double_param_0,
	.param .u32 map2_transpose_add_double_param_1,
	.param .u64 map2_transpose_add_double_param_2,
	.param .u32 map2_transpose_add_double_param_3,
	.param .u64 map2_transpose_add_double_param_4,
	.param .u32 map2_transpose_add_double_param_5,
	.param .u64 map2_transpose_add_double_param_6,
	.param .u32 map2_transpose_add_double_param_7
)
{
	.reg .pred 	%p<13>;
	.reg .b32 	%r<68>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<25>;
	// demoted variable
	.shared .align 8 .b8 map2_transpose_add_double$__cuda_local_var_16371_1747_non_const_tile[8448];

	ld.param.u32 	%r25, [map2_transpose_add_double_param_0];
	ld.param.u32 	%r26, [map2_transpose_add_double_param_1];
	ld.param.u64 	%rd6, [map2_transpose_add_double_param_2];
	ld.param.u32 	%r27, [map2_transpose_add_double_param_3];
	ld.param.u64 	%rd7, [map2_transpose_add_double_param_4];
	ld.param.u32 	%r28, [map2_transpose_add_double_param_5];
	ld.param.u64 	%rd8, [map2_transpose_add_double_param_6];
	ld.param.u32 	%r29, [map2_transpose_add_double_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r30, %ctaid.y;
	mov.u32 	%r31, %ntid.y;
	mul.lo.s32 	%r62, %r30, %r31;
	setp.ge.s32	%p2, %r62, %r26;
	@%p2 bra 	BB59_16;

	cvta.to.global.u64 	%rd1, %rd6;
	cvta.to.global.u64 	%rd2, %rd7;
	cvta.to.global.u64 	%rd3, %rd8;

BB59_2:
	mov.u32 	%r33, %ctaid.x;
	mul.lo.s32 	%r63, %r33, %r1;
	setp.ge.s32	%p3, %r63, %r25;
	@%p3 bra 	BB59_15;

	add.s32 	%r35, %r62, 32;
	min.s32 	%r4, %r26, %r35;

BB59_4:
	add.s32 	%r38, %r63, 32;
	min.s32 	%r7, %r25, %r38;
	mov.u32 	%r39, %tid.y;
	add.s32 	%r64, %r39, %r63;
	setp.ge.s32	%p4, %r64, %r7;
	@%p4 bra 	BB59_9;

BB59_5:
	mov.u32 	%r40, %tid.x;
	add.s32 	%r65, %r40, %r62;
	setp.ge.s32	%p5, %r65, %r4;
	@%p5 bra 	BB59_8;

	mul.lo.s32 	%r10, %r64, %r29;
	sub.s32 	%r42, %r64, %r63;
	cvt.s64.s32	%rd4, %r42;

BB59_7:
	add.s32 	%r44, %r65, %r10;
	mul.wide.s32 	%rd9, %r44, 8;
	add.s64 	%rd10, %rd3, %rd9;
	ld.global.f64 	%fd1, [%rd10];
	sub.s32 	%r45, %r65, %r62;
	mul.lo.s64 	%rd11, %rd4, 264;
	mov.u64 	%rd12, map2_transpose_add_double$__cuda_local_var_16371_1747_non_const_tile;
	add.s64 	%rd13, %rd12, %rd11;
	mul.wide.s32 	%rd14, %r45, 8;
	add.s64 	%rd15, %rd13, %rd14;
	st.shared.f64 	[%rd15], %fd1;
	add.s32 	%r65, %r65, %r1;
	setp.lt.s32	%p6, %r65, %r4;
	@%p6 bra 	BB59_7;

BB59_8:
	add.s32 	%r64, %r64, %r31;
	setp.lt.s32	%p7, %r64, %r7;
	@%p7 bra 	BB59_5;

BB59_9:
	add.s32 	%r66, %r39, %r62;
	setp.lt.s32	%p1, %r66, %r4;
	bar.sync 	0;
	@!%p1 bra 	BB59_14;
	bra.uni 	BB59_10;

BB59_10:
	mov.u32 	%r50, %tid.x;
	add.s32 	%r67, %r50, %r63;
	setp.ge.s32	%p8, %r67, %r7;
	@%p8 bra 	BB59_13;

	mul.lo.s32 	%r17, %r66, %r28;
	sub.s32 	%r52, %r66, %r62;
	cvt.s64.s32	%rd5, %r52;
	mul.lo.s32 	%r18, %r66, %r27;

BB59_12:
	add.s32 	%r54, %r67, %r17;
	mul.wide.s32 	%rd16, %r54, 8;
	add.s64 	%rd17, %rd2, %rd16;
	sub.s32 	%r55, %r67, %r63;
	mul.wide.s32 	%rd18, %r55, 264;
	mov.u64 	%rd19, map2_transpose_add_double$__cuda_local_var_16371_1747_non_const_tile;
	add.s64 	%rd20, %rd19, %rd18;
	shl.b64 	%rd21, %rd5, 3;
	add.s64 	%rd22, %rd20, %rd21;
	ld.shared.f64 	%fd2, [%rd22];
	ld.global.f64 	%fd3, [%rd17];
	add.f64 	%fd4, %fd3, %fd2;
	add.s32 	%r56, %r67, %r18;
	mul.wide.s32 	%rd23, %r56, 8;
	add.s64 	%rd24, %rd1, %rd23;
	st.global.f64 	[%rd24], %fd4;
	add.s32 	%r67, %r67, %r1;
	setp.lt.s32	%p9, %r67, %r7;
	@%p9 bra 	BB59_12;

BB59_13:
	add.s32 	%r66, %r66, %r31;
	setp.lt.s32	%p10, %r66, %r4;
	@%p10 bra 	BB59_10;

BB59_14:
	bar.sync 	0;
	mov.u32 	%r59, %nctaid.x;
	mad.lo.s32 	%r63, %r59, %r1, %r63;
	setp.lt.s32	%p11, %r63, %r25;
	@%p11 bra 	BB59_4;

BB59_15:
	mov.u32 	%r60, %nctaid.y;
	mad.lo.s32 	%r62, %r60, %r31, %r62;
	setp.lt.s32	%p12, %r62, %r26;
	@%p12 bra 	BB59_2;

BB59_16:
	ret;
}

	// .globl	map2_sub_double
.visible .entry map2_sub_double(
	.param .u32 map2_sub_double_param_0,
	.param .u32 map2_sub_double_param_1,
	.param .u64 map2_sub_double_param_2,
	.param .u32 map2_sub_double_param_3,
	.param .u64 map2_sub_double_param_4,
	.param .u32 map2_sub_double_param_5,
	.param .u64 map2_sub_double_param_6,
	.param .u32 map2_sub_double_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<30>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<13>;


	ld.param.u32 	%r13, [map2_sub_double_param_0];
	ld.param.u32 	%r14, [map2_sub_double_param_1];
	ld.param.u64 	%rd4, [map2_sub_double_param_2];
	ld.param.u32 	%r15, [map2_sub_double_param_3];
	ld.param.u64 	%rd5, [map2_sub_double_param_4];
	ld.param.u32 	%r16, [map2_sub_double_param_5];
	ld.param.u64 	%rd6, [map2_sub_double_param_6];
	ld.param.u32 	%r17, [map2_sub_double_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r18, %ctaid.x;
	mov.u32 	%r19, %tid.x;
	mad.lo.s32 	%r28, %r1, %r18, %r19;
	setp.ge.s32	%p1, %r28, %r14;
	@%p1 bra 	BB60_6;

	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd6;
	cvta.to.global.u64 	%rd3, %rd5;
	mov.u32 	%r20, %tid.y;
	mov.u32 	%r21, %ntid.y;
	mov.u32 	%r22, %ctaid.y;
	mad.lo.s32 	%r3, %r21, %r22, %r20;
	mov.u32 	%r23, %nctaid.x;
	mul.lo.s32 	%r4, %r23, %r1;
	mov.u32 	%r24, %nctaid.y;
	mul.lo.s32 	%r5, %r24, %r21;

BB60_2:
	setp.ge.s32	%p2, %r3, %r13;
	@%p2 bra 	BB60_5;

	mul.lo.s32 	%r7, %r28, %r16;
	mul.lo.s32 	%r8, %r28, %r17;
	mul.lo.s32 	%r9, %r28, %r15;
	mov.u32 	%r29, %r3;

BB60_4:
	mov.u32 	%r10, %r29;
	add.s32 	%r25, %r10, %r7;
	mul.wide.s32 	%rd7, %r25, 8;
	add.s64 	%rd8, %rd3, %rd7;
	add.s32 	%r26, %r10, %r8;
	mul.wide.s32 	%rd9, %r26, 8;
	add.s64 	%rd10, %rd2, %rd9;
	ld.global.f64 	%fd1, [%rd10];
	ld.global.f64 	%fd2, [%rd8];
	sub.f64 	%fd3, %fd2, %fd1;
	add.s32 	%r27, %r10, %r9;
	mul.wide.s32 	%rd11, %r27, 8;
	add.s64 	%rd12, %rd1, %rd11;
	st.global.f64 	[%rd12], %fd3;
	add.s32 	%r11, %r5, %r10;
	setp.lt.s32	%p3, %r11, %r13;
	mov.u32 	%r29, %r11;
	@%p3 bra 	BB60_4;

BB60_5:
	add.s32 	%r28, %r4, %r28;
	setp.lt.s32	%p4, %r28, %r14;
	@%p4 bra 	BB60_2;

BB60_6:
	ret;
}

	// .globl	map2_v_s_sub_double
.visible .entry map2_v_s_sub_double(
	.param .u32 map2_v_s_sub_double_param_0,
	.param .u32 map2_v_s_sub_double_param_1,
	.param .u64 map2_v_s_sub_double_param_2,
	.param .u32 map2_v_s_sub_double_param_3,
	.param .u64 map2_v_s_sub_double_param_4,
	.param .u32 map2_v_s_sub_double_param_5,
	.param .f64 map2_v_s_sub_double_param_6
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map2_v_s_sub_double_param_0];
	ld.param.u32 	%r13, [map2_v_s_sub_double_param_1];
	ld.param.u64 	%rd3, [map2_v_s_sub_double_param_2];
	ld.param.u32 	%r14, [map2_v_s_sub_double_param_3];
	ld.param.u64 	%rd4, [map2_v_s_sub_double_param_4];
	ld.param.u32 	%r15, [map2_v_s_sub_double_param_5];
	ld.param.f64 	%fd1, [map2_v_s_sub_double_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB61_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB61_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB61_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB61_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd2, [%rd6];
	sub.f64 	%fd3, %fd2, %fd1;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd3;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB61_4;

BB61_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB61_2;

BB61_6:
	ret;
}

	// .globl	map2_s_v_sub_double
.visible .entry map2_s_v_sub_double(
	.param .u32 map2_s_v_sub_double_param_0,
	.param .u32 map2_s_v_sub_double_param_1,
	.param .u64 map2_s_v_sub_double_param_2,
	.param .u32 map2_s_v_sub_double_param_3,
	.param .f64 map2_s_v_sub_double_param_4,
	.param .u64 map2_s_v_sub_double_param_5,
	.param .u32 map2_s_v_sub_double_param_6
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map2_s_v_sub_double_param_0];
	ld.param.u32 	%r13, [map2_s_v_sub_double_param_1];
	ld.param.u64 	%rd3, [map2_s_v_sub_double_param_2];
	ld.param.u32 	%r14, [map2_s_v_sub_double_param_3];
	ld.param.f64 	%fd1, [map2_s_v_sub_double_param_4];
	ld.param.u64 	%rd4, [map2_s_v_sub_double_param_5];
	ld.param.u32 	%r15, [map2_s_v_sub_double_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB62_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB62_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB62_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB62_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd2, [%rd6];
	sub.f64 	%fd3, %fd1, %fd2;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd3;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB62_4;

BB62_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB62_2;

BB62_6:
	ret;
}

	// .globl	map2_transpose_sub_double
.visible .entry map2_transpose_sub_double(
	.param .u32 map2_transpose_sub_double_param_0,
	.param .u32 map2_transpose_sub_double_param_1,
	.param .u64 map2_transpose_sub_double_param_2,
	.param .u32 map2_transpose_sub_double_param_3,
	.param .u64 map2_transpose_sub_double_param_4,
	.param .u32 map2_transpose_sub_double_param_5,
	.param .u64 map2_transpose_sub_double_param_6,
	.param .u32 map2_transpose_sub_double_param_7
)
{
	.reg .pred 	%p<13>;
	.reg .b32 	%r<68>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<25>;
	// demoted variable
	.shared .align 8 .b8 map2_transpose_sub_double$__cuda_local_var_16372_1747_non_const_tile[8448];

	ld.param.u32 	%r25, [map2_transpose_sub_double_param_0];
	ld.param.u32 	%r26, [map2_transpose_sub_double_param_1];
	ld.param.u64 	%rd6, [map2_transpose_sub_double_param_2];
	ld.param.u32 	%r27, [map2_transpose_sub_double_param_3];
	ld.param.u64 	%rd7, [map2_transpose_sub_double_param_4];
	ld.param.u32 	%r28, [map2_transpose_sub_double_param_5];
	ld.param.u64 	%rd8, [map2_transpose_sub_double_param_6];
	ld.param.u32 	%r29, [map2_transpose_sub_double_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r30, %ctaid.y;
	mov.u32 	%r31, %ntid.y;
	mul.lo.s32 	%r62, %r30, %r31;
	setp.ge.s32	%p2, %r62, %r26;
	@%p2 bra 	BB63_16;

	cvta.to.global.u64 	%rd1, %rd6;
	cvta.to.global.u64 	%rd2, %rd7;
	cvta.to.global.u64 	%rd3, %rd8;

BB63_2:
	mov.u32 	%r33, %ctaid.x;
	mul.lo.s32 	%r63, %r33, %r1;
	setp.ge.s32	%p3, %r63, %r25;
	@%p3 bra 	BB63_15;

	add.s32 	%r35, %r62, 32;
	min.s32 	%r4, %r26, %r35;

BB63_4:
	add.s32 	%r38, %r63, 32;
	min.s32 	%r7, %r25, %r38;
	mov.u32 	%r39, %tid.y;
	add.s32 	%r64, %r39, %r63;
	setp.ge.s32	%p4, %r64, %r7;
	@%p4 bra 	BB63_9;

BB63_5:
	mov.u32 	%r40, %tid.x;
	add.s32 	%r65, %r40, %r62;
	setp.ge.s32	%p5, %r65, %r4;
	@%p5 bra 	BB63_8;

	mul.lo.s32 	%r10, %r64, %r29;
	sub.s32 	%r42, %r64, %r63;
	cvt.s64.s32	%rd4, %r42;

BB63_7:
	add.s32 	%r44, %r65, %r10;
	mul.wide.s32 	%rd9, %r44, 8;
	add.s64 	%rd10, %rd3, %rd9;
	ld.global.f64 	%fd1, [%rd10];
	sub.s32 	%r45, %r65, %r62;
	mul.lo.s64 	%rd11, %rd4, 264;
	mov.u64 	%rd12, map2_transpose_sub_double$__cuda_local_var_16372_1747_non_const_tile;
	add.s64 	%rd13, %rd12, %rd11;
	mul.wide.s32 	%rd14, %r45, 8;
	add.s64 	%rd15, %rd13, %rd14;
	st.shared.f64 	[%rd15], %fd1;
	add.s32 	%r65, %r65, %r1;
	setp.lt.s32	%p6, %r65, %r4;
	@%p6 bra 	BB63_7;

BB63_8:
	add.s32 	%r64, %r64, %r31;
	setp.lt.s32	%p7, %r64, %r7;
	@%p7 bra 	BB63_5;

BB63_9:
	add.s32 	%r66, %r39, %r62;
	setp.lt.s32	%p1, %r66, %r4;
	bar.sync 	0;
	@!%p1 bra 	BB63_14;
	bra.uni 	BB63_10;

BB63_10:
	mov.u32 	%r50, %tid.x;
	add.s32 	%r67, %r50, %r63;
	setp.ge.s32	%p8, %r67, %r7;
	@%p8 bra 	BB63_13;

	mul.lo.s32 	%r17, %r66, %r28;
	sub.s32 	%r52, %r66, %r62;
	cvt.s64.s32	%rd5, %r52;
	mul.lo.s32 	%r18, %r66, %r27;

BB63_12:
	add.s32 	%r54, %r67, %r17;
	mul.wide.s32 	%rd16, %r54, 8;
	add.s64 	%rd17, %rd2, %rd16;
	sub.s32 	%r55, %r67, %r63;
	mul.wide.s32 	%rd18, %r55, 264;
	mov.u64 	%rd19, map2_transpose_sub_double$__cuda_local_var_16372_1747_non_const_tile;
	add.s64 	%rd20, %rd19, %rd18;
	shl.b64 	%rd21, %rd5, 3;
	add.s64 	%rd22, %rd20, %rd21;
	ld.shared.f64 	%fd2, [%rd22];
	ld.global.f64 	%fd3, [%rd17];
	sub.f64 	%fd4, %fd3, %fd2;
	add.s32 	%r56, %r67, %r18;
	mul.wide.s32 	%rd23, %r56, 8;
	add.s64 	%rd24, %rd1, %rd23;
	st.global.f64 	[%rd24], %fd4;
	add.s32 	%r67, %r67, %r1;
	setp.lt.s32	%p9, %r67, %r7;
	@%p9 bra 	BB63_12;

BB63_13:
	add.s32 	%r66, %r66, %r31;
	setp.lt.s32	%p10, %r66, %r4;
	@%p10 bra 	BB63_10;

BB63_14:
	bar.sync 	0;
	mov.u32 	%r59, %nctaid.x;
	mad.lo.s32 	%r63, %r59, %r1, %r63;
	setp.lt.s32	%p11, %r63, %r25;
	@%p11 bra 	BB63_4;

BB63_15:
	mov.u32 	%r60, %nctaid.y;
	mad.lo.s32 	%r62, %r60, %r31, %r62;
	setp.lt.s32	%p12, %r62, %r26;
	@%p12 bra 	BB63_2;

BB63_16:
	ret;
}

	// .globl	map2_mul_double
.visible .entry map2_mul_double(
	.param .u32 map2_mul_double_param_0,
	.param .u32 map2_mul_double_param_1,
	.param .u64 map2_mul_double_param_2,
	.param .u32 map2_mul_double_param_3,
	.param .u64 map2_mul_double_param_4,
	.param .u32 map2_mul_double_param_5,
	.param .u64 map2_mul_double_param_6,
	.param .u32 map2_mul_double_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<30>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<13>;


	ld.param.u32 	%r13, [map2_mul_double_param_0];
	ld.param.u32 	%r14, [map2_mul_double_param_1];
	ld.param.u64 	%rd4, [map2_mul_double_param_2];
	ld.param.u32 	%r15, [map2_mul_double_param_3];
	ld.param.u64 	%rd5, [map2_mul_double_param_4];
	ld.param.u32 	%r16, [map2_mul_double_param_5];
	ld.param.u64 	%rd6, [map2_mul_double_param_6];
	ld.param.u32 	%r17, [map2_mul_double_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r18, %ctaid.x;
	mov.u32 	%r19, %tid.x;
	mad.lo.s32 	%r28, %r1, %r18, %r19;
	setp.ge.s32	%p1, %r28, %r14;
	@%p1 bra 	BB64_6;

	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd6;
	cvta.to.global.u64 	%rd3, %rd5;
	mov.u32 	%r20, %tid.y;
	mov.u32 	%r21, %ntid.y;
	mov.u32 	%r22, %ctaid.y;
	mad.lo.s32 	%r3, %r21, %r22, %r20;
	mov.u32 	%r23, %nctaid.x;
	mul.lo.s32 	%r4, %r23, %r1;
	mov.u32 	%r24, %nctaid.y;
	mul.lo.s32 	%r5, %r24, %r21;

BB64_2:
	setp.ge.s32	%p2, %r3, %r13;
	@%p2 bra 	BB64_5;

	mul.lo.s32 	%r7, %r28, %r16;
	mul.lo.s32 	%r8, %r28, %r17;
	mul.lo.s32 	%r9, %r28, %r15;
	mov.u32 	%r29, %r3;

BB64_4:
	mov.u32 	%r10, %r29;
	add.s32 	%r25, %r10, %r7;
	mul.wide.s32 	%rd7, %r25, 8;
	add.s64 	%rd8, %rd3, %rd7;
	add.s32 	%r26, %r10, %r8;
	mul.wide.s32 	%rd9, %r26, 8;
	add.s64 	%rd10, %rd2, %rd9;
	ld.global.f64 	%fd1, [%rd10];
	ld.global.f64 	%fd2, [%rd8];
	mul.f64 	%fd3, %fd2, %fd1;
	add.s32 	%r27, %r10, %r9;
	mul.wide.s32 	%rd11, %r27, 8;
	add.s64 	%rd12, %rd1, %rd11;
	st.global.f64 	[%rd12], %fd3;
	add.s32 	%r11, %r5, %r10;
	setp.lt.s32	%p3, %r11, %r13;
	mov.u32 	%r29, %r11;
	@%p3 bra 	BB64_4;

BB64_5:
	add.s32 	%r28, %r4, %r28;
	setp.lt.s32	%p4, %r28, %r14;
	@%p4 bra 	BB64_2;

BB64_6:
	ret;
}

	// .globl	map2_v_s_mul_double
.visible .entry map2_v_s_mul_double(
	.param .u32 map2_v_s_mul_double_param_0,
	.param .u32 map2_v_s_mul_double_param_1,
	.param .u64 map2_v_s_mul_double_param_2,
	.param .u32 map2_v_s_mul_double_param_3,
	.param .u64 map2_v_s_mul_double_param_4,
	.param .u32 map2_v_s_mul_double_param_5,
	.param .f64 map2_v_s_mul_double_param_6
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map2_v_s_mul_double_param_0];
	ld.param.u32 	%r13, [map2_v_s_mul_double_param_1];
	ld.param.u64 	%rd3, [map2_v_s_mul_double_param_2];
	ld.param.u32 	%r14, [map2_v_s_mul_double_param_3];
	ld.param.u64 	%rd4, [map2_v_s_mul_double_param_4];
	ld.param.u32 	%r15, [map2_v_s_mul_double_param_5];
	ld.param.f64 	%fd1, [map2_v_s_mul_double_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB65_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB65_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB65_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB65_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd2, [%rd6];
	mul.f64 	%fd3, %fd2, %fd1;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd3;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB65_4;

BB65_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB65_2;

BB65_6:
	ret;
}

	// .globl	map2_s_v_mul_double
.visible .entry map2_s_v_mul_double(
	.param .u32 map2_s_v_mul_double_param_0,
	.param .u32 map2_s_v_mul_double_param_1,
	.param .u64 map2_s_v_mul_double_param_2,
	.param .u32 map2_s_v_mul_double_param_3,
	.param .f64 map2_s_v_mul_double_param_4,
	.param .u64 map2_s_v_mul_double_param_5,
	.param .u32 map2_s_v_mul_double_param_6
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map2_s_v_mul_double_param_0];
	ld.param.u32 	%r13, [map2_s_v_mul_double_param_1];
	ld.param.u64 	%rd3, [map2_s_v_mul_double_param_2];
	ld.param.u32 	%r14, [map2_s_v_mul_double_param_3];
	ld.param.f64 	%fd1, [map2_s_v_mul_double_param_4];
	ld.param.u64 	%rd4, [map2_s_v_mul_double_param_5];
	ld.param.u32 	%r15, [map2_s_v_mul_double_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB66_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB66_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB66_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB66_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd2, [%rd6];
	mul.f64 	%fd3, %fd2, %fd1;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd3;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB66_4;

BB66_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB66_2;

BB66_6:
	ret;
}

	// .globl	map2_transpose_mul_double
.visible .entry map2_transpose_mul_double(
	.param .u32 map2_transpose_mul_double_param_0,
	.param .u32 map2_transpose_mul_double_param_1,
	.param .u64 map2_transpose_mul_double_param_2,
	.param .u32 map2_transpose_mul_double_param_3,
	.param .u64 map2_transpose_mul_double_param_4,
	.param .u32 map2_transpose_mul_double_param_5,
	.param .u64 map2_transpose_mul_double_param_6,
	.param .u32 map2_transpose_mul_double_param_7
)
{
	.reg .pred 	%p<13>;
	.reg .b32 	%r<68>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<25>;
	// demoted variable
	.shared .align 8 .b8 map2_transpose_mul_double$__cuda_local_var_16373_1747_non_const_tile[8448];

	ld.param.u32 	%r25, [map2_transpose_mul_double_param_0];
	ld.param.u32 	%r26, [map2_transpose_mul_double_param_1];
	ld.param.u64 	%rd6, [map2_transpose_mul_double_param_2];
	ld.param.u32 	%r27, [map2_transpose_mul_double_param_3];
	ld.param.u64 	%rd7, [map2_transpose_mul_double_param_4];
	ld.param.u32 	%r28, [map2_transpose_mul_double_param_5];
	ld.param.u64 	%rd8, [map2_transpose_mul_double_param_6];
	ld.param.u32 	%r29, [map2_transpose_mul_double_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r30, %ctaid.y;
	mov.u32 	%r31, %ntid.y;
	mul.lo.s32 	%r62, %r30, %r31;
	setp.ge.s32	%p2, %r62, %r26;
	@%p2 bra 	BB67_16;

	cvta.to.global.u64 	%rd1, %rd6;
	cvta.to.global.u64 	%rd2, %rd7;
	cvta.to.global.u64 	%rd3, %rd8;

BB67_2:
	mov.u32 	%r33, %ctaid.x;
	mul.lo.s32 	%r63, %r33, %r1;
	setp.ge.s32	%p3, %r63, %r25;
	@%p3 bra 	BB67_15;

	add.s32 	%r35, %r62, 32;
	min.s32 	%r4, %r26, %r35;

BB67_4:
	add.s32 	%r38, %r63, 32;
	min.s32 	%r7, %r25, %r38;
	mov.u32 	%r39, %tid.y;
	add.s32 	%r64, %r39, %r63;
	setp.ge.s32	%p4, %r64, %r7;
	@%p4 bra 	BB67_9;

BB67_5:
	mov.u32 	%r40, %tid.x;
	add.s32 	%r65, %r40, %r62;
	setp.ge.s32	%p5, %r65, %r4;
	@%p5 bra 	BB67_8;

	mul.lo.s32 	%r10, %r64, %r29;
	sub.s32 	%r42, %r64, %r63;
	cvt.s64.s32	%rd4, %r42;

BB67_7:
	add.s32 	%r44, %r65, %r10;
	mul.wide.s32 	%rd9, %r44, 8;
	add.s64 	%rd10, %rd3, %rd9;
	ld.global.f64 	%fd1, [%rd10];
	sub.s32 	%r45, %r65, %r62;
	mul.lo.s64 	%rd11, %rd4, 264;
	mov.u64 	%rd12, map2_transpose_mul_double$__cuda_local_var_16373_1747_non_const_tile;
	add.s64 	%rd13, %rd12, %rd11;
	mul.wide.s32 	%rd14, %r45, 8;
	add.s64 	%rd15, %rd13, %rd14;
	st.shared.f64 	[%rd15], %fd1;
	add.s32 	%r65, %r65, %r1;
	setp.lt.s32	%p6, %r65, %r4;
	@%p6 bra 	BB67_7;

BB67_8:
	add.s32 	%r64, %r64, %r31;
	setp.lt.s32	%p7, %r64, %r7;
	@%p7 bra 	BB67_5;

BB67_9:
	add.s32 	%r66, %r39, %r62;
	setp.lt.s32	%p1, %r66, %r4;
	bar.sync 	0;
	@!%p1 bra 	BB67_14;
	bra.uni 	BB67_10;

BB67_10:
	mov.u32 	%r50, %tid.x;
	add.s32 	%r67, %r50, %r63;
	setp.ge.s32	%p8, %r67, %r7;
	@%p8 bra 	BB67_13;

	mul.lo.s32 	%r17, %r66, %r28;
	sub.s32 	%r52, %r66, %r62;
	cvt.s64.s32	%rd5, %r52;
	mul.lo.s32 	%r18, %r66, %r27;

BB67_12:
	add.s32 	%r54, %r67, %r17;
	mul.wide.s32 	%rd16, %r54, 8;
	add.s64 	%rd17, %rd2, %rd16;
	sub.s32 	%r55, %r67, %r63;
	mul.wide.s32 	%rd18, %r55, 264;
	mov.u64 	%rd19, map2_transpose_mul_double$__cuda_local_var_16373_1747_non_const_tile;
	add.s64 	%rd20, %rd19, %rd18;
	shl.b64 	%rd21, %rd5, 3;
	add.s64 	%rd22, %rd20, %rd21;
	ld.shared.f64 	%fd2, [%rd22];
	ld.global.f64 	%fd3, [%rd17];
	mul.f64 	%fd4, %fd3, %fd2;
	add.s32 	%r56, %r67, %r18;
	mul.wide.s32 	%rd23, %r56, 8;
	add.s64 	%rd24, %rd1, %rd23;
	st.global.f64 	[%rd24], %fd4;
	add.s32 	%r67, %r67, %r1;
	setp.lt.s32	%p9, %r67, %r7;
	@%p9 bra 	BB67_12;

BB67_13:
	add.s32 	%r66, %r66, %r31;
	setp.lt.s32	%p10, %r66, %r4;
	@%p10 bra 	BB67_10;

BB67_14:
	bar.sync 	0;
	mov.u32 	%r59, %nctaid.x;
	mad.lo.s32 	%r63, %r59, %r1, %r63;
	setp.lt.s32	%p11, %r63, %r25;
	@%p11 bra 	BB67_4;

BB67_15:
	mov.u32 	%r60, %nctaid.y;
	mad.lo.s32 	%r62, %r60, %r31, %r62;
	setp.lt.s32	%p12, %r62, %r26;
	@%p12 bra 	BB67_2;

BB67_16:
	ret;
}

	// .globl	map2_div_double
.visible .entry map2_div_double(
	.param .u32 map2_div_double_param_0,
	.param .u32 map2_div_double_param_1,
	.param .u64 map2_div_double_param_2,
	.param .u32 map2_div_double_param_3,
	.param .u64 map2_div_double_param_4,
	.param .u32 map2_div_double_param_5,
	.param .u64 map2_div_double_param_6,
	.param .u32 map2_div_double_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<30>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<13>;


	ld.param.u32 	%r13, [map2_div_double_param_0];
	ld.param.u32 	%r14, [map2_div_double_param_1];
	ld.param.u64 	%rd4, [map2_div_double_param_2];
	ld.param.u32 	%r15, [map2_div_double_param_3];
	ld.param.u64 	%rd5, [map2_div_double_param_4];
	ld.param.u32 	%r16, [map2_div_double_param_5];
	ld.param.u64 	%rd6, [map2_div_double_param_6];
	ld.param.u32 	%r17, [map2_div_double_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r18, %ctaid.x;
	mov.u32 	%r19, %tid.x;
	mad.lo.s32 	%r28, %r1, %r18, %r19;
	setp.ge.s32	%p1, %r28, %r14;
	@%p1 bra 	BB68_6;

	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd6;
	cvta.to.global.u64 	%rd3, %rd5;
	mov.u32 	%r20, %tid.y;
	mov.u32 	%r21, %ntid.y;
	mov.u32 	%r22, %ctaid.y;
	mad.lo.s32 	%r3, %r21, %r22, %r20;
	mov.u32 	%r23, %nctaid.x;
	mul.lo.s32 	%r4, %r23, %r1;
	mov.u32 	%r24, %nctaid.y;
	mul.lo.s32 	%r5, %r24, %r21;

BB68_2:
	setp.ge.s32	%p2, %r3, %r13;
	@%p2 bra 	BB68_5;

	mul.lo.s32 	%r7, %r28, %r16;
	mul.lo.s32 	%r8, %r28, %r17;
	mul.lo.s32 	%r9, %r28, %r15;
	mov.u32 	%r29, %r3;

BB68_4:
	mov.u32 	%r10, %r29;
	add.s32 	%r25, %r10, %r7;
	mul.wide.s32 	%rd7, %r25, 8;
	add.s64 	%rd8, %rd3, %rd7;
	add.s32 	%r26, %r10, %r8;
	mul.wide.s32 	%rd9, %r26, 8;
	add.s64 	%rd10, %rd2, %rd9;
	ld.global.f64 	%fd1, [%rd10];
	ld.global.f64 	%fd2, [%rd8];
	div.rn.f64 	%fd3, %fd2, %fd1;
	add.s32 	%r27, %r10, %r9;
	mul.wide.s32 	%rd11, %r27, 8;
	add.s64 	%rd12, %rd1, %rd11;
	st.global.f64 	[%rd12], %fd3;
	add.s32 	%r11, %r5, %r10;
	setp.lt.s32	%p3, %r11, %r13;
	mov.u32 	%r29, %r11;
	@%p3 bra 	BB68_4;

BB68_5:
	add.s32 	%r28, %r4, %r28;
	setp.lt.s32	%p4, %r28, %r14;
	@%p4 bra 	BB68_2;

BB68_6:
	ret;
}

	// .globl	map2_v_s_div_double
.visible .entry map2_v_s_div_double(
	.param .u32 map2_v_s_div_double_param_0,
	.param .u32 map2_v_s_div_double_param_1,
	.param .u64 map2_v_s_div_double_param_2,
	.param .u32 map2_v_s_div_double_param_3,
	.param .u64 map2_v_s_div_double_param_4,
	.param .u32 map2_v_s_div_double_param_5,
	.param .f64 map2_v_s_div_double_param_6
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map2_v_s_div_double_param_0];
	ld.param.u32 	%r13, [map2_v_s_div_double_param_1];
	ld.param.u64 	%rd3, [map2_v_s_div_double_param_2];
	ld.param.u32 	%r14, [map2_v_s_div_double_param_3];
	ld.param.u64 	%rd4, [map2_v_s_div_double_param_4];
	ld.param.u32 	%r15, [map2_v_s_div_double_param_5];
	ld.param.f64 	%fd1, [map2_v_s_div_double_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB69_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB69_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB69_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB69_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd2, [%rd6];
	div.rn.f64 	%fd3, %fd2, %fd1;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd3;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB69_4;

BB69_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB69_2;

BB69_6:
	ret;
}

	// .globl	map2_s_v_div_double
.visible .entry map2_s_v_div_double(
	.param .u32 map2_s_v_div_double_param_0,
	.param .u32 map2_s_v_div_double_param_1,
	.param .u64 map2_s_v_div_double_param_2,
	.param .u32 map2_s_v_div_double_param_3,
	.param .f64 map2_s_v_div_double_param_4,
	.param .u64 map2_s_v_div_double_param_5,
	.param .u32 map2_s_v_div_double_param_6
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map2_s_v_div_double_param_0];
	ld.param.u32 	%r13, [map2_s_v_div_double_param_1];
	ld.param.u64 	%rd3, [map2_s_v_div_double_param_2];
	ld.param.u32 	%r14, [map2_s_v_div_double_param_3];
	ld.param.f64 	%fd1, [map2_s_v_div_double_param_4];
	ld.param.u64 	%rd4, [map2_s_v_div_double_param_5];
	ld.param.u32 	%r15, [map2_s_v_div_double_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB70_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB70_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB70_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB70_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd2, [%rd6];
	div.rn.f64 	%fd3, %fd1, %fd2;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd3;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB70_4;

BB70_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB70_2;

BB70_6:
	ret;
}

	// .globl	map2_transpose_div_double
.visible .entry map2_transpose_div_double(
	.param .u32 map2_transpose_div_double_param_0,
	.param .u32 map2_transpose_div_double_param_1,
	.param .u64 map2_transpose_div_double_param_2,
	.param .u32 map2_transpose_div_double_param_3,
	.param .u64 map2_transpose_div_double_param_4,
	.param .u32 map2_transpose_div_double_param_5,
	.param .u64 map2_transpose_div_double_param_6,
	.param .u32 map2_transpose_div_double_param_7
)
{
	.reg .pred 	%p<13>;
	.reg .b32 	%r<68>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<25>;
	// demoted variable
	.shared .align 8 .b8 map2_transpose_div_double$__cuda_local_var_16374_1747_non_const_tile[8448];

	ld.param.u32 	%r25, [map2_transpose_div_double_param_0];
	ld.param.u32 	%r26, [map2_transpose_div_double_param_1];
	ld.param.u64 	%rd6, [map2_transpose_div_double_param_2];
	ld.param.u32 	%r27, [map2_transpose_div_double_param_3];
	ld.param.u64 	%rd7, [map2_transpose_div_double_param_4];
	ld.param.u32 	%r28, [map2_transpose_div_double_param_5];
	ld.param.u64 	%rd8, [map2_transpose_div_double_param_6];
	ld.param.u32 	%r29, [map2_transpose_div_double_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r30, %ctaid.y;
	mov.u32 	%r31, %ntid.y;
	mul.lo.s32 	%r62, %r30, %r31;
	setp.ge.s32	%p2, %r62, %r26;
	@%p2 bra 	BB71_16;

	cvta.to.global.u64 	%rd1, %rd6;
	cvta.to.global.u64 	%rd2, %rd7;
	cvta.to.global.u64 	%rd3, %rd8;

BB71_2:
	mov.u32 	%r33, %ctaid.x;
	mul.lo.s32 	%r63, %r33, %r1;
	setp.ge.s32	%p3, %r63, %r25;
	@%p3 bra 	BB71_15;

	add.s32 	%r35, %r62, 32;
	min.s32 	%r4, %r26, %r35;

BB71_4:
	add.s32 	%r38, %r63, 32;
	min.s32 	%r7, %r25, %r38;
	mov.u32 	%r39, %tid.y;
	add.s32 	%r64, %r39, %r63;
	setp.ge.s32	%p4, %r64, %r7;
	@%p4 bra 	BB71_9;

BB71_5:
	mov.u32 	%r40, %tid.x;
	add.s32 	%r65, %r40, %r62;
	setp.ge.s32	%p5, %r65, %r4;
	@%p5 bra 	BB71_8;

	mul.lo.s32 	%r10, %r64, %r29;
	sub.s32 	%r42, %r64, %r63;
	cvt.s64.s32	%rd4, %r42;

BB71_7:
	add.s32 	%r44, %r65, %r10;
	mul.wide.s32 	%rd9, %r44, 8;
	add.s64 	%rd10, %rd3, %rd9;
	ld.global.f64 	%fd1, [%rd10];
	sub.s32 	%r45, %r65, %r62;
	mul.lo.s64 	%rd11, %rd4, 264;
	mov.u64 	%rd12, map2_transpose_div_double$__cuda_local_var_16374_1747_non_const_tile;
	add.s64 	%rd13, %rd12, %rd11;
	mul.wide.s32 	%rd14, %r45, 8;
	add.s64 	%rd15, %rd13, %rd14;
	st.shared.f64 	[%rd15], %fd1;
	add.s32 	%r65, %r65, %r1;
	setp.lt.s32	%p6, %r65, %r4;
	@%p6 bra 	BB71_7;

BB71_8:
	add.s32 	%r64, %r64, %r31;
	setp.lt.s32	%p7, %r64, %r7;
	@%p7 bra 	BB71_5;

BB71_9:
	add.s32 	%r66, %r39, %r62;
	setp.lt.s32	%p1, %r66, %r4;
	bar.sync 	0;
	@!%p1 bra 	BB71_14;
	bra.uni 	BB71_10;

BB71_10:
	mov.u32 	%r50, %tid.x;
	add.s32 	%r67, %r50, %r63;
	setp.ge.s32	%p8, %r67, %r7;
	@%p8 bra 	BB71_13;

	mul.lo.s32 	%r17, %r66, %r28;
	sub.s32 	%r52, %r66, %r62;
	cvt.s64.s32	%rd5, %r52;
	mul.lo.s32 	%r18, %r66, %r27;

BB71_12:
	add.s32 	%r54, %r67, %r17;
	mul.wide.s32 	%rd16, %r54, 8;
	add.s64 	%rd17, %rd2, %rd16;
	sub.s32 	%r55, %r67, %r63;
	mul.wide.s32 	%rd18, %r55, 264;
	mov.u64 	%rd19, map2_transpose_div_double$__cuda_local_var_16374_1747_non_const_tile;
	add.s64 	%rd20, %rd19, %rd18;
	shl.b64 	%rd21, %rd5, 3;
	add.s64 	%rd22, %rd20, %rd21;
	ld.shared.f64 	%fd2, [%rd22];
	ld.global.f64 	%fd3, [%rd17];
	div.rn.f64 	%fd4, %fd3, %fd2;
	add.s32 	%r56, %r67, %r18;
	mul.wide.s32 	%rd23, %r56, 8;
	add.s64 	%rd24, %rd1, %rd23;
	st.global.f64 	[%rd24], %fd4;
	add.s32 	%r67, %r67, %r1;
	setp.lt.s32	%p9, %r67, %r7;
	@%p9 bra 	BB71_12;

BB71_13:
	add.s32 	%r66, %r66, %r31;
	setp.lt.s32	%p10, %r66, %r4;
	@%p10 bra 	BB71_10;

BB71_14:
	bar.sync 	0;
	mov.u32 	%r59, %nctaid.x;
	mad.lo.s32 	%r63, %r59, %r1, %r63;
	setp.lt.s32	%p11, %r63, %r25;
	@%p11 bra 	BB71_4;

BB71_15:
	mov.u32 	%r60, %nctaid.y;
	mad.lo.s32 	%r62, %r60, %r31, %r62;
	setp.lt.s32	%p12, %r62, %r26;
	@%p12 bra 	BB71_2;

BB71_16:
	ret;
}

	// .globl	map2_mod_double
.visible .entry map2_mod_double(
	.param .u32 map2_mod_double_param_0,
	.param .u32 map2_mod_double_param_1,
	.param .u64 map2_mod_double_param_2,
	.param .u32 map2_mod_double_param_3,
	.param .u64 map2_mod_double_param_4,
	.param .u32 map2_mod_double_param_5,
	.param .u64 map2_mod_double_param_6,
	.param .u32 map2_mod_double_param_7
)
{
	.reg .pred 	%p<20>;
	.reg .b32 	%r<73>;
	.reg .f64 	%fd<24>;
	.reg .b64 	%rd<31>;


	ld.param.u32 	%r21, [map2_mod_double_param_0];
	ld.param.u32 	%r22, [map2_mod_double_param_1];
	ld.param.u64 	%rd6, [map2_mod_double_param_2];
	ld.param.u32 	%r23, [map2_mod_double_param_3];
	ld.param.u64 	%rd7, [map2_mod_double_param_4];
	ld.param.u32 	%r24, [map2_mod_double_param_5];
	ld.param.u64 	%rd8, [map2_mod_double_param_6];
	ld.param.u32 	%r25, [map2_mod_double_param_7];
	mov.u32 	%r26, %tid.x;
	mov.u32 	%r27, %ntid.x;
	mov.u32 	%r28, %ctaid.x;
	mad.lo.s32 	%r68, %r27, %r28, %r26;
	setp.ge.s32	%p1, %r68, %r22;
	@%p1 bra 	BB72_21;

	mov.u32 	%r29, %ntid.y;
	mov.u32 	%r30, %nctaid.y;
	mul.lo.s32 	%r2, %r30, %r29;
	cvta.to.global.u64 	%rd9, %rd7;
	cvta.to.global.u64 	%rd12, %rd8;
	cvta.to.global.u64 	%rd27, %rd6;

BB72_2:
	mov.u32 	%r31, %ctaid.y;
	mov.u32 	%r33, %tid.y;
	mad.lo.s32 	%r69, %r29, %r31, %r33;
	setp.ge.s32	%p2, %r69, %r21;
	@%p2 bra 	BB72_20;

	mul.lo.s32 	%r4, %r68, %r24;
	mul.lo.s32 	%r5, %r68, %r25;
	mul.lo.s32 	%r6, %r68, %r23;

BB72_4:
	add.s32 	%r38, %r69, %r4;
	mul.wide.s32 	%rd10, %r38, 8;
	add.s64 	%rd11, %rd9, %rd10;
	add.s32 	%r39, %r69, %r5;
	mul.wide.s32 	%rd13, %r39, 8;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.f64 	%fd1, [%rd11];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd1;
	}
	and.b32  	%r40, %r9, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r41, %temp}, %fd1;
	}
	ld.global.f64 	%fd2, [%rd14];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r42}, %fd2;
	}
	and.b32  	%r43, %r42, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r44, %temp}, %fd2;
	}
	mov.b64 	%fd20, {%r41, %r40};
	mov.b64 	%fd21, {%r44, %r43};
	setp.gt.u32	%p3, %r40, 2146435071;
	setp.gt.u32	%p4, %r43, 2146435071;
	or.pred  	%p5, %p3, %p4;
	@%p5 bra 	BB72_16;
	bra.uni 	BB72_5;

BB72_16:
	setp.gtu.f64	%p14, %fd20, 0d7FF0000000000000;
	setp.gtu.f64	%p15, %fd21, 0d7FF0000000000000;
	or.pred  	%p16, %p14, %p15;
	@%p16 bra 	BB72_18;
	bra.uni 	BB72_17;

BB72_18:
	add.f64 	%fd23, %fd1, %fd2;
	bra.uni 	BB72_19;

BB72_5:
	setp.eq.f64	%p6, %fd21, 0d0000000000000000;
	mov.f64 	%fd15, 0dFFF8000000000000;
	mov.f64 	%fd23, %fd15;
	@%p6 bra 	BB72_19;

	setp.ltu.f64	%p7, %fd20, %fd21;
	mov.f64 	%fd23, %fd1;
	@%p7 bra 	BB72_19;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r45}, %fd20;
	}
	shr.u32 	%r70, %r45, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r46}, %fd21;
	}
	shr.u32 	%r71, %r46, 20;
	setp.ne.s32	%p8, %r70, 0;
	@%p8 bra 	BB72_9;

	mul.f64 	%fd20, %fd20, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd20;
	}
	shr.u32 	%r48, %r47, 20;
	add.s32 	%r70, %r48, -54;

BB72_9:
	setp.ne.s32	%p9, %r71, 0;
	@%p9 bra 	BB72_11;

	mul.f64 	%fd21, %fd21, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r49}, %fd21;
	}
	shr.u32 	%r50, %r49, 20;
	add.s32 	%r71, %r50, -54;

BB72_11:
	mov.b64 	 %rd15, %fd20;
	and.b64  	%rd16, %rd15, 4503599627370495;
	or.b64  	%rd30, %rd16, 4503599627370496;
	mov.b64 	 %rd17, %fd21;
	and.b64  	%rd18, %rd17, 4503599627370495;
	or.b64  	%rd2, %rd18, 4503599627370496;
	add.s32 	%r51, %r70, 1;
	sub.s32 	%r72, %r51, %r71;

BB72_12:
	sub.s64 	%rd19, %rd30, %rd2;
	mov.b64 	 %fd16, %rd19;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r52}, %fd16;
	}
	setp.lt.s32	%p10, %r52, 0;
	selp.b64	%rd20, %rd30, %rd19, %p10;
	add.s64 	%rd30, %rd20, %rd20;
	add.s32 	%r72, %r72, -1;
	setp.gt.s32	%p11, %r72, 0;
	@%p11 bra 	BB72_12;

	shr.u64 	%rd5, %rd30, 1;
	setp.eq.s64	%p12, %rd5, 0;
	mov.f64 	%fd22, 0d0000000000000000;
	@%p12 bra 	BB72_15;

	mov.b64 	 %fd18, %rd5;
	mul.f64 	%fd19, %fd18, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r53}, %fd19;
	}
	shr.u32 	%r54, %r53, 20;
	mov.u32 	%r55, 55;
	sub.s32 	%r56, %r55, %r54;
	sub.s32 	%r57, %r71, %r56;
	shl.b64 	%rd21, %rd5, %r56;
	setp.lt.s32	%p13, %r57, 1;
	mov.u32 	%r58, 1;
	sub.s32 	%r59, %r58, %r57;
	shr.u64 	%rd22, %rd21, %r59;
	add.s32 	%r60, %r57, 4095;
	cvt.u64.u32	%rd23, %r60;
	shl.b64 	%rd24, %rd23, 52;
	add.s64 	%rd25, %rd24, %rd21;
	selp.b64	%rd26, %rd22, %rd25, %p13;
	mov.b64 	 %fd22, %rd26;

BB72_15:
	and.b32  	%r61, %r9, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r62}, %fd22;
	}
	or.b32  	%r63, %r62, %r61;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r64, %temp}, %fd22;
	}
	mov.b64 	%fd23, {%r64, %r63};
	bra.uni 	BB72_19;

BB72_17:
	setp.eq.f64	%p17, %fd20, 0d7FF0000000000000;
	selp.f64	%fd23, 0dFFF8000000000000, %fd1, %p17;

BB72_19:
	add.s32 	%r65, %r69, %r6;
	mul.wide.s32 	%rd28, %r65, 8;
	add.s64 	%rd29, %rd27, %rd28;
	st.global.f64 	[%rd29], %fd23;
	add.s32 	%r69, %r2, %r69;
	setp.lt.s32	%p18, %r69, %r21;
	@%p18 bra 	BB72_4;

BB72_20:
	mov.u32 	%r66, %nctaid.x;
	mad.lo.s32 	%r68, %r66, %r27, %r68;
	setp.lt.s32	%p19, %r68, %r22;
	@%p19 bra 	BB72_2;

BB72_21:
	ret;
}

	// .globl	map2_v_s_mod_double
.visible .entry map2_v_s_mod_double(
	.param .u32 map2_v_s_mod_double_param_0,
	.param .u32 map2_v_s_mod_double_param_1,
	.param .u64 map2_v_s_mod_double_param_2,
	.param .u32 map2_v_s_mod_double_param_3,
	.param .u64 map2_v_s_mod_double_param_4,
	.param .u32 map2_v_s_mod_double_param_5,
	.param .f64 map2_v_s_mod_double_param_6
)
{
	.reg .pred 	%p<24>;
	.reg .b32 	%r<77>;
	.reg .f64 	%fd<30>;
	.reg .b64 	%rd<33>;


	ld.param.u32 	%r22, [map2_v_s_mod_double_param_0];
	ld.param.u32 	%r23, [map2_v_s_mod_double_param_1];
	ld.param.u64 	%rd6, [map2_v_s_mod_double_param_2];
	ld.param.u32 	%r24, [map2_v_s_mod_double_param_3];
	ld.param.u64 	%rd7, [map2_v_s_mod_double_param_4];
	ld.param.u32 	%r25, [map2_v_s_mod_double_param_5];
	ld.param.f64 	%fd19, [map2_v_s_mod_double_param_6];
	mov.u32 	%r26, %tid.x;
	mov.u32 	%r27, %ntid.x;
	mov.u32 	%r28, %ctaid.x;
	mad.lo.s32 	%r72, %r27, %r28, %r26;
	setp.ge.s32	%p1, %r72, %r23;
	@%p1 bra 	BB73_25;

	mov.u32 	%r29, %ntid.y;
	mov.u32 	%r30, %nctaid.y;
	mul.lo.s32 	%r2, %r30, %r29;

BB73_2:
	mov.u32 	%r31, %ctaid.y;
	mov.u32 	%r33, %tid.y;
	mad.lo.s32 	%r76, %r29, %r31, %r33;
	setp.ge.s32	%p2, %r76, %r22;
	@%p2 bra 	BB73_24;

	mul.lo.s32 	%r4, %r72, %r25;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd19;
	}
	and.b32  	%r36, %r35, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd19;
	}
	mov.b64 	%fd1, {%r37, %r36};
	setp.gt.u32	%p3, %r36, 2146435071;
	mul.lo.s32 	%r5, %r72, %r24;
	mul.f64 	%fd2, %fd1, 0d4350000000000000;
	@%p3 bra 	BB73_20;
	bra.uni 	BB73_4;

BB73_20:
	add.s32 	%r65, %r76, %r4;
	cvta.to.global.u64 	%rd26, %rd7;
	mul.wide.s32 	%rd27, %r65, 8;
	add.s64 	%rd28, %rd26, %rd27;
	ld.global.f64 	%fd14, [%rd28];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r66}, %fd14;
	}
	and.b32  	%r67, %r66, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r68, %temp}, %fd14;
	}
	mov.b64 	%fd15, {%r68, %r67};
	setp.gtu.f64	%p18, %fd15, 0d7FF0000000000000;
	setp.gtu.f64	%p19, %fd1, 0d7FF0000000000000;
	or.pred  	%p20, %p18, %p19;
	@%p20 bra 	BB73_22;
	bra.uni 	BB73_21;

BB73_22:
	add.f64 	%fd29, %fd14, %fd19;
	bra.uni 	BB73_23;

BB73_21:
	setp.eq.f64	%p21, %fd15, 0d7FF0000000000000;
	selp.f64	%fd29, 0dFFF8000000000000, %fd14, %p21;

BB73_23:
	add.s32 	%r69, %r76, %r5;
	cvta.to.global.u64 	%rd29, %rd6;
	mul.wide.s32 	%rd30, %r69, 8;
	add.s64 	%rd31, %rd29, %rd30;
	st.global.f64 	[%rd31], %fd29;
	add.s32 	%r76, %r2, %r76;
	setp.lt.s32	%p22, %r76, %r22;
	@%p22 bra 	BB73_20;
	bra.uni 	BB73_24;

BB73_4:
	add.s32 	%r41, %r76, %r4;
	cvta.to.global.u64 	%rd8, %rd7;
	mul.wide.s32 	%rd9, %r41, 8;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.f64 	%fd3, [%rd10];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd3;
	}
	and.b32  	%r42, %r8, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r43, %temp}, %fd3;
	}
	mov.b64 	%fd25, {%r43, %r42};
	setp.gt.u32	%p4, %r42, 2146435071;
	@%p4 bra 	BB73_16;
	bra.uni 	BB73_5;

BB73_16:
	setp.gtu.f64	%p13, %fd1, 0d7FF0000000000000;
	setp.gtu.f64	%p14, %fd25, 0d7FF0000000000000;
	or.pred  	%p15, %p14, %p13;
	@%p15 bra 	BB73_18;
	bra.uni 	BB73_17;

BB73_18:
	add.f64 	%fd28, %fd3, %fd19;
	bra.uni 	BB73_19;

BB73_5:
	setp.eq.f64	%p5, %fd1, 0d0000000000000000;
	mov.f64 	%fd20, 0dFFF8000000000000;
	mov.f64 	%fd28, %fd20;
	@%p5 bra 	BB73_19;

	setp.ltu.f64	%p6, %fd25, %fd1;
	mov.f64 	%fd28, %fd3;
	@%p6 bra 	BB73_19;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r44}, %fd25;
	}
	shr.u32 	%r73, %r44, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r45}, %fd1;
	}
	shr.u32 	%r74, %r45, 20;
	setp.ne.s32	%p7, %r73, 0;
	@%p7 bra 	BB73_9;

	mul.f64 	%fd25, %fd25, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r46}, %fd25;
	}
	shr.u32 	%r47, %r46, 20;
	add.s32 	%r73, %r47, -54;

BB73_9:
	setp.ne.s32	%p8, %r74, 0;
	mov.f64 	%fd26, %fd1;
	@%p8 bra 	BB73_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r48}, %fd2;
	}
	shr.u32 	%r49, %r48, 20;
	add.s32 	%r74, %r49, -54;
	mov.f64 	%fd26, %fd2;

BB73_11:
	mov.f64 	%fd7, %fd26;
	mov.b64 	 %rd11, %fd25;
	and.b64  	%rd12, %rd11, 4503599627370495;
	or.b64  	%rd32, %rd12, 4503599627370496;
	mov.b64 	 %rd13, %fd7;
	and.b64  	%rd14, %rd13, 4503599627370495;
	or.b64  	%rd2, %rd14, 4503599627370496;
	add.s32 	%r50, %r73, 1;
	sub.s32 	%r75, %r50, %r74;

BB73_12:
	sub.s64 	%rd15, %rd32, %rd2;
	mov.b64 	 %fd21, %rd15;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r51}, %fd21;
	}
	setp.lt.s32	%p9, %r51, 0;
	selp.b64	%rd16, %rd32, %rd15, %p9;
	add.s64 	%rd32, %rd16, %rd16;
	add.s32 	%r75, %r75, -1;
	setp.gt.s32	%p10, %r75, 0;
	@%p10 bra 	BB73_12;

	shr.u64 	%rd5, %rd32, 1;
	setp.eq.s64	%p11, %rd5, 0;
	mov.f64 	%fd27, 0d0000000000000000;
	@%p11 bra 	BB73_15;

	mov.b64 	 %fd23, %rd5;
	mul.f64 	%fd24, %fd23, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r52}, %fd24;
	}
	shr.u32 	%r53, %r52, 20;
	mov.u32 	%r54, 55;
	sub.s32 	%r55, %r54, %r53;
	sub.s32 	%r56, %r74, %r55;
	shl.b64 	%rd17, %rd5, %r55;
	setp.lt.s32	%p12, %r56, 1;
	mov.u32 	%r57, 1;
	sub.s32 	%r58, %r57, %r56;
	shr.u64 	%rd18, %rd17, %r58;
	add.s32 	%r59, %r56, 4095;
	cvt.u64.u32	%rd19, %r59;
	shl.b64 	%rd20, %rd19, 52;
	add.s64 	%rd21, %rd20, %rd17;
	selp.b64	%rd22, %rd18, %rd21, %p12;
	mov.b64 	 %fd27, %rd22;

BB73_15:
	and.b32  	%r60, %r8, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r61}, %fd27;
	}
	or.b32  	%r62, %r61, %r60;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r63, %temp}, %fd27;
	}
	mov.b64 	%fd28, {%r63, %r62};
	bra.uni 	BB73_19;

BB73_17:
	setp.eq.f64	%p16, %fd25, 0d7FF0000000000000;
	selp.f64	%fd28, 0dFFF8000000000000, %fd3, %p16;

BB73_19:
	add.s32 	%r64, %r76, %r5;
	cvta.to.global.u64 	%rd23, %rd6;
	mul.wide.s32 	%rd24, %r64, 8;
	add.s64 	%rd25, %rd23, %rd24;
	st.global.f64 	[%rd25], %fd28;
	add.s32 	%r76, %r2, %r76;
	setp.lt.s32	%p17, %r76, %r22;
	@%p17 bra 	BB73_4;

BB73_24:
	mov.u32 	%r70, %nctaid.x;
	mad.lo.s32 	%r72, %r70, %r27, %r72;
	setp.lt.s32	%p23, %r72, %r23;
	@%p23 bra 	BB73_2;

BB73_25:
	ret;
}

	// .globl	map2_s_v_mod_double
.visible .entry map2_s_v_mod_double(
	.param .u32 map2_s_v_mod_double_param_0,
	.param .u32 map2_s_v_mod_double_param_1,
	.param .u64 map2_s_v_mod_double_param_2,
	.param .u32 map2_s_v_mod_double_param_3,
	.param .f64 map2_s_v_mod_double_param_4,
	.param .u64 map2_s_v_mod_double_param_5,
	.param .u32 map2_s_v_mod_double_param_6
)
{
	.reg .pred 	%p<20>;
	.reg .b32 	%r<68>;
	.reg .f64 	%fd<25>;
	.reg .b64 	%rd<27>;


	ld.param.u32 	%r17, [map2_s_v_mod_double_param_0];
	ld.param.u32 	%r18, [map2_s_v_mod_double_param_1];
	ld.param.u64 	%rd6, [map2_s_v_mod_double_param_2];
	ld.param.u32 	%r19, [map2_s_v_mod_double_param_3];
	ld.param.f64 	%fd13, [map2_s_v_mod_double_param_4];
	ld.param.u64 	%rd7, [map2_s_v_mod_double_param_5];
	ld.param.u32 	%r20, [map2_s_v_mod_double_param_6];
	mov.u32 	%r21, %tid.x;
	mov.u32 	%r22, %ntid.x;
	mov.u32 	%r23, %ctaid.x;
	mad.lo.s32 	%r63, %r22, %r23, %r21;
	setp.ge.s32	%p1, %r63, %r18;
	@%p1 bra 	BB74_19;

	cvta.to.global.u64 	%rd8, %rd7;
	cvta.to.global.u64 	%rd23, %rd6;

BB74_2:
	mov.u32 	%r24, %ctaid.y;
	mov.u32 	%r25, %ntid.y;
	mov.u32 	%r26, %tid.y;
	mad.lo.s32 	%r64, %r25, %r24, %r26;
	setp.ge.s32	%p2, %r64, %r17;
	@%p2 bra 	BB74_18;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd13;
	}
	and.b32  	%r28, %r3, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r29, %temp}, %fd13;
	}
	mov.b64 	%fd1, {%r29, %r28};
	mul.f64 	%fd2, %fd1, 0d4350000000000000;

BB74_4:
	setp.gt.u32	%p3, %r28, 2146435071;
	mad.lo.s32 	%r34, %r63, %r20, %r64;
	mul.wide.s32 	%rd9, %r34, 8;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.f64 	%fd3, [%rd10];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd3;
	}
	and.b32  	%r36, %r35, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd3;
	}
	mov.b64 	%fd22, {%r37, %r36};
	setp.gt.u32	%p4, %r36, 2146435071;
	or.pred  	%p5, %p3, %p4;
	@%p5 bra 	BB74_16;
	bra.uni 	BB74_5;

BB74_16:
	setp.gtu.f64	%p14, %fd1, 0d7FF0000000000000;
	setp.gtu.f64	%p15, %fd22, 0d7FF0000000000000;
	or.pred  	%p16, %p14, %p15;
	setp.eq.f64	%p17, %fd1, 0d7FF0000000000000;
	selp.f64	%fd19, 0dFFF8000000000000, %fd13, %p17;
	add.f64 	%fd20, %fd3, %fd13;
	selp.f64	%fd11, %fd20, %fd19, %p16;
	mov.f64 	%fd24, %fd11;
	bra.uni 	BB74_17;

BB74_5:
	setp.eq.f64	%p6, %fd22, 0d0000000000000000;
	mov.f64 	%fd14, 0dFFF8000000000000;
	mov.f64 	%fd24, %fd14;
	@%p6 bra 	BB74_17;

	setp.ltu.f64	%p7, %fd1, %fd22;
	mov.f64 	%fd24, %fd13;
	@%p7 bra 	BB74_17;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd1;
	}
	shr.u32 	%r65, %r38, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r39}, %fd22;
	}
	shr.u32 	%r66, %r39, 20;
	setp.ne.s32	%p8, %r65, 0;
	mov.f64 	%fd21, %fd1;
	@%p8 bra 	BB74_9;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r40}, %fd2;
	}
	shr.u32 	%r41, %r40, 20;
	add.s32 	%r65, %r41, -54;
	mov.f64 	%fd21, %fd2;

BB74_9:
	mov.f64 	%fd5, %fd21;
	setp.ne.s32	%p9, %r66, 0;
	@%p9 bra 	BB74_11;

	mul.f64 	%fd22, %fd22, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r42}, %fd22;
	}
	shr.u32 	%r43, %r42, 20;
	add.s32 	%r66, %r43, -54;

BB74_11:
	mov.b64 	 %rd11, %fd5;
	and.b64  	%rd12, %rd11, 4503599627370495;
	or.b64  	%rd26, %rd12, 4503599627370496;
	mov.b64 	 %rd13, %fd22;
	and.b64  	%rd14, %rd13, 4503599627370495;
	or.b64  	%rd2, %rd14, 4503599627370496;
	add.s32 	%r44, %r65, 1;
	sub.s32 	%r67, %r44, %r66;

BB74_12:
	sub.s64 	%rd15, %rd26, %rd2;
	mov.b64 	 %fd15, %rd15;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r45}, %fd15;
	}
	setp.lt.s32	%p10, %r45, 0;
	selp.b64	%rd16, %rd26, %rd15, %p10;
	add.s64 	%rd26, %rd16, %rd16;
	add.s32 	%r67, %r67, -1;
	setp.gt.s32	%p11, %r67, 0;
	@%p11 bra 	BB74_12;

	shr.u64 	%rd5, %rd26, 1;
	setp.eq.s64	%p12, %rd5, 0;
	mov.f64 	%fd23, 0d0000000000000000;
	@%p12 bra 	BB74_15;

	mov.b64 	 %fd17, %rd5;
	mul.f64 	%fd18, %fd17, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r46}, %fd18;
	}
	shr.u32 	%r47, %r46, 20;
	mov.u32 	%r48, 55;
	sub.s32 	%r49, %r48, %r47;
	sub.s32 	%r50, %r66, %r49;
	shl.b64 	%rd17, %rd5, %r49;
	setp.lt.s32	%p13, %r50, 1;
	mov.u32 	%r51, 1;
	sub.s32 	%r52, %r51, %r50;
	shr.u64 	%rd18, %rd17, %r52;
	add.s32 	%r53, %r50, 4095;
	cvt.u64.u32	%rd19, %r53;
	shl.b64 	%rd20, %rd19, 52;
	add.s64 	%rd21, %rd20, %rd17;
	selp.b64	%rd22, %rd18, %rd21, %p13;
	mov.b64 	 %fd23, %rd22;

BB74_15:
	and.b32  	%r54, %r3, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r55}, %fd23;
	}
	or.b32  	%r56, %r55, %r54;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r57, %temp}, %fd23;
	}
	mov.b64 	%fd10, {%r57, %r56};
	mov.f64 	%fd24, %fd10;

BB74_17:
	mov.f64 	%fd12, %fd24;
	mad.lo.s32 	%r58, %r63, %r19, %r64;
	mul.wide.s32 	%rd24, %r58, 8;
	add.s64 	%rd25, %rd23, %rd24;
	st.global.f64 	[%rd25], %fd12;
	mov.u32 	%r60, %nctaid.y;
	mad.lo.s32 	%r64, %r60, %r25, %r64;
	setp.lt.s32	%p18, %r64, %r17;
	@%p18 bra 	BB74_4;

BB74_18:
	mov.u32 	%r61, %nctaid.x;
	mad.lo.s32 	%r63, %r61, %r22, %r63;
	setp.lt.s32	%p19, %r63, %r18;
	@%p19 bra 	BB74_2;

BB74_19:
	ret;
}

	// .globl	map2_transpose_mod_double
.visible .entry map2_transpose_mod_double(
	.param .u32 map2_transpose_mod_double_param_0,
	.param .u32 map2_transpose_mod_double_param_1,
	.param .u64 map2_transpose_mod_double_param_2,
	.param .u32 map2_transpose_mod_double_param_3,
	.param .u64 map2_transpose_mod_double_param_4,
	.param .u32 map2_transpose_mod_double_param_5,
	.param .u64 map2_transpose_mod_double_param_6,
	.param .u32 map2_transpose_mod_double_param_7
)
{
	.reg .pred 	%p<28>;
	.reg .b32 	%r<106>;
	.reg .f64 	%fd<25>;
	.reg .b64 	%rd<43>;
	// demoted variable
	.shared .align 8 .b8 map2_transpose_mod_double$__cuda_local_var_16375_1747_non_const_tile[8448];

	ld.param.u32 	%r35, [map2_transpose_mod_double_param_0];
	ld.param.u32 	%r36, [map2_transpose_mod_double_param_1];
	ld.param.u64 	%rd11, [map2_transpose_mod_double_param_2];
	ld.param.u32 	%r37, [map2_transpose_mod_double_param_3];
	ld.param.u64 	%rd12, [map2_transpose_mod_double_param_4];
	ld.param.u32 	%r38, [map2_transpose_mod_double_param_5];
	ld.param.u64 	%rd13, [map2_transpose_mod_double_param_6];
	ld.param.u32 	%r39, [map2_transpose_mod_double_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r40, %ctaid.y;
	mov.u32 	%r41, %ntid.y;
	mul.lo.s32 	%r97, %r40, %r41;
	setp.ge.s32	%p2, %r97, %r36;
	@%p2 bra 	BB75_31;

	cvta.to.global.u64 	%rd1, %rd11;
	cvta.to.global.u64 	%rd2, %rd12;
	cvta.to.global.u64 	%rd3, %rd13;

BB75_2:
	mov.u32 	%r43, %ctaid.x;
	mul.lo.s32 	%r98, %r43, %r1;
	setp.ge.s32	%p3, %r98, %r35;
	@%p3 bra 	BB75_30;

	add.s32 	%r45, %r97, 32;
	min.s32 	%r4, %r36, %r45;

BB75_4:
	add.s32 	%r48, %r98, 32;
	min.s32 	%r7, %r35, %r48;
	mov.u32 	%r49, %tid.y;
	add.s32 	%r99, %r49, %r98;
	setp.ge.s32	%p4, %r99, %r7;
	@%p4 bra 	BB75_9;

BB75_5:
	mov.u32 	%r50, %tid.x;
	add.s32 	%r100, %r50, %r97;
	setp.ge.s32	%p5, %r100, %r4;
	@%p5 bra 	BB75_8;

	mul.lo.s32 	%r10, %r99, %r39;
	sub.s32 	%r52, %r99, %r98;
	cvt.s64.s32	%rd4, %r52;

BB75_7:
	add.s32 	%r54, %r100, %r10;
	mul.wide.s32 	%rd14, %r54, 8;
	add.s64 	%rd15, %rd3, %rd14;
	ld.global.f64 	%fd15, [%rd15];
	sub.s32 	%r55, %r100, %r97;
	mul.lo.s64 	%rd16, %rd4, 264;
	mov.u64 	%rd17, map2_transpose_mod_double$__cuda_local_var_16375_1747_non_const_tile;
	add.s64 	%rd18, %rd17, %rd16;
	mul.wide.s32 	%rd19, %r55, 8;
	add.s64 	%rd20, %rd18, %rd19;
	st.shared.f64 	[%rd20], %fd15;
	add.s32 	%r100, %r100, %r1;
	setp.lt.s32	%p6, %r100, %r4;
	@%p6 bra 	BB75_7;

BB75_8:
	add.s32 	%r99, %r99, %r41;
	setp.lt.s32	%p7, %r99, %r7;
	@%p7 bra 	BB75_5;

BB75_9:
	add.s32 	%r101, %r49, %r97;
	setp.lt.s32	%p1, %r101, %r4;
	bar.sync 	0;
	@!%p1 bra 	BB75_29;
	bra.uni 	BB75_10;

BB75_10:
	mov.u32 	%r60, %tid.x;
	add.s32 	%r102, %r60, %r98;
	setp.ge.s32	%p8, %r102, %r7;
	@%p8 bra 	BB75_28;

	mul.lo.s32 	%r17, %r101, %r38;
	sub.s32 	%r62, %r101, %r97;
	cvt.s64.s32	%rd5, %r62;
	mul.lo.s32 	%r18, %r101, %r37;

BB75_12:
	add.s32 	%r64, %r102, %r17;
	mul.wide.s32 	%rd21, %r64, 8;
	add.s64 	%rd22, %rd2, %rd21;
	sub.s32 	%r65, %r102, %r98;
	mul.wide.s32 	%rd23, %r65, 264;
	mov.u64 	%rd24, map2_transpose_mod_double$__cuda_local_var_16375_1747_non_const_tile;
	add.s64 	%rd25, %rd24, %rd23;
	shl.b64 	%rd26, %rd5, 3;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.f64 	%fd1, [%rd22];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd1;
	}
	and.b32  	%r66, %r21, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r67, %temp}, %fd1;
	}
	ld.shared.f64 	%fd2, [%rd27];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r68}, %fd2;
	}
	and.b32  	%r69, %r68, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r70, %temp}, %fd2;
	}
	mov.b64 	%fd21, {%r67, %r66};
	mov.b64 	%fd22, {%r70, %r69};
	setp.gt.u32	%p9, %r66, 2146435071;
	setp.gt.u32	%p10, %r69, 2146435071;
	or.pred  	%p11, %p9, %p10;
	@%p11 bra 	BB75_24;
	bra.uni 	BB75_13;

BB75_24:
	setp.gtu.f64	%p20, %fd21, 0d7FF0000000000000;
	setp.gtu.f64	%p21, %fd22, 0d7FF0000000000000;
	or.pred  	%p22, %p20, %p21;
	@%p22 bra 	BB75_26;
	bra.uni 	BB75_25;

BB75_26:
	add.f64 	%fd24, %fd1, %fd2;
	bra.uni 	BB75_27;

BB75_13:
	setp.eq.f64	%p12, %fd22, 0d0000000000000000;
	mov.f64 	%fd16, 0dFFF8000000000000;
	mov.f64 	%fd24, %fd16;
	@%p12 bra 	BB75_27;

	setp.ltu.f64	%p13, %fd21, %fd22;
	mov.f64 	%fd24, %fd1;
	@%p13 bra 	BB75_27;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r71}, %fd21;
	}
	shr.u32 	%r103, %r71, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r72}, %fd22;
	}
	shr.u32 	%r104, %r72, 20;
	setp.ne.s32	%p14, %r103, 0;
	@%p14 bra 	BB75_17;

	mul.f64 	%fd21, %fd21, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r73}, %fd21;
	}
	shr.u32 	%r74, %r73, 20;
	add.s32 	%r103, %r74, -54;

BB75_17:
	setp.ne.s32	%p15, %r104, 0;
	@%p15 bra 	BB75_19;

	mul.f64 	%fd22, %fd22, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r75}, %fd22;
	}
	shr.u32 	%r76, %r75, 20;
	add.s32 	%r104, %r76, -54;

BB75_19:
	mov.b64 	 %rd28, %fd21;
	and.b64  	%rd29, %rd28, 4503599627370495;
	or.b64  	%rd42, %rd29, 4503599627370496;
	mov.b64 	 %rd30, %fd22;
	and.b64  	%rd31, %rd30, 4503599627370495;
	or.b64  	%rd7, %rd31, 4503599627370496;
	add.s32 	%r77, %r103, 1;
	sub.s32 	%r105, %r77, %r104;

BB75_20:
	sub.s64 	%rd32, %rd42, %rd7;
	mov.b64 	 %fd17, %rd32;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r78}, %fd17;
	}
	setp.lt.s32	%p16, %r78, 0;
	selp.b64	%rd33, %rd42, %rd32, %p16;
	add.s64 	%rd42, %rd33, %rd33;
	add.s32 	%r105, %r105, -1;
	setp.gt.s32	%p17, %r105, 0;
	@%p17 bra 	BB75_20;

	shr.u64 	%rd10, %rd42, 1;
	setp.eq.s64	%p18, %rd10, 0;
	mov.f64 	%fd23, 0d0000000000000000;
	@%p18 bra 	BB75_23;

	mov.b64 	 %fd19, %rd10;
	mul.f64 	%fd20, %fd19, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r79}, %fd20;
	}
	shr.u32 	%r80, %r79, 20;
	mov.u32 	%r81, 55;
	sub.s32 	%r82, %r81, %r80;
	sub.s32 	%r83, %r104, %r82;
	shl.b64 	%rd34, %rd10, %r82;
	setp.lt.s32	%p19, %r83, 1;
	mov.u32 	%r84, 1;
	sub.s32 	%r85, %r84, %r83;
	shr.u64 	%rd35, %rd34, %r85;
	add.s32 	%r86, %r83, 4095;
	cvt.u64.u32	%rd36, %r86;
	shl.b64 	%rd37, %rd36, 52;
	add.s64 	%rd38, %rd37, %rd34;
	selp.b64	%rd39, %rd35, %rd38, %p19;
	mov.b64 	 %fd23, %rd39;

BB75_23:
	and.b32  	%r87, %r21, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r88}, %fd23;
	}
	or.b32  	%r89, %r88, %r87;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r90, %temp}, %fd23;
	}
	mov.b64 	%fd24, {%r90, %r89};
	bra.uni 	BB75_27;

BB75_25:
	setp.eq.f64	%p23, %fd21, 0d7FF0000000000000;
	selp.f64	%fd24, 0dFFF8000000000000, %fd1, %p23;

BB75_27:
	add.s32 	%r91, %r102, %r18;
	mul.wide.s32 	%rd40, %r91, 8;
	add.s64 	%rd41, %rd1, %rd40;
	st.global.f64 	[%rd41], %fd24;
	add.s32 	%r102, %r102, %r1;
	setp.lt.s32	%p24, %r102, %r7;
	@%p24 bra 	BB75_12;

BB75_28:
	add.s32 	%r101, %r101, %r41;
	setp.lt.s32	%p25, %r101, %r4;
	@%p25 bra 	BB75_10;

BB75_29:
	bar.sync 	0;
	mov.u32 	%r94, %nctaid.x;
	mad.lo.s32 	%r98, %r94, %r1, %r98;
	setp.lt.s32	%p26, %r98, %r35;
	@%p26 bra 	BB75_4;

BB75_30:
	mov.u32 	%r95, %nctaid.y;
	mad.lo.s32 	%r97, %r95, %r41, %r97;
	setp.lt.s32	%p27, %r97, %r36;
	@%p27 bra 	BB75_2;

BB75_31:
	ret;
}

	// .globl	map2_pow_double
.visible .entry map2_pow_double(
	.param .u32 map2_pow_double_param_0,
	.param .u32 map2_pow_double_param_1,
	.param .u64 map2_pow_double_param_2,
	.param .u32 map2_pow_double_param_3,
	.param .u64 map2_pow_double_param_4,
	.param .u32 map2_pow_double_param_5,
	.param .u64 map2_pow_double_param_6,
	.param .u32 map2_pow_double_param_7
)
{
	.reg .pred 	%p<26>;
	.reg .b32 	%r<59>;
	.reg .f64 	%fd<25>;
	.reg .b64 	%rd<15>;


	ld.param.u32 	%r9, [map2_pow_double_param_0];
	ld.param.u32 	%r10, [map2_pow_double_param_1];
	ld.param.u64 	%rd2, [map2_pow_double_param_2];
	ld.param.u32 	%r11, [map2_pow_double_param_3];
	ld.param.u64 	%rd3, [map2_pow_double_param_4];
	ld.param.u32 	%r12, [map2_pow_double_param_5];
	ld.param.u64 	%rd4, [map2_pow_double_param_6];
	ld.param.u32 	%r13, [map2_pow_double_param_7];
	mov.u32 	%r14, %tid.x;
	mov.u32 	%r15, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mad.lo.s32 	%r57, %r15, %r16, %r14;
	setp.ge.s32	%p2, %r57, %r10;
	@%p2 bra 	BB76_20;

	cvta.to.global.u64 	%rd5, %rd3;
	cvta.to.global.u64 	%rd8, %rd4;
	cvta.to.global.u64 	%rd12, %rd2;

BB76_2:
	mov.u32 	%r17, %ctaid.y;
	mov.u32 	%r18, %ntid.y;
	mov.u32 	%r19, %tid.y;
	mad.lo.s32 	%r58, %r18, %r17, %r19;
	setp.ge.s32	%p3, %r58, %r9;
	@%p3 bra 	BB76_19;

BB76_3:
	mad.lo.s32 	%r24, %r57, %r12, %r58;
	mul.wide.s32 	%rd6, %r24, 8;
	add.s64 	%rd7, %rd5, %rd6;
	mad.lo.s32 	%r25, %r57, %r13, %r58;
	mul.wide.s32 	%rd9, %r25, 8;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.f64 	%fd1, [%rd7];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd1;
	}
	ld.global.f64 	%fd2, [%rd10];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd2;
	}
	bfe.u32 	%r26, %r6, 20, 11;
	add.s32 	%r27, %r26, -1012;
	mov.b64 	 %rd11, %fd2;
	shl.b64 	%rd1, %rd11, %r27;
	setp.eq.s64	%p4, %rd1, -9223372036854775808;
	abs.f64 	%fd3, %fd1;
	// Callseq Start 19
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd24, [retval0+0];
	
	//{
	}// Callseq End 19
	setp.lt.s32	%p5, %r5, 0;
	and.pred  	%p1, %p5, %p4;
	@!%p1 bra 	BB76_5;
	bra.uni 	BB76_4;

BB76_4:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd24;
	}
	xor.b32  	%r29, %r28, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r30, %temp}, %fd24;
	}
	mov.b64 	%fd24, {%r30, %r29};

BB76_5:
	mov.f64 	%fd23, %fd24;
	setp.eq.f64	%p6, %fd1, 0d0000000000000000;
	@%p6 bra 	BB76_8;
	bra.uni 	BB76_6;

BB76_8:
	selp.b32	%r31, %r5, 0, %p4;
	or.b32  	%r32, %r31, 2146435072;
	setp.lt.s32	%p10, %r6, 0;
	selp.b32	%r33, %r32, %r31, %p10;
	mov.u32 	%r34, 0;
	mov.b64 	%fd23, {%r34, %r33};
	bra.uni 	BB76_9;

BB76_6:
	setp.gt.s32	%p7, %r5, -1;
	@%p7 bra 	BB76_9;

	cvt.rzi.f64.f64	%fd14, %fd2;
	setp.neu.f64	%p8, %fd14, %fd2;
	selp.f64	%fd23, 0dFFF8000000000000, %fd23, %p8;

BB76_9:
	mov.f64 	%fd9, %fd23;
	add.f64 	%fd10, %fd1, %fd2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd10;
	}
	and.b32  	%r36, %r35, 2146435072;
	setp.ne.s32	%p11, %r36, 2146435072;
	mov.f64 	%fd22, %fd9;
	@%p11 bra 	BB76_18;

	setp.gtu.f64	%p12, %fd3, 0d7FF0000000000000;
	mov.f64 	%fd22, %fd10;
	@%p12 bra 	BB76_18;

	abs.f64 	%fd15, %fd2;
	setp.gtu.f64	%p13, %fd15, 0d7FF0000000000000;
	mov.f64 	%fd21, %fd10;
	mov.f64 	%fd22, %fd21;
	@%p13 bra 	BB76_18;

	and.b32  	%r37, %r6, 2147483647;
	setp.ne.s32	%p14, %r37, 2146435072;
	@%p14 bra 	BB76_14;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd2;
	}
	setp.eq.s32	%p15, %r38, 0;
	@%p15 bra 	BB76_17;
	bra.uni 	BB76_14;

BB76_17:
	setp.gt.f64	%p18, %fd3, 0d3FF0000000000000;
	selp.b32	%r47, 2146435072, 0, %p18;
	xor.b32  	%r48, %r47, 2146435072;
	setp.lt.s32	%p19, %r6, 0;
	selp.b32	%r49, %r48, %r47, %p19;
	setp.eq.f64	%p20, %fd1, 0dBFF0000000000000;
	selp.b32	%r50, 1072693248, %r49, %p20;
	mov.u32 	%r51, 0;
	mov.b64 	%fd22, {%r51, %r50};
	bra.uni 	BB76_18;

BB76_14:
	and.b32  	%r39, %r5, 2147483647;
	setp.ne.s32	%p16, %r39, 2146435072;
	mov.f64 	%fd19, %fd9;
	mov.f64 	%fd22, %fd19;
	@%p16 bra 	BB76_18;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r40, %temp}, %fd1;
	}
	setp.ne.s32	%p17, %r40, 0;
	mov.f64 	%fd22, %fd9;
	@%p17 bra 	BB76_18;

	shr.s32 	%r41, %r6, 31;
	and.b32  	%r42, %r41, -2146435072;
	add.s32 	%r43, %r42, 2146435072;
	or.b32  	%r44, %r43, -2147483648;
	selp.b32	%r45, %r44, %r43, %p1;
	mov.u32 	%r46, 0;
	mov.b64 	%fd22, {%r46, %r45};

BB76_18:
	setp.eq.f64	%p21, %fd2, 0d0000000000000000;
	setp.eq.f64	%p22, %fd1, 0d3FF0000000000000;
	or.pred  	%p23, %p22, %p21;
	selp.f64	%fd16, 0d3FF0000000000000, %fd22, %p23;
	mad.lo.s32 	%r52, %r57, %r11, %r58;
	mul.wide.s32 	%rd13, %r52, 8;
	add.s64 	%rd14, %rd12, %rd13;
	st.global.f64 	[%rd14], %fd16;
	mov.u32 	%r54, %nctaid.y;
	mad.lo.s32 	%r58, %r54, %r18, %r58;
	setp.lt.s32	%p24, %r58, %r9;
	@%p24 bra 	BB76_3;

BB76_19:
	mov.u32 	%r55, %nctaid.x;
	mad.lo.s32 	%r57, %r55, %r15, %r57;
	setp.lt.s32	%p25, %r57, %r10;
	@%p25 bra 	BB76_2;

BB76_20:
	ret;
}

	// .globl	map2_v_s_pow_double
.visible .entry map2_v_s_pow_double(
	.param .u32 map2_v_s_pow_double_param_0,
	.param .u32 map2_v_s_pow_double_param_1,
	.param .u64 map2_v_s_pow_double_param_2,
	.param .u32 map2_v_s_pow_double_param_3,
	.param .u64 map2_v_s_pow_double_param_4,
	.param .u32 map2_v_s_pow_double_param_5,
	.param .f64 map2_v_s_pow_double_param_6
)
{
	.reg .pred 	%p<26>;
	.reg .b32 	%r<59>;
	.reg .f64 	%fd<25>;
	.reg .b64 	%rd<13>;


	ld.param.u32 	%r10, [map2_v_s_pow_double_param_0];
	ld.param.u32 	%r11, [map2_v_s_pow_double_param_1];
	ld.param.u64 	%rd1, [map2_v_s_pow_double_param_2];
	ld.param.u32 	%r12, [map2_v_s_pow_double_param_3];
	ld.param.u64 	%rd2, [map2_v_s_pow_double_param_4];
	ld.param.u32 	%r13, [map2_v_s_pow_double_param_5];
	ld.param.f64 	%fd13, [map2_v_s_pow_double_param_6];
	mov.u32 	%r14, %tid.x;
	mov.u32 	%r15, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mad.lo.s32 	%r57, %r15, %r16, %r14;
	setp.ge.s32	%p2, %r57, %r11;
	@%p2 bra 	BB77_21;

	cvta.to.global.u64 	%rd5, %rd2;
	cvta.to.global.u64 	%rd10, %rd1;

BB77_2:
	mov.u32 	%r17, %ctaid.y;
	mov.u32 	%r18, %ntid.y;
	mov.u32 	%r19, %tid.y;
	mad.lo.s32 	%r58, %r18, %r17, %r19;
	setp.ge.s32	%p3, %r58, %r10;
	@%p3 bra 	BB77_20;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd13;
	}
	shr.s32 	%r21, %r3, 31;
	and.b32  	%r22, %r21, -2146435072;
	add.s32 	%r4, %r22, 2146435072;

BB77_4:
	bfe.u32 	%r26, %r3, 20, 11;
	add.s32 	%r27, %r26, -1012;
	mov.b64 	 %rd3, %fd13;
	shl.b64 	%rd4, %rd3, %r27;
	setp.eq.s64	%p4, %rd4, -9223372036854775808;
	mad.lo.s32 	%r28, %r57, %r13, %r58;
	mul.wide.s32 	%rd6, %r28, 8;
	add.s64 	%rd7, %rd5, %rd6;
	ld.global.f64 	%fd1, [%rd7];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd1;
	}
	abs.f64 	%fd2, %fd1;
	// Callseq Start 20
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd24, [retval0+0];
	
	//{
	}// Callseq End 20
	setp.lt.s32	%p5, %r7, 0;
	and.pred  	%p1, %p5, %p4;
	@!%p1 bra 	BB77_6;
	bra.uni 	BB77_5;

BB77_5:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd24;
	}
	xor.b32  	%r30, %r29, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r31, %temp}, %fd24;
	}
	mov.b64 	%fd24, {%r31, %r30};

BB77_6:
	mov.f64 	%fd23, %fd24;
	setp.eq.f64	%p6, %fd1, 0d0000000000000000;
	@%p6 bra 	BB77_9;
	bra.uni 	BB77_7;

BB77_9:
	setp.lt.s32	%p9, %r3, 0;
	bfe.u32 	%r32, %r3, 20, 11;
	add.s32 	%r33, %r32, -1012;
	shl.b64 	%rd9, %rd3, %r33;
	setp.eq.s64	%p10, %rd9, -9223372036854775808;
	selp.b32	%r34, %r7, 0, %p10;
	or.b32  	%r35, %r34, 2146435072;
	selp.b32	%r36, %r35, %r34, %p9;
	mov.u32 	%r37, 0;
	mov.b64 	%fd23, {%r37, %r36};
	bra.uni 	BB77_10;

BB77_7:
	setp.gt.s32	%p7, %r7, -1;
	@%p7 bra 	BB77_10;

	cvt.rzi.f64.f64	%fd14, %fd13;
	setp.neu.f64	%p8, %fd14, %fd13;
	selp.f64	%fd23, 0dFFF8000000000000, %fd23, %p8;

BB77_10:
	mov.f64 	%fd8, %fd23;
	add.f64 	%fd9, %fd1, %fd13;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd9;
	}
	and.b32  	%r39, %r38, 2146435072;
	setp.ne.s32	%p11, %r39, 2146435072;
	mov.f64 	%fd22, %fd8;
	@%p11 bra 	BB77_19;

	setp.gtu.f64	%p12, %fd2, 0d7FF0000000000000;
	mov.f64 	%fd22, %fd9;
	@%p12 bra 	BB77_19;

	abs.f64 	%fd15, %fd13;
	setp.gtu.f64	%p13, %fd15, 0d7FF0000000000000;
	mov.f64 	%fd21, %fd9;
	mov.f64 	%fd22, %fd21;
	@%p13 bra 	BB77_19;

	and.b32  	%r40, %r3, 2147483647;
	setp.ne.s32	%p14, %r40, 2146435072;
	@%p14 bra 	BB77_15;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r41, %temp}, %fd13;
	}
	setp.eq.s32	%p15, %r41, 0;
	@%p15 bra 	BB77_18;
	bra.uni 	BB77_15;

BB77_18:
	setp.lt.s32	%p18, %r3, 0;
	setp.gt.f64	%p19, %fd2, 0d3FF0000000000000;
	selp.b32	%r47, 2146435072, 0, %p19;
	xor.b32  	%r48, %r47, 2146435072;
	selp.b32	%r49, %r48, %r47, %p18;
	setp.eq.f64	%p20, %fd1, 0dBFF0000000000000;
	selp.b32	%r50, 1072693248, %r49, %p20;
	mov.u32 	%r51, 0;
	mov.b64 	%fd22, {%r51, %r50};
	bra.uni 	BB77_19;

BB77_15:
	and.b32  	%r42, %r7, 2147483647;
	setp.ne.s32	%p16, %r42, 2146435072;
	mov.f64 	%fd19, %fd8;
	mov.f64 	%fd22, %fd19;
	@%p16 bra 	BB77_19;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r43, %temp}, %fd1;
	}
	setp.ne.s32	%p17, %r43, 0;
	mov.f64 	%fd22, %fd8;
	@%p17 bra 	BB77_19;

	or.b32  	%r44, %r4, -2147483648;
	selp.b32	%r45, %r44, %r4, %p1;
	mov.u32 	%r46, 0;
	mov.b64 	%fd22, {%r46, %r45};

BB77_19:
	setp.eq.f64	%p21, %fd1, 0d3FF0000000000000;
	setp.eq.f64	%p22, %fd13, 0d0000000000000000;
	or.pred  	%p23, %p21, %p22;
	selp.f64	%fd16, 0d3FF0000000000000, %fd22, %p23;
	mad.lo.s32 	%r52, %r57, %r12, %r58;
	mul.wide.s32 	%rd11, %r52, 8;
	add.s64 	%rd12, %rd10, %rd11;
	st.global.f64 	[%rd12], %fd16;
	mov.u32 	%r54, %nctaid.y;
	mad.lo.s32 	%r58, %r54, %r18, %r58;
	setp.lt.s32	%p24, %r58, %r10;
	@%p24 bra 	BB77_4;

BB77_20:
	mov.u32 	%r55, %nctaid.x;
	mad.lo.s32 	%r57, %r55, %r15, %r57;
	setp.lt.s32	%p25, %r57, %r11;
	@%p25 bra 	BB77_2;

BB77_21:
	ret;
}

	// .globl	map2_s_v_pow_double
.visible .entry map2_s_v_pow_double(
	.param .u32 map2_s_v_pow_double_param_0,
	.param .u32 map2_s_v_pow_double_param_1,
	.param .u64 map2_s_v_pow_double_param_2,
	.param .u32 map2_s_v_pow_double_param_3,
	.param .f64 map2_s_v_pow_double_param_4,
	.param .u64 map2_s_v_pow_double_param_5,
	.param .u32 map2_s_v_pow_double_param_6
)
{
	.reg .pred 	%p<27>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<24>;
	.reg .b64 	%rd<11>;


	ld.param.u32 	%r10, [map2_s_v_pow_double_param_0];
	ld.param.u32 	%r11, [map2_s_v_pow_double_param_1];
	ld.param.u64 	%rd2, [map2_s_v_pow_double_param_2];
	ld.param.u32 	%r12, [map2_s_v_pow_double_param_3];
	ld.param.f64 	%fd14, [map2_s_v_pow_double_param_4];
	ld.param.u64 	%rd3, [map2_s_v_pow_double_param_5];
	ld.param.u32 	%r13, [map2_s_v_pow_double_param_6];
	mov.u32 	%r14, %tid.x;
	mov.u32 	%r15, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mad.lo.s32 	%r55, %r15, %r16, %r14;
	setp.ge.s32	%p2, %r55, %r11;
	@%p2 bra 	BB78_20;

	cvta.to.global.u64 	%rd4, %rd3;
	cvta.to.global.u64 	%rd8, %rd2;

BB78_2:
	mov.u32 	%r17, %ctaid.y;
	mov.u32 	%r18, %ntid.y;
	mov.u32 	%r19, %tid.y;
	mad.lo.s32 	%r56, %r18, %r17, %r19;
	setp.ge.s32	%p3, %r56, %r10;
	@%p3 bra 	BB78_19;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd14;
	}
	abs.f64 	%fd1, %fd14;
	setp.gt.f64	%p4, %fd1, 0d3FF0000000000000;
	selp.b32	%r4, 2146435072, 0, %p4;

BB78_4:
	mad.lo.s32 	%r24, %r55, %r13, %r56;
	mul.wide.s32 	%rd5, %r24, 8;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.f64 	%fd2, [%rd6];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd2;
	}
	bfe.u32 	%r25, %r7, 20, 11;
	add.s32 	%r26, %r25, -1012;
	mov.b64 	 %rd7, %fd2;
	shl.b64 	%rd1, %rd7, %r26;
	setp.eq.s64	%p5, %rd1, -9223372036854775808;
	// Callseq Start 21
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd1;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd23, [retval0+0];
	
	//{
	}// Callseq End 21
	setp.lt.s32	%p6, %r3, 0;
	and.pred  	%p1, %p6, %p5;
	@!%p1 bra 	BB78_6;
	bra.uni 	BB78_5;

BB78_5:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd23;
	}
	xor.b32  	%r28, %r27, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r29, %temp}, %fd23;
	}
	mov.b64 	%fd23, {%r29, %r28};

BB78_6:
	mov.f64 	%fd22, %fd23;
	setp.eq.f64	%p7, %fd14, 0d0000000000000000;
	@%p7 bra 	BB78_9;
	bra.uni 	BB78_7;

BB78_9:
	selp.b32	%r30, %r3, 0, %p5;
	or.b32  	%r31, %r30, 2146435072;
	setp.lt.s32	%p11, %r7, 0;
	selp.b32	%r32, %r31, %r30, %p11;
	mov.u32 	%r33, 0;
	mov.b64 	%fd22, {%r33, %r32};
	bra.uni 	BB78_10;

BB78_7:
	setp.gt.s32	%p8, %r3, -1;
	@%p8 bra 	BB78_10;

	cvt.rzi.f64.f64	%fd15, %fd2;
	setp.neu.f64	%p9, %fd15, %fd2;
	selp.f64	%fd22, 0dFFF8000000000000, %fd22, %p9;

BB78_10:
	mov.f64 	%fd8, %fd22;
	add.f64 	%fd9, %fd2, %fd14;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd9;
	}
	and.b32  	%r35, %r34, 2146435072;
	setp.ne.s32	%p12, %r35, 2146435072;
	setp.gtu.f64	%p13, %fd1, 0d7FF0000000000000;
	or.pred  	%p14, %p12, %p13;
	selp.f64	%fd10, %fd8, %fd9, %p12;
	mov.f64 	%fd21, %fd10;
	@%p14 bra 	BB78_18;

	abs.f64 	%fd16, %fd2;
	setp.gtu.f64	%p15, %fd16, 0d7FF0000000000000;
	mov.f64 	%fd21, %fd9;
	@%p15 bra 	BB78_18;

	and.b32  	%r36, %r7, 2147483647;
	setp.ne.s32	%p16, %r36, 2146435072;
	@%p16 bra 	BB78_14;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd2;
	}
	setp.eq.s32	%p17, %r37, 0;
	@%p17 bra 	BB78_17;
	bra.uni 	BB78_14;

BB78_17:
	setp.eq.f64	%p20, %fd14, 0dBFF0000000000000;
	xor.b32  	%r46, %r4, 2146435072;
	setp.lt.s32	%p21, %r7, 0;
	selp.b32	%r47, %r46, %r4, %p21;
	selp.b32	%r48, 1072693248, %r47, %p20;
	mov.u32 	%r49, 0;
	mov.b64 	%fd21, {%r49, %r48};
	bra.uni 	BB78_18;

BB78_14:
	and.b32  	%r38, %r3, 2147483647;
	setp.ne.s32	%p18, %r38, 2146435072;
	mov.f64 	%fd21, %fd8;
	@%p18 bra 	BB78_18;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r39, %temp}, %fd14;
	}
	setp.ne.s32	%p19, %r39, 0;
	mov.f64 	%fd21, %fd8;
	@%p19 bra 	BB78_18;

	shr.s32 	%r40, %r7, 31;
	and.b32  	%r41, %r40, -2146435072;
	add.s32 	%r42, %r41, 2146435072;
	or.b32  	%r43, %r42, -2147483648;
	selp.b32	%r44, %r43, %r42, %p1;
	mov.u32 	%r45, 0;
	mov.b64 	%fd21, {%r45, %r44};

BB78_18:
	setp.eq.f64	%p22, %fd2, 0d0000000000000000;
	setp.eq.f64	%p23, %fd14, 0d3FF0000000000000;
	or.pred  	%p24, %p23, %p22;
	selp.f64	%fd17, 0d3FF0000000000000, %fd21, %p24;
	mad.lo.s32 	%r50, %r55, %r12, %r56;
	mul.wide.s32 	%rd9, %r50, 8;
	add.s64 	%rd10, %rd8, %rd9;
	st.global.f64 	[%rd10], %fd17;
	mov.u32 	%r52, %nctaid.y;
	mad.lo.s32 	%r56, %r52, %r18, %r56;
	setp.lt.s32	%p25, %r56, %r10;
	@%p25 bra 	BB78_4;

BB78_19:
	mov.u32 	%r53, %nctaid.x;
	mad.lo.s32 	%r55, %r53, %r15, %r55;
	setp.lt.s32	%p26, %r55, %r11;
	@%p26 bra 	BB78_2;

BB78_20:
	ret;
}

	// .globl	map2_transpose_pow_double
.visible .entry map2_transpose_pow_double(
	.param .u32 map2_transpose_pow_double_param_0,
	.param .u32 map2_transpose_pow_double_param_1,
	.param .u64 map2_transpose_pow_double_param_2,
	.param .u32 map2_transpose_pow_double_param_3,
	.param .u64 map2_transpose_pow_double_param_4,
	.param .u32 map2_transpose_pow_double_param_5,
	.param .u64 map2_transpose_pow_double_param_6,
	.param .u32 map2_transpose_pow_double_param_7
)
{
	.reg .pred 	%p<34>;
	.reg .b32 	%r<96>;
	.reg .f64 	%fd<26>;
	.reg .b64 	%rd<27>;
	// demoted variable
	.shared .align 8 .b8 map2_transpose_pow_double$__cuda_local_var_16376_1747_non_const_tile[8448];

	ld.param.u32 	%r27, [map2_transpose_pow_double_param_0];
	ld.param.u32 	%r28, [map2_transpose_pow_double_param_1];
	ld.param.u64 	%rd7, [map2_transpose_pow_double_param_2];
	ld.param.u32 	%r29, [map2_transpose_pow_double_param_3];
	ld.param.u64 	%rd8, [map2_transpose_pow_double_param_4];
	ld.param.u32 	%r30, [map2_transpose_pow_double_param_5];
	ld.param.u64 	%rd9, [map2_transpose_pow_double_param_6];
	ld.param.u32 	%r31, [map2_transpose_pow_double_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r32, %ctaid.y;
	mov.u32 	%r33, %ntid.y;
	mul.lo.s32 	%r90, %r32, %r33;
	setp.ge.s32	%p3, %r90, %r28;
	@%p3 bra 	BB79_31;

	cvta.to.global.u64 	%rd1, %rd7;
	cvta.to.global.u64 	%rd2, %rd8;
	cvta.to.global.u64 	%rd3, %rd9;

BB79_2:
	mov.u32 	%r35, %ctaid.x;
	mul.lo.s32 	%r91, %r35, %r1;
	setp.ge.s32	%p4, %r91, %r27;
	@%p4 bra 	BB79_30;

	add.s32 	%r37, %r90, 32;
	min.s32 	%r4, %r28, %r37;

BB79_4:
	add.s32 	%r40, %r91, 32;
	min.s32 	%r7, %r27, %r40;
	mov.u32 	%r41, %tid.y;
	add.s32 	%r92, %r41, %r91;
	setp.ge.s32	%p5, %r92, %r7;
	@%p5 bra 	BB79_9;

BB79_5:
	mov.u32 	%r42, %tid.x;
	add.s32 	%r93, %r42, %r90;
	setp.ge.s32	%p6, %r93, %r4;
	@%p6 bra 	BB79_8;

	mul.lo.s32 	%r10, %r92, %r31;
	sub.s32 	%r44, %r92, %r91;
	cvt.s64.s32	%rd4, %r44;

BB79_7:
	add.s32 	%r46, %r93, %r10;
	mul.wide.s32 	%rd10, %r46, 8;
	add.s64 	%rd11, %rd3, %rd10;
	ld.global.f64 	%fd14, [%rd11];
	sub.s32 	%r47, %r93, %r90;
	mul.lo.s64 	%rd12, %rd4, 264;
	mov.u64 	%rd13, map2_transpose_pow_double$__cuda_local_var_16376_1747_non_const_tile;
	add.s64 	%rd14, %rd13, %rd12;
	mul.wide.s32 	%rd15, %r47, 8;
	add.s64 	%rd16, %rd14, %rd15;
	st.shared.f64 	[%rd16], %fd14;
	add.s32 	%r93, %r93, %r1;
	setp.lt.s32	%p7, %r93, %r4;
	@%p7 bra 	BB79_7;

BB79_8:
	add.s32 	%r92, %r92, %r33;
	setp.lt.s32	%p8, %r92, %r7;
	@%p8 bra 	BB79_5;

BB79_9:
	add.s32 	%r94, %r41, %r90;
	setp.lt.s32	%p1, %r94, %r4;
	bar.sync 	0;
	@!%p1 bra 	BB79_29;
	bra.uni 	BB79_10;

BB79_10:
	mov.u32 	%r52, %tid.x;
	add.s32 	%r95, %r52, %r91;
	setp.ge.s32	%p9, %r95, %r7;
	@%p9 bra 	BB79_28;

	mul.lo.s32 	%r17, %r94, %r30;
	sub.s32 	%r54, %r94, %r90;
	cvt.s64.s32	%rd5, %r54;
	mul.lo.s32 	%r18, %r94, %r29;

BB79_12:
	add.s32 	%r56, %r95, %r17;
	mul.wide.s32 	%rd17, %r56, 8;
	add.s64 	%rd18, %rd2, %rd17;
	sub.s32 	%r57, %r95, %r91;
	mul.wide.s32 	%rd19, %r57, 264;
	mov.u64 	%rd20, map2_transpose_pow_double$__cuda_local_var_16376_1747_non_const_tile;
	add.s64 	%rd21, %rd20, %rd19;
	shl.b64 	%rd22, %rd5, 3;
	add.s64 	%rd23, %rd21, %rd22;
	ld.global.f64 	%fd1, [%rd18];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd1;
	}
	ld.shared.f64 	%fd2, [%rd23];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r22}, %fd2;
	}
	bfe.u32 	%r58, %r22, 20, 11;
	add.s32 	%r59, %r58, -1012;
	mov.b64 	 %rd24, %fd2;
	shl.b64 	%rd6, %rd24, %r59;
	setp.eq.s64	%p10, %rd6, -9223372036854775808;
	abs.f64 	%fd3, %fd1;
	// Callseq Start 22
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd3;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd25, [retval0+0];
	
	//{
	}// Callseq End 22
	setp.lt.s32	%p11, %r21, 0;
	and.pred  	%p2, %p11, %p10;
	@!%p2 bra 	BB79_14;
	bra.uni 	BB79_13;

BB79_13:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r60}, %fd25;
	}
	xor.b32  	%r61, %r60, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r62, %temp}, %fd25;
	}
	mov.b64 	%fd25, {%r62, %r61};

BB79_14:
	mov.f64 	%fd24, %fd25;
	setp.eq.f64	%p12, %fd1, 0d0000000000000000;
	@%p12 bra 	BB79_17;
	bra.uni 	BB79_15;

BB79_17:
	selp.b32	%r63, %r21, 0, %p10;
	or.b32  	%r64, %r63, 2146435072;
	setp.lt.s32	%p16, %r22, 0;
	selp.b32	%r65, %r64, %r63, %p16;
	mov.u32 	%r66, 0;
	mov.b64 	%fd24, {%r66, %r65};
	bra.uni 	BB79_18;

BB79_15:
	setp.gt.s32	%p13, %r21, -1;
	@%p13 bra 	BB79_18;

	cvt.rzi.f64.f64	%fd15, %fd2;
	setp.neu.f64	%p14, %fd15, %fd2;
	selp.f64	%fd24, 0dFFF8000000000000, %fd24, %p14;

BB79_18:
	mov.f64 	%fd9, %fd24;
	add.f64 	%fd10, %fd1, %fd2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r67}, %fd10;
	}
	and.b32  	%r68, %r67, 2146435072;
	setp.ne.s32	%p17, %r68, 2146435072;
	mov.f64 	%fd23, %fd9;
	@%p17 bra 	BB79_27;

	setp.gtu.f64	%p18, %fd3, 0d7FF0000000000000;
	mov.f64 	%fd23, %fd10;
	@%p18 bra 	BB79_27;

	abs.f64 	%fd16, %fd2;
	setp.gtu.f64	%p19, %fd16, 0d7FF0000000000000;
	mov.f64 	%fd22, %fd10;
	mov.f64 	%fd23, %fd22;
	@%p19 bra 	BB79_27;

	and.b32  	%r69, %r22, 2147483647;
	setp.ne.s32	%p20, %r69, 2146435072;
	@%p20 bra 	BB79_23;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r70, %temp}, %fd2;
	}
	setp.eq.s32	%p21, %r70, 0;
	@%p21 bra 	BB79_26;
	bra.uni 	BB79_23;

BB79_26:
	setp.gt.f64	%p24, %fd3, 0d3FF0000000000000;
	selp.b32	%r79, 2146435072, 0, %p24;
	xor.b32  	%r80, %r79, 2146435072;
	setp.lt.s32	%p25, %r22, 0;
	selp.b32	%r81, %r80, %r79, %p25;
	setp.eq.f64	%p26, %fd1, 0dBFF0000000000000;
	selp.b32	%r82, 1072693248, %r81, %p26;
	mov.u32 	%r83, 0;
	mov.b64 	%fd23, {%r83, %r82};
	bra.uni 	BB79_27;

BB79_23:
	and.b32  	%r71, %r21, 2147483647;
	setp.ne.s32	%p22, %r71, 2146435072;
	mov.f64 	%fd20, %fd9;
	mov.f64 	%fd23, %fd20;
	@%p22 bra 	BB79_27;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r72, %temp}, %fd1;
	}
	setp.ne.s32	%p23, %r72, 0;
	mov.f64 	%fd23, %fd9;
	@%p23 bra 	BB79_27;

	shr.s32 	%r73, %r22, 31;
	and.b32  	%r74, %r73, -2146435072;
	add.s32 	%r75, %r74, 2146435072;
	or.b32  	%r76, %r75, -2147483648;
	selp.b32	%r77, %r76, %r75, %p2;
	mov.u32 	%r78, 0;
	mov.b64 	%fd23, {%r78, %r77};

BB79_27:
	setp.eq.f64	%p27, %fd2, 0d0000000000000000;
	setp.eq.f64	%p28, %fd1, 0d3FF0000000000000;
	or.pred  	%p29, %p28, %p27;
	selp.f64	%fd17, 0d3FF0000000000000, %fd23, %p29;
	add.s32 	%r84, %r95, %r18;
	mul.wide.s32 	%rd25, %r84, 8;
	add.s64 	%rd26, %rd1, %rd25;
	st.global.f64 	[%rd26], %fd17;
	add.s32 	%r95, %r95, %r1;
	setp.lt.s32	%p30, %r95, %r7;
	@%p30 bra 	BB79_12;

BB79_28:
	add.s32 	%r94, %r94, %r33;
	setp.lt.s32	%p31, %r94, %r4;
	@%p31 bra 	BB79_10;

BB79_29:
	bar.sync 	0;
	mov.u32 	%r87, %nctaid.x;
	mad.lo.s32 	%r91, %r87, %r1, %r91;
	setp.lt.s32	%p32, %r91, %r27;
	@%p32 bra 	BB79_4;

BB79_30:
	mov.u32 	%r88, %nctaid.y;
	mad.lo.s32 	%r90, %r88, %r33, %r90;
	setp.lt.s32	%p33, %r90, %r28;
	@%p33 bra 	BB79_2;

BB79_31:
	ret;
}

	// .globl	map2_max_double
.visible .entry map2_max_double(
	.param .u32 map2_max_double_param_0,
	.param .u32 map2_max_double_param_1,
	.param .u64 map2_max_double_param_2,
	.param .u32 map2_max_double_param_3,
	.param .u64 map2_max_double_param_4,
	.param .u32 map2_max_double_param_5,
	.param .u64 map2_max_double_param_6,
	.param .u32 map2_max_double_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<30>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<13>;


	ld.param.u32 	%r13, [map2_max_double_param_0];
	ld.param.u32 	%r14, [map2_max_double_param_1];
	ld.param.u64 	%rd4, [map2_max_double_param_2];
	ld.param.u32 	%r15, [map2_max_double_param_3];
	ld.param.u64 	%rd5, [map2_max_double_param_4];
	ld.param.u32 	%r16, [map2_max_double_param_5];
	ld.param.u64 	%rd6, [map2_max_double_param_6];
	ld.param.u32 	%r17, [map2_max_double_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r18, %ctaid.x;
	mov.u32 	%r19, %tid.x;
	mad.lo.s32 	%r28, %r1, %r18, %r19;
	setp.ge.s32	%p1, %r28, %r14;
	@%p1 bra 	BB80_6;

	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd6;
	cvta.to.global.u64 	%rd3, %rd5;
	mov.u32 	%r20, %tid.y;
	mov.u32 	%r21, %ntid.y;
	mov.u32 	%r22, %ctaid.y;
	mad.lo.s32 	%r3, %r21, %r22, %r20;
	mov.u32 	%r23, %nctaid.x;
	mul.lo.s32 	%r4, %r23, %r1;
	mov.u32 	%r24, %nctaid.y;
	mul.lo.s32 	%r5, %r24, %r21;

BB80_2:
	setp.ge.s32	%p2, %r3, %r13;
	@%p2 bra 	BB80_5;

	mul.lo.s32 	%r7, %r28, %r16;
	mul.lo.s32 	%r8, %r28, %r17;
	mul.lo.s32 	%r9, %r28, %r15;
	mov.u32 	%r29, %r3;

BB80_4:
	mov.u32 	%r10, %r29;
	add.s32 	%r25, %r10, %r7;
	mul.wide.s32 	%rd7, %r25, 8;
	add.s64 	%rd8, %rd3, %rd7;
	add.s32 	%r26, %r10, %r8;
	mul.wide.s32 	%rd9, %r26, 8;
	add.s64 	%rd10, %rd2, %rd9;
	ld.global.f64 	%fd1, [%rd10];
	ld.global.f64 	%fd2, [%rd8];
	max.f64 	%fd3, %fd2, %fd1;
	add.s32 	%r27, %r10, %r9;
	mul.wide.s32 	%rd11, %r27, 8;
	add.s64 	%rd12, %rd1, %rd11;
	st.global.f64 	[%rd12], %fd3;
	add.s32 	%r11, %r5, %r10;
	setp.lt.s32	%p3, %r11, %r13;
	mov.u32 	%r29, %r11;
	@%p3 bra 	BB80_4;

BB80_5:
	add.s32 	%r28, %r4, %r28;
	setp.lt.s32	%p4, %r28, %r14;
	@%p4 bra 	BB80_2;

BB80_6:
	ret;
}

	// .globl	map2_v_s_max_double
.visible .entry map2_v_s_max_double(
	.param .u32 map2_v_s_max_double_param_0,
	.param .u32 map2_v_s_max_double_param_1,
	.param .u64 map2_v_s_max_double_param_2,
	.param .u32 map2_v_s_max_double_param_3,
	.param .u64 map2_v_s_max_double_param_4,
	.param .u32 map2_v_s_max_double_param_5,
	.param .f64 map2_v_s_max_double_param_6
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map2_v_s_max_double_param_0];
	ld.param.u32 	%r13, [map2_v_s_max_double_param_1];
	ld.param.u64 	%rd3, [map2_v_s_max_double_param_2];
	ld.param.u32 	%r14, [map2_v_s_max_double_param_3];
	ld.param.u64 	%rd4, [map2_v_s_max_double_param_4];
	ld.param.u32 	%r15, [map2_v_s_max_double_param_5];
	ld.param.f64 	%fd1, [map2_v_s_max_double_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB81_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB81_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB81_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB81_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd2, [%rd6];
	max.f64 	%fd3, %fd2, %fd1;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd3;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB81_4;

BB81_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB81_2;

BB81_6:
	ret;
}

	// .globl	map2_s_v_max_double
.visible .entry map2_s_v_max_double(
	.param .u32 map2_s_v_max_double_param_0,
	.param .u32 map2_s_v_max_double_param_1,
	.param .u64 map2_s_v_max_double_param_2,
	.param .u32 map2_s_v_max_double_param_3,
	.param .f64 map2_s_v_max_double_param_4,
	.param .u64 map2_s_v_max_double_param_5,
	.param .u32 map2_s_v_max_double_param_6
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map2_s_v_max_double_param_0];
	ld.param.u32 	%r13, [map2_s_v_max_double_param_1];
	ld.param.u64 	%rd3, [map2_s_v_max_double_param_2];
	ld.param.u32 	%r14, [map2_s_v_max_double_param_3];
	ld.param.f64 	%fd1, [map2_s_v_max_double_param_4];
	ld.param.u64 	%rd4, [map2_s_v_max_double_param_5];
	ld.param.u32 	%r15, [map2_s_v_max_double_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB82_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB82_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB82_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB82_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd2, [%rd6];
	max.f64 	%fd3, %fd1, %fd2;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd3;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB82_4;

BB82_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB82_2;

BB82_6:
	ret;
}

	// .globl	map2_transpose_max_double
.visible .entry map2_transpose_max_double(
	.param .u32 map2_transpose_max_double_param_0,
	.param .u32 map2_transpose_max_double_param_1,
	.param .u64 map2_transpose_max_double_param_2,
	.param .u32 map2_transpose_max_double_param_3,
	.param .u64 map2_transpose_max_double_param_4,
	.param .u32 map2_transpose_max_double_param_5,
	.param .u64 map2_transpose_max_double_param_6,
	.param .u32 map2_transpose_max_double_param_7
)
{
	.reg .pred 	%p<13>;
	.reg .b32 	%r<68>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<25>;
	// demoted variable
	.shared .align 8 .b8 map2_transpose_max_double$__cuda_local_var_16377_1747_non_const_tile[8448];

	ld.param.u32 	%r25, [map2_transpose_max_double_param_0];
	ld.param.u32 	%r26, [map2_transpose_max_double_param_1];
	ld.param.u64 	%rd6, [map2_transpose_max_double_param_2];
	ld.param.u32 	%r27, [map2_transpose_max_double_param_3];
	ld.param.u64 	%rd7, [map2_transpose_max_double_param_4];
	ld.param.u32 	%r28, [map2_transpose_max_double_param_5];
	ld.param.u64 	%rd8, [map2_transpose_max_double_param_6];
	ld.param.u32 	%r29, [map2_transpose_max_double_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r30, %ctaid.y;
	mov.u32 	%r31, %ntid.y;
	mul.lo.s32 	%r62, %r30, %r31;
	setp.ge.s32	%p2, %r62, %r26;
	@%p2 bra 	BB83_16;

	cvta.to.global.u64 	%rd1, %rd6;
	cvta.to.global.u64 	%rd2, %rd7;
	cvta.to.global.u64 	%rd3, %rd8;

BB83_2:
	mov.u32 	%r33, %ctaid.x;
	mul.lo.s32 	%r63, %r33, %r1;
	setp.ge.s32	%p3, %r63, %r25;
	@%p3 bra 	BB83_15;

	add.s32 	%r35, %r62, 32;
	min.s32 	%r4, %r26, %r35;

BB83_4:
	add.s32 	%r38, %r63, 32;
	min.s32 	%r7, %r25, %r38;
	mov.u32 	%r39, %tid.y;
	add.s32 	%r64, %r39, %r63;
	setp.ge.s32	%p4, %r64, %r7;
	@%p4 bra 	BB83_9;

BB83_5:
	mov.u32 	%r40, %tid.x;
	add.s32 	%r65, %r40, %r62;
	setp.ge.s32	%p5, %r65, %r4;
	@%p5 bra 	BB83_8;

	mul.lo.s32 	%r10, %r64, %r29;
	sub.s32 	%r42, %r64, %r63;
	cvt.s64.s32	%rd4, %r42;

BB83_7:
	add.s32 	%r44, %r65, %r10;
	mul.wide.s32 	%rd9, %r44, 8;
	add.s64 	%rd10, %rd3, %rd9;
	ld.global.f64 	%fd1, [%rd10];
	sub.s32 	%r45, %r65, %r62;
	mul.lo.s64 	%rd11, %rd4, 264;
	mov.u64 	%rd12, map2_transpose_max_double$__cuda_local_var_16377_1747_non_const_tile;
	add.s64 	%rd13, %rd12, %rd11;
	mul.wide.s32 	%rd14, %r45, 8;
	add.s64 	%rd15, %rd13, %rd14;
	st.shared.f64 	[%rd15], %fd1;
	add.s32 	%r65, %r65, %r1;
	setp.lt.s32	%p6, %r65, %r4;
	@%p6 bra 	BB83_7;

BB83_8:
	add.s32 	%r64, %r64, %r31;
	setp.lt.s32	%p7, %r64, %r7;
	@%p7 bra 	BB83_5;

BB83_9:
	add.s32 	%r66, %r39, %r62;
	setp.lt.s32	%p1, %r66, %r4;
	bar.sync 	0;
	@!%p1 bra 	BB83_14;
	bra.uni 	BB83_10;

BB83_10:
	mov.u32 	%r50, %tid.x;
	add.s32 	%r67, %r50, %r63;
	setp.ge.s32	%p8, %r67, %r7;
	@%p8 bra 	BB83_13;

	mul.lo.s32 	%r17, %r66, %r28;
	sub.s32 	%r52, %r66, %r62;
	cvt.s64.s32	%rd5, %r52;
	mul.lo.s32 	%r18, %r66, %r27;

BB83_12:
	add.s32 	%r54, %r67, %r17;
	mul.wide.s32 	%rd16, %r54, 8;
	add.s64 	%rd17, %rd2, %rd16;
	sub.s32 	%r55, %r67, %r63;
	mul.wide.s32 	%rd18, %r55, 264;
	mov.u64 	%rd19, map2_transpose_max_double$__cuda_local_var_16377_1747_non_const_tile;
	add.s64 	%rd20, %rd19, %rd18;
	shl.b64 	%rd21, %rd5, 3;
	add.s64 	%rd22, %rd20, %rd21;
	ld.shared.f64 	%fd2, [%rd22];
	ld.global.f64 	%fd3, [%rd17];
	max.f64 	%fd4, %fd3, %fd2;
	add.s32 	%r56, %r67, %r18;
	mul.wide.s32 	%rd23, %r56, 8;
	add.s64 	%rd24, %rd1, %rd23;
	st.global.f64 	[%rd24], %fd4;
	add.s32 	%r67, %r67, %r1;
	setp.lt.s32	%p9, %r67, %r7;
	@%p9 bra 	BB83_12;

BB83_13:
	add.s32 	%r66, %r66, %r31;
	setp.lt.s32	%p10, %r66, %r4;
	@%p10 bra 	BB83_10;

BB83_14:
	bar.sync 	0;
	mov.u32 	%r59, %nctaid.x;
	mad.lo.s32 	%r63, %r59, %r1, %r63;
	setp.lt.s32	%p11, %r63, %r25;
	@%p11 bra 	BB83_4;

BB83_15:
	mov.u32 	%r60, %nctaid.y;
	mad.lo.s32 	%r62, %r60, %r31, %r62;
	setp.lt.s32	%p12, %r62, %r26;
	@%p12 bra 	BB83_2;

BB83_16:
	ret;
}

	// .globl	map2_min_double
.visible .entry map2_min_double(
	.param .u32 map2_min_double_param_0,
	.param .u32 map2_min_double_param_1,
	.param .u64 map2_min_double_param_2,
	.param .u32 map2_min_double_param_3,
	.param .u64 map2_min_double_param_4,
	.param .u32 map2_min_double_param_5,
	.param .u64 map2_min_double_param_6,
	.param .u32 map2_min_double_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<30>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<13>;


	ld.param.u32 	%r13, [map2_min_double_param_0];
	ld.param.u32 	%r14, [map2_min_double_param_1];
	ld.param.u64 	%rd4, [map2_min_double_param_2];
	ld.param.u32 	%r15, [map2_min_double_param_3];
	ld.param.u64 	%rd5, [map2_min_double_param_4];
	ld.param.u32 	%r16, [map2_min_double_param_5];
	ld.param.u64 	%rd6, [map2_min_double_param_6];
	ld.param.u32 	%r17, [map2_min_double_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r18, %ctaid.x;
	mov.u32 	%r19, %tid.x;
	mad.lo.s32 	%r28, %r1, %r18, %r19;
	setp.ge.s32	%p1, %r28, %r14;
	@%p1 bra 	BB84_6;

	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd6;
	cvta.to.global.u64 	%rd3, %rd5;
	mov.u32 	%r20, %tid.y;
	mov.u32 	%r21, %ntid.y;
	mov.u32 	%r22, %ctaid.y;
	mad.lo.s32 	%r3, %r21, %r22, %r20;
	mov.u32 	%r23, %nctaid.x;
	mul.lo.s32 	%r4, %r23, %r1;
	mov.u32 	%r24, %nctaid.y;
	mul.lo.s32 	%r5, %r24, %r21;

BB84_2:
	setp.ge.s32	%p2, %r3, %r13;
	@%p2 bra 	BB84_5;

	mul.lo.s32 	%r7, %r28, %r16;
	mul.lo.s32 	%r8, %r28, %r17;
	mul.lo.s32 	%r9, %r28, %r15;
	mov.u32 	%r29, %r3;

BB84_4:
	mov.u32 	%r10, %r29;
	add.s32 	%r25, %r10, %r7;
	mul.wide.s32 	%rd7, %r25, 8;
	add.s64 	%rd8, %rd3, %rd7;
	add.s32 	%r26, %r10, %r8;
	mul.wide.s32 	%rd9, %r26, 8;
	add.s64 	%rd10, %rd2, %rd9;
	ld.global.f64 	%fd1, [%rd10];
	ld.global.f64 	%fd2, [%rd8];
	min.f64 	%fd3, %fd2, %fd1;
	add.s32 	%r27, %r10, %r9;
	mul.wide.s32 	%rd11, %r27, 8;
	add.s64 	%rd12, %rd1, %rd11;
	st.global.f64 	[%rd12], %fd3;
	add.s32 	%r11, %r5, %r10;
	setp.lt.s32	%p3, %r11, %r13;
	mov.u32 	%r29, %r11;
	@%p3 bra 	BB84_4;

BB84_5:
	add.s32 	%r28, %r4, %r28;
	setp.lt.s32	%p4, %r28, %r14;
	@%p4 bra 	BB84_2;

BB84_6:
	ret;
}

	// .globl	map2_v_s_min_double
.visible .entry map2_v_s_min_double(
	.param .u32 map2_v_s_min_double_param_0,
	.param .u32 map2_v_s_min_double_param_1,
	.param .u64 map2_v_s_min_double_param_2,
	.param .u32 map2_v_s_min_double_param_3,
	.param .u64 map2_v_s_min_double_param_4,
	.param .u32 map2_v_s_min_double_param_5,
	.param .f64 map2_v_s_min_double_param_6
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map2_v_s_min_double_param_0];
	ld.param.u32 	%r13, [map2_v_s_min_double_param_1];
	ld.param.u64 	%rd3, [map2_v_s_min_double_param_2];
	ld.param.u32 	%r14, [map2_v_s_min_double_param_3];
	ld.param.u64 	%rd4, [map2_v_s_min_double_param_4];
	ld.param.u32 	%r15, [map2_v_s_min_double_param_5];
	ld.param.f64 	%fd1, [map2_v_s_min_double_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB85_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB85_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB85_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB85_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd2, [%rd6];
	min.f64 	%fd3, %fd2, %fd1;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd3;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB85_4;

BB85_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB85_2;

BB85_6:
	ret;
}

	// .globl	map2_s_v_min_double
.visible .entry map2_s_v_min_double(
	.param .u32 map2_s_v_min_double_param_0,
	.param .u32 map2_s_v_min_double_param_1,
	.param .u64 map2_s_v_min_double_param_2,
	.param .u32 map2_s_v_min_double_param_3,
	.param .f64 map2_s_v_min_double_param_4,
	.param .u64 map2_s_v_min_double_param_5,
	.param .u32 map2_s_v_min_double_param_6
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map2_s_v_min_double_param_0];
	ld.param.u32 	%r13, [map2_s_v_min_double_param_1];
	ld.param.u64 	%rd3, [map2_s_v_min_double_param_2];
	ld.param.u32 	%r14, [map2_s_v_min_double_param_3];
	ld.param.f64 	%fd1, [map2_s_v_min_double_param_4];
	ld.param.u64 	%rd4, [map2_s_v_min_double_param_5];
	ld.param.u32 	%r15, [map2_s_v_min_double_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB86_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB86_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB86_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB86_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd2, [%rd6];
	min.f64 	%fd3, %fd1, %fd2;
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd3;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB86_4;

BB86_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB86_2;

BB86_6:
	ret;
}

	// .globl	map2_transpose_min_double
.visible .entry map2_transpose_min_double(
	.param .u32 map2_transpose_min_double_param_0,
	.param .u32 map2_transpose_min_double_param_1,
	.param .u64 map2_transpose_min_double_param_2,
	.param .u32 map2_transpose_min_double_param_3,
	.param .u64 map2_transpose_min_double_param_4,
	.param .u32 map2_transpose_min_double_param_5,
	.param .u64 map2_transpose_min_double_param_6,
	.param .u32 map2_transpose_min_double_param_7
)
{
	.reg .pred 	%p<13>;
	.reg .b32 	%r<68>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<25>;
	// demoted variable
	.shared .align 8 .b8 map2_transpose_min_double$__cuda_local_var_16378_1747_non_const_tile[8448];

	ld.param.u32 	%r25, [map2_transpose_min_double_param_0];
	ld.param.u32 	%r26, [map2_transpose_min_double_param_1];
	ld.param.u64 	%rd6, [map2_transpose_min_double_param_2];
	ld.param.u32 	%r27, [map2_transpose_min_double_param_3];
	ld.param.u64 	%rd7, [map2_transpose_min_double_param_4];
	ld.param.u32 	%r28, [map2_transpose_min_double_param_5];
	ld.param.u64 	%rd8, [map2_transpose_min_double_param_6];
	ld.param.u32 	%r29, [map2_transpose_min_double_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r30, %ctaid.y;
	mov.u32 	%r31, %ntid.y;
	mul.lo.s32 	%r62, %r30, %r31;
	setp.ge.s32	%p2, %r62, %r26;
	@%p2 bra 	BB87_16;

	cvta.to.global.u64 	%rd1, %rd6;
	cvta.to.global.u64 	%rd2, %rd7;
	cvta.to.global.u64 	%rd3, %rd8;

BB87_2:
	mov.u32 	%r33, %ctaid.x;
	mul.lo.s32 	%r63, %r33, %r1;
	setp.ge.s32	%p3, %r63, %r25;
	@%p3 bra 	BB87_15;

	add.s32 	%r35, %r62, 32;
	min.s32 	%r4, %r26, %r35;

BB87_4:
	add.s32 	%r38, %r63, 32;
	min.s32 	%r7, %r25, %r38;
	mov.u32 	%r39, %tid.y;
	add.s32 	%r64, %r39, %r63;
	setp.ge.s32	%p4, %r64, %r7;
	@%p4 bra 	BB87_9;

BB87_5:
	mov.u32 	%r40, %tid.x;
	add.s32 	%r65, %r40, %r62;
	setp.ge.s32	%p5, %r65, %r4;
	@%p5 bra 	BB87_8;

	mul.lo.s32 	%r10, %r64, %r29;
	sub.s32 	%r42, %r64, %r63;
	cvt.s64.s32	%rd4, %r42;

BB87_7:
	add.s32 	%r44, %r65, %r10;
	mul.wide.s32 	%rd9, %r44, 8;
	add.s64 	%rd10, %rd3, %rd9;
	ld.global.f64 	%fd1, [%rd10];
	sub.s32 	%r45, %r65, %r62;
	mul.lo.s64 	%rd11, %rd4, 264;
	mov.u64 	%rd12, map2_transpose_min_double$__cuda_local_var_16378_1747_non_const_tile;
	add.s64 	%rd13, %rd12, %rd11;
	mul.wide.s32 	%rd14, %r45, 8;
	add.s64 	%rd15, %rd13, %rd14;
	st.shared.f64 	[%rd15], %fd1;
	add.s32 	%r65, %r65, %r1;
	setp.lt.s32	%p6, %r65, %r4;
	@%p6 bra 	BB87_7;

BB87_8:
	add.s32 	%r64, %r64, %r31;
	setp.lt.s32	%p7, %r64, %r7;
	@%p7 bra 	BB87_5;

BB87_9:
	add.s32 	%r66, %r39, %r62;
	setp.lt.s32	%p1, %r66, %r4;
	bar.sync 	0;
	@!%p1 bra 	BB87_14;
	bra.uni 	BB87_10;

BB87_10:
	mov.u32 	%r50, %tid.x;
	add.s32 	%r67, %r50, %r63;
	setp.ge.s32	%p8, %r67, %r7;
	@%p8 bra 	BB87_13;

	mul.lo.s32 	%r17, %r66, %r28;
	sub.s32 	%r52, %r66, %r62;
	cvt.s64.s32	%rd5, %r52;
	mul.lo.s32 	%r18, %r66, %r27;

BB87_12:
	add.s32 	%r54, %r67, %r17;
	mul.wide.s32 	%rd16, %r54, 8;
	add.s64 	%rd17, %rd2, %rd16;
	sub.s32 	%r55, %r67, %r63;
	mul.wide.s32 	%rd18, %r55, 264;
	mov.u64 	%rd19, map2_transpose_min_double$__cuda_local_var_16378_1747_non_const_tile;
	add.s64 	%rd20, %rd19, %rd18;
	shl.b64 	%rd21, %rd5, 3;
	add.s64 	%rd22, %rd20, %rd21;
	ld.shared.f64 	%fd2, [%rd22];
	ld.global.f64 	%fd3, [%rd17];
	min.f64 	%fd4, %fd3, %fd2;
	add.s32 	%r56, %r67, %r18;
	mul.wide.s32 	%rd23, %r56, 8;
	add.s64 	%rd24, %rd1, %rd23;
	st.global.f64 	[%rd24], %fd4;
	add.s32 	%r67, %r67, %r1;
	setp.lt.s32	%p9, %r67, %r7;
	@%p9 bra 	BB87_12;

BB87_13:
	add.s32 	%r66, %r66, %r31;
	setp.lt.s32	%p10, %r66, %r4;
	@%p10 bra 	BB87_10;

BB87_14:
	bar.sync 	0;
	mov.u32 	%r59, %nctaid.x;
	mad.lo.s32 	%r63, %r59, %r1, %r63;
	setp.lt.s32	%p11, %r63, %r25;
	@%p11 bra 	BB87_4;

BB87_15:
	mov.u32 	%r60, %nctaid.y;
	mad.lo.s32 	%r62, %r60, %r31, %r62;
	setp.lt.s32	%p12, %r62, %r26;
	@%p12 bra 	BB87_2;

BB87_16:
	ret;
}

	// .globl	map2_set_double
.visible .entry map2_set_double(
	.param .u32 map2_set_double_param_0,
	.param .u32 map2_set_double_param_1,
	.param .u64 map2_set_double_param_2,
	.param .u32 map2_set_double_param_3,
	.param .u64 map2_set_double_param_4,
	.param .u32 map2_set_double_param_5,
	.param .u64 map2_set_double_param_6,
	.param .u32 map2_set_double_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map2_set_double_param_0];
	ld.param.u32 	%r13, [map2_set_double_param_1];
	ld.param.u64 	%rd3, [map2_set_double_param_2];
	ld.param.u32 	%r14, [map2_set_double_param_3];
	ld.param.u64 	%rd4, [map2_set_double_param_6];
	ld.param.u32 	%r15, [map2_set_double_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB88_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB88_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB88_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB88_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd1;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB88_4;

BB88_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB88_2;

BB88_6:
	ret;
}

	// .globl	map2_v_s_set_double
.visible .entry map2_v_s_set_double(
	.param .u32 map2_v_s_set_double_param_0,
	.param .u32 map2_v_s_set_double_param_1,
	.param .u64 map2_v_s_set_double_param_2,
	.param .u32 map2_v_s_set_double_param_3,
	.param .u64 map2_v_s_set_double_param_4,
	.param .u32 map2_v_s_set_double_param_5,
	.param .f64 map2_v_s_set_double_param_6
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<24>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<5>;


	ld.param.u32 	%r11, [map2_v_s_set_double_param_0];
	ld.param.u32 	%r12, [map2_v_s_set_double_param_1];
	ld.param.u64 	%rd2, [map2_v_s_set_double_param_2];
	ld.param.u32 	%r13, [map2_v_s_set_double_param_3];
	ld.param.f64 	%fd1, [map2_v_s_set_double_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r14, %ctaid.x;
	mov.u32 	%r15, %tid.x;
	mad.lo.s32 	%r22, %r1, %r14, %r15;
	setp.ge.s32	%p1, %r22, %r12;
	@%p1 bra 	BB89_6;

	cvta.to.global.u64 	%rd1, %rd2;
	mov.u32 	%r16, %tid.y;
	mov.u32 	%r17, %ntid.y;
	mov.u32 	%r18, %ctaid.y;
	mad.lo.s32 	%r3, %r17, %r18, %r16;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r4, %r19, %r1;
	mov.u32 	%r20, %nctaid.y;
	mul.lo.s32 	%r5, %r20, %r17;

BB89_2:
	setp.ge.s32	%p2, %r3, %r11;
	@%p2 bra 	BB89_5;

	mul.lo.s32 	%r7, %r22, %r13;
	mov.u32 	%r23, %r3;

BB89_4:
	mov.u32 	%r8, %r23;
	add.s32 	%r21, %r8, %r7;
	mul.wide.s32 	%rd3, %r21, 8;
	add.s64 	%rd4, %rd1, %rd3;
	st.global.f64 	[%rd4], %fd1;
	add.s32 	%r9, %r5, %r8;
	setp.lt.s32	%p3, %r9, %r11;
	mov.u32 	%r23, %r9;
	@%p3 bra 	BB89_4;

BB89_5:
	add.s32 	%r22, %r4, %r22;
	setp.lt.s32	%p4, %r22, %r12;
	@%p4 bra 	BB89_2;

BB89_6:
	ret;
}

	// .globl	map2_s_v_set_double
.visible .entry map2_s_v_set_double(
	.param .u32 map2_s_v_set_double_param_0,
	.param .u32 map2_s_v_set_double_param_1,
	.param .u64 map2_s_v_set_double_param_2,
	.param .u32 map2_s_v_set_double_param_3,
	.param .f64 map2_s_v_set_double_param_4,
	.param .u64 map2_s_v_set_double_param_5,
	.param .u32 map2_s_v_set_double_param_6
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<27>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r12, [map2_s_v_set_double_param_0];
	ld.param.u32 	%r13, [map2_s_v_set_double_param_1];
	ld.param.u64 	%rd3, [map2_s_v_set_double_param_2];
	ld.param.u32 	%r14, [map2_s_v_set_double_param_3];
	ld.param.u64 	%rd4, [map2_s_v_set_double_param_5];
	ld.param.u32 	%r15, [map2_s_v_set_double_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r25, %r1, %r16, %r17;
	setp.ge.s32	%p1, %r25, %r13;
	@%p1 bra 	BB90_6;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r18, %tid.y;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mad.lo.s32 	%r3, %r19, %r20, %r18;
	mov.u32 	%r21, %nctaid.x;
	mul.lo.s32 	%r4, %r21, %r1;
	mov.u32 	%r22, %nctaid.y;
	mul.lo.s32 	%r5, %r22, %r19;

BB90_2:
	setp.ge.s32	%p2, %r3, %r12;
	@%p2 bra 	BB90_5;

	mul.lo.s32 	%r7, %r25, %r15;
	mul.lo.s32 	%r8, %r25, %r14;
	mov.u32 	%r26, %r3;

BB90_4:
	mov.u32 	%r9, %r26;
	add.s32 	%r23, %r9, %r7;
	mul.wide.s32 	%rd5, %r23, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	add.s32 	%r24, %r9, %r8;
	mul.wide.s32 	%rd7, %r24, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd1;
	add.s32 	%r10, %r5, %r9;
	setp.lt.s32	%p3, %r10, %r12;
	mov.u32 	%r26, %r10;
	@%p3 bra 	BB90_4;

BB90_5:
	add.s32 	%r25, %r4, %r25;
	setp.lt.s32	%p4, %r25, %r13;
	@%p4 bra 	BB90_2;

BB90_6:
	ret;
}

	// .globl	map2_transpose_set_double
.visible .entry map2_transpose_set_double(
	.param .u32 map2_transpose_set_double_param_0,
	.param .u32 map2_transpose_set_double_param_1,
	.param .u64 map2_transpose_set_double_param_2,
	.param .u32 map2_transpose_set_double_param_3,
	.param .u64 map2_transpose_set_double_param_4,
	.param .u32 map2_transpose_set_double_param_5,
	.param .u64 map2_transpose_set_double_param_6,
	.param .u32 map2_transpose_set_double_param_7
)
{
	.reg .pred 	%p<13>;
	.reg .b32 	%r<65>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<21>;
	// demoted variable
	.shared .align 8 .b8 map2_transpose_set_double$__cuda_local_var_16379_1747_non_const_tile[8448];

	ld.param.u32 	%r24, [map2_transpose_set_double_param_0];
	ld.param.u32 	%r25, [map2_transpose_set_double_param_1];
	ld.param.u64 	%rd5, [map2_transpose_set_double_param_2];
	ld.param.u32 	%r26, [map2_transpose_set_double_param_3];
	ld.param.u64 	%rd6, [map2_transpose_set_double_param_6];
	ld.param.u32 	%r27, [map2_transpose_set_double_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r28, %ctaid.y;
	mov.u32 	%r29, %ntid.y;
	mul.lo.s32 	%r59, %r28, %r29;
	setp.ge.s32	%p2, %r59, %r25;
	@%p2 bra 	BB91_16;

	cvta.to.global.u64 	%rd1, %rd5;
	cvta.to.global.u64 	%rd2, %rd6;

BB91_2:
	mov.u32 	%r31, %ctaid.x;
	mul.lo.s32 	%r60, %r31, %r1;
	setp.ge.s32	%p3, %r60, %r24;
	@%p3 bra 	BB91_15;

	add.s32 	%r33, %r59, 32;
	min.s32 	%r4, %r25, %r33;

BB91_4:
	add.s32 	%r36, %r60, 32;
	min.s32 	%r7, %r24, %r36;
	mov.u32 	%r37, %tid.y;
	add.s32 	%r61, %r37, %r60;
	setp.ge.s32	%p4, %r61, %r7;
	@%p4 bra 	BB91_9;

BB91_5:
	mov.u32 	%r38, %tid.x;
	add.s32 	%r62, %r38, %r59;
	setp.ge.s32	%p5, %r62, %r4;
	@%p5 bra 	BB91_8;

	mul.lo.s32 	%r10, %r61, %r27;
	sub.s32 	%r40, %r61, %r60;
	cvt.s64.s32	%rd3, %r40;

BB91_7:
	add.s32 	%r42, %r62, %r10;
	mul.wide.s32 	%rd7, %r42, 8;
	add.s64 	%rd8, %rd2, %rd7;
	ld.global.f64 	%fd1, [%rd8];
	sub.s32 	%r43, %r62, %r59;
	mul.lo.s64 	%rd9, %rd3, 264;
	mov.u64 	%rd10, map2_transpose_set_double$__cuda_local_var_16379_1747_non_const_tile;
	add.s64 	%rd11, %rd10, %rd9;
	mul.wide.s32 	%rd12, %r43, 8;
	add.s64 	%rd13, %rd11, %rd12;
	st.shared.f64 	[%rd13], %fd1;
	add.s32 	%r62, %r62, %r1;
	setp.lt.s32	%p6, %r62, %r4;
	@%p6 bra 	BB91_7;

BB91_8:
	add.s32 	%r61, %r61, %r29;
	setp.lt.s32	%p7, %r61, %r7;
	@%p7 bra 	BB91_5;

BB91_9:
	add.s32 	%r63, %r37, %r59;
	setp.lt.s32	%p1, %r63, %r4;
	bar.sync 	0;
	@!%p1 bra 	BB91_14;
	bra.uni 	BB91_10;

BB91_10:
	mov.u32 	%r48, %tid.x;
	add.s32 	%r64, %r48, %r60;
	setp.ge.s32	%p8, %r64, %r7;
	@%p8 bra 	BB91_13;

	sub.s32 	%r50, %r63, %r59;
	cvt.s64.s32	%rd4, %r50;
	mul.lo.s32 	%r17, %r63, %r26;

BB91_12:
	sub.s32 	%r52, %r64, %r60;
	mul.wide.s32 	%rd14, %r52, 264;
	mov.u64 	%rd15, map2_transpose_set_double$__cuda_local_var_16379_1747_non_const_tile;
	add.s64 	%rd16, %rd15, %rd14;
	shl.b64 	%rd17, %rd4, 3;
	add.s64 	%rd18, %rd16, %rd17;
	ld.shared.f64 	%fd2, [%rd18];
	add.s32 	%r53, %r64, %r17;
	mul.wide.s32 	%rd19, %r53, 8;
	add.s64 	%rd20, %rd1, %rd19;
	st.global.f64 	[%rd20], %fd2;
	add.s32 	%r64, %r64, %r1;
	setp.lt.s32	%p9, %r64, %r7;
	@%p9 bra 	BB91_12;

BB91_13:
	add.s32 	%r63, %r63, %r29;
	setp.lt.s32	%p10, %r63, %r4;
	@%p10 bra 	BB91_10;

BB91_14:
	bar.sync 	0;
	mov.u32 	%r56, %nctaid.x;
	mad.lo.s32 	%r60, %r56, %r1, %r60;
	setp.lt.s32	%p11, %r60, %r24;
	@%p11 bra 	BB91_4;

BB91_15:
	mov.u32 	%r57, %nctaid.y;
	mad.lo.s32 	%r59, %r57, %r29, %r59;
	setp.lt.s32	%p12, %r59, %r25;
	@%p12 bra 	BB91_2;

BB91_16:
	ret;
}

	// .globl	reduce_add_double
.visible .entry reduce_add_double(
	.param .u32 reduce_add_double_param_0,
	.param .u32 reduce_add_double_param_1,
	.param .u64 reduce_add_double_param_2,
	.param .u64 reduce_add_double_param_3,
	.param .u32 reduce_add_double_param_4
)
{
	.reg .pred 	%p<8>;
	.reg .b32 	%r<50>;
	.reg .f64 	%fd<15>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r15, [reduce_add_double_param_0];
	ld.param.u32 	%r16, [reduce_add_double_param_1];
	ld.param.u64 	%rd2, [reduce_add_double_param_2];
	ld.param.u64 	%rd3, [reduce_add_double_param_3];
	ld.param.u32 	%r17, [reduce_add_double_param_4];
	mov.u32 	%r1, %ntid.y;
	mov.u32 	%r18, %ctaid.y;
	mov.u32 	%r19, %tid.y;
	mad.lo.s32 	%r47, %r1, %r18, %r19;
	mov.f64 	%fd14, 0d0000000000000000;
	setp.ge.s32	%p1, %r47, %r16;
	@%p1 bra 	BB92_6;

	cvta.to.global.u64 	%rd1, %rd3;
	mov.u32 	%r20, %ntid.x;
	mov.u32 	%r21, %tid.x;
	mov.u32 	%r22, %ctaid.x;
	mad.lo.s32 	%r3, %r20, %r22, %r21;
	mov.u32 	%r23, %nctaid.y;
	mul.lo.s32 	%r4, %r23, %r1;
	mov.u32 	%r24, %nctaid.x;
	mul.lo.s32 	%r5, %r24, %r20;
	mov.f64 	%fd14, 0d0000000000000000;

BB92_2:
	setp.ge.s32	%p2, %r3, %r15;
	@%p2 bra 	BB92_5;

	mul.lo.s32 	%r7, %r47, %r17;
	mov.u32 	%r48, %r3;

BB92_4:
	mov.u32 	%r8, %r48;
	add.s32 	%r25, %r8, %r7;
	mul.wide.s32 	%rd4, %r25, 8;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.f64 	%fd11, [%rd5];
	add.f64 	%fd14, %fd14, %fd11;
	add.s32 	%r9, %r5, %r8;
	setp.lt.s32	%p3, %r9, %r15;
	mov.u32 	%r48, %r9;
	@%p3 bra 	BB92_4;

BB92_5:
	add.s32 	%r47, %r4, %r47;
	setp.lt.s32	%p4, %r47, %r16;
	@%p4 bra 	BB92_2;

BB92_6:
	bar.sync 	0;
	mov.u32 	%r11, %ntid.x;
	setp.lt.u32	%p5, %r11, 2;
	@%p5 bra 	BB92_9;

	mov.u32 	%r27, WARP_SZ;
	mov.u32 	%r28, 32;
	sub.s32 	%r29, %r28, %r27;
	shl.b32 	%r30, %r29, 8;
	or.b32  	%r12, %r30, 31;
	mov.u32 	%r49, 1;

BB92_8:
	// inline asm
	mov.b64 { %r31, %r32 }, %fd14;
	// inline asm
	// inline asm
	shfl.down.b32 %r33, %r32, %r49, %r12;
	// inline asm
	// inline asm
	shfl.down.b32 %r37, %r31, %r49, %r12;
	// inline asm
	mov.b64 	%fd13, {%r37, %r33};
	add.f64 	%fd14, %fd14, %fd13;
	shl.b32 	%r49, %r49, 1;
	setp.lt.u32	%p6, %r49, %r11;
	@%p6 bra 	BB92_8;

BB92_9:
	mov.u32 	%r41, %tid.x;
	and.b32  	%r42, %r41, 31;
	setp.ne.s32	%p7, %r42, 0;
	@%p7 bra 	BB92_11;

	cvta.to.global.u64 	%rd6, %rd2;
	mov.u32 	%r43, %ctaid.x;
	mov.u32 	%r44, %nctaid.y;
	mad.lo.s32 	%r46, %r44, %r43, %r18;
	mul.wide.u32 	%rd7, %r46, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd14;

BB92_11:
	ret;
}

	// .globl	reduce_col_add_double
.visible .entry reduce_col_add_double(
	.param .u32 reduce_col_add_double_param_0,
	.param .u32 reduce_col_add_double_param_1,
	.param .u64 reduce_col_add_double_param_2,
	.param .u64 reduce_col_add_double_param_3,
	.param .u32 reduce_col_add_double_param_4
)
{
	.reg .pred 	%p<8>;
	.reg .b32 	%r<40>;
	.reg .f64 	%fd<13>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r15, [reduce_col_add_double_param_0];
	ld.param.u32 	%r16, [reduce_col_add_double_param_1];
	ld.param.u64 	%rd3, [reduce_col_add_double_param_2];
	ld.param.u64 	%rd4, [reduce_col_add_double_param_3];
	ld.param.u32 	%r17, [reduce_col_add_double_param_4];
	mov.u32 	%r1, %ntid.y;
	mov.u32 	%r18, %ctaid.x;
	mov.u32 	%r19, %tid.y;
	mad.lo.s32 	%r37, %r1, %r18, %r19;
	setp.ge.s32	%p1, %r37, %r16;
	@%p1 bra 	BB93_10;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r3, %tid.x;
	mov.u32 	%r4, %ntid.x;
	and.b32  	%r5, %r3, 31;
	mov.u32 	%r20, %nctaid.x;
	mul.lo.s32 	%r6, %r20, %r1;
	mov.u32 	%r21, WARP_SZ;
	mov.u32 	%r22, 32;
	sub.s32 	%r23, %r22, %r21;
	shl.b32 	%r24, %r23, 8;
	or.b32  	%r7, %r24, 31;

BB93_2:
	mov.f64 	%fd12, 0d0000000000000000;
	setp.ge.s32	%p2, %r3, %r15;
	@%p2 bra 	BB93_5;

	mul.lo.s32 	%r9, %r37, %r17;
	mov.f64 	%fd12, 0d0000000000000000;
	mov.u32 	%r38, %r3;

BB93_4:
	mov.u32 	%r10, %r38;
	add.s32 	%r25, %r10, %r9;
	mul.wide.s32 	%rd5, %r25, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd9, [%rd6];
	add.f64 	%fd12, %fd12, %fd9;
	add.s32 	%r11, %r4, %r10;
	setp.lt.s32	%p3, %r11, %r15;
	mov.u32 	%r38, %r11;
	@%p3 bra 	BB93_4;

BB93_5:
	bar.sync 	0;
	mov.u32 	%r39, 1;
	setp.lt.u32	%p4, %r4, 2;
	@%p4 bra 	BB93_7;

BB93_6:
	// inline asm
	mov.b64 { %r27, %r28 }, %fd12;
	// inline asm
	// inline asm
	shfl.down.b32 %r29, %r28, %r39, %r7;
	// inline asm
	// inline asm
	shfl.down.b32 %r33, %r27, %r39, %r7;
	// inline asm
	mov.b64 	%fd11, {%r33, %r29};
	add.f64 	%fd12, %fd12, %fd11;
	shl.b32 	%r39, %r39, 1;
	setp.lt.u32	%p5, %r39, %r4;
	@%p5 bra 	BB93_6;

BB93_7:
	setp.ne.s32	%p6, %r5, 0;
	@%p6 bra 	BB93_9;

	mul.wide.s32 	%rd7, %r37, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd12;

BB93_9:
	add.s32 	%r37, %r6, %r37;
	setp.lt.s32	%p7, %r37, %r16;
	@%p7 bra 	BB93_2;

BB93_10:
	ret;
}

	// .globl	reduce_row_add_double
.visible .entry reduce_row_add_double(
	.param .u32 reduce_row_add_double_param_0,
	.param .u32 reduce_row_add_double_param_1,
	.param .u64 reduce_row_add_double_param_2,
	.param .u64 reduce_row_add_double_param_3,
	.param .u32 reduce_row_add_double_param_4
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<18>;
	.reg .f64 	%fd<10>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r8, [reduce_row_add_double_param_0];
	ld.param.u32 	%r9, [reduce_row_add_double_param_1];
	ld.param.u64 	%rd3, [reduce_row_add_double_param_2];
	ld.param.u64 	%rd4, [reduce_row_add_double_param_3];
	ld.param.u32 	%r10, [reduce_row_add_double_param_4];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r11, %ctaid.x;
	mov.u32 	%r12, %tid.x;
	mad.lo.s32 	%r16, %r11, %r1, %r12;
	setp.ge.s32	%p1, %r16, %r8;
	@%p1 bra 	BB94_5;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r13, %nctaid.x;
	mul.lo.s32 	%r3, %r13, %r1;

BB94_2:
	mov.f64 	%fd8, 0d0000000000000000;
	mov.f64 	%fd9, %fd8;
	mov.u32 	%r17, 0;
	setp.lt.s32	%p2, %r9, 1;
	@%p2 bra 	BB94_4;

BB94_3:
	mad.lo.s32 	%r15, %r17, %r10, %r16;
	mul.wide.s32 	%rd5, %r15, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd6, [%rd6];
	add.f64 	%fd9, %fd9, %fd6;
	add.s32 	%r17, %r17, 1;
	setp.lt.s32	%p3, %r17, %r9;
	mov.f64 	%fd8, %fd9;
	@%p3 bra 	BB94_3;

BB94_4:
	mul.wide.s32 	%rd7, %r16, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd8;
	add.s32 	%r16, %r16, %r3;
	setp.lt.s32	%p4, %r16, %r8;
	@%p4 bra 	BB94_2;

BB94_5:
	ret;
}

	// .globl	reduce_max_double
.visible .entry reduce_max_double(
	.param .u32 reduce_max_double_param_0,
	.param .u32 reduce_max_double_param_1,
	.param .u64 reduce_max_double_param_2,
	.param .u64 reduce_max_double_param_3,
	.param .u32 reduce_max_double_param_4
)
{
	.reg .pred 	%p<8>;
	.reg .b32 	%r<50>;
	.reg .f64 	%fd<15>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r15, [reduce_max_double_param_0];
	ld.param.u32 	%r16, [reduce_max_double_param_1];
	ld.param.u64 	%rd2, [reduce_max_double_param_2];
	ld.param.u64 	%rd3, [reduce_max_double_param_3];
	ld.param.u32 	%r17, [reduce_max_double_param_4];
	mov.u32 	%r1, %ntid.y;
	mov.u32 	%r18, %ctaid.y;
	mov.u32 	%r19, %tid.y;
	mad.lo.s32 	%r47, %r1, %r18, %r19;
	mov.f64 	%fd14, 0dFFF0000000000000;
	setp.ge.s32	%p1, %r47, %r16;
	@%p1 bra 	BB95_6;

	cvta.to.global.u64 	%rd1, %rd3;
	mov.u32 	%r20, %ntid.x;
	mov.u32 	%r21, %tid.x;
	mov.u32 	%r22, %ctaid.x;
	mad.lo.s32 	%r3, %r20, %r22, %r21;
	mov.u32 	%r23, %nctaid.y;
	mul.lo.s32 	%r4, %r23, %r1;
	mov.u32 	%r24, %nctaid.x;
	mul.lo.s32 	%r5, %r24, %r20;
	mov.f64 	%fd14, 0dFFF0000000000000;

BB95_2:
	setp.ge.s32	%p2, %r3, %r15;
	@%p2 bra 	BB95_5;

	mul.lo.s32 	%r7, %r47, %r17;
	mov.u32 	%r48, %r3;

BB95_4:
	mov.u32 	%r8, %r48;
	add.s32 	%r25, %r8, %r7;
	mul.wide.s32 	%rd4, %r25, 8;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.f64 	%fd11, [%rd5];
	max.f64 	%fd14, %fd14, %fd11;
	add.s32 	%r9, %r5, %r8;
	setp.lt.s32	%p3, %r9, %r15;
	mov.u32 	%r48, %r9;
	@%p3 bra 	BB95_4;

BB95_5:
	add.s32 	%r47, %r4, %r47;
	setp.lt.s32	%p4, %r47, %r16;
	@%p4 bra 	BB95_2;

BB95_6:
	bar.sync 	0;
	mov.u32 	%r11, %ntid.x;
	setp.lt.u32	%p5, %r11, 2;
	@%p5 bra 	BB95_9;

	mov.u32 	%r27, WARP_SZ;
	mov.u32 	%r28, 32;
	sub.s32 	%r29, %r28, %r27;
	shl.b32 	%r30, %r29, 8;
	or.b32  	%r12, %r30, 31;
	mov.u32 	%r49, 1;

BB95_8:
	// inline asm
	mov.b64 { %r31, %r32 }, %fd14;
	// inline asm
	// inline asm
	shfl.down.b32 %r33, %r32, %r49, %r12;
	// inline asm
	// inline asm
	shfl.down.b32 %r37, %r31, %r49, %r12;
	// inline asm
	mov.b64 	%fd13, {%r37, %r33};
	max.f64 	%fd14, %fd14, %fd13;
	shl.b32 	%r49, %r49, 1;
	setp.lt.u32	%p6, %r49, %r11;
	@%p6 bra 	BB95_8;

BB95_9:
	mov.u32 	%r41, %tid.x;
	and.b32  	%r42, %r41, 31;
	setp.ne.s32	%p7, %r42, 0;
	@%p7 bra 	BB95_11;

	cvta.to.global.u64 	%rd6, %rd2;
	mov.u32 	%r43, %ctaid.x;
	mov.u32 	%r44, %nctaid.y;
	mad.lo.s32 	%r46, %r44, %r43, %r18;
	mul.wide.u32 	%rd7, %r46, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd14;

BB95_11:
	ret;
}

	// .globl	reduce_col_max_double
.visible .entry reduce_col_max_double(
	.param .u32 reduce_col_max_double_param_0,
	.param .u32 reduce_col_max_double_param_1,
	.param .u64 reduce_col_max_double_param_2,
	.param .u64 reduce_col_max_double_param_3,
	.param .u32 reduce_col_max_double_param_4
)
{
	.reg .pred 	%p<8>;
	.reg .b32 	%r<40>;
	.reg .f64 	%fd<13>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r15, [reduce_col_max_double_param_0];
	ld.param.u32 	%r16, [reduce_col_max_double_param_1];
	ld.param.u64 	%rd3, [reduce_col_max_double_param_2];
	ld.param.u64 	%rd4, [reduce_col_max_double_param_3];
	ld.param.u32 	%r17, [reduce_col_max_double_param_4];
	mov.u32 	%r1, %ntid.y;
	mov.u32 	%r18, %ctaid.x;
	mov.u32 	%r19, %tid.y;
	mad.lo.s32 	%r37, %r1, %r18, %r19;
	setp.ge.s32	%p1, %r37, %r16;
	@%p1 bra 	BB96_10;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r3, %tid.x;
	mov.u32 	%r4, %ntid.x;
	and.b32  	%r5, %r3, 31;
	mov.u32 	%r20, %nctaid.x;
	mul.lo.s32 	%r6, %r20, %r1;
	mov.u32 	%r21, WARP_SZ;
	mov.u32 	%r22, 32;
	sub.s32 	%r23, %r22, %r21;
	shl.b32 	%r24, %r23, 8;
	or.b32  	%r7, %r24, 31;

BB96_2:
	mov.f64 	%fd12, 0dFFF0000000000000;
	setp.ge.s32	%p2, %r3, %r15;
	@%p2 bra 	BB96_5;

	mul.lo.s32 	%r9, %r37, %r17;
	mov.f64 	%fd12, 0dFFF0000000000000;
	mov.u32 	%r38, %r3;

BB96_4:
	mov.u32 	%r10, %r38;
	add.s32 	%r25, %r10, %r9;
	mul.wide.s32 	%rd5, %r25, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd9, [%rd6];
	max.f64 	%fd12, %fd12, %fd9;
	add.s32 	%r11, %r4, %r10;
	setp.lt.s32	%p3, %r11, %r15;
	mov.u32 	%r38, %r11;
	@%p3 bra 	BB96_4;

BB96_5:
	bar.sync 	0;
	mov.u32 	%r39, 1;
	setp.lt.u32	%p4, %r4, 2;
	@%p4 bra 	BB96_7;

BB96_6:
	// inline asm
	mov.b64 { %r27, %r28 }, %fd12;
	// inline asm
	// inline asm
	shfl.down.b32 %r29, %r28, %r39, %r7;
	// inline asm
	// inline asm
	shfl.down.b32 %r33, %r27, %r39, %r7;
	// inline asm
	mov.b64 	%fd11, {%r33, %r29};
	max.f64 	%fd12, %fd12, %fd11;
	shl.b32 	%r39, %r39, 1;
	setp.lt.u32	%p5, %r39, %r4;
	@%p5 bra 	BB96_6;

BB96_7:
	setp.ne.s32	%p6, %r5, 0;
	@%p6 bra 	BB96_9;

	mul.wide.s32 	%rd7, %r37, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd12;

BB96_9:
	add.s32 	%r37, %r6, %r37;
	setp.lt.s32	%p7, %r37, %r16;
	@%p7 bra 	BB96_2;

BB96_10:
	ret;
}

	// .globl	reduce_row_max_double
.visible .entry reduce_row_max_double(
	.param .u32 reduce_row_max_double_param_0,
	.param .u32 reduce_row_max_double_param_1,
	.param .u64 reduce_row_max_double_param_2,
	.param .u64 reduce_row_max_double_param_3,
	.param .u32 reduce_row_max_double_param_4
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<18>;
	.reg .f64 	%fd<10>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r8, [reduce_row_max_double_param_0];
	ld.param.u32 	%r9, [reduce_row_max_double_param_1];
	ld.param.u64 	%rd3, [reduce_row_max_double_param_2];
	ld.param.u64 	%rd4, [reduce_row_max_double_param_3];
	ld.param.u32 	%r10, [reduce_row_max_double_param_4];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r11, %ctaid.x;
	mov.u32 	%r12, %tid.x;
	mad.lo.s32 	%r16, %r11, %r1, %r12;
	setp.ge.s32	%p1, %r16, %r8;
	@%p1 bra 	BB97_5;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r13, %nctaid.x;
	mul.lo.s32 	%r3, %r13, %r1;

BB97_2:
	mov.f64 	%fd8, 0dFFF0000000000000;
	mov.f64 	%fd9, %fd8;
	mov.u32 	%r17, 0;
	setp.lt.s32	%p2, %r9, 1;
	@%p2 bra 	BB97_4;

BB97_3:
	mad.lo.s32 	%r15, %r17, %r10, %r16;
	mul.wide.s32 	%rd5, %r15, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd6, [%rd6];
	max.f64 	%fd9, %fd9, %fd6;
	add.s32 	%r17, %r17, 1;
	setp.lt.s32	%p3, %r17, %r9;
	mov.f64 	%fd8, %fd9;
	@%p3 bra 	BB97_3;

BB97_4:
	mul.wide.s32 	%rd7, %r16, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd8;
	add.s32 	%r16, %r16, %r3;
	setp.lt.s32	%p4, %r16, %r8;
	@%p4 bra 	BB97_2;

BB97_5:
	ret;
}

	// .globl	reduce_min_double
.visible .entry reduce_min_double(
	.param .u32 reduce_min_double_param_0,
	.param .u32 reduce_min_double_param_1,
	.param .u64 reduce_min_double_param_2,
	.param .u64 reduce_min_double_param_3,
	.param .u32 reduce_min_double_param_4
)
{
	.reg .pred 	%p<8>;
	.reg .b32 	%r<50>;
	.reg .f64 	%fd<15>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r15, [reduce_min_double_param_0];
	ld.param.u32 	%r16, [reduce_min_double_param_1];
	ld.param.u64 	%rd2, [reduce_min_double_param_2];
	ld.param.u64 	%rd3, [reduce_min_double_param_3];
	ld.param.u32 	%r17, [reduce_min_double_param_4];
	mov.u32 	%r1, %ntid.y;
	mov.u32 	%r18, %ctaid.y;
	mov.u32 	%r19, %tid.y;
	mad.lo.s32 	%r47, %r1, %r18, %r19;
	mov.f64 	%fd14, 0d7FF0000000000000;
	setp.ge.s32	%p1, %r47, %r16;
	@%p1 bra 	BB98_6;

	cvta.to.global.u64 	%rd1, %rd3;
	mov.u32 	%r20, %ntid.x;
	mov.u32 	%r21, %tid.x;
	mov.u32 	%r22, %ctaid.x;
	mad.lo.s32 	%r3, %r20, %r22, %r21;
	mov.u32 	%r23, %nctaid.y;
	mul.lo.s32 	%r4, %r23, %r1;
	mov.u32 	%r24, %nctaid.x;
	mul.lo.s32 	%r5, %r24, %r20;
	mov.f64 	%fd14, 0d7FF0000000000000;

BB98_2:
	setp.ge.s32	%p2, %r3, %r15;
	@%p2 bra 	BB98_5;

	mul.lo.s32 	%r7, %r47, %r17;
	mov.u32 	%r48, %r3;

BB98_4:
	mov.u32 	%r8, %r48;
	add.s32 	%r25, %r8, %r7;
	mul.wide.s32 	%rd4, %r25, 8;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.f64 	%fd11, [%rd5];
	min.f64 	%fd14, %fd14, %fd11;
	add.s32 	%r9, %r5, %r8;
	setp.lt.s32	%p3, %r9, %r15;
	mov.u32 	%r48, %r9;
	@%p3 bra 	BB98_4;

BB98_5:
	add.s32 	%r47, %r4, %r47;
	setp.lt.s32	%p4, %r47, %r16;
	@%p4 bra 	BB98_2;

BB98_6:
	bar.sync 	0;
	mov.u32 	%r11, %ntid.x;
	setp.lt.u32	%p5, %r11, 2;
	@%p5 bra 	BB98_9;

	mov.u32 	%r27, WARP_SZ;
	mov.u32 	%r28, 32;
	sub.s32 	%r29, %r28, %r27;
	shl.b32 	%r30, %r29, 8;
	or.b32  	%r12, %r30, 31;
	mov.u32 	%r49, 1;

BB98_8:
	// inline asm
	mov.b64 { %r31, %r32 }, %fd14;
	// inline asm
	// inline asm
	shfl.down.b32 %r33, %r32, %r49, %r12;
	// inline asm
	// inline asm
	shfl.down.b32 %r37, %r31, %r49, %r12;
	// inline asm
	mov.b64 	%fd13, {%r37, %r33};
	min.f64 	%fd14, %fd14, %fd13;
	shl.b32 	%r49, %r49, 1;
	setp.lt.u32	%p6, %r49, %r11;
	@%p6 bra 	BB98_8;

BB98_9:
	mov.u32 	%r41, %tid.x;
	and.b32  	%r42, %r41, 31;
	setp.ne.s32	%p7, %r42, 0;
	@%p7 bra 	BB98_11;

	cvta.to.global.u64 	%rd6, %rd2;
	mov.u32 	%r43, %ctaid.x;
	mov.u32 	%r44, %nctaid.y;
	mad.lo.s32 	%r46, %r44, %r43, %r18;
	mul.wide.u32 	%rd7, %r46, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd14;

BB98_11:
	ret;
}

	// .globl	reduce_col_min_double
.visible .entry reduce_col_min_double(
	.param .u32 reduce_col_min_double_param_0,
	.param .u32 reduce_col_min_double_param_1,
	.param .u64 reduce_col_min_double_param_2,
	.param .u64 reduce_col_min_double_param_3,
	.param .u32 reduce_col_min_double_param_4
)
{
	.reg .pred 	%p<8>;
	.reg .b32 	%r<40>;
	.reg .f64 	%fd<13>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r15, [reduce_col_min_double_param_0];
	ld.param.u32 	%r16, [reduce_col_min_double_param_1];
	ld.param.u64 	%rd3, [reduce_col_min_double_param_2];
	ld.param.u64 	%rd4, [reduce_col_min_double_param_3];
	ld.param.u32 	%r17, [reduce_col_min_double_param_4];
	mov.u32 	%r1, %ntid.y;
	mov.u32 	%r18, %ctaid.x;
	mov.u32 	%r19, %tid.y;
	mad.lo.s32 	%r37, %r1, %r18, %r19;
	setp.ge.s32	%p1, %r37, %r16;
	@%p1 bra 	BB99_10;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r3, %tid.x;
	mov.u32 	%r4, %ntid.x;
	and.b32  	%r5, %r3, 31;
	mov.u32 	%r20, %nctaid.x;
	mul.lo.s32 	%r6, %r20, %r1;
	mov.u32 	%r21, WARP_SZ;
	mov.u32 	%r22, 32;
	sub.s32 	%r23, %r22, %r21;
	shl.b32 	%r24, %r23, 8;
	or.b32  	%r7, %r24, 31;

BB99_2:
	mov.f64 	%fd12, 0d7FF0000000000000;
	setp.ge.s32	%p2, %r3, %r15;
	@%p2 bra 	BB99_5;

	mul.lo.s32 	%r9, %r37, %r17;
	mov.f64 	%fd12, 0d7FF0000000000000;
	mov.u32 	%r38, %r3;

BB99_4:
	mov.u32 	%r10, %r38;
	add.s32 	%r25, %r10, %r9;
	mul.wide.s32 	%rd5, %r25, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd9, [%rd6];
	min.f64 	%fd12, %fd12, %fd9;
	add.s32 	%r11, %r4, %r10;
	setp.lt.s32	%p3, %r11, %r15;
	mov.u32 	%r38, %r11;
	@%p3 bra 	BB99_4;

BB99_5:
	bar.sync 	0;
	mov.u32 	%r39, 1;
	setp.lt.u32	%p4, %r4, 2;
	@%p4 bra 	BB99_7;

BB99_6:
	// inline asm
	mov.b64 { %r27, %r28 }, %fd12;
	// inline asm
	// inline asm
	shfl.down.b32 %r29, %r28, %r39, %r7;
	// inline asm
	// inline asm
	shfl.down.b32 %r33, %r27, %r39, %r7;
	// inline asm
	mov.b64 	%fd11, {%r33, %r29};
	min.f64 	%fd12, %fd12, %fd11;
	shl.b32 	%r39, %r39, 1;
	setp.lt.u32	%p5, %r39, %r4;
	@%p5 bra 	BB99_6;

BB99_7:
	setp.ne.s32	%p6, %r5, 0;
	@%p6 bra 	BB99_9;

	mul.wide.s32 	%rd7, %r37, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd12;

BB99_9:
	add.s32 	%r37, %r6, %r37;
	setp.lt.s32	%p7, %r37, %r16;
	@%p7 bra 	BB99_2;

BB99_10:
	ret;
}

	// .globl	reduce_row_min_double
.visible .entry reduce_row_min_double(
	.param .u32 reduce_row_min_double_param_0,
	.param .u32 reduce_row_min_double_param_1,
	.param .u64 reduce_row_min_double_param_2,
	.param .u64 reduce_row_min_double_param_3,
	.param .u32 reduce_row_min_double_param_4
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<18>;
	.reg .f64 	%fd<10>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r8, [reduce_row_min_double_param_0];
	ld.param.u32 	%r9, [reduce_row_min_double_param_1];
	ld.param.u64 	%rd3, [reduce_row_min_double_param_2];
	ld.param.u64 	%rd4, [reduce_row_min_double_param_3];
	ld.param.u32 	%r10, [reduce_row_min_double_param_4];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r11, %ctaid.x;
	mov.u32 	%r12, %tid.x;
	mad.lo.s32 	%r16, %r11, %r1, %r12;
	setp.ge.s32	%p1, %r16, %r8;
	@%p1 bra 	BB100_5;

	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r13, %nctaid.x;
	mul.lo.s32 	%r3, %r13, %r1;

BB100_2:
	mov.f64 	%fd8, 0d7FF0000000000000;
	mov.f64 	%fd9, %fd8;
	mov.u32 	%r17, 0;
	setp.lt.s32	%p2, %r9, 1;
	@%p2 bra 	BB100_4;

BB100_3:
	mad.lo.s32 	%r15, %r17, %r10, %r16;
	mul.wide.s32 	%rd5, %r15, 8;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f64 	%fd6, [%rd6];
	min.f64 	%fd9, %fd9, %fd6;
	add.s32 	%r17, %r17, 1;
	setp.lt.s32	%p3, %r17, %r9;
	mov.f64 	%fd8, %fd9;
	@%p3 bra 	BB100_3;

BB100_4:
	mul.wide.s32 	%rd7, %r16, 8;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f64 	[%rd8], %fd8;
	add.s32 	%r16, %r16, %r3;
	setp.lt.s32	%p4, %r16, %r8;
	@%p4 bra 	BB100_2;

BB100_5:
	ret;
}

.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
{
	.local .align 8 .b8 	__local_depot101[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<9>;
	.reg .b32 	%r<42>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<101>;


	mov.u64 	%rd100, __local_depot101;
	cvta.local.u64 	%SP, %rd100;
	ld.param.f64 	%fd4, [__internal_trig_reduction_slowpathd_param_0];
	ld.param.u64 	%rd37, [__internal_trig_reduction_slowpathd_param_1];
	add.u64 	%rd38, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd38;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd4;
	}
	and.b32  	%r40, %r1, -2147483648;
	shr.u32 	%r3, %r1, 20;
	bfe.u32 	%r4, %r1, 20, 11;
	setp.eq.s32	%p1, %r4, 2047;
	@%p1 bra 	BB101_13;

	add.s32 	%r16, %r4, -1024;
	shr.u32 	%r17, %r16, 6;
	mov.u32 	%r18, 16;
	sub.s32 	%r5, %r18, %r17;
	mov.u32 	%r19, 19;
	sub.s32 	%r20, %r19, %r17;
	mov.u32 	%r21, 18;
	min.s32 	%r6, %r21, %r20;
	setp.gt.s32	%p2, %r5, %r6;
	mov.u64 	%rd94, 0;
	mov.u64 	%rd93, %rd1;
	@%p2 bra 	BB101_4;

	mov.b64 	 %rd41, %fd4;
	shl.b64 	%rd42, %rd41, 11;
	or.b64  	%rd3, %rd42, -9223372036854775808;
	add.s32 	%r7, %r5, -1;
	mov.u64 	%rd92, %rd1;
	bfe.u32 	%r22, %r1, 20, 11;
	add.s32 	%r23, %r22, -1024;
	shr.u32 	%r24, %r23, 6;
	neg.s32 	%r25, %r24;
	mul.wide.s32 	%rd43, %r25, 8;
	mov.u64 	%rd44, __cudart_i2opi_d;
	add.s64 	%rd45, %rd43, %rd44;
	add.s64 	%rd90, %rd45, 120;
	mov.u64 	%rd94, 0;
	mov.u64 	%rd91, %rd1;
	mov.u32 	%r39, %r7;

BB101_3:
	.pragma "nounroll";
	mov.u32 	%r8, %r39;
	mov.u64 	%rd7, %rd91;
	ld.const.u64 	%rd48, [%rd90];
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, alo, ahi, blo, bhi, clo, chi;
	mov.b64         {alo,ahi}, %rd48;    
	mov.b64         {blo,bhi}, %rd3;    
	mov.b64         {clo,chi}, %rd94;    
	mad.lo.cc.u32   r0, alo, blo, clo;
	madc.hi.cc.u32  r1, alo, blo, chi;
	madc.hi.u32     r2, alo, bhi,   0;
	mad.lo.cc.u32   r1, alo, bhi,  r1;
	madc.hi.cc.u32  r2, ahi, blo,  r2;
	madc.hi.u32     r3, ahi, bhi,   0;
	mad.lo.cc.u32   r1, ahi, blo,  r1;
	madc.lo.cc.u32  r2, ahi, bhi,  r2;
	addc.u32        r3,  r3,   0;     
	mov.b64         %rd46, {r0,r1};      
	mov.b64         %rd94, {r2,r3};      
	}
	// inline asm
	st.local.u64 	[%rd92], %rd46;
	add.s32 	%r9, %r8, 1;
	sub.s32 	%r26, %r9, %r7;
	mul.wide.s32 	%rd51, %r26, 8;
	add.s64 	%rd92, %rd1, %rd51;
	add.s64 	%rd13, %rd7, 8;
	mov.u64 	%rd93, %rd13;
	add.s64 	%rd90, %rd90, 8;
	setp.lt.s32	%p3, %r9, %r6;
	mov.u64 	%rd91, %rd13;
	mov.u32 	%r39, %r9;
	@%p3 bra 	BB101_3;

BB101_4:
	st.local.u64 	[%rd93], %rd94;
	ld.local.u64 	%rd95, [%rd1+16];
	ld.local.u64 	%rd96, [%rd1+24];
	and.b32  	%r10, %r3, 63;
	setp.eq.s32	%p4, %r10, 0;
	@%p4 bra 	BB101_6;

	mov.u32 	%r27, 64;
	sub.s32 	%r28, %r27, %r10;
	shl.b64 	%rd52, %rd96, %r10;
	shr.u64 	%rd53, %rd95, %r28;
	or.b64  	%rd96, %rd52, %rd53;
	shl.b64 	%rd54, %rd95, %r10;
	ld.local.u64 	%rd55, [%rd1+8];
	shr.u64 	%rd56, %rd55, %r28;
	or.b64  	%rd95, %rd56, %rd54;

BB101_6:
	cvta.to.local.u64 	%rd57, %rd37;
	shr.u64 	%rd58, %rd96, 62;
	cvt.u32.u64	%r29, %rd58;
	shr.u64 	%rd59, %rd95, 62;
	shl.b64 	%rd60, %rd96, 2;
	or.b64  	%rd98, %rd60, %rd59;
	shl.b64 	%rd97, %rd95, 2;
	shr.u64 	%rd61, %rd96, 61;
	cvt.u32.u64	%r30, %rd61;
	and.b32  	%r31, %r30, 1;
	add.s32 	%r32, %r31, %r29;
	neg.s32 	%r33, %r32;
	setp.eq.s32	%p5, %r40, 0;
	selp.b32	%r34, %r32, %r33, %p5;
	st.local.u32 	[%rd57], %r34;
	setp.eq.s32	%p6, %r31, 0;
	@%p6 bra 	BB101_8;

	mov.u64 	%rd65, 0;
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, a0, a1, a2, a3, b0, b1, b2, b3;
	mov.b64         {a0,a1}, %rd65;
	mov.b64         {a2,a3}, %rd65;
	mov.b64         {b0,b1}, %rd97;
	mov.b64         {b2,b3}, %rd98;
	sub.cc.u32      r0, a0, b0; 
	subc.cc.u32     r1, a1, b1; 
	subc.cc.u32     r2, a2, b2; 
	subc.u32        r3, a3, b3; 
	mov.b64         %rd97, {r0,r1};
	mov.b64         %rd98, {r2,r3};
	}
	// inline asm
	xor.b32  	%r40, %r40, -2147483648;

BB101_8:
	clz.b64 	%r41, %rd98;
	setp.eq.s32	%p7, %r41, 0;
	@%p7 bra 	BB101_10;

	shl.b64 	%rd68, %rd98, %r41;
	mov.u32 	%r35, 64;
	sub.s32 	%r36, %r35, %r41;
	shr.u64 	%rd69, %rd97, %r36;
	or.b64  	%rd98, %rd69, %rd68;

BB101_10:
	mov.u64 	%rd73, -3958705157555305931;
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, alo, ahi, blo, bhi;
	mov.b64         {alo,ahi}, %rd98;   
	mov.b64         {blo,bhi}, %rd73;   
	mul.lo.u32      r0, alo, blo;    
	mul.hi.u32      r1, alo, blo;    
	mad.lo.cc.u32   r1, alo, bhi, r1;
	madc.hi.u32     r2, alo, bhi,  0;
	mad.lo.cc.u32   r1, ahi, blo, r1;
	madc.hi.cc.u32  r2, ahi, blo, r2;
	madc.hi.u32     r3, ahi, bhi,  0;
	mad.lo.cc.u32   r2, ahi, bhi, r2;
	addc.u32        r3, r3,  0;      
	mov.b64         %rd70, {r0,r1};     
	mov.b64         %rd99, {r2,r3};     
	}
	// inline asm
	setp.lt.s64	%p8, %rd99, 1;
	@%p8 bra 	BB101_12;

	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, a0, a1, a2, a3, b0, b1, b2, b3;
	mov.b64         {a0,a1}, %rd70;
	mov.b64         {a2,a3}, %rd99;
	mov.b64         {b0,b1}, %rd70;
	mov.b64         {b2,b3}, %rd99;
	add.cc.u32      r0, a0, b0; 
	addc.cc.u32     r1, a1, b1; 
	addc.cc.u32     r2, a2, b2; 
	addc.u32        r3, a3, b3; 
	mov.b64         %rd74, {r0,r1};
	mov.b64         %rd99, {r2,r3};
	}
	// inline asm
	add.s32 	%r41, %r41, 1;

BB101_12:
	cvt.u64.u32	%rd80, %r40;
	shl.b64 	%rd81, %rd80, 32;
	mov.u32 	%r37, 1022;
	sub.s32 	%r38, %r37, %r41;
	cvt.u64.u32	%rd82, %r38;
	shl.b64 	%rd83, %rd82, 52;
	add.s64 	%rd84, %rd99, 1;
	shr.u64 	%rd85, %rd84, 10;
	add.s64 	%rd86, %rd85, 1;
	shr.u64 	%rd87, %rd86, 1;
	add.s64 	%rd88, %rd87, %rd83;
	or.b64  	%rd89, %rd88, %rd81;
	mov.b64 	 %fd4, %rd89;

BB101_13:
	st.param.f64	[func_retval0+0], %fd4;
	ret;
}

.func  (.param .b64 func_retval0) __internal_accurate_pow(
	.param .b64 __internal_accurate_pow_param_0,
	.param .b64 __internal_accurate_pow_param_1
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<52>;
	.reg .f64 	%fd<134>;


	ld.param.f64 	%fd12, [__internal_accurate_pow_param_0];
	ld.param.f64 	%fd13, [__internal_accurate_pow_param_1];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r49}, %fd12;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd12;
	}
	shr.u32 	%r50, %r49, 20;
	setp.ne.s32	%p1, %r50, 0;
	@%p1 bra 	BB102_2;

	mul.f64 	%fd14, %fd12, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r49}, %fd14;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd14;
	}
	shr.u32 	%r16, %r49, 20;
	add.s32 	%r50, %r16, -54;

BB102_2:
	add.s32 	%r51, %r50, -1023;
	and.b32  	%r17, %r49, -2146435073;
	or.b32  	%r18, %r17, 1072693248;
	mov.b64 	%fd132, {%r48, %r18};
	setp.lt.u32	%p2, %r18, 1073127583;
	@%p2 bra 	BB102_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd132;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd132;
	}
	add.s32 	%r21, %r20, -1048576;
	mov.b64 	%fd132, {%r19, %r21};
	add.s32 	%r51, %r50, -1022;

BB102_4:
	add.f64 	%fd16, %fd132, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd15,%fd16;
	// inline asm
	neg.f64 	%fd17, %fd16;
	mov.f64 	%fd18, 0d3FF0000000000000;
	fma.rn.f64 	%fd19, %fd17, %fd15, %fd18;
	fma.rn.f64 	%fd20, %fd19, %fd19, %fd19;
	fma.rn.f64 	%fd21, %fd20, %fd15, %fd15;
	add.f64 	%fd22, %fd132, 0dBFF0000000000000;
	mul.f64 	%fd23, %fd22, %fd21;
	fma.rn.f64 	%fd24, %fd22, %fd21, %fd23;
	mul.f64 	%fd25, %fd24, %fd24;
	mov.f64 	%fd26, 0d3ED0F5D241AD3B5A;
	mov.f64 	%fd27, 0d3EB0F5FF7D2CAFE2;
	fma.rn.f64 	%fd28, %fd27, %fd25, %fd26;
	mov.f64 	%fd29, 0d3EF3B20A75488A3F;
	fma.rn.f64 	%fd30, %fd28, %fd25, %fd29;
	mov.f64 	%fd31, 0d3F1745CDE4FAECD5;
	fma.rn.f64 	%fd32, %fd30, %fd25, %fd31;
	mov.f64 	%fd33, 0d3F3C71C7258A578B;
	fma.rn.f64 	%fd34, %fd32, %fd25, %fd33;
	mov.f64 	%fd35, 0d3F6249249242B910;
	fma.rn.f64 	%fd36, %fd34, %fd25, %fd35;
	mov.f64 	%fd37, 0d3F89999999999DFB;
	fma.rn.f64 	%fd38, %fd36, %fd25, %fd37;
	sub.f64 	%fd39, %fd22, %fd24;
	add.f64 	%fd40, %fd39, %fd39;
	neg.f64 	%fd41, %fd24;
	fma.rn.f64 	%fd42, %fd41, %fd22, %fd40;
	mul.f64 	%fd43, %fd21, %fd42;
	fma.rn.f64 	%fd44, %fd25, %fd38, 0d3FB5555555555555;
	mov.f64 	%fd45, 0d3FB5555555555555;
	sub.f64 	%fd46, %fd45, %fd44;
	fma.rn.f64 	%fd47, %fd25, %fd38, %fd46;
	add.f64 	%fd48, %fd47, 0d0000000000000000;
	add.f64 	%fd49, %fd48, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd50, %fd44, %fd49;
	sub.f64 	%fd51, %fd44, %fd50;
	add.f64 	%fd52, %fd49, %fd51;
	mul.rn.f64 	%fd53, %fd24, %fd24;
	neg.f64 	%fd54, %fd53;
	fma.rn.f64 	%fd55, %fd24, %fd24, %fd54;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd43;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd43;
	}
	add.s32 	%r24, %r23, 1048576;
	mov.b64 	%fd56, {%r22, %r24};
	fma.rn.f64 	%fd57, %fd24, %fd56, %fd55;
	mul.rn.f64 	%fd58, %fd53, %fd24;
	neg.f64 	%fd59, %fd58;
	fma.rn.f64 	%fd60, %fd53, %fd24, %fd59;
	fma.rn.f64 	%fd61, %fd53, %fd43, %fd60;
	fma.rn.f64 	%fd62, %fd57, %fd24, %fd61;
	mul.rn.f64 	%fd63, %fd50, %fd58;
	neg.f64 	%fd64, %fd63;
	fma.rn.f64 	%fd65, %fd50, %fd58, %fd64;
	fma.rn.f64 	%fd66, %fd50, %fd62, %fd65;
	fma.rn.f64 	%fd67, %fd52, %fd58, %fd66;
	add.f64 	%fd68, %fd63, %fd67;
	sub.f64 	%fd69, %fd63, %fd68;
	add.f64 	%fd70, %fd67, %fd69;
	add.f64 	%fd71, %fd24, %fd68;
	sub.f64 	%fd72, %fd24, %fd71;
	add.f64 	%fd73, %fd68, %fd72;
	add.f64 	%fd74, %fd70, %fd73;
	add.f64 	%fd75, %fd43, %fd74;
	add.f64 	%fd76, %fd71, %fd75;
	sub.f64 	%fd77, %fd71, %fd76;
	add.f64 	%fd78, %fd75, %fd77;
	xor.b32  	%r25, %r51, -2147483648;
	mov.u32 	%r26, 1127219200;
	mov.b64 	%fd79, {%r25, %r26};
	mov.u32 	%r27, -2147483648;
	mov.b64 	%fd80, {%r27, %r26};
	sub.f64 	%fd81, %fd79, %fd80;
	mov.f64 	%fd82, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd83, %fd81, %fd82, %fd76;
	neg.f64 	%fd84, %fd81;
	fma.rn.f64 	%fd85, %fd84, %fd82, %fd83;
	sub.f64 	%fd86, %fd85, %fd76;
	sub.f64 	%fd87, %fd78, %fd86;
	mov.f64 	%fd88, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd89, %fd81, %fd88, %fd87;
	add.f64 	%fd90, %fd83, %fd89;
	sub.f64 	%fd91, %fd83, %fd90;
	add.f64 	%fd92, %fd89, %fd91;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd13;
	}
	add.s32 	%r29, %r28, %r28;
	setp.gt.u32	%p3, %r29, -33554433;
	and.b32  	%r30, %r28, -15728641;
	selp.b32	%r31, %r30, %r28, %p3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r32, %temp}, %fd13;
	}
	mov.b64 	%fd93, {%r32, %r31};
	mul.rn.f64 	%fd94, %fd90, %fd93;
	neg.f64 	%fd95, %fd94;
	fma.rn.f64 	%fd96, %fd90, %fd93, %fd95;
	fma.rn.f64 	%fd97, %fd92, %fd93, %fd96;
	add.f64 	%fd4, %fd94, %fd97;
	sub.f64 	%fd98, %fd94, %fd4;
	add.f64 	%fd5, %fd97, %fd98;
	mov.f64 	%fd99, 0d4338000000000000;
	mov.f64 	%fd100, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd101, %fd4, %fd100, %fd99;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r13, %temp}, %fd101;
	}
	mov.f64 	%fd102, 0dC338000000000000;
	add.rn.f64 	%fd103, %fd101, %fd102;
	mov.f64 	%fd104, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd105, %fd103, %fd104, %fd4;
	mov.f64 	%fd106, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd107, %fd103, %fd106, %fd105;
	mov.f64 	%fd108, 0d3E928AF3FCA213EA;
	mov.f64 	%fd109, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd110, %fd109, %fd107, %fd108;
	mov.f64 	%fd111, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd112, %fd110, %fd107, %fd111;
	mov.f64 	%fd113, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd114, %fd112, %fd107, %fd113;
	mov.f64 	%fd115, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd116, %fd114, %fd107, %fd115;
	mov.f64 	%fd117, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd118, %fd116, %fd107, %fd117;
	mov.f64 	%fd119, 0d3F81111111122322;
	fma.rn.f64 	%fd120, %fd118, %fd107, %fd119;
	mov.f64 	%fd121, 0d3FA55555555502A1;
	fma.rn.f64 	%fd122, %fd120, %fd107, %fd121;
	mov.f64 	%fd123, 0d3FC5555555555511;
	fma.rn.f64 	%fd124, %fd122, %fd107, %fd123;
	mov.f64 	%fd125, 0d3FE000000000000B;
	fma.rn.f64 	%fd126, %fd124, %fd107, %fd125;
	fma.rn.f64 	%fd127, %fd126, %fd107, %fd18;
	fma.rn.f64 	%fd128, %fd127, %fd107, %fd18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r14, %temp}, %fd128;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd128;
	}
	shl.b32 	%r33, %r13, 20;
	add.s32 	%r34, %r15, %r33;
	mov.b64 	%fd133, {%r14, %r34};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd4;
	}
	mov.b32 	 %f2, %r35;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p4, %f1, 0f4086232B;
	@%p4 bra 	BB102_7;

	setp.lt.f64	%p5, %fd4, 0d0000000000000000;
	add.f64 	%fd129, %fd4, 0d7FF0000000000000;
	selp.f64	%fd133, 0d0000000000000000, %fd129, %p5;
	setp.geu.f32	%p6, %f1, 0f40874800;
	@%p6 bra 	BB102_7;

	shr.u32 	%r36, %r13, 31;
	add.s32 	%r37, %r13, %r36;
	shr.s32 	%r38, %r37, 1;
	shl.b32 	%r39, %r38, 20;
	add.s32 	%r40, %r39, %r15;
	mov.b64 	%fd130, {%r14, %r40};
	sub.s32 	%r41, %r13, %r38;
	shl.b32 	%r42, %r41, 20;
	add.s32 	%r43, %r42, 1072693248;
	mov.u32 	%r44, 0;
	mov.b64 	%fd131, {%r44, %r43};
	mul.f64 	%fd133, %fd130, %fd131;

BB102_7:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r45}, %fd133;
	}
	and.b32  	%r46, %r45, 2147483647;
	setp.ne.s32	%p7, %r46, 2146435072;
	@%p7 bra 	BB102_9;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd133;
	}
	setp.eq.s32	%p8, %r47, 0;
	@%p8 bra 	BB102_10;

BB102_9:
	fma.rn.f64 	%fd133, %fd133, %fd5, %fd133;

BB102_10:
	st.param.f64	[func_retval0+0], %fd133;
	ret;
}

.func  (.param .b64 func_retval0) __internal_lgamma_pos(
	.param .b64 __internal_lgamma_pos_param_0
)
{
	.reg .pred 	%p<14>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<58>;
	.reg .f64 	%fd<296>;


	ld.param.f64 	%fd26, [__internal_lgamma_pos_param_0];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r54}, %fd26;
	}
	setp.gt.s32	%p1, %r54, 1074266111;
	@%p1 bra 	BB103_12;
	bra.uni 	BB103_1;

BB103_12:
	setp.gt.s32	%p8, %r54, 1075838975;
	@%p8 bra 	BB103_14;
	bra.uni 	BB103_13;

BB103_14:
	// inline asm
	rcp.approx.ftz.f64 %fd216,%fd26;
	// inline asm
	neg.f64 	%fd14, %fd26;
	mov.f64 	%fd218, 0d3FF0000000000000;
	fma.rn.f64 	%fd219, %fd14, %fd216, %fd218;
	fma.rn.f64 	%fd220, %fd219, %fd219, %fd219;
	fma.rn.f64 	%fd221, %fd220, %fd216, %fd216;
	mul.f64 	%fd222, %fd221, %fd221;
	mov.f64 	%fd223, 0d3F4B68B992738FBF;
	mov.f64 	%fd224, 0dBF5AC321034783F9;
	fma.rn.f64 	%fd225, %fd224, %fd222, %fd223;
	mov.f64 	%fd226, 0dBF4380D01E4F7B8C;
	fma.rn.f64 	%fd227, %fd225, %fd222, %fd226;
	mov.f64 	%fd228, 0d3F4A019FA29F7264;
	fma.rn.f64 	%fd229, %fd227, %fd222, %fd228;
	mov.f64 	%fd230, 0dBF66C16C16B2ACEC;
	fma.rn.f64 	%fd231, %fd229, %fd222, %fd230;
	mov.f64 	%fd232, 0d3FB5555555555545;
	fma.rn.f64 	%fd233, %fd231, %fd222, %fd232;
	mov.f64 	%fd234, 0d3FED67F1C864BEAE;
	fma.rn.f64 	%fd15, %fd233, %fd221, %fd234;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r55, %temp}, %fd26;
	}
	mov.u32 	%r56, -1023;
	setp.gt.s32	%p9, %r54, 1048575;
	mov.f64 	%fd292, %fd26;
	@%p9 bra 	BB103_16;

	mul.f64 	%fd16, %fd26, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r54}, %fd16;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r55, %temp}, %fd16;
	}
	mov.u32 	%r56, -1077;
	mov.f64 	%fd292, %fd16;

BB103_16:
	mov.f64 	%fd17, %fd292;
	add.s32 	%r36, %r54, -1;
	setp.lt.u32	%p10, %r36, 2146435071;
	@%p10 bra 	BB103_18;
	bra.uni 	BB103_17;

BB103_18:
	shr.u32 	%r38, %r54, 20;
	add.s32 	%r57, %r56, %r38;
	and.b32  	%r39, %r54, -2146435073;
	or.b32  	%r40, %r39, 1072693248;
	mov.b64 	%fd293, {%r55, %r40};
	setp.lt.s32	%p12, %r40, 1073127583;
	@%p12 bra 	BB103_20;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r41, %temp}, %fd293;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r42}, %fd293;
	}
	add.s32 	%r43, %r42, -1048576;
	mov.b64 	%fd293, {%r41, %r43};
	add.s32 	%r57, %r57, 1;

BB103_20:
	add.f64 	%fd238, %fd293, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd237,%fd238;
	// inline asm
	neg.f64 	%fd239, %fd238;
	fma.rn.f64 	%fd241, %fd239, %fd237, %fd218;
	fma.rn.f64 	%fd242, %fd241, %fd241, %fd241;
	fma.rn.f64 	%fd243, %fd242, %fd237, %fd237;
	add.f64 	%fd244, %fd293, 0dBFF0000000000000;
	mul.f64 	%fd245, %fd244, %fd243;
	fma.rn.f64 	%fd246, %fd244, %fd243, %fd245;
	mul.f64 	%fd247, %fd246, %fd246;
	mov.f64 	%fd248, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd249, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd250, %fd249, %fd247, %fd248;
	mov.f64 	%fd251, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd252, %fd250, %fd247, %fd251;
	mov.f64 	%fd253, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd254, %fd252, %fd247, %fd253;
	mov.f64 	%fd255, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd256, %fd254, %fd247, %fd255;
	mov.f64 	%fd257, 0d3F624924923BE72D;
	fma.rn.f64 	%fd258, %fd256, %fd247, %fd257;
	mov.f64 	%fd259, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd260, %fd258, %fd247, %fd259;
	mov.f64 	%fd261, 0d3FB5555555555554;
	fma.rn.f64 	%fd262, %fd260, %fd247, %fd261;
	sub.f64 	%fd263, %fd244, %fd246;
	add.f64 	%fd264, %fd263, %fd263;
	neg.f64 	%fd265, %fd246;
	fma.rn.f64 	%fd266, %fd265, %fd244, %fd264;
	mul.f64 	%fd267, %fd243, %fd266;
	mul.f64 	%fd268, %fd247, %fd262;
	fma.rn.f64 	%fd269, %fd268, %fd246, %fd267;
	xor.b32  	%r44, %r57, -2147483648;
	mov.u32 	%r45, 1127219200;
	mov.b64 	%fd270, {%r44, %r45};
	mov.u32 	%r46, -2147483648;
	mov.b64 	%fd271, {%r46, %r45};
	sub.f64 	%fd272, %fd270, %fd271;
	mov.f64 	%fd273, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd274, %fd272, %fd273, %fd246;
	neg.f64 	%fd275, %fd272;
	fma.rn.f64 	%fd276, %fd275, %fd273, %fd274;
	sub.f64 	%fd277, %fd276, %fd246;
	sub.f64 	%fd278, %fd269, %fd277;
	mov.f64 	%fd279, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd280, %fd272, %fd279, %fd278;
	add.f64 	%fd294, %fd274, %fd280;
	bra.uni 	BB103_21;

BB103_1:
	setp.gt.s32	%p2, %r54, 1073217535;
	@%p2 bra 	BB103_11;
	bra.uni 	BB103_2;

BB103_11:
	add.f64 	%fd146, %fd26, 0dC000000000000000;
	mov.f64 	%fd147, 0dBE71FA71D78C0EE2;
	mov.f64 	%fd148, 0d3E452636124338B3;
	fma.rn.f64 	%fd149, %fd148, %fd146, %fd147;
	mov.f64 	%fd150, 0d3E8D111F31E61306;
	fma.rn.f64 	%fd151, %fd149, %fd146, %fd150;
	mov.f64 	%fd152, 0dBEA0502BBE1B2706;
	fma.rn.f64 	%fd153, %fd151, %fd146, %fd152;
	mov.f64 	%fd154, 0d3EB06850B2970292;
	fma.rn.f64 	%fd155, %fd153, %fd146, %fd154;
	mov.f64 	%fd156, 0dBEC108474875033D;
	fma.rn.f64 	%fd157, %fd155, %fd146, %fd156;
	mov.f64 	%fd158, 0d3ED24ACCC62909DC;
	fma.rn.f64 	%fd159, %fd157, %fd146, %fd158;
	mov.f64 	%fd160, 0dBEE3CB25209E63BE;
	fma.rn.f64 	%fd161, %fd159, %fd146, %fd160;
	mov.f64 	%fd162, 0d3EF581CBBC8CDC7B;
	fma.rn.f64 	%fd163, %fd161, %fd146, %fd162;
	mov.f64 	%fd164, 0dBF078E04B85C7597;
	fma.rn.f64 	%fd165, %fd163, %fd146, %fd164;
	mov.f64 	%fd166, 0d3F1A12730CF45051;
	fma.rn.f64 	%fd167, %fd165, %fd146, %fd166;
	mov.f64 	%fd168, 0dBF2D3FD354062012;
	fma.rn.f64 	%fd169, %fd167, %fd146, %fd168;
	mov.f64 	%fd170, 0d3F40B36B0B4DE323;
	fma.rn.f64 	%fd171, %fd169, %fd146, %fd170;
	mov.f64 	%fd172, 0dBF538AC5C6D0317A;
	fma.rn.f64 	%fd173, %fd171, %fd146, %fd172;
	mov.f64 	%fd174, 0d3F67ADD6EAAB19FC;
	fma.rn.f64 	%fd175, %fd173, %fd146, %fd174;
	mov.f64 	%fd176, 0dBF7E404FC20E4D5B;
	fma.rn.f64 	%fd177, %fd175, %fd146, %fd176;
	mov.f64 	%fd178, 0d3F951322AC7DA390;
	fma.rn.f64 	%fd179, %fd177, %fd146, %fd178;
	mov.f64 	%fd180, 0dBFB13E001A5578A3;
	fma.rn.f64 	%fd181, %fd179, %fd146, %fd180;
	mov.f64 	%fd182, 0d3FD4A34CC4A60FA3;
	fma.rn.f64 	%fd183, %fd181, %fd146, %fd182;
	mov.f64 	%fd184, 0d3FDB0EE6072093CF;
	fma.rn.f64 	%fd185, %fd183, %fd146, %fd184;
	mul.f64 	%fd295, %fd146, %fd185;
	bra.uni 	BB103_22;

BB103_13:
	add.f64 	%fd186, %fd26, 0dC008000000000000;
	mov.f64 	%fd187, 0dC1122B7730207EF3;
	mov.f64 	%fd188, 0dC0AF7040BB18FB05;
	fma.rn.f64 	%fd189, %fd188, %fd186, %fd187;
	mov.f64 	%fd190, 0dC1585A0DB81DE7D0;
	fma.rn.f64 	%fd191, %fd189, %fd186, %fd190;
	mov.f64 	%fd192, 0dC18A992B8BA94677;
	fma.rn.f64 	%fd193, %fd191, %fd186, %fd192;
	mov.f64 	%fd194, 0dC1AAC5CB6957CC20;
	fma.rn.f64 	%fd195, %fd193, %fd186, %fd194;
	mov.f64 	%fd196, 0dC1BC0E2B308774BE;
	fma.rn.f64 	%fd197, %fd195, %fd186, %fd196;
	mov.f64 	%fd198, 0dC1C6BA13DCAE7F67;
	fma.rn.f64 	%fd199, %fd197, %fd186, %fd198;
	mov.f64 	%fd200, 0dC1CCF33B9C3D120C;
	fma.rn.f64 	%fd201, %fd199, %fd186, %fd200;
	add.f64 	%fd202, %fd186, 0dC08FF62E0BE189FE;
	mov.f64 	%fd203, 0dC10074FACE10C93F;
	fma.rn.f64 	%fd204, %fd202, %fd186, %fd203;
	mov.f64 	%fd205, 0dC151B662F8D75791;
	fma.rn.f64 	%fd206, %fd204, %fd186, %fd205;
	mov.f64 	%fd207, 0dC18EE64AB4D207F7;
	fma.rn.f64 	%fd208, %fd206, %fd186, %fd207;
	mov.f64 	%fd209, 0dC1B9051687C9951A;
	fma.rn.f64 	%fd210, %fd208, %fd186, %fd209;
	mov.f64 	%fd211, 0dC1D2B866BF0B853D;
	fma.rn.f64 	%fd212, %fd210, %fd186, %fd211;
	mov.f64 	%fd213, 0dC1D4E2130E9DC133;
	fma.rn.f64 	%fd214, %fd212, %fd186, %fd213;
	div.rn.f64 	%fd215, %fd201, %fd214;
	add.f64 	%fd295, %fd186, %fd215;
	bra.uni 	BB103_22;

BB103_2:
	setp.gt.s32	%p3, %r54, 1072064101;
	@%p3 bra 	BB103_10;
	bra.uni 	BB103_3;

BB103_10:
	mov.f64 	%fd101, 0d3FF0000000000000;
	sub.f64 	%fd102, %fd101, %fd26;
	mov.f64 	%fd103, 0d3FA3EB504359EB88;
	mov.f64 	%fd104, 0d3F881F6D2A4C4310;
	fma.rn.f64 	%fd105, %fd104, %fd102, %fd103;
	mov.f64 	%fd106, 0d3FAE35D8DEB06317;
	fma.rn.f64 	%fd107, %fd105, %fd102, %fd106;
	mov.f64 	%fd108, 0d3FAED469A8B6ECCE;
	fma.rn.f64 	%fd109, %fd107, %fd102, %fd108;
	mov.f64 	%fd110, 0d3FACC1B1C357BEFE;
	fma.rn.f64 	%fd111, %fd109, %fd102, %fd110;
	mov.f64 	%fd112, 0d3FAD7154DB67F79F;
	fma.rn.f64 	%fd113, %fd111, %fd102, %fd112;
	mov.f64 	%fd114, 0d3FAFCC622CF2F7BB;
	fma.rn.f64 	%fd115, %fd113, %fd102, %fd114;
	mov.f64 	%fd116, 0d3FB11747A4D1CC43;
	fma.rn.f64 	%fd117, %fd115, %fd102, %fd116;
	mov.f64 	%fd118, 0d3FB24CE16A21B8AC;
	fma.rn.f64 	%fd119, %fd117, %fd102, %fd118;
	mov.f64 	%fd120, 0d3FB3B1C21A7BCB00;
	fma.rn.f64 	%fd121, %fd119, %fd102, %fd120;
	mov.f64 	%fd122, 0d3FB556723452ED57;
	fma.rn.f64 	%fd123, %fd121, %fd102, %fd122;
	mov.f64 	%fd124, 0d3FB748C00891544F;
	fma.rn.f64 	%fd125, %fd123, %fd102, %fd124;
	mov.f64 	%fd126, 0d3FB9A0207808CF40;
	fma.rn.f64 	%fd127, %fd125, %fd102, %fd126;
	mov.f64 	%fd128, 0d3FBC80673B8AE26B;
	fma.rn.f64 	%fd129, %fd127, %fd102, %fd128;
	mov.f64 	%fd130, 0d3FC010B364B7E555;
	fma.rn.f64 	%fd131, %fd129, %fd102, %fd130;
	mov.f64 	%fd132, 0d3FC2703A1D239658;
	fma.rn.f64 	%fd133, %fd131, %fd102, %fd132;
	mov.f64 	%fd134, 0d3FC5B40CB1137E6E;
	fma.rn.f64 	%fd135, %fd133, %fd102, %fd134;
	mov.f64 	%fd136, 0d3FCA8B9C17AC4F03;
	fma.rn.f64 	%fd137, %fd135, %fd102, %fd136;
	mov.f64 	%fd138, 0d3FD151322AC7CB52;
	fma.rn.f64 	%fd139, %fd137, %fd102, %fd138;
	mov.f64 	%fd140, 0d3FD9A4D55BEAB1D4;
	fma.rn.f64 	%fd141, %fd139, %fd102, %fd140;
	mov.f64 	%fd142, 0d3FEA51A6625307D6;
	fma.rn.f64 	%fd143, %fd141, %fd102, %fd142;
	mov.f64 	%fd144, 0d3FE2788CFC6FB619;
	fma.rn.f64 	%fd145, %fd143, %fd102, %fd144;
	mul.f64 	%fd295, %fd102, %fd145;
	bra.uni 	BB103_22;

BB103_17:
	mov.f64 	%fd235, 0d7FF0000000000000;
	fma.rn.f64 	%fd236, %fd17, %fd235, %fd235;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r37}, %fd17;
	}
	mov.b32 	 %f2, %r37;
	setp.eq.f32	%p11, %f2, 0f00000000;
	selp.f64	%fd294, 0dFFF0000000000000, %fd236, %p11;

BB103_21:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd294;
	}
	add.s32 	%r48, %r47, -1048576;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd294;
	}
	mov.b64 	%fd281, {%r49, %r48};
	add.f64 	%fd282, %fd26, 0dBFE0000000000000;
	fma.rn.f64 	%fd283, %fd281, %fd282, %fd15;
	fma.rn.f64 	%fd284, %fd281, %fd282, %fd14;
	add.f64 	%fd285, %fd283, %fd284;
	setp.eq.f64	%p13, %fd26, 0d7FF0000000000000;
	selp.f64	%fd295, %fd26, %fd285, %p13;
	bra.uni 	BB103_22;

BB103_3:
	mov.f64 	%fd27, 0d3EA7B77CEB0625E8;
	mov.f64 	%fd28, 0dBE7844988BFE6590;
	fma.rn.f64 	%fd29, %fd28, %fd26, %fd27;
	mov.f64 	%fd30, 0dBE998C69C8710CC4;
	fma.rn.f64 	%fd31, %fd29, %fd26, %fd30;
	mov.f64 	%fd32, 0dBEF6527A5A11CF6E;
	fma.rn.f64 	%fd33, %fd31, %fd26, %fd32;
	mov.f64 	%fd34, 0d3F20EC2950B1B5DE;
	fma.rn.f64 	%fd35, %fd33, %fd26, %fd34;
	mov.f64 	%fd36, 0dBF2C4D80C24BA278;
	fma.rn.f64 	%fd37, %fd35, %fd26, %fd36;
	mov.f64 	%fd38, 0dBF5315B4E8CC0D09;
	fma.rn.f64 	%fd39, %fd37, %fd26, %fd38;
	mov.f64 	%fd40, 0d3F7D917F15D50020;
	fma.rn.f64 	%fd41, %fd39, %fd26, %fd40;
	mov.f64 	%fd42, 0dBF83B4ABB41CB6FA;
	fma.rn.f64 	%fd43, %fd41, %fd26, %fd42;
	mov.f64 	%fd44, 0dBFA59AF1275B7120;
	fma.rn.f64 	%fd45, %fd43, %fd26, %fd44;
	mov.f64 	%fd46, 0d3FC5512321A168A0;
	fma.rn.f64 	%fd47, %fd45, %fd26, %fd46;
	mov.f64 	%fd48, 0dBFA5815E8FDCE74C;
	fma.rn.f64 	%fd49, %fd47, %fd26, %fd48;
	mov.f64 	%fd50, 0dBFE4FCF4026ADD1A;
	fma.rn.f64 	%fd51, %fd49, %fd26, %fd50;
	mov.f64 	%fd52, 0d3FE2788CFC6FB5C8;
	fma.rn.f64 	%fd53, %fd51, %fd26, %fd52;
	mul.f64 	%fd54, %fd53, %fd26;
	fma.rn.f64 	%fd290, %fd54, %fd26, %fd26;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd290;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r51, %temp}, %fd290;
	}
	mov.u32 	%r52, -1023;
	setp.gt.s32	%p4, %r50, 1048575;
	@%p4 bra 	BB103_5;

	mul.f64 	%fd290, %fd290, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd290;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r51, %temp}, %fd290;
	}
	mov.u32 	%r52, -1077;

BB103_5:
	add.s32 	%r23, %r50, -1;
	setp.lt.u32	%p5, %r23, 2146435071;
	@%p5 bra 	BB103_7;
	bra.uni 	BB103_6;

BB103_7:
	shr.u32 	%r25, %r50, 20;
	add.s32 	%r53, %r52, %r25;
	and.b32  	%r26, %r50, -2146435073;
	or.b32  	%r27, %r26, 1072693248;
	mov.b64 	%fd291, {%r51, %r27};
	setp.lt.s32	%p7, %r27, 1073127583;
	@%p7 bra 	BB103_9;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r28, %temp}, %fd291;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd291;
	}
	add.s32 	%r30, %r29, -1048576;
	mov.b64 	%fd291, {%r28, %r30};
	add.s32 	%r53, %r53, 1;

BB103_9:
	add.f64 	%fd58, %fd291, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd57,%fd58;
	// inline asm
	neg.f64 	%fd59, %fd58;
	mov.f64 	%fd60, 0d3FF0000000000000;
	fma.rn.f64 	%fd61, %fd59, %fd57, %fd60;
	fma.rn.f64 	%fd62, %fd61, %fd61, %fd61;
	fma.rn.f64 	%fd63, %fd62, %fd57, %fd57;
	add.f64 	%fd64, %fd291, 0dBFF0000000000000;
	mul.f64 	%fd65, %fd64, %fd63;
	fma.rn.f64 	%fd66, %fd64, %fd63, %fd65;
	mul.f64 	%fd67, %fd66, %fd66;
	mov.f64 	%fd68, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd69, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd70, %fd69, %fd67, %fd68;
	mov.f64 	%fd71, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd72, %fd70, %fd67, %fd71;
	mov.f64 	%fd73, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd74, %fd72, %fd67, %fd73;
	mov.f64 	%fd75, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd76, %fd74, %fd67, %fd75;
	mov.f64 	%fd77, 0d3F624924923BE72D;
	fma.rn.f64 	%fd78, %fd76, %fd67, %fd77;
	mov.f64 	%fd79, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd80, %fd78, %fd67, %fd79;
	mov.f64 	%fd81, 0d3FB5555555555554;
	fma.rn.f64 	%fd82, %fd80, %fd67, %fd81;
	sub.f64 	%fd83, %fd64, %fd66;
	add.f64 	%fd84, %fd83, %fd83;
	neg.f64 	%fd85, %fd66;
	fma.rn.f64 	%fd86, %fd85, %fd64, %fd84;
	mul.f64 	%fd87, %fd63, %fd86;
	mul.f64 	%fd88, %fd67, %fd82;
	fma.rn.f64 	%fd89, %fd88, %fd66, %fd87;
	xor.b32  	%r31, %r53, -2147483648;
	mov.u32 	%r32, 1127219200;
	mov.b64 	%fd90, {%r31, %r32};
	mov.u32 	%r33, -2147483648;
	mov.b64 	%fd91, {%r33, %r32};
	sub.f64 	%fd92, %fd90, %fd91;
	mov.f64 	%fd93, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd94, %fd92, %fd93, %fd66;
	neg.f64 	%fd95, %fd92;
	fma.rn.f64 	%fd96, %fd95, %fd93, %fd94;
	sub.f64 	%fd97, %fd96, %fd66;
	sub.f64 	%fd98, %fd89, %fd97;
	mov.f64 	%fd99, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd100, %fd92, %fd99, %fd98;
	add.f64 	%fd8, %fd94, %fd100;
	neg.f64 	%fd295, %fd8;
	bra.uni 	BB103_22;

BB103_6:
	mov.f64 	%fd55, 0d7FF0000000000000;
	fma.rn.f64 	%fd56, %fd290, %fd55, %fd55;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r24}, %fd290;
	}
	mov.b32 	 %f1, %r24;
	setp.eq.f32	%p6, %f1, 0f00000000;
	selp.f64	%fd4, 0dFFF0000000000000, %fd56, %p6;
	neg.f64 	%fd295, %fd4;

BB103_22:
	st.param.f64	[func_retval0+0], %fd295;
	ret;
}


